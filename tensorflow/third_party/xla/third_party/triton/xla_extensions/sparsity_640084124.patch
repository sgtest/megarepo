# TODO(karupayun): Merge this patch with sparse_dot.patch

diff --git a/lib/Dialect/TritonGPU/Transforms/AccelerateMatmul.cpp b/lib/Dialect/TritonGPU/Transforms/AccelerateMatmul.cpp
--- a/lib/Dialect/TritonGPU/Transforms/AccelerateMatmul.cpp
+++ b/lib/Dialect/TritonGPU/Transforms/AccelerateMatmul.cpp
@@ -384,7 +398,7 @@ class SparseBlockedToMMA : public mlir::
 
     auto instrShape =
         mmaVersionToInstrShape(versionMajor, retShapePerCTA,
-                               cast<TensorOrMemDesc>(a.getType()), numWarps);
+                               cast<RankedTensorType>(a.getType()), numWarps);
     auto warpsPerTile = BlockedToMMA::getWarpsPerTile(
         dotOp, retShapePerCTA, versionMajor, numWarps, instrShape);
     NvidiaMmaEncodingAttr mmaEnc =
diff --git a/lib/Dialect/TritonGPU/Transforms/Pipeliner/MatmulLoopPipeline.cpp b/lib/Dialect/TritonGPU/Transforms/Pipeliner/MatmulLoopPipeline.cpp
--- a/lib/Dialect/TritonGPU/Transforms/Pipeliner/MatmulLoopPipeline.cpp
+++ b/lib/Dialect/TritonGPU/Transforms/Pipeliner/MatmulLoopPipeline.cpp
@@ -189,7 +189,7 @@ public:
 };
 
 static bool isDotLikeOp(Operation* op) {
-  return op.hasTrait<OpTrait::DotLike> || isa<ttg::SparseDotOp>(op);
+  return op->hasTrait<OpTrait::DotLike>() || isa<ttg::SparseDotOp>(op);
 }
 
 // Replace the ForOp's yield with a new one with the given operands appended.
diff --git a/lib/Dialect/TritonGPU/Transforms/ReduceDataDuplication.cpp b/lib/Dialect/TritonGPU/Transforms/ReduceDataDuplication.cpp
--- a/lib/Dialect/TritonGPU/Transforms/ReduceDataDuplication.cpp
+++ b/lib/Dialect/TritonGPU/Transforms/ReduceDataDuplication.cpp
@@ -100,8 +100,11 @@ public:
         triton::gpu::getCTALayout(srcEncoding));
 
     auto dstType = cast<RankedTensorType>(cvtOp.getType());
+    auto sharedMemorySpace =
+        triton::gpu::SharedMemorySpaceAttr::get(srcType.getContext());
     auto tmpType = triton::MemDescType::get(
-        dstType.getShape(), dstType.getElementType(), sharedLayout);
+        dstType.getShape(), dstType.getElementType(), sharedLayout,
+        sharedMemorySpace);
 
     OpBuilder builder(cvtOp);
     auto tmp = builder.create<triton::gpu::LocalAllocOp>(
