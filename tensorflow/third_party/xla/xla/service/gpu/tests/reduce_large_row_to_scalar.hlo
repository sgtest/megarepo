// RUN: hlo-opt %s --platform=gpu --stage=llvm-before-optimizations --xla_gpu_target_config_filename=%S/../../../tools/hlo_opt/gpu_specs/%{GPU}.txtpb --split-input-file | FileCheck %s --check-prefixes=CHECK,CHECK-%{PTX}

HloModule LargeReduction, is_scheduled=true

Sum {
    x.1 = c128[] parameter(0)
    y.1 = c128[] parameter(1)
    ROOT add.1 = c128[] add(x.1, y.1)
}

fused_computation {
  param_0 = c128[10000]{0} parameter(0)
  param_1 = c128[] parameter(1)
  ROOT out1.1 = c128[] reduce(c128[10000]{0} param_0, c128[] param_1), dimensions={0}, to_apply=Sum
}

ENTRY reduce.1 {
    parameter = c128[10000] parameter(0)
    init_value = c128[] constant((0, 0))
    ROOT wrapped_out1 = c128[] fusion(c128[10000]{0} parameter, c128[] init_value), kind=kInput, calls=fused_computation
}

// CHECK-LABEL: entry:
// CHECK:         %[[VAL_0:.*]] = alloca %[[VAL_1:.*]], align 8
// CHECK:         %[[VAL_2:.*]] = alloca %[[VAL_1]], align 8
// CHECK:         %[[VAL_3:.*]] = alloca %[[VAL_1]], align 8
// CHECK:         %[[VAL_4:.*]] = alloca %[[VAL_1]], align 8
// CHECK:         %[[VAL_5:.*]] = alloca %[[VAL_1]], align 8
// CHECK:         %[[VAL_6:.*]] = alloca %[[VAL_1]], align 8
// CHECK:         %[[VAL_7:.*]] = alloca %[[VAL_1]], align 8
// CHECK:         %[[VAL_8:.*]] = alloca %[[VAL_1]], align 8
// CHECK:         %[[VAL_9:.*]] = alloca %[[VAL_1]], align 8
// CHECK:         %[[VAL_10:.*]] = alloca %[[VAL_1]], align 8
// CHECK:         %[[VAL_11:.*]] = alloca %[[VAL_1]], align 8
// CHECK:         %[[VAL_12:.*]] = alloca %[[VAL_1]], align 8
// CHECK:         %[[VAL_13:.*]] = alloca %[[VAL_1]], align 8
// CHECK:         %[[VAL_14:.*]] = alloca %[[VAL_1]], align 8
// CHECK:         %[[VAL_15:.*]] = alloca %[[VAL_1]], align 8
// CHECK:         %[[VAL_16:.*]] = alloca %[[VAL_1]], align 8
// CHECK:         %[[VAL_17:.*]] = alloca %[[VAL_1]], align 8
// CHECK:         %[[VAL_18:.*]] = alloca %[[VAL_1]], align 8
// CHECK:         %[[VAL_19:.*]] = alloca %[[VAL_1]], align 8
// CHECK:         %[[VAL_20:.*]] = alloca %[[VAL_1]], align 8
// CHECK:         %[[VAL_21:.*]] = alloca %[[VAL_1]], align 8
// CHECK:         %[[VAL_22:.*]] = alloca %[[VAL_1]], align 8
// CHECK:         %[[VAL_23:.*]] = alloca %[[VAL_1]], align 8
// CHECK:         %[[VAL_24:.*]] = alloca i32, align 4
// CHECK:         %[[VAL_25:.*]] = alloca %[[VAL_1]], align 8
// CHECK:         %[[VAL_26:.*]] = alloca %[[VAL_1]], align 8
// CHECK:         %[[VAL_27:.*]] = alloca i32, align 4
// CHECK:         %[[VAL_28:.*]] = alloca i32, align 4
// CHECK:         %[[VAL_29:.*]] = alloca %[[VAL_1]], align 8
// CHECK:         %[[VAL_30:.*]] = alloca %[[VAL_1]], align 8
// CHECK-PTX:     %[[VAL_31:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.y(), !range !2
// CHECK-GCN:     %[[VAL_31:.*]] = call i32 @llvm.amdgcn.workgroup.id.y
// CHECK:         %[[VAL_32:.*]] = icmp eq i32 %[[VAL_31]], 0
// CHECK:         br i1 %[[VAL_32]], label %[[VAL_33:.*]], label %[[VAL_34:.*]]
// CHECK:       reduce-group-0-after:                             ; preds = %[[VAL_35:.*]], %[[VAL_36:.*]]
// CHECK:         ret void
// CHECK:       reduce-group-0-true:                              ; preds = %[[VAL_36]]
// CHECK:         %[[VAL_37:.*]] = load %[[VAL_1]], ptr %[[VAL_38:.*]], align 1, !invariant.load !3
// CHECK:         store %[[VAL_1]] %[[VAL_37]], ptr %[[VAL_29]], align 1
// CHECK-PTX:     %[[VAL_39:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.tid.x(), !range !4
// CHECK-GCN:     %[[VAL_39:.*]] = call i32 @llvm.amdgcn.workitem.id.x
// CHECK-PTX:     %[[VAL_40:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !2
// CHECK-GCN:     %[[VAL_40:.*]] = call i32 @llvm.amdgcn.workgroup.id.x
// CHECK:         %[[VAL_41:.*]] = udiv i32 %[[VAL_39]], 640
// CHECK:         %[[VAL_42:.*]] = urem i32 %[[VAL_39]], 640
// CHECK:         %[[VAL_43:.*]] = udiv i32 %[[VAL_42]], 640
// CHECK:         %[[VAL_44:.*]] = urem i32 %[[VAL_39]], 640
// CHECK:         %[[VAL_45:.*]] = mul i32 %[[VAL_44]], 2
// CHECK:         %[[VAL_46:.*]] = urem i32 %[[VAL_39]], 32
// CHECK:         %[[VAL_47:.*]] = udiv i32 %[[VAL_40]], 1
// CHECK:         %[[VAL_48:.*]] = urem i32 %[[VAL_47]], 1
// CHECK:         %[[VAL_49:.*]] = udiv i32 %[[VAL_40]], 1
// CHECK:         %[[VAL_50:.*]] = urem i32 %[[VAL_49]], 1
// CHECK:         %[[VAL_51:.*]] = udiv i32 %[[VAL_40]], 1
// CHECK:         %[[VAL_52:.*]] = icmp eq i32 %[[VAL_48]], 0
// CHECK:         %[[VAL_53:.*]] = select i1 %[[VAL_52]], i32 10000, i32 10240
// CHECK:         %[[VAL_54:.*]] = mul i32 %[[VAL_51]], 1
// CHECK:         %[[VAL_55:.*]] = mul i32 %[[VAL_50]], 1
// CHECK:         %[[VAL_56:.*]] = mul i32 %[[VAL_48]], 10240
// CHECK:         store i32 %[[VAL_43]], ptr %[[VAL_28]], align 4
// CHECK:         br label %[[VAL_57:.*]]
// CHECK:       loop1.loop_header:                                ; preds = %[[VAL_58:.*]], %[[VAL_33]]
// CHECK:         %[[VAL_59:.*]] = load i32, ptr %[[VAL_28]], align 4
// CHECK:         %[[VAL_60:.*]] = icmp uge i32 %[[VAL_59]], 1
// CHECK:         br i1 %[[VAL_60]], label %[[VAL_61:.*]], label %[[VAL_62:.*]]
// CHECK:       loop1.loop_body:                                  ; preds = %[[VAL_57]]
// CHECK:         %[[VAL_63:.*]] = add nuw nsw i32 %[[VAL_59]], 1
// CHECK:         store i32 %[[VAL_63]], ptr %[[VAL_28]], align 4
// CHECK:         %[[VAL_64:.*]] = icmp eq i32 %[[VAL_59]], %[[VAL_43]]
// CHECK:         %[[VAL_65:.*]] = icmp eq i32 10240, %[[VAL_53]]
// CHECK:         br i1 %[[VAL_65]], label %[[VAL_66:.*]], label %[[VAL_67:.*]]
// CHECK:       is_full_tile-after:                               ; preds = %[[VAL_68:.*]], %[[VAL_69:.*]]
// CHECK:         br label %[[VAL_57]], !llvm.loop !5
// CHECK:       loop1.loop_exit:                                  ; preds = %[[VAL_57]]
// CHECK:         %[[VAL_70:.*]] = load i128, ptr %[[VAL_29]], align 16
// CHECK:         %[[VAL_71:.*]] = bitcast i128 %[[VAL_70]] to <4 x i32>
// CHECK:         %[[VAL_72:.*]] = extractelement <4 x i32> %[[VAL_71]], i64 0
// CHECK:         %[[VAL_73:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_72]], i32 16, i32 31)
// CHECK:         %[[VAL_74:.*]] = insertelement <4 x i32> %[[VAL_71]], i32 %[[VAL_73]], i64 0
// CHECK:         %[[VAL_75:.*]] = extractelement <4 x i32> %[[VAL_74]], i64 1
// CHECK:         %[[VAL_76:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_75]], i32 16, i32 31)
// CHECK:         %[[VAL_77:.*]] = insertelement <4 x i32> %[[VAL_74]], i32 %[[VAL_76]], i64 1
// CHECK:         %[[VAL_78:.*]] = extractelement <4 x i32> %[[VAL_77]], i64 2
// CHECK:         %[[VAL_79:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_78]], i32 16, i32 31)
// CHECK:         %[[VAL_80:.*]] = insertelement <4 x i32> %[[VAL_77]], i32 %[[VAL_79]], i64 2
// CHECK:         %[[VAL_81:.*]] = extractelement <4 x i32> %[[VAL_80]], i64 3
// CHECK:         %[[VAL_82:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_81]], i32 16, i32 31)
// CHECK:         %[[VAL_83:.*]] = insertelement <4 x i32> %[[VAL_80]], i32 %[[VAL_82]], i64 3
// CHECK:         %[[VAL_84:.*]] = bitcast <4 x i32> %[[VAL_83]] to i128
// CHECK:         store i128 %[[VAL_84]], ptr %[[VAL_21]], align 16
// CHECK:         call void @[[SUM:Sum.*]](ptr %[[VAL_29]], ptr %[[VAL_21]], ptr %[[VAL_20]])
// CHECK:         %[[VAL_85:.*]] = load %[[VAL_1]], ptr %[[VAL_20]], align 1
// CHECK:         store %[[VAL_1]] %[[VAL_85]], ptr %[[VAL_29]], align 1
// CHECK:         %[[VAL_86:.*]] = load i128, ptr %[[VAL_29]], align 16
// CHECK:         %[[VAL_87:.*]] = bitcast i128 %[[VAL_86]] to <4 x i32>
// CHECK:         %[[VAL_88:.*]] = extractelement <4 x i32> %[[VAL_87]], i64 0
// CHECK:         %[[VAL_89:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_88]], i32 8, i32 31)
// CHECK:         %[[VAL_90:.*]] = insertelement <4 x i32> %[[VAL_87]], i32 %[[VAL_89]], i64 0
// CHECK:         %[[VAL_91:.*]] = extractelement <4 x i32> %[[VAL_90]], i64 1
// CHECK:         %[[VAL_92:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_91]], i32 8, i32 31)
// CHECK:         %[[VAL_93:.*]] = insertelement <4 x i32> %[[VAL_90]], i32 %[[VAL_92]], i64 1
// CHECK:         %[[VAL_94:.*]] = extractelement <4 x i32> %[[VAL_93]], i64 2
// CHECK:         %[[VAL_95:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_94]], i32 8, i32 31)
// CHECK:         %[[VAL_96:.*]] = insertelement <4 x i32> %[[VAL_93]], i32 %[[VAL_95]], i64 2
// CHECK:         %[[VAL_97:.*]] = extractelement <4 x i32> %[[VAL_96]], i64 3
// CHECK:         %[[VAL_98:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_97]], i32 8, i32 31)
// CHECK:         %[[VAL_99:.*]] = insertelement <4 x i32> %[[VAL_96]], i32 %[[VAL_98]], i64 3
// CHECK:         %[[VAL_100:.*]] = bitcast <4 x i32> %[[VAL_99]] to i128
// CHECK:         store i128 %[[VAL_100]], ptr %[[VAL_19]], align 16
// CHECK:         call void @[[SUM]](ptr %[[VAL_29]], ptr %[[VAL_19]], ptr %[[VAL_18]])
// CHECK:         %[[VAL_101:.*]] = load %[[VAL_1]], ptr %[[VAL_18]], align 1
// CHECK:         store %[[VAL_1]] %[[VAL_101]], ptr %[[VAL_29]], align 1
// CHECK:         %[[VAL_102:.*]] = load i128, ptr %[[VAL_29]], align 16
// CHECK:         %[[VAL_103:.*]] = bitcast i128 %[[VAL_102]] to <4 x i32>
// CHECK:         %[[VAL_104:.*]] = extractelement <4 x i32> %[[VAL_103]], i64 0
// CHECK:         %[[VAL_105:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_104]], i32 4, i32 31)
// CHECK:         %[[VAL_106:.*]] = insertelement <4 x i32> %[[VAL_103]], i32 %[[VAL_105]], i64 0
// CHECK:         %[[VAL_107:.*]] = extractelement <4 x i32> %[[VAL_106]], i64 1
// CHECK:         %[[VAL_108:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_107]], i32 4, i32 31)
// CHECK:         %[[VAL_109:.*]] = insertelement <4 x i32> %[[VAL_106]], i32 %[[VAL_108]], i64 1
// CHECK:         %[[VAL_110:.*]] = extractelement <4 x i32> %[[VAL_109]], i64 2
// CHECK:         %[[VAL_111:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_110]], i32 4, i32 31)
// CHECK:         %[[VAL_112:.*]] = insertelement <4 x i32> %[[VAL_109]], i32 %[[VAL_111]], i64 2
// CHECK:         %[[VAL_113:.*]] = extractelement <4 x i32> %[[VAL_112]], i64 3
// CHECK:         %[[VAL_114:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_113]], i32 4, i32 31)
// CHECK:         %[[VAL_115:.*]] = insertelement <4 x i32> %[[VAL_112]], i32 %[[VAL_114]], i64 3
// CHECK:         %[[VAL_116:.*]] = bitcast <4 x i32> %[[VAL_115]] to i128
// CHECK:         store i128 %[[VAL_116]], ptr %[[VAL_17]], align 16
// CHECK:         call void @[[SUM]](ptr %[[VAL_29]], ptr %[[VAL_17]], ptr %[[VAL_16]])
// CHECK:         %[[VAL_117:.*]] = load %[[VAL_1]], ptr %[[VAL_16]], align 1
// CHECK:         store %[[VAL_1]] %[[VAL_117]], ptr %[[VAL_29]], align 1
// CHECK:         %[[VAL_118:.*]] = load i128, ptr %[[VAL_29]], align 16
// CHECK:         %[[VAL_119:.*]] = bitcast i128 %[[VAL_118]] to <4 x i32>
// CHECK:         %[[VAL_120:.*]] = extractelement <4 x i32> %[[VAL_119]], i64 0
// CHECK:         %[[VAL_121:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_120]], i32 2, i32 31)
// CHECK:         %[[VAL_122:.*]] = insertelement <4 x i32> %[[VAL_119]], i32 %[[VAL_121]], i64 0
// CHECK:         %[[VAL_123:.*]] = extractelement <4 x i32> %[[VAL_122]], i64 1
// CHECK:         %[[VAL_124:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_123]], i32 2, i32 31)
// CHECK:         %[[VAL_125:.*]] = insertelement <4 x i32> %[[VAL_122]], i32 %[[VAL_124]], i64 1
// CHECK:         %[[VAL_126:.*]] = extractelement <4 x i32> %[[VAL_125]], i64 2
// CHECK:         %[[VAL_127:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_126]], i32 2, i32 31)
// CHECK:         %[[VAL_128:.*]] = insertelement <4 x i32> %[[VAL_125]], i32 %[[VAL_127]], i64 2
// CHECK:         %[[VAL_129:.*]] = extractelement <4 x i32> %[[VAL_128]], i64 3
// CHECK:         %[[VAL_130:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_129]], i32 2, i32 31)
// CHECK:         %[[VAL_131:.*]] = insertelement <4 x i32> %[[VAL_128]], i32 %[[VAL_130]], i64 3
// CHECK:         %[[VAL_132:.*]] = bitcast <4 x i32> %[[VAL_131]] to i128
// CHECK:         store i128 %[[VAL_132]], ptr %[[VAL_15]], align 16
// CHECK:         call void @[[SUM]](ptr %[[VAL_29]], ptr %[[VAL_15]], ptr %[[VAL_14]])
// CHECK:         %[[VAL_133:.*]] = load %[[VAL_1]], ptr %[[VAL_14]], align 1
// CHECK:         store %[[VAL_1]] %[[VAL_133]], ptr %[[VAL_29]], align 1
// CHECK:         %[[VAL_134:.*]] = load i128, ptr %[[VAL_29]], align 16
// CHECK:         %[[VAL_135:.*]] = bitcast i128 %[[VAL_134]] to <4 x i32>
// CHECK:         %[[VAL_136:.*]] = extractelement <4 x i32> %[[VAL_135]], i64 0
// CHECK:         %[[VAL_137:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_136]], i32 1, i32 31)
// CHECK:         %[[VAL_138:.*]] = insertelement <4 x i32> %[[VAL_135]], i32 %[[VAL_137]], i64 0
// CHECK:         %[[VAL_139:.*]] = extractelement <4 x i32> %[[VAL_138]], i64 1
// CHECK:         %[[VAL_140:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_139]], i32 1, i32 31)
// CHECK:         %[[VAL_141:.*]] = insertelement <4 x i32> %[[VAL_138]], i32 %[[VAL_140]], i64 1
// CHECK:         %[[VAL_142:.*]] = extractelement <4 x i32> %[[VAL_141]], i64 2
// CHECK:         %[[VAL_143:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_142]], i32 1, i32 31)
// CHECK:         %[[VAL_144:.*]] = insertelement <4 x i32> %[[VAL_141]], i32 %[[VAL_143]], i64 2
// CHECK:         %[[VAL_145:.*]] = extractelement <4 x i32> %[[VAL_144]], i64 3
// CHECK:         %[[VAL_146:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_145]], i32 1, i32 31)
// CHECK:         %[[VAL_147:.*]] = insertelement <4 x i32> %[[VAL_144]], i32 %[[VAL_146]], i64 3
// CHECK:         %[[VAL_148:.*]] = bitcast <4 x i32> %[[VAL_147]] to i128
// CHECK:         store i128 %[[VAL_148]], ptr %[[VAL_13]], align 16
// CHECK:         call void @[[SUM]](ptr %[[VAL_29]], ptr %[[VAL_13]], ptr %[[VAL_12]])
// CHECK:         %[[VAL_149:.*]] = load %[[VAL_1]], ptr %[[VAL_12]], align 1
// CHECK:         store %[[VAL_1]] %[[VAL_149]], ptr %[[VAL_29]], align 1
// CHECK:         %[[VAL_150:.*]] = udiv i32 %[[VAL_44]], 32
// CHECK:         %[[VAL_152:.*]] = icmp ult i32 %[[VAL_43]], 1
// CHECK:         br i1 %[[VAL_152]], label %[[VAL_154:.*]], label %[[VAL_35]]
// CHECK:       thread_in_bounds-after:                           ; preds = %[[VAL_155:.*]], %[[VAL_61]]
// CHECK:         br label %[[VAL_34]]
// CHECK:       is_full_tile-true:                                ; preds = %[[VAL_62]]
// CHECK:         store i32 0, ptr %[[VAL_27]], align 4
// CHECK:         br label %[[VAL_156:.*]]
// CHECK:       loop2.loop_header:                                ; preds = %[[VAL_157:.*]], %[[VAL_66]]
// CHECK:         %[[VAL_158:.*]] = load i32, ptr %[[VAL_27]], align 4
// CHECK:         %[[VAL_159:.*]] = icmp uge i32 %[[VAL_158]], 8
// CHECK:         br i1 %[[VAL_159]], label %[[VAL_69]], label %[[VAL_157]]
// CHECK:       loop2.loop_body:                                  ; preds = %[[VAL_156]]
// CHECK:         %[[VAL_160:.*]] = add nuw nsw i32 %[[VAL_158]], 1
// CHECK:         store i32 %[[VAL_160]], ptr %[[VAL_27]], align 4
// CHECK:         %[[VAL_161:.*]] = icmp eq i32 %[[VAL_158]], 0
// CHECK:         %[[VAL_162:.*]] = mul i32 %[[VAL_158]], 1280
// CHECK:         %[[VAL_163:.*]] = add i32 %[[VAL_162]], 0
// CHECK:         %[[VAL_164:.*]] = add i32 %[[VAL_163]], %[[VAL_45]]
// CHECK:         %[[VAL_165:.*]] = add i32 %[[VAL_54]], 0
// CHECK:         %[[VAL_166:.*]] = add i32 %[[VAL_55]], %[[VAL_59]]
// CHECK:         %[[VAL_167:.*]] = add i32 %[[VAL_56]], %[[VAL_164]]
// CHECK:         %[[VAL_168:.*]] = getelementptr inbounds [10000 x %[[VAL_1]]], ptr %[[VAL_169:.*]], i32 0, i32 %[[VAL_167]]
// CHECK:         %[[VAL_170:.*]] = load %[[VAL_1]], ptr %[[VAL_168]], align 1, !invariant.load !3
// CHECK:         store %[[VAL_1]] %[[VAL_170]], ptr %[[VAL_30]], align 1
// CHECK:         call void @[[SUM]](ptr %[[VAL_29]], ptr %[[VAL_30]], ptr %[[VAL_26]])
// CHECK:         %[[VAL_172:.*]] = load %[[VAL_1]], ptr %[[VAL_26]], align 1
// CHECK:         store %[[VAL_1]] %[[VAL_172]], ptr %[[VAL_29]], align 1
// CHECK:         %[[VAL_173:.*]] = mul i32 %[[VAL_158]], 1280
// CHECK:         %[[VAL_174:.*]] = add i32 %[[VAL_173]], 1
// CHECK:         %[[VAL_175:.*]] = add i32 %[[VAL_174]], %[[VAL_45]]
// CHECK:         %[[VAL_176:.*]] = add i32 %[[VAL_54]], 0
// CHECK:         %[[VAL_177:.*]] = add i32 %[[VAL_55]], %[[VAL_59]]
// CHECK:         %[[VAL_178:.*]] = add i32 %[[VAL_56]], %[[VAL_175]]
// CHECK:         %[[VAL_179:.*]] = getelementptr inbounds [10000 x %[[VAL_1]]], ptr %[[VAL_169]], i32 0, i32 %[[VAL_178]]
// CHECK:         %[[VAL_180:.*]] = load %[[VAL_1]], ptr %[[VAL_179]], align 1, !invariant.load !3
// CHECK:         store %[[VAL_1]] %[[VAL_180]], ptr %[[VAL_30]], align 1
// CHECK:         call void @[[SUM]](ptr %[[VAL_29]], ptr %[[VAL_30]], ptr %[[VAL_25]])
// CHECK:         %[[VAL_182:.*]] = load %[[VAL_1]], ptr %[[VAL_25]], align 1
// CHECK:         store %[[VAL_1]] %[[VAL_182]], ptr %[[VAL_29]], align 1
// CHECK:         br label %[[VAL_156]], !llvm.loop !7
// CHECK:       loop2.loop_exit:                                  ; preds = %[[VAL_156]]
// CHECK:         br label %[[VAL_58]]
// CHECK:       is_full_tile-false:                               ; preds = %[[VAL_62]]
// CHECK:         store i32 0, ptr %[[VAL_24]], align 4
// CHECK:         br label %[[VAL_183:.*]]
// CHECK:       loop2.loop_header7:                               ; preds = %[[VAL_184:.*]], %[[VAL_67]]
// CHECK:         %[[VAL_185:.*]] = load i32, ptr %[[VAL_24]], align 4
// CHECK:         %[[VAL_186:.*]] = icmp uge i32 %[[VAL_185]], 8
// CHECK:         br i1 %[[VAL_186]], label %[[VAL_68]], label %[[VAL_187:.*]]
// CHECK:       loop2.loop_body8:                                 ; preds = %[[VAL_183]]
// CHECK:         %[[VAL_188:.*]] = add nuw nsw i32 %[[VAL_185]], 1
// CHECK:         store i32 %[[VAL_188]], ptr %[[VAL_24]], align 4
// CHECK:         %[[VAL_189:.*]] = icmp eq i32 %[[VAL_185]], 0
// CHECK:         %[[VAL_190:.*]] = mul i32 %[[VAL_185]], 1280
// CHECK:         %[[VAL_191:.*]] = add i32 %[[VAL_190]], 0
// CHECK:         %[[VAL_192:.*]] = add i32 %[[VAL_191]], %[[VAL_45]]
// CHECK:         %[[VAL_193:.*]] = icmp ult i32 %[[VAL_192]], %[[VAL_53]]
// CHECK:         br i1 %[[VAL_193]], label %[[VAL_194:.*]], label %[[VAL_195:.*]]
// CHECK:       x_in_tile-after:                                  ; preds = %[[VAL_194]], %[[VAL_187]]
// CHECK:         %[[VAL_196:.*]] = mul i32 %[[VAL_185]], 1280
// CHECK:         %[[VAL_197:.*]] = add i32 %[[VAL_196]], 1
// CHECK:         %[[VAL_198:.*]] = add i32 %[[VAL_197]], %[[VAL_45]]
// CHECK:         %[[VAL_199:.*]] = icmp ult i32 %[[VAL_198]], %[[VAL_53]]
// CHECK:         br i1 %[[VAL_199]], label %[[VAL_200:.*]], label %[[VAL_184]]
// CHECK:       x_in_tile-after16:                                ; preds = %[[VAL_200]], %[[VAL_195]]
// CHECK:         br label %[[VAL_183]], !llvm.loop !9
// CHECK:       loop2.loop_exit6:                                 ; preds = %[[VAL_183]]
// CHECK:         br label %[[VAL_58]]
// CHECK:       x_in_tile-true:                                   ; preds = %[[VAL_187]]
// CHECK:         %[[VAL_201:.*]] = add i32 %[[VAL_54]], 0
// CHECK:         %[[VAL_202:.*]] = add i32 %[[VAL_55]], %[[VAL_59]]
// CHECK:         %[[VAL_203:.*]] = add i32 %[[VAL_56]], %[[VAL_192]]
// CHECK:         %[[VAL_204:.*]] = getelementptr inbounds [10000 x %[[VAL_1]]], ptr %[[VAL_169]], i32 0, i32 %[[VAL_203]]
// CHECK:         %[[VAL_205:.*]] = load %[[VAL_1]], ptr %[[VAL_204]], align 1, !invariant.load !3
// CHECK:         store %[[VAL_1]] %[[VAL_205]], ptr %[[VAL_30]], align 1
// CHECK:         call void @[[SUM]](ptr %[[VAL_29]], ptr %[[VAL_30]], ptr %[[VAL_23]])
// CHECK:         %[[VAL_207:.*]] = load %[[VAL_1]], ptr %[[VAL_23]], align 1
// CHECK:         store %[[VAL_1]] %[[VAL_207]], ptr %[[VAL_29]], align 1
// CHECK:         br label %[[VAL_195]]
// CHECK:       x_in_tile-true15:                                 ; preds = %[[VAL_195]]
// CHECK:         %[[VAL_208:.*]] = add i32 %[[VAL_54]], 0
// CHECK:         %[[VAL_209:.*]] = add i32 %[[VAL_55]], %[[VAL_59]]
// CHECK:         %[[VAL_210:.*]] = add i32 %[[VAL_56]], %[[VAL_198]]
// CHECK:         %[[VAL_211:.*]] = getelementptr inbounds [10000 x %[[VAL_1]]], ptr %[[VAL_169]], i32 0, i32 %[[VAL_210]]
// CHECK:         %[[VAL_212:.*]] = load %[[VAL_1]], ptr %[[VAL_211]], align 1, !invariant.load !3
// CHECK:         store %[[VAL_1]] %[[VAL_212]], ptr %[[VAL_30]], align 1
// CHECK:         call void @[[SUM]](ptr %[[VAL_29]], ptr %[[VAL_30]], ptr %[[VAL_22]])
// CHECK:         %[[VAL_214:.*]] = load %[[VAL_1]], ptr %[[VAL_22]], align 1
// CHECK:         store %[[VAL_1]] %[[VAL_214]], ptr %[[VAL_29]], align 1
// CHECK:         br label %[[VAL_184]]
// CHECK:       thread_in_bounds-true:                            ; preds = %[[VAL_61]]
// CHECK:         %[[VAL_215:.*]] = icmp eq i32 %[[VAL_46]], 0
// CHECK:         br i1 %[[VAL_215]], label %[[VAL_216:.*]], label %[[VAL_217:.*]]
// CHECK:       intra_warp_reduce_write-after:                    ; preds = %[[VAL_216]], %[[VAL_154]]
// CHECK:         call void @llvm.nvvm.barrier0()
// CHECK:         %[[VAL_218:.*]] = icmp eq i32 %[[VAL_150]], 0
// CHECK:         br i1 %[[VAL_218]], label %[[VAL_219:.*]], label %[[VAL_155]]
// CHECK:       inter_warp_reduce-after:                          ; preds = %[[VAL_220:.*]], %[[VAL_217]]
// CHECK:         br label %[[VAL_35]]
// CHECK:       intra_warp_reduce_write-true:                     ; preds = %[[VAL_154]]
// CHECK:         %[[VAL_221:.*]] = load %[[VAL_1]], ptr %[[VAL_29]], align 1
// CHECK:         %[[VAL_222:.*]] = getelementptr inbounds [1 x [20 x %[[VAL_1]]]], ptr addrspace(3) @shared_cache, i32 0, i32 %[[VAL_43]], i32 %[[VAL_150]]
// CHECK:         %[[VAL_223:.*]] = addrspacecast ptr addrspace(3) %[[VAL_222]] to ptr
// CHECK:         store %[[VAL_1]] %[[VAL_221]], ptr %[[VAL_223]], align 1
// CHECK:         br label %[[VAL_217]]
// CHECK:       inter_warp_reduce-true:                           ; preds = %[[VAL_217]]
// CHECK:         %[[VAL_224:.*]] = getelementptr inbounds [1 x [20 x %[[VAL_1]]]], ptr addrspace(3) @shared_cache, i32 0, i32 %[[VAL_43]], i32 %[[VAL_46]]
// CHECK:         %[[VAL_225:.*]] = addrspacecast ptr addrspace(3) %[[VAL_224]] to ptr
// CHECK:         store %[[VAL_1]] %[[VAL_37]], ptr %[[VAL_11]], align 1
// CHECK:         %[[VAL_226:.*]] = icmp ult i32 %[[VAL_44]], 20
// CHECK:         %[[VAL_227:.*]] = select i1 %[[VAL_226]], ptr %[[VAL_225]], ptr %[[VAL_11]]
// CHECK:         %[[VAL_228:.*]] = load i128, ptr %[[VAL_227]], align 16
// CHECK:         %[[VAL_229:.*]] = bitcast i128 %[[VAL_228]] to <4 x i32>
// CHECK:         %[[VAL_230:.*]] = extractelement <4 x i32> %[[VAL_229]], i64 0
// CHECK:         %[[VAL_231:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_230]], i32 16, i32 31)
// CHECK:         %[[VAL_232:.*]] = insertelement <4 x i32> %[[VAL_229]], i32 %[[VAL_231]], i64 0
// CHECK:         %[[VAL_233:.*]] = extractelement <4 x i32> %[[VAL_232]], i64 1
// CHECK:         %[[VAL_234:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_233]], i32 16, i32 31)
// CHECK:         %[[VAL_235:.*]] = insertelement <4 x i32> %[[VAL_232]], i32 %[[VAL_234]], i64 1
// CHECK:         %[[VAL_236:.*]] = extractelement <4 x i32> %[[VAL_235]], i64 2
// CHECK:         %[[VAL_237:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_236]], i32 16, i32 31)
// CHECK:         %[[VAL_238:.*]] = insertelement <4 x i32> %[[VAL_235]], i32 %[[VAL_237]], i64 2
// CHECK:         %[[VAL_239:.*]] = extractelement <4 x i32> %[[VAL_238]], i64 3
// CHECK:         %[[VAL_240:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_239]], i32 16, i32 31)
// CHECK:         %[[VAL_241:.*]] = insertelement <4 x i32> %[[VAL_238]], i32 %[[VAL_240]], i64 3
// CHECK:         %[[VAL_242:.*]] = bitcast <4 x i32> %[[VAL_241]] to i128
// CHECK:         store i128 %[[VAL_242]], ptr %[[VAL_10]], align 16
// CHECK:         call void @[[SUM]](ptr %[[VAL_227]], ptr %[[VAL_10]], ptr %[[VAL_9]])
// CHECK:         %[[VAL_243:.*]] = load %[[VAL_1]], ptr %[[VAL_9]], align 1
// CHECK:         store %[[VAL_1]] %[[VAL_243]], ptr %[[VAL_227]], align 1
// CHECK:         %[[VAL_244:.*]] = load i128, ptr %[[VAL_227]], align 16
// CHECK:         %[[VAL_245:.*]] = bitcast i128 %[[VAL_244]] to <4 x i32>
// CHECK:         %[[VAL_246:.*]] = extractelement <4 x i32> %[[VAL_245]], i64 0
// CHECK:         %[[VAL_247:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_246]], i32 8, i32 31)
// CHECK:         %[[VAL_248:.*]] = insertelement <4 x i32> %[[VAL_245]], i32 %[[VAL_247]], i64 0
// CHECK:         %[[VAL_249:.*]] = extractelement <4 x i32> %[[VAL_248]], i64 1
// CHECK:         %[[VAL_250:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_249]], i32 8, i32 31)
// CHECK:         %[[VAL_251:.*]] = insertelement <4 x i32> %[[VAL_248]], i32 %[[VAL_250]], i64 1
// CHECK:         %[[VAL_252:.*]] = extractelement <4 x i32> %[[VAL_251]], i64 2
// CHECK:         %[[VAL_253:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_252]], i32 8, i32 31)
// CHECK:         %[[VAL_254:.*]] = insertelement <4 x i32> %[[VAL_251]], i32 %[[VAL_253]], i64 2
// CHECK:         %[[VAL_255:.*]] = extractelement <4 x i32> %[[VAL_254]], i64 3
// CHECK:         %[[VAL_256:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_255]], i32 8, i32 31)
// CHECK:         %[[VAL_257:.*]] = insertelement <4 x i32> %[[VAL_254]], i32 %[[VAL_256]], i64 3
// CHECK:         %[[VAL_258:.*]] = bitcast <4 x i32> %[[VAL_257]] to i128
// CHECK:         store i128 %[[VAL_258]], ptr %[[VAL_8]], align 16
// CHECK:         call void @[[SUM]](ptr %[[VAL_227]], ptr %[[VAL_8]], ptr %[[VAL_7]])
// CHECK:         %[[VAL_259:.*]] = load %[[VAL_1]], ptr %[[VAL_7]], align 1
// CHECK:         store %[[VAL_1]] %[[VAL_259]], ptr %[[VAL_227]], align 1
// CHECK:         %[[VAL_260:.*]] = load i128, ptr %[[VAL_227]], align 16
// CHECK:         %[[VAL_261:.*]] = bitcast i128 %[[VAL_260]] to <4 x i32>
// CHECK:         %[[VAL_262:.*]] = extractelement <4 x i32> %[[VAL_261]], i64 0
// CHECK:         %[[VAL_263:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_262]], i32 4, i32 31)
// CHECK:         %[[VAL_264:.*]] = insertelement <4 x i32> %[[VAL_261]], i32 %[[VAL_263]], i64 0
// CHECK:         %[[VAL_265:.*]] = extractelement <4 x i32> %[[VAL_264]], i64 1
// CHECK:         %[[VAL_266:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_265]], i32 4, i32 31)
// CHECK:         %[[VAL_267:.*]] = insertelement <4 x i32> %[[VAL_264]], i32 %[[VAL_266]], i64 1
// CHECK:         %[[VAL_268:.*]] = extractelement <4 x i32> %[[VAL_267]], i64 2
// CHECK:         %[[VAL_269:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_268]], i32 4, i32 31)
// CHECK:         %[[VAL_270:.*]] = insertelement <4 x i32> %[[VAL_267]], i32 %[[VAL_269]], i64 2
// CHECK:         %[[VAL_271:.*]] = extractelement <4 x i32> %[[VAL_270]], i64 3
// CHECK:         %[[VAL_272:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_271]], i32 4, i32 31)
// CHECK:         %[[VAL_273:.*]] = insertelement <4 x i32> %[[VAL_270]], i32 %[[VAL_272]], i64 3
// CHECK:         %[[VAL_274:.*]] = bitcast <4 x i32> %[[VAL_273]] to i128
// CHECK:         store i128 %[[VAL_274]], ptr %[[VAL_6]], align 16
// CHECK:         call void @[[SUM]](ptr %[[VAL_227]], ptr %[[VAL_6]], ptr %[[VAL_5]])
// CHECK:         %[[VAL_275:.*]] = load %[[VAL_1]], ptr %[[VAL_5]], align 1
// CHECK:         store %[[VAL_1]] %[[VAL_275]], ptr %[[VAL_227]], align 1
// CHECK:         %[[VAL_276:.*]] = load i128, ptr %[[VAL_227]], align 16
// CHECK:         %[[VAL_277:.*]] = bitcast i128 %[[VAL_276]] to <4 x i32>
// CHECK:         %[[VAL_278:.*]] = extractelement <4 x i32> %[[VAL_277]], i64 0
// CHECK:         %[[VAL_279:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_278]], i32 2, i32 31)
// CHECK:         %[[VAL_280:.*]] = insertelement <4 x i32> %[[VAL_277]], i32 %[[VAL_279]], i64 0
// CHECK:         %[[VAL_281:.*]] = extractelement <4 x i32> %[[VAL_280]], i64 1
// CHECK:         %[[VAL_282:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_281]], i32 2, i32 31)
// CHECK:         %[[VAL_283:.*]] = insertelement <4 x i32> %[[VAL_280]], i32 %[[VAL_282]], i64 1
// CHECK:         %[[VAL_284:.*]] = extractelement <4 x i32> %[[VAL_283]], i64 2
// CHECK:         %[[VAL_285:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_284]], i32 2, i32 31)
// CHECK:         %[[VAL_286:.*]] = insertelement <4 x i32> %[[VAL_283]], i32 %[[VAL_285]], i64 2
// CHECK:         %[[VAL_287:.*]] = extractelement <4 x i32> %[[VAL_286]], i64 3
// CHECK:         %[[VAL_288:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_287]], i32 2, i32 31)
// CHECK:         %[[VAL_289:.*]] = insertelement <4 x i32> %[[VAL_286]], i32 %[[VAL_288]], i64 3
// CHECK:         %[[VAL_290:.*]] = bitcast <4 x i32> %[[VAL_289]] to i128
// CHECK:         store i128 %[[VAL_290]], ptr %[[VAL_4]], align 16
// CHECK:         call void @[[SUM]](ptr %[[VAL_227]], ptr %[[VAL_4]], ptr %[[VAL_3]])
// CHECK:         %[[VAL_291:.*]] = load %[[VAL_1]], ptr %[[VAL_3]], align 1
// CHECK:         store %[[VAL_1]] %[[VAL_291]], ptr %[[VAL_227]], align 1
// CHECK:         %[[VAL_292:.*]] = load i128, ptr %[[VAL_227]], align 16
// CHECK:         %[[VAL_293:.*]] = bitcast i128 %[[VAL_292]] to <4 x i32>
// CHECK:         %[[VAL_294:.*]] = extractelement <4 x i32> %[[VAL_293]], i64 0
// CHECK:         %[[VAL_295:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_294]], i32 1, i32 31)
// CHECK:         %[[VAL_296:.*]] = insertelement <4 x i32> %[[VAL_293]], i32 %[[VAL_295]], i64 0
// CHECK:         %[[VAL_297:.*]] = extractelement <4 x i32> %[[VAL_296]], i64 1
// CHECK:         %[[VAL_298:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_297]], i32 1, i32 31)
// CHECK:         %[[VAL_299:.*]] = insertelement <4 x i32> %[[VAL_296]], i32 %[[VAL_298]], i64 1
// CHECK:         %[[VAL_300:.*]] = extractelement <4 x i32> %[[VAL_299]], i64 2
// CHECK:         %[[VAL_301:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_300]], i32 1, i32 31)
// CHECK:         %[[VAL_302:.*]] = insertelement <4 x i32> %[[VAL_299]], i32 %[[VAL_301]], i64 2
// CHECK:         %[[VAL_303:.*]] = extractelement <4 x i32> %[[VAL_302]], i64 3
// CHECK:         %[[VAL_304:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_303]], i32 1, i32 31)
// CHECK:         %[[VAL_305:.*]] = insertelement <4 x i32> %[[VAL_302]], i32 %[[VAL_304]], i64 3
// CHECK:         %[[VAL_306:.*]] = bitcast <4 x i32> %[[VAL_305]] to i128
// CHECK:         store i128 %[[VAL_306]], ptr %[[VAL_2]], align 16
// CHECK:         call void @[[SUM]](ptr %[[VAL_227]], ptr %[[VAL_2]], ptr %[[VAL_0]])
// CHECK:         %[[VAL_307:.*]] = load %[[VAL_1]], ptr %[[VAL_0]], align 1
// CHECK:         store %[[VAL_1]] %[[VAL_307]], ptr %[[VAL_227]], align 1
// CHECK:         %[[VAL_308:.*]] = icmp eq i32 %[[VAL_44]], 0
// CHECK:         br i1 %[[VAL_308]], label %[[VAL_309:.*]], label %[[VAL_220]]
// CHECK:       reduction_write_output-after:                     ; preds = %[[VAL_309]], %[[VAL_219]]
// CHECK:         br label %[[VAL_155]]
// CHECK:       reduction_write_output-true:                      ; preds = %[[VAL_219]]
// CHECK:         %[[VAL_310:.*]] = add i32 %[[VAL_54]], %[[VAL_41]]
// CHECK:         %[[VAL_311:.*]] = add i32 %[[VAL_55]], %[[VAL_43]]
// CHECK:         %[[VAL_312:.*]] = add i32 %[[VAL_56]], %[[VAL_45]]
// CHECK:         %[[VAL_313:.*]] = load %[[VAL_1]], ptr %[[VAL_227]], align 1
// CHECK:         store %[[VAL_1]] %[[VAL_313]], ptr %[[VAL_314:.*]], align 1
// CHECK:         br label %[[VAL_220]]
// CHECK:       entry:
// CHECK:         %[[VAL_315:.*]] = alloca %[[VAL_316:.*]], align 8
// CHECK:         %[[VAL_317:.*]] = load %[[VAL_316]], ptr %[[VAL_318:.*]], align 1
// CHECK:         %[[VAL_319:.*]] = load %[[VAL_316]], ptr %[[VAL_320:.*]], align 1
// CHECK:         %[[VAL_321:.*]] = extractvalue %[[VAL_316]] %[[VAL_317]], 0
// CHECK:         %[[VAL_322:.*]] = extractvalue %[[VAL_316]] %[[VAL_319]], 0
// CHECK:         %[[VAL_323:.*]] = fadd double %[[VAL_321]], %[[VAL_322]]
// CHECK:         %[[VAL_324:.*]] = extractvalue %[[VAL_316]] %[[VAL_317]], 1
// CHECK:         %[[VAL_325:.*]] = extractvalue %[[VAL_316]] %[[VAL_319]], 1
// CHECK:         %[[VAL_326:.*]] = fadd double %[[VAL_324]], %[[VAL_325]]
// CHECK:         %[[VAL_327:.*]] = insertvalue %[[VAL_316]] zeroinitializer, double %[[VAL_323]], 0
// CHECK:         %[[VAL_328:.*]] = insertvalue %[[VAL_316]] %[[VAL_327]], double %[[VAL_326]], 1
// CHECK:         store %[[VAL_316]] %[[VAL_328]], ptr %[[VAL_315]], align 1
// CHECK:         %[[VAL_329:.*]] = load %[[VAL_316]], ptr %[[VAL_315]], align 1
// CHECK:         store %[[VAL_316]] %[[VAL_329]], ptr %[[VAL_330:.*]], align 1
// CHECK:         ret void
