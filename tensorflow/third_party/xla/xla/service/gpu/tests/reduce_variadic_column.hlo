// RUN: hlo-opt %s --platform=gpu --stage=llvm-before-optimizations --xla_gpu_target_config_filename=%S/../../../tools/hlo_opt/gpu_specs/%{GPU}.txtpb | FileCheck %s --check-prefixes=CHECK,CHECK-%{PTX}

HloModule Test, is_scheduled=true

Add {
  scalar_lhs.0 = f32[] parameter(0)
  scalar_rhs.0 = f32[] parameter(1)
  scalar_lhs.1 = f32[] parameter(2)
  scalar_rhs.1 = f32[] parameter(3)
  add.0 = f32[] add(scalar_lhs.0, scalar_lhs.1)
  add.1 = f32[] add(scalar_rhs.0, scalar_rhs.1)
  ROOT t = (f32[], f32[]) tuple(add.0, add.1)
}

fused_computation {
  param_0 = f32[5,200,300]{2,1,0} parameter(0)
  param_1 = f32[5,200,300]{2,1,0} parameter(1)
  param_2 = f32[] parameter(2)
  ROOT d.1 = (f32[200]{0}, f32[200]{0}) reduce(f32[5,200,300]{2,1,0} param_0, f32[5,200,300]{2,1,0} %param_1, f32[] param_2, f32[] param_2), dimensions={0,2}, to_apply=Add
}

ENTRY main {
  a = f32[5, 200, 300]{2,1,0} parameter(0)
  b = f32[5, 200, 300]{2,1,0} parameter(1)
  c = f32[] constant(0)
  ROOT wrapped_d = (f32[200]{0}, f32[200]{0}) fusion(f32[5,200,300]{2,1,0} a, f32[5,200,300]{2,1,0} b, f32[] c), kind=kInput, calls=fused_computation
}

// CHECK-LABEL: entry:
// CHECK:         %[[VAL_0:.*]] = alloca float, align 4
// CHECK:         %[[VAL_1:.*]] = alloca float, align 4
// CHECK:         %[[VAL_2:.*]] = alloca float, align 4
// CHECK:         %[[VAL_3:.*]] = alloca float, align 4
// CHECK:         %[[VAL_4:.*]] = alloca [2 x ptr], align 8
// CHECK:         %[[VAL_5:.*]] = alloca float, align 4
// CHECK:         %[[VAL_6:.*]] = alloca float, align 4
// CHECK:         %[[VAL_7:.*]] = alloca float, align 4
// CHECK:         %[[VAL_8:.*]] = alloca float, align 4
// CHECK:         %[[VAL_9:.*]] = alloca [2 x ptr], align 8
// CHECK:         %[[VAL_10:.*]] = alloca float, align 4
// CHECK:         %[[VAL_11:.*]] = alloca float, align 4
// CHECK:         %[[VAL_12:.*]] = alloca float, align 4
// CHECK:         %[[VAL_13:.*]] = alloca float, align 4
// CHECK:         %[[VAL_14:.*]] = alloca [2 x ptr], align 8
// CHECK:         %[[VAL_15:.*]] = alloca float, align 4
// CHECK:         %[[VAL_16:.*]] = alloca float, align 4
// CHECK:         %[[VAL_17:.*]] = alloca float, align 4
// CHECK:         %[[VAL_18:.*]] = alloca float, align 4
// CHECK:         %[[VAL_19:.*]] = alloca [2 x ptr], align 8
// CHECK:         %[[VAL_20:.*]] = alloca float, align 4
// CHECK:         %[[VAL_21:.*]] = alloca float, align 4
// CHECK:         %[[VAL_22:.*]] = alloca float, align 4
// CHECK:         %[[VAL_23:.*]] = alloca float, align 4
// CHECK:         %[[VAL_24:.*]] = alloca [2 x ptr], align 8
// CHECK:         %[[VAL_25:.*]] = alloca float, align 4
// CHECK:         %[[VAL_26:.*]] = alloca float, align 4
// CHECK:         %[[VAL_27:.*]] = alloca float, align 4
// CHECK:         %[[VAL_28:.*]] = alloca float, align 4
// CHECK:         %[[VAL_29:.*]] = alloca [2 x ptr], align 8
// CHECK:         %[[VAL_30:.*]] = alloca i32, align 4
// CHECK:         %[[VAL_31:.*]] = alloca float, align 4
// CHECK:         %[[VAL_32:.*]] = alloca float, align 4
// CHECK:         %[[VAL_33:.*]] = alloca [2 x ptr], align 8
// CHECK:         %[[VAL_34:.*]] = alloca i32, align 4
// CHECK:         %[[VAL_35:.*]] = alloca i32, align 4
// CHECK:         %[[VAL_36:.*]] = alloca i32, align 4
// CHECK:         %[[VAL_37:.*]] = alloca float, align 4
// CHECK:         %[[VAL_38:.*]] = alloca float, align 4
// CHECK:         %[[VAL_39:.*]] = alloca float, align 4
// CHECK:         %[[VAL_40:.*]] = alloca float, align 4
// CHECK-PTX:     %[[VAL_41:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.y(), !range !2
// CHECK-GCN:     %[[VAL_41:.*]] = call i32 @llvm.amdgcn.workgroup.id.y
// CHECK:         %[[VAL_42:.*]] = icmp eq i32 %[[VAL_41]], 0
// CHECK:         br i1 %[[VAL_42]], label %[[VAL_43:.*]], label %[[VAL_44:.*]]
// CHECK:       reduce-group-0-after:                             ; preds = %[[VAL_45:.*]], %[[VAL_46:.*]]
// CHECK:         ret void
// CHECK:       reduce-group-0-true:                              ; preds = %[[VAL_46]]
// CHECK:         %[[VAL_47:.*]] = load float, ptr %[[VAL_48:.*]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_47]], ptr %[[VAL_39]], align 4
// CHECK:         %[[VAL_49:.*]] = load float, ptr %[[VAL_48]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_49]], ptr %[[VAL_37]], align 4
// CHECK-PTX:     %[[VAL_50:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.tid.x(), !range !4
// CHECK-GCN:     %[[VAL_50:.*]] = call i32 @llvm.amdgcn.workitem.id.x
// CHECK-PTX:     %[[VAL_51:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !5
// CHECK-GCN:     %[[VAL_51:.*]] = call i32 @llvm.amdgcn.workgroup.id.x
// CHECK:         %[[VAL_52:.*]] = udiv i32 %[[VAL_50]], 256
// CHECK:         %[[VAL_53:.*]] = urem i32 %[[VAL_50]], 256
// CHECK:         %[[VAL_54:.*]] = udiv i32 %[[VAL_53]], 32
// CHECK:         %[[VAL_55:.*]] = urem i32 %[[VAL_50]], 32
// CHECK:         %[[VAL_56:.*]] = mul i32 %[[VAL_55]], 1
// CHECK:         %[[VAL_57:.*]] = urem i32 %[[VAL_50]], 32
// CHECK:         %[[VAL_58:.*]] = udiv i32 %[[VAL_51]], 1
// CHECK:         %[[VAL_59:.*]] = urem i32 %[[VAL_58]], 1
// CHECK:         %[[VAL_60:.*]] = udiv i32 %[[VAL_51]], 1
// CHECK:         %[[VAL_61:.*]] = urem i32 %[[VAL_60]], 25
// CHECK:         %[[VAL_62:.*]] = udiv i32 %[[VAL_51]], 25
// CHECK:         %[[VAL_63:.*]] = icmp eq i32 %[[VAL_59]], 0
// CHECK:         %[[VAL_64:.*]] = select i1 %[[VAL_63]], i32 300, i32 512
// CHECK:         %[[VAL_65:.*]] = mul i32 %[[VAL_62]], 5
// CHECK:         %[[VAL_66:.*]] = mul i32 %[[VAL_61]], 8
// CHECK:         %[[VAL_67:.*]] = mul i32 %[[VAL_59]], 512
// CHECK:         store i32 %[[VAL_52]], ptr %[[VAL_36]], align 4
// CHECK:         br label %[[VAL_68:.*]]
// CHECK:       loop0.loop_header:                                ; preds = %[[VAL_69:.*]], %[[VAL_43]]
// CHECK:         %[[VAL_70:.*]] = load i32, ptr %[[VAL_36]], align 4
// CHECK:         %[[VAL_71:.*]] = icmp uge i32 %[[VAL_70]], 5
// CHECK:         br i1 %[[VAL_71]], label %[[VAL_72:.*]], label %[[VAL_73:.*]]
// CHECK:       loop0.loop_body:                                  ; preds = %[[VAL_68]]
// CHECK:         %[[VAL_74:.*]] = add nuw nsw i32 %[[VAL_70]], 1
// CHECK:         store i32 %[[VAL_74]], ptr %[[VAL_36]], align 4
// CHECK:         %[[VAL_75:.*]] = icmp eq i32 %[[VAL_70]], %[[VAL_52]]
// CHECK:         store i32 %[[VAL_54]], ptr %[[VAL_35]], align 4
// CHECK:         br label %[[VAL_76:.*]]
// CHECK:       loop1.loop_header:                                ; preds = %[[VAL_77:.*]], %[[VAL_73]]
// CHECK:         %[[VAL_78:.*]] = load i32, ptr %[[VAL_35]], align 4
// CHECK:         %[[VAL_79:.*]] = icmp uge i32 %[[VAL_78]], 8
// CHECK:         br i1 %[[VAL_79]], label %[[VAL_69]], label %[[VAL_80:.*]]
// CHECK:       loop1.loop_body:                                  ; preds = %[[VAL_76]]
// CHECK:         %[[VAL_81:.*]] = add nuw nsw i32 %[[VAL_78]], 8
// CHECK:         store i32 %[[VAL_81]], ptr %[[VAL_35]], align 4
// CHECK:         %[[VAL_82:.*]] = icmp eq i32 %[[VAL_78]], %[[VAL_54]]
// CHECK:         %[[VAL_83:.*]] = icmp eq i32 512, %[[VAL_64]]
// CHECK:         br i1 %[[VAL_83]], label %[[VAL_84:.*]], label %[[VAL_85:.*]]
// CHECK:       is_full_tile-after:                               ; preds = %[[VAL_86:.*]], %[[VAL_87:.*]]
// CHECK:         br label %[[VAL_76]], !llvm.loop !6
// CHECK:       loop1.loop_exit:                                  ; preds = %[[VAL_76]]
// CHECK:         br label %[[VAL_68]], !llvm.loop !8
// CHECK:       loop0.loop_exit:                                  ; preds = %[[VAL_68]]
// CHECK:         %[[VAL_88:.*]] = load float, ptr %[[VAL_39]], align 4
// CHECK:         %[[VAL_89:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_88]], i32 16, i32 31)
// CHECK:         store float %[[VAL_89]], ptr %[[VAL_26]], align 4
// CHECK:         %[[VAL_90:.*]] = load float, ptr %[[VAL_37]], align 4
// CHECK:         %[[VAL_91:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_90]], i32 16, i32 31)
// CHECK:         store float %[[VAL_91]], ptr %[[VAL_25]], align 4
// CHECK:         %[[VAL_92:.*]] = getelementptr inbounds [2 x ptr], ptr %[[VAL_24]], i64 0, i64 0
// CHECK:         store ptr %[[VAL_22]], ptr %[[VAL_92]], align 8
// CHECK:         %[[VAL_93:.*]] = getelementptr inbounds [2 x ptr], ptr %[[VAL_24]], i64 0, i64 1
// CHECK:         store ptr %[[VAL_23]], ptr %[[VAL_93]], align 8
// CHECK:         call void @[[ADD:Add.*]](ptr %[[VAL_39]], ptr %[[VAL_37]], ptr %[[VAL_26]], ptr %[[VAL_25]], ptr %[[VAL_24]])
// CHECK:         %[[VAL_94:.*]] = load float, ptr %[[VAL_22]], align 4
// CHECK:         %[[VAL_95:.*]] = load float, ptr %[[VAL_23]], align 4
// CHECK:         store float %[[VAL_94]], ptr %[[VAL_39]], align 4
// CHECK:         store float %[[VAL_95]], ptr %[[VAL_37]], align 4
// CHECK:         %[[VAL_96:.*]] = load float, ptr %[[VAL_39]], align 4
// CHECK:         %[[VAL_97:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_96]], i32 8, i32 31)
// CHECK:         store float %[[VAL_97]], ptr %[[VAL_21]], align 4
// CHECK:         %[[VAL_98:.*]] = load float, ptr %[[VAL_37]], align 4
// CHECK:         %[[VAL_99:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_98]], i32 8, i32 31)
// CHECK:         store float %[[VAL_99]], ptr %[[VAL_20]], align 4
// CHECK:         %[[VAL_100:.*]] = getelementptr inbounds [2 x ptr], ptr %[[VAL_19]], i64 0, i64 0
// CHECK:         store ptr %[[VAL_17]], ptr %[[VAL_100]], align 8
// CHECK:         %[[VAL_101:.*]] = getelementptr inbounds [2 x ptr], ptr %[[VAL_19]], i64 0, i64 1
// CHECK:         store ptr %[[VAL_18]], ptr %[[VAL_101]], align 8
// CHECK:         call void @[[ADD]](ptr %[[VAL_39]], ptr %[[VAL_37]], ptr %[[VAL_21]], ptr %[[VAL_20]], ptr %[[VAL_19]])
// CHECK:         %[[VAL_102:.*]] = load float, ptr %[[VAL_17]], align 4
// CHECK:         %[[VAL_103:.*]] = load float, ptr %[[VAL_18]], align 4
// CHECK:         store float %[[VAL_102]], ptr %[[VAL_39]], align 4
// CHECK:         store float %[[VAL_103]], ptr %[[VAL_37]], align 4
// CHECK:         %[[VAL_104:.*]] = load float, ptr %[[VAL_39]], align 4
// CHECK:         %[[VAL_105:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_104]], i32 4, i32 31)
// CHECK:         store float %[[VAL_105]], ptr %[[VAL_16]], align 4
// CHECK:         %[[VAL_106:.*]] = load float, ptr %[[VAL_37]], align 4
// CHECK:         %[[VAL_107:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_106]], i32 4, i32 31)
// CHECK:         store float %[[VAL_107]], ptr %[[VAL_15]], align 4
// CHECK:         %[[VAL_108:.*]] = getelementptr inbounds [2 x ptr], ptr %[[VAL_14]], i64 0, i64 0
// CHECK:         store ptr %[[VAL_12]], ptr %[[VAL_108]], align 8
// CHECK:         %[[VAL_109:.*]] = getelementptr inbounds [2 x ptr], ptr %[[VAL_14]], i64 0, i64 1
// CHECK:         store ptr %[[VAL_13]], ptr %[[VAL_109]], align 8
// CHECK:         call void @[[ADD]](ptr %[[VAL_39]], ptr %[[VAL_37]], ptr %[[VAL_16]], ptr %[[VAL_15]], ptr %[[VAL_14]])
// CHECK:         %[[VAL_110:.*]] = load float, ptr %[[VAL_12]], align 4
// CHECK:         %[[VAL_111:.*]] = load float, ptr %[[VAL_13]], align 4
// CHECK:         store float %[[VAL_110]], ptr %[[VAL_39]], align 4
// CHECK:         store float %[[VAL_111]], ptr %[[VAL_37]], align 4
// CHECK:         %[[VAL_112:.*]] = load float, ptr %[[VAL_39]], align 4
// CHECK:         %[[VAL_113:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_112]], i32 2, i32 31)
// CHECK:         store float %[[VAL_113]], ptr %[[VAL_11]], align 4
// CHECK:         %[[VAL_114:.*]] = load float, ptr %[[VAL_37]], align 4
// CHECK:         %[[VAL_115:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_114]], i32 2, i32 31)
// CHECK:         store float %[[VAL_115]], ptr %[[VAL_10]], align 4
// CHECK:         %[[VAL_116:.*]] = getelementptr inbounds [2 x ptr], ptr %[[VAL_9]], i64 0, i64 0
// CHECK:         store ptr %[[VAL_7]], ptr %[[VAL_116]], align 8
// CHECK:         %[[VAL_117:.*]] = getelementptr inbounds [2 x ptr], ptr %[[VAL_9]], i64 0, i64 1
// CHECK:         store ptr %[[VAL_8]], ptr %[[VAL_117]], align 8
// CHECK:         call void @[[ADD]](ptr %[[VAL_39]], ptr %[[VAL_37]], ptr %[[VAL_11]], ptr %[[VAL_10]], ptr %[[VAL_9]])
// CHECK:         %[[VAL_118:.*]] = load float, ptr %[[VAL_7]], align 4
// CHECK:         %[[VAL_119:.*]] = load float, ptr %[[VAL_8]], align 4
// CHECK:         store float %[[VAL_118]], ptr %[[VAL_39]], align 4
// CHECK:         store float %[[VAL_119]], ptr %[[VAL_37]], align 4
// CHECK:         %[[VAL_120:.*]] = load float, ptr %[[VAL_39]], align 4
// CHECK:         %[[VAL_121:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_120]], i32 1, i32 31)
// CHECK:         store float %[[VAL_121]], ptr %[[VAL_6]], align 4
// CHECK:         %[[VAL_122:.*]] = load float, ptr %[[VAL_37]], align 4
// CHECK:         %[[VAL_123:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_122]], i32 1, i32 31)
// CHECK:         store float %[[VAL_123]], ptr %[[VAL_5]], align 4
// CHECK:         %[[VAL_124:.*]] = getelementptr inbounds [2 x ptr], ptr %[[VAL_4]], i64 0, i64 0
// CHECK:         store ptr %[[VAL_2]], ptr %[[VAL_124]], align 8
// CHECK:         %[[VAL_125:.*]] = getelementptr inbounds [2 x ptr], ptr %[[VAL_4]], i64 0, i64 1
// CHECK:         store ptr %[[VAL_3]], ptr %[[VAL_125]], align 8
// CHECK:         call void @[[ADD]](ptr %[[VAL_39]], ptr %[[VAL_37]], ptr %[[VAL_6]], ptr %[[VAL_5]], ptr %[[VAL_4]])
// CHECK:         %[[VAL_126:.*]] = load float, ptr %[[VAL_2]], align 4
// CHECK:         %[[VAL_127:.*]] = load float, ptr %[[VAL_3]], align 4
// CHECK:         store float %[[VAL_126]], ptr %[[VAL_39]], align 4
// CHECK:         store float %[[VAL_127]], ptr %[[VAL_37]], align 4
// CHECK:         %[[VAL_128:.*]] = udiv i32 %[[VAL_55]], 32
// CHECK:         %[[VAL_130:.*]] = icmp ult i32 %[[VAL_54]], 8
// CHECK:         br i1 %[[VAL_130]], label %[[VAL_132:.*]], label %[[VAL_45]]
// CHECK:       thread_in_bounds-after:                           ; preds = %[[VAL_133:.*]], %[[VAL_72]]
// CHECK:         br label %[[VAL_44]]
// CHECK:       is_full_tile-true:                                ; preds = %[[VAL_80]]
// CHECK:         store i32 0, ptr %[[VAL_34]], align 4
// CHECK:         br label %[[VAL_134:.*]]
// CHECK:       loop2.loop_header:                                ; preds = %[[VAL_135:.*]], %[[VAL_84]]
// CHECK:         %[[VAL_136:.*]] = load i32, ptr %[[VAL_34]], align 4
// CHECK:         %[[VAL_137:.*]] = icmp uge i32 %[[VAL_136]], 16
// CHECK:         br i1 %[[VAL_137]], label %[[VAL_87]], label %[[VAL_135]]
// CHECK:       loop2.loop_body:                                  ; preds = %[[VAL_134]]
// CHECK:         %[[VAL_138:.*]] = add nuw nsw i32 %[[VAL_136]], 1
// CHECK:         store i32 %[[VAL_138]], ptr %[[VAL_34]], align 4
// CHECK:         %[[VAL_139:.*]] = icmp eq i32 %[[VAL_136]], 0
// CHECK:         %[[VAL_140:.*]] = mul i32 %[[VAL_136]], 32
// CHECK:         %[[VAL_141:.*]] = add i32 %[[VAL_140]], 0
// CHECK:         %[[VAL_142:.*]] = add i32 %[[VAL_141]], %[[VAL_56]]
// CHECK:         %[[VAL_143:.*]] = add i32 %[[VAL_65]], %[[VAL_70]]
// CHECK:         %[[VAL_144:.*]] = add i32 %[[VAL_66]], %[[VAL_78]]
// CHECK:         %[[VAL_145:.*]] = add i32 %[[VAL_67]], %[[VAL_142]]
// CHECK:         %[[VAL_146:.*]] = getelementptr inbounds [5 x [200 x [300 x float]]], ptr %[[VAL_147:.*]], i32 0, i32 %[[VAL_143]], i32 %[[VAL_144]], i32 %[[VAL_145]]
// CHECK:         %[[VAL_148:.*]] = load float, ptr %[[VAL_146]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_148]], ptr %[[VAL_40]], align 4
// CHECK:         %[[VAL_150:.*]] = getelementptr inbounds [5 x [200 x [300 x float]]], ptr %[[VAL_151:.*]], i32 0, i32 %[[VAL_143]], i32 %[[VAL_144]], i32 %[[VAL_145]]
// CHECK:         %[[VAL_152:.*]] = load float, ptr %[[VAL_150]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_152]], ptr %[[VAL_38]], align 4
// CHECK:         %[[VAL_154:.*]] = getelementptr inbounds [2 x ptr], ptr %[[VAL_33]], i64 0, i64 0
// CHECK:         store ptr %[[VAL_31]], ptr %[[VAL_154]], align 8
// CHECK:         %[[VAL_155:.*]] = getelementptr inbounds [2 x ptr], ptr %[[VAL_33]], i64 0, i64 1
// CHECK:         store ptr %[[VAL_32]], ptr %[[VAL_155]], align 8
// CHECK:         call void @[[ADD]](ptr %[[VAL_39]], ptr %[[VAL_37]], ptr %[[VAL_40]], ptr %[[VAL_38]], ptr %[[VAL_33]])
// CHECK:         %[[VAL_156:.*]] = load float, ptr %[[VAL_31]], align 4
// CHECK:         %[[VAL_157:.*]] = load float, ptr %[[VAL_32]], align 4
// CHECK:         store float %[[VAL_156]], ptr %[[VAL_39]], align 4
// CHECK:         store float %[[VAL_157]], ptr %[[VAL_37]], align 4
// CHECK:         br label %[[VAL_134]], !llvm.loop !9
// CHECK:       loop2.loop_exit:                                  ; preds = %[[VAL_134]]
// CHECK:         br label %[[VAL_77]]
// CHECK:       is_full_tile-false:                               ; preds = %[[VAL_80]]
// CHECK:         store i32 0, ptr %[[VAL_30]], align 4
// CHECK:         br label %[[VAL_158:.*]]
// CHECK:       loop2.loop_header9:                               ; preds = %[[VAL_159:.*]], %[[VAL_85]]
// CHECK:         %[[VAL_160:.*]] = load i32, ptr %[[VAL_30]], align 4
// CHECK:         %[[VAL_161:.*]] = icmp uge i32 %[[VAL_160]], 16
// CHECK:         br i1 %[[VAL_161]], label %[[VAL_86]], label %[[VAL_162:.*]]
// CHECK:       loop2.loop_body10:                                ; preds = %[[VAL_158]]
// CHECK:         %[[VAL_163:.*]] = add nuw nsw i32 %[[VAL_160]], 1
// CHECK:         store i32 %[[VAL_163]], ptr %[[VAL_30]], align 4
// CHECK:         %[[VAL_164:.*]] = icmp eq i32 %[[VAL_160]], 0
// CHECK:         %[[VAL_165:.*]] = mul i32 %[[VAL_160]], 32
// CHECK:         %[[VAL_166:.*]] = add i32 %[[VAL_165]], 0
// CHECK:         %[[VAL_167:.*]] = add i32 %[[VAL_166]], %[[VAL_56]]
// CHECK:         %[[VAL_168:.*]] = icmp ult i32 %[[VAL_167]], %[[VAL_64]]
// CHECK:         br i1 %[[VAL_168]], label %[[VAL_169:.*]], label %[[VAL_159]]
// CHECK:       x_in_tile-after:                                  ; preds = %[[VAL_169]], %[[VAL_162]]
// CHECK:         br label %[[VAL_158]], !llvm.loop !11
// CHECK:       loop2.loop_exit8:                                 ; preds = %[[VAL_158]]
// CHECK:         br label %[[VAL_77]]
// CHECK:       x_in_tile-true:                                   ; preds = %[[VAL_162]]
// CHECK:         %[[VAL_170:.*]] = add i32 %[[VAL_65]], %[[VAL_70]]
// CHECK:         %[[VAL_171:.*]] = add i32 %[[VAL_66]], %[[VAL_78]]
// CHECK:         %[[VAL_172:.*]] = add i32 %[[VAL_67]], %[[VAL_167]]
// CHECK:         %[[VAL_173:.*]] = getelementptr inbounds [5 x [200 x [300 x float]]], ptr %[[VAL_147]], i32 0, i32 %[[VAL_170]], i32 %[[VAL_171]], i32 %[[VAL_172]]
// CHECK:         %[[VAL_174:.*]] = load float, ptr %[[VAL_173]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_174]], ptr %[[VAL_40]], align 4
// CHECK:         %[[VAL_176:.*]] = getelementptr inbounds [5 x [200 x [300 x float]]], ptr %[[VAL_151]], i32 0, i32 %[[VAL_170]], i32 %[[VAL_171]], i32 %[[VAL_172]]
// CHECK:         %[[VAL_177:.*]] = load float, ptr %[[VAL_176]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_177]], ptr %[[VAL_38]], align 4
// CHECK:         %[[VAL_179:.*]] = getelementptr inbounds [2 x ptr], ptr %[[VAL_29]], i64 0, i64 0
// CHECK:         store ptr %[[VAL_27]], ptr %[[VAL_179]], align 8
// CHECK:         %[[VAL_180:.*]] = getelementptr inbounds [2 x ptr], ptr %[[VAL_29]], i64 0, i64 1
// CHECK:         store ptr %[[VAL_28]], ptr %[[VAL_180]], align 8
// CHECK:         call void @[[ADD]](ptr %[[VAL_39]], ptr %[[VAL_37]], ptr %[[VAL_40]], ptr %[[VAL_38]], ptr %[[VAL_29]])
// CHECK:         %[[VAL_181:.*]] = load float, ptr %[[VAL_27]], align 4
// CHECK:         %[[VAL_182:.*]] = load float, ptr %[[VAL_28]], align 4
// CHECK:         store float %[[VAL_181]], ptr %[[VAL_39]], align 4
// CHECK:         store float %[[VAL_182]], ptr %[[VAL_37]], align 4
// CHECK:         br label %[[VAL_159]]
// CHECK:       thread_in_bounds-true:                            ; preds = %[[VAL_72]]
// CHECK:         %[[VAL_183:.*]] = icmp eq i32 %[[VAL_57]], 0
// CHECK:         br i1 %[[VAL_183]], label %[[VAL_184:.*]], label %[[VAL_185:.*]]
// CHECK:       intra_warp_reduce_write-after:                    ; preds = %[[VAL_184]], %[[VAL_132]]
// CHECK:         call void @llvm.nvvm.barrier0()
// CHECK:         %[[VAL_186:.*]] = icmp eq i32 %[[VAL_128]], 0
// CHECK:         br i1 %[[VAL_186]], label %[[VAL_187:.*]], label %[[VAL_133]]
// CHECK:       inter_warp_reduce-after:                          ; preds = %[[VAL_188:.*]], %[[VAL_185]]
// CHECK:         br label %[[VAL_45]]
// CHECK:       intra_warp_reduce_write-true:                     ; preds = %[[VAL_132]]
// CHECK:         %[[VAL_189:.*]] = load float, ptr %[[VAL_39]], align 4
// CHECK:         %[[VAL_190:.*]] = getelementptr inbounds [8 x [1 x float]], ptr addrspace(3) @shared_cache, i32 0, i32 %[[VAL_54]], i32 %[[VAL_128]]
// CHECK:         %[[VAL_191:.*]] = addrspacecast ptr addrspace(3) %[[VAL_190]] to ptr
// CHECK:         store float %[[VAL_189]], ptr %[[VAL_191]], align 4
// CHECK:         %[[VAL_192:.*]] = load float, ptr %[[VAL_37]], align 4
// CHECK:         %[[VAL_193:.*]] = getelementptr inbounds [8 x [1 x float]], ptr addrspace(3) @shared_cache1, i32 0, i32 %[[VAL_54]], i32 %[[VAL_128]]
// CHECK:         %[[VAL_194:.*]] = addrspacecast ptr addrspace(3) %[[VAL_193]] to ptr
// CHECK:         store float %[[VAL_192]], ptr %[[VAL_194]], align 4
// CHECK:         br label %[[VAL_185]]
// CHECK:       inter_warp_reduce-true:                           ; preds = %[[VAL_185]]
// CHECK:         %[[VAL_195:.*]] = getelementptr inbounds [8 x [1 x float]], ptr addrspace(3) @shared_cache, i32 0, i32 %[[VAL_54]], i32 %[[VAL_57]]
// CHECK:         %[[VAL_196:.*]] = addrspacecast ptr addrspace(3) %[[VAL_195]] to ptr
// CHECK:         store float %[[VAL_47]], ptr %[[VAL_1]], align 4
// CHECK:         %[[VAL_197:.*]] = icmp ult i32 %[[VAL_55]], 1
// CHECK:         %[[VAL_198:.*]] = select i1 %[[VAL_197]], ptr %[[VAL_196]], ptr %[[VAL_1]]
// CHECK:         %[[VAL_199:.*]] = getelementptr inbounds [8 x [1 x float]], ptr addrspace(3) @shared_cache1, i32 0, i32 %[[VAL_54]], i32 %[[VAL_57]]
// CHECK:         %[[VAL_200:.*]] = addrspacecast ptr addrspace(3) %[[VAL_199]] to ptr
// CHECK:         store float %[[VAL_49]], ptr %[[VAL_0]], align 4
// CHECK:         %[[VAL_201:.*]] = icmp ult i32 %[[VAL_55]], 1
// CHECK:         %[[VAL_202:.*]] = select i1 %[[VAL_201]], ptr %[[VAL_200]], ptr %[[VAL_0]]
// CHECK:         %[[VAL_203:.*]] = icmp eq i32 %[[VAL_55]], 0
// CHECK:         br i1 %[[VAL_203]], label %[[VAL_204:.*]], label %[[VAL_188]]
// CHECK:       reduction_write_output-after:                     ; preds = %[[VAL_204]], %[[VAL_187]]
// CHECK:         br label %[[VAL_133]]
// CHECK:       reduction_write_output-true:                      ; preds = %[[VAL_187]]
// CHECK:         %[[VAL_205:.*]] = add i32 %[[VAL_65]], %[[VAL_52]]
// CHECK:         %[[VAL_206:.*]] = add i32 %[[VAL_66]], %[[VAL_54]]
// CHECK:         %[[VAL_207:.*]] = add i32 %[[VAL_67]], %[[VAL_56]]
// CHECK:         %[[VAL_208:.*]] = udiv i32 %[[VAL_206]], 1
// CHECK:         %[[VAL_209:.*]] = getelementptr inbounds [200 x float], ptr %[[VAL_210:.*]], i32 0, i32 %[[VAL_208]]
// CHECK:         %[[VAL_211:.*]] = load float, ptr %[[VAL_198]], align 4
// CHECK:         store float %[[VAL_211]], ptr %[[VAL_209]], align 4
// CHECK:         %[[VAL_212:.*]] = add i32 %[[VAL_65]], %[[VAL_52]]
// CHECK:         %[[VAL_213:.*]] = add i32 %[[VAL_66]], %[[VAL_54]]
// CHECK:         %[[VAL_214:.*]] = add i32 %[[VAL_67]], %[[VAL_56]]
// CHECK:         %[[VAL_215:.*]] = udiv i32 %[[VAL_213]], 1
// CHECK:         %[[VAL_216:.*]] = getelementptr inbounds [200 x float], ptr %[[VAL_217:.*]], i32 0, i32 %[[VAL_215]]
// CHECK:         %[[VAL_218:.*]] = load float, ptr %[[VAL_202]], align 4
// CHECK:         store float %[[VAL_218]], ptr %[[VAL_216]], align 4
// CHECK:         br label %[[VAL_188]]
// CHECK:       entry:
// CHECK:         %[[VAL_219:.*]] = alloca float, align 4
// CHECK:         %[[VAL_220:.*]] = alloca float, align 4
// CHECK:         %[[VAL_221:.*]] = alloca [2 x ptr], align 8
// CHECK:         %[[VAL_222:.*]] = alloca [2 x ptr], align 8
// CHECK:         %[[VAL_223:.*]] = alloca [2 x ptr], align 8
// CHECK:         %[[VAL_224:.*]] = load float, ptr %[[VAL_225:.*]], align 4
// CHECK:         %[[VAL_226:.*]] = load float, ptr %[[VAL_227:.*]], align 4
// CHECK:         %[[VAL_228:.*]] = fadd float %[[VAL_224]], %[[VAL_226]]
// CHECK:         store float %[[VAL_228]], ptr %[[VAL_220]], align 4
// CHECK:         %[[VAL_229:.*]] = load float, ptr %[[VAL_230:.*]], align 4
// CHECK:         %[[VAL_231:.*]] = load float, ptr %[[VAL_232:.*]], align 4
// CHECK:         %[[VAL_233:.*]] = fadd float %[[VAL_229]], %[[VAL_231]]
// CHECK:         store float %[[VAL_233]], ptr %[[VAL_219]], align 4
// CHECK:         %[[VAL_234:.*]] = getelementptr inbounds [2 x ptr], ptr %[[VAL_223]], i64 0, i64 0
// CHECK:         store ptr %[[VAL_220]], ptr %[[VAL_234]], align 8
// CHECK:         %[[VAL_235:.*]] = getelementptr inbounds [2 x ptr], ptr %[[VAL_223]], i64 0, i64 1
// CHECK:         store ptr %[[VAL_219]], ptr %[[VAL_235]], align 8
// CHECK:         %[[VAL_236:.*]] = getelementptr inbounds [2 x ptr], ptr %[[VAL_237:.*]], i64 0, i64 0
// CHECK:         %[[VAL_238:.*]] = load ptr, ptr %[[VAL_236]], align 8, !dereferenceable !12, !align !13
// CHECK:         %[[VAL_239:.*]] = getelementptr inbounds [2 x ptr], ptr %[[VAL_223]], i64 0, i64 0
// CHECK:         %[[VAL_240:.*]] = load ptr, ptr %[[VAL_239]], align 8, !dereferenceable !12, !align !13
// CHECK:         %[[VAL_241:.*]] = load float, ptr %[[VAL_240]], align 4
// CHECK:         store float %[[VAL_241]], ptr %[[VAL_238]], align 4
// CHECK:         %[[VAL_242:.*]] = getelementptr inbounds [2 x ptr], ptr %[[VAL_237]], i64 0, i64 1
// CHECK:         %[[VAL_243:.*]] = load ptr, ptr %[[VAL_242]], align 8, !dereferenceable !12, !align !13
// CHECK:         %[[VAL_244:.*]] = getelementptr inbounds [2 x ptr], ptr %[[VAL_223]], i64 0, i64 1
// CHECK:         %[[VAL_245:.*]] = load ptr, ptr %[[VAL_244]], align 8, !dereferenceable !12, !align !13
// CHECK:         %[[VAL_246:.*]] = load float, ptr %[[VAL_245]], align 4
// CHECK:         store float %[[VAL_246]], ptr %[[VAL_243]], align 4
// CHECK:         ret void
