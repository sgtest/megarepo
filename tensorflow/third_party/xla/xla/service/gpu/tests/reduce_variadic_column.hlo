// RUN: hlo-opt %s --platform=gpu --stage=llvm-before-optimizations --xla_gpu_target_config_filename=%S/../../../tools/hlo_opt/gpu_specs/%{GPU}.txtpb | FileCheck %s --check-prefixes=CHECK,CHECK-%{PTX}

HloModule Test, is_scheduled=true

Add {
  scalar_lhs.0 = f32[] parameter(0)
  scalar_rhs.0 = f32[] parameter(1)
  scalar_lhs.1 = f32[] parameter(2)
  scalar_rhs.1 = f32[] parameter(3)
  add.0 = f32[] add(scalar_lhs.0, scalar_lhs.1)
  add.1 = f32[] add(scalar_rhs.0, scalar_rhs.1)
  ROOT t = (f32[], f32[]) tuple(add.0, add.1)
}

fused_computation {
  param_0 = f32[5,200,300]{2,1,0} parameter(0)
  param_1 = f32[5,200,300]{2,1,0} parameter(1)
  param_2 = f32[] parameter(2)
  ROOT d.1 = (f32[200]{0}, f32[200]{0}) reduce(f32[5,200,300]{2,1,0} param_0, f32[5,200,300]{2,1,0} %param_1, f32[] param_2, f32[] param_2), dimensions={0,2}, to_apply=Add
}

ENTRY main {
  a = f32[5, 200, 300]{2,1,0} parameter(0)
  b = f32[5, 200, 300]{2,1,0} parameter(1)
  c = f32[] constant(0)
  ROOT wrapped_d = (f32[200]{0}, f32[200]{0}) fusion(f32[5,200,300]{2,1,0} a, f32[5,200,300]{2,1,0} b, f32[] c), kind=kInput, calls=fused_computation
}

// CHECK-LABEL: entry:
// CHECK:         %[[VAL_0:.*]] = alloca float, align 4
// CHECK:         %[[VAL_1:.*]] = alloca float, align 4
// CHECK:         %[[VAL_2:.*]] = alloca float, align 4
// CHECK:         %[[VAL_3:.*]] = alloca float, align 4
// CHECK:         %[[VAL_4:.*]] = alloca [2 x ptr], align 8
// CHECK:         %[[VAL_5:.*]] = alloca float, align 4
// CHECK:         %[[VAL_6:.*]] = alloca float, align 4
// CHECK:         %[[VAL_7:.*]] = alloca float, align 4
// CHECK:         %[[VAL_8:.*]] = alloca float, align 4
// CHECK:         %[[VAL_9:.*]] = alloca [2 x ptr], align 8
// CHECK:         %[[VAL_10:.*]] = alloca float, align 4
// CHECK:         %[[VAL_11:.*]] = alloca float, align 4
// CHECK:         %[[VAL_12:.*]] = alloca float, align 4
// CHECK:         %[[VAL_13:.*]] = alloca float, align 4
// CHECK:         %[[VAL_14:.*]] = alloca [2 x ptr], align 8
// CHECK:         %[[VAL_15:.*]] = alloca float, align 4
// CHECK:         %[[VAL_16:.*]] = alloca float, align 4
// CHECK:         %[[VAL_17:.*]] = alloca float, align 4
// CHECK:         %[[VAL_18:.*]] = alloca float, align 4
// CHECK:         %[[VAL_19:.*]] = alloca [2 x ptr], align 8
// CHECK:         %[[VAL_20:.*]] = alloca float, align 4
// CHECK:         %[[VAL_21:.*]] = alloca float, align 4
// CHECK:         %[[VAL_22:.*]] = alloca float, align 4
// CHECK:         %[[VAL_23:.*]] = alloca float, align 4
// CHECK:         %[[VAL_24:.*]] = alloca [2 x ptr], align 8
// CHECK:         %[[VAL_25:.*]] = alloca float, align 4
// CHECK:         %[[VAL_26:.*]] = alloca float, align 4
// CHECK:         %[[VAL_27:.*]] = alloca float, align 4
// CHECK:         %[[VAL_28:.*]] = alloca float, align 4
// CHECK:         %[[VAL_29:.*]] = alloca [2 x ptr], align 8
// CHECK:         %[[VAL_30:.*]] = alloca i32, align 4
// CHECK:         %[[VAL_31:.*]] = alloca float, align 4
// CHECK:         %[[VAL_32:.*]] = alloca float, align 4
// CHECK:         %[[VAL_33:.*]] = alloca [2 x ptr], align 8
// CHECK:         %[[VAL_34:.*]] = alloca i32, align 4
// CHECK:         %[[VAL_35:.*]] = alloca i32, align 4
// CHECK:         %[[VAL_36:.*]] = alloca i32, align 4
// CHECK:         %[[VAL_37:.*]] = alloca float, align 4
// CHECK:         %[[VAL_38:.*]] = alloca float, align 4
// CHECK:         %[[VAL_39:.*]] = alloca float, align 4
// CHECK:         %[[VAL_40:.*]] = alloca float, align 4
// CHECK-PTX:     %[[VAL_41:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.y(), !range !2
// CHECK-GCN:     %[[VAL_41:.*]] = call i32 @llvm.amdgcn.workgroup.id.y
// CHECK:         %[[VAL_42:.*]] = icmp eq i32 %[[VAL_41]], 0
// CHECK:         br i1 %[[VAL_42]], label %[[VAL_43:.*]], label %[[VAL_44:.*]]
// CHECK:       reduce-group-0-after:                             ; preds = %[[VAL_45:.*]], %[[VAL_46:.*]]
// CHECK:         ret void
// CHECK:       reduce-group-0-true:                              ; preds = %[[VAL_46]]
// CHECK:         %[[VAL_47:.*]] = load float, ptr %[[VAL_48:.*]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_47]], ptr %[[VAL_39]], align 4
// CHECK:         %[[VAL_49:.*]] = load float, ptr %[[VAL_48]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_49]], ptr %[[VAL_37]], align 4
// CHECK-PTX:     %[[VAL_50:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.tid.x(), !range !4
// CHECK-GCN:     %[[VAL_50:.*]] = call i32 @llvm.amdgcn.workitem.id.x
// CHECK-PTX:     %[[VAL_51:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !5
// CHECK-GCN:     %[[VAL_51:.*]] = call i32 @llvm.amdgcn.workgroup.id.x
// CHECK:         %[[VAL_52:.*]] = urem i32 %[[VAL_50]], 32
// CHECK:         %[[VAL_53:.*]] = udiv i32 %[[VAL_50]], 32
// CHECK:         %[[VAL_54:.*]] = mul i32 %[[VAL_51]], 1
// CHECK:         %[[VAL_55:.*]] = add i32 %[[VAL_54]], %[[VAL_53]]
// CHECK:         %[[VAL_56:.*]] = icmp ult i32 %[[VAL_55]], 200
// CHECK:         br i1 %[[VAL_56]], label %[[VAL_57:.*]], label %[[VAL_58:.*]]
// CHECK:       9:                                                ; preds = %[[VAL_43]]
// CHECK:         %[[VAL_60:.*]] = udiv i32 %[[VAL_52]], 32
// CHECK:         %[[VAL_59:.*]] = urem i32 %[[VAL_52]], 32
// CHECK:         %[[THREAD_X:.*]] = mul i32 %[[VAL_59]], 1
// CHECK:         %[[VAL_61:.*]] = urem i32 %[[VAL_52]], 32
// CHECK:         %[[VAL_62:.*]] = udiv i32 %[[VAL_55]], 1
// CHECK:         %[[VAL_63:.*]] = urem i32 %[[VAL_62]], 1
// CHECK:         %[[VAL_64:.*]] = udiv i32 %[[VAL_55]], 1
// CHECK:         %[[VAL_65:.*]] = urem i32 %[[VAL_64]], 200
// CHECK:         %[[VAL_66:.*]] = udiv i32 %[[VAL_55]], 200
// CHECK:         %[[VAL_69:.*]] = icmp eq i32 %[[VAL_63]], 0
// CHECK:         %[[VAL_70:.*]] = select i1 %[[VAL_69]], i32 300, i32 512
// CHECK:         %[[VAL_71:.*]] = mul i32 %[[VAL_66]], 5
// CHECK:         %[[VAL_72:.*]] = mul i32 %[[VAL_65]], 1
// CHECK:         %[[VAL_73:.*]] = mul i32 %[[VAL_63]], 512
// CHECK:         store i32 0, ptr %[[VAL_36]], align 4
// CHECK:         br label %[[VAL_77:.*]]
// CHECK:       loop0.loop_header:                               ; preds = %[[VAL_78:.*]], %[[VAL_57]]
// CHECK:         %[[VAL_79:.*]] = load i32, ptr %[[VAL_36]], align 4
// CHECK:         %[[VAL_80:.*]] = icmp uge i32 %[[VAL_79]], 5
// CHECK:         br i1 %[[VAL_80]], label %[[VAL_81:.*]], label %[[VAL_82:.*]]
// CHECK:       loop0.loop_body:                                 ; preds = %[[VAL_77]]
// CHECK:         %[[VAL_83:.*]] = add nuw nsw i32 %[[VAL_79]], 1
// CHECK:         store i32 %[[VAL_83]], ptr %[[VAL_36]], align 4
// CHECK:         %[[VAL_84:.*]] = icmp eq i32 %[[VAL_79]], 0
// CHECK:         store i32 %[[VAL_60]], ptr %[[VAL_35]], align 4
// CHECK:         br label %[[VAL_86:.*]]
// CHECK:       loop1.loop_header:                            ; preds = %[[VAL_87:.*]], %[[VAL_82]]
// CHECK:         %[[VAL_88:.*]] = load i32, ptr %[[VAL_35]], align 4
// CHECK:         %[[VAL_89:.*]] = icmp uge i32 %[[VAL_88]], 1
// CHECK:         br i1 %[[VAL_89]], label %[[VAL_78]], label %[[VAL_90:.*]]
// CHECK:       loop1.loop_body:                              ; preds = %[[VAL_86]]
// CHECK:         %[[VAL_91:.*]] = add nuw nsw i32 %[[VAL_88]], 1
// CHECK:         store i32 %[[VAL_91]], ptr %[[VAL_35]], align 4
// CHECK:         %[[VAL_92:.*]] = icmp eq i32 %[[VAL_88]], %[[VAL_60]]
// CHECK:         %[[VAL_93:.*]] = icmp eq i32 512, %[[VAL_70]]
// CHECK:         br i1 %[[VAL_93]], label %[[VAL_94:.*]], label %[[VAL_95:.*]]
// CHECK:       is_full_tile-after:                               ; preds = %[[VAL_96:.*]], %[[VAL_97:.*]]
// CHECK:         br label %[[VAL_86]], !llvm.loop !6
// CHECK:       loop1.loop_exit:                              ; preds = %[[VAL_86]]
// CHECK:         br label %[[VAL_77]], !llvm.loop !8
// CHECK:       loop0.loop_exit:                                 ; preds = %[[VAL_77]]
// CHECK:         %[[VAL_98:.*]] = load float, ptr %[[VAL_39]], align 4
// CHECK:         %[[VAL_99:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_98]], i32 16, i32 31)
// CHECK:         store float %[[VAL_99]], ptr %[[VAL_26]], align 4
// CHECK:         %[[VAL_100:.*]] = load float, ptr %[[VAL_37]], align 4
// CHECK:         %[[VAL_101:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_100]], i32 16, i32 31)
// CHECK:         store float %[[VAL_101]], ptr %[[VAL_25]], align 4
// CHECK:         %[[VAL_102:.*]] = getelementptr inbounds [2 x ptr], ptr %[[VAL_24]], i64 0, i64 0
// CHECK:         store ptr %[[VAL_22]], ptr %[[VAL_102]], align 8
// CHECK:         %[[VAL_103:.*]] = getelementptr inbounds [2 x ptr], ptr %[[VAL_24]], i64 0, i64 1
// CHECK:         store ptr %[[VAL_23]], ptr %[[VAL_103]], align 8
// CHECK:         call void @[[ADD:Add.*]](ptr %[[VAL_39]], ptr %[[VAL_37]], ptr %[[VAL_26]], ptr %[[VAL_25]], ptr %[[VAL_24]])
// CHECK:         %[[VAL_104:.*]] = load float, ptr %[[VAL_22]], align 4
// CHECK:         %[[VAL_105:.*]] = load float, ptr %[[VAL_23]], align 4
// CHECK:         store float %[[VAL_104]], ptr %[[VAL_39]], align 4
// CHECK:         store float %[[VAL_105]], ptr %[[VAL_37]], align 4
// CHECK:         %[[VAL_106:.*]] = load float, ptr %[[VAL_39]], align 4
// CHECK:         %[[VAL_107:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_106]], i32 8, i32 31)
// CHECK:         store float %[[VAL_107]], ptr %[[VAL_21]], align 4
// CHECK:         %[[VAL_108:.*]] = load float, ptr %[[VAL_37]], align 4
// CHECK:         %[[VAL_109:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_108]], i32 8, i32 31)
// CHECK:         store float %[[VAL_109]], ptr %[[VAL_20]], align 4
// CHECK:         %[[VAL_110:.*]] = getelementptr inbounds [2 x ptr], ptr %[[VAL_19]], i64 0, i64 0
// CHECK:         store ptr %[[VAL_17]], ptr %[[VAL_110]], align 8
// CHECK:         %[[VAL_111:.*]] = getelementptr inbounds [2 x ptr], ptr %[[VAL_19]], i64 0, i64 1
// CHECK:         store ptr %[[VAL_18]], ptr %[[VAL_111]], align 8
// CHECK:         call void @[[ADD]](ptr %[[VAL_39]], ptr %[[VAL_37]], ptr %[[VAL_21]], ptr %[[VAL_20]], ptr %[[VAL_19]])
// CHECK:         %[[VAL_112:.*]] = load float, ptr %[[VAL_17]], align 4
// CHECK:         %[[VAL_113:.*]] = load float, ptr %[[VAL_18]], align 4
// CHECK:         store float %[[VAL_112]], ptr %[[VAL_39]], align 4
// CHECK:         store float %[[VAL_113]], ptr %[[VAL_37]], align 4
// CHECK:         %[[VAL_114:.*]] = load float, ptr %[[VAL_39]], align 4
// CHECK:         %[[VAL_115:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_114]], i32 4, i32 31)
// CHECK:         store float %[[VAL_115]], ptr %[[VAL_16]], align 4
// CHECK:         %[[VAL_116:.*]] = load float, ptr %[[VAL_37]], align 4
// CHECK:         %[[VAL_117:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_116]], i32 4, i32 31)
// CHECK:         store float %[[VAL_117]], ptr %[[VAL_15]], align 4
// CHECK:         %[[VAL_118:.*]] = getelementptr inbounds [2 x ptr], ptr %[[VAL_14]], i64 0, i64 0
// CHECK:         store ptr %[[VAL_12]], ptr %[[VAL_118]], align 8
// CHECK:         %[[VAL_119:.*]] = getelementptr inbounds [2 x ptr], ptr %[[VAL_14]], i64 0, i64 1
// CHECK:         store ptr %[[VAL_13]], ptr %[[VAL_119]], align 8
// CHECK:         call void @[[ADD]](ptr %[[VAL_39]], ptr %[[VAL_37]], ptr %[[VAL_16]], ptr %[[VAL_15]], ptr %[[VAL_14]])
// CHECK:         %[[VAL_120:.*]] = load float, ptr %[[VAL_12]], align 4
// CHECK:         %[[VAL_121:.*]] = load float, ptr %[[VAL_13]], align 4
// CHECK:         store float %[[VAL_120]], ptr %[[VAL_39]], align 4
// CHECK:         store float %[[VAL_121]], ptr %[[VAL_37]], align 4
// CHECK:         %[[VAL_122:.*]] = load float, ptr %[[VAL_39]], align 4
// CHECK:         %[[VAL_123:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_122]], i32 2, i32 31)
// CHECK:         store float %[[VAL_123]], ptr %[[VAL_11]], align 4
// CHECK:         %[[VAL_124:.*]] = load float, ptr %[[VAL_37]], align 4
// CHECK:         %[[VAL_125:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_124]], i32 2, i32 31)
// CHECK:         store float %[[VAL_125]], ptr %[[VAL_10]], align 4
// CHECK:         %[[VAL_126:.*]] = getelementptr inbounds [2 x ptr], ptr %[[VAL_9]], i64 0, i64 0
// CHECK:         store ptr %[[VAL_7]], ptr %[[VAL_126]], align 8
// CHECK:         %[[VAL_127:.*]] = getelementptr inbounds [2 x ptr], ptr %[[VAL_9]], i64 0, i64 1
// CHECK:         store ptr %[[VAL_8]], ptr %[[VAL_127]], align 8
// CHECK:         call void @[[ADD]](ptr %[[VAL_39]], ptr %[[VAL_37]], ptr %[[VAL_11]], ptr %[[VAL_10]], ptr %[[VAL_9]])
// CHECK:         %[[VAL_128:.*]] = load float, ptr %[[VAL_7]], align 4
// CHECK:         %[[VAL_129:.*]] = load float, ptr %[[VAL_8]], align 4
// CHECK:         store float %[[VAL_128]], ptr %[[VAL_39]], align 4
// CHECK:         store float %[[VAL_129]], ptr %[[VAL_37]], align 4
// CHECK:         %[[VAL_130:.*]] = load float, ptr %[[VAL_39]], align 4
// CHECK:         %[[VAL_131:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_130]], i32 1, i32 31)
// CHECK:         store float %[[VAL_131]], ptr %[[VAL_6]], align 4
// CHECK:         %[[VAL_132:.*]] = load float, ptr %[[VAL_37]], align 4
// CHECK:         %[[VAL_133:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_132]], i32 1, i32 31)
// CHECK:         store float %[[VAL_133]], ptr %[[VAL_5]], align 4
// CHECK:         %[[VAL_134:.*]] = getelementptr inbounds [2 x ptr], ptr %[[VAL_4]], i64 0, i64 0
// CHECK:         store ptr %[[VAL_2]], ptr %[[VAL_134]], align 8
// CHECK:         %[[VAL_135:.*]] = getelementptr inbounds [2 x ptr], ptr %[[VAL_4]], i64 0, i64 1
// CHECK:         store ptr %[[VAL_3]], ptr %[[VAL_135]], align 8
// CHECK:         call void @[[ADD]](ptr %[[VAL_39]], ptr %[[VAL_37]], ptr %[[VAL_6]], ptr %[[VAL_5]], ptr %[[VAL_4]])
// CHECK:         %[[VAL_136:.*]] = load float, ptr %[[VAL_2]], align 4
// CHECK:         %[[VAL_137:.*]] = load float, ptr %[[VAL_3]], align 4
// CHECK:         store float %[[VAL_136]], ptr %[[VAL_39]], align 4
// CHECK:         store float %[[VAL_137]], ptr %[[VAL_37]], align 4
// CHECK:         %[[VAL_138:.*]] = udiv i32 %[[VAL_59]], 32
// CHECK:         %[[VAL_139:.*]] = icmp eq i32 %[[VAL_61]], 0
// CHECK:         br i1 %[[VAL_139]], label %[[VAL_140:.*]], label %[[VAL_141:.*]]
// CHECK:       intra_warp_reduce_write-after:                    ; preds = %[[VAL_140]], %[[VAL_81]]
// CHECK:         call void @llvm.nvvm.barrier0()
// CHECK:         %[[VAL_142:.*]] = icmp eq i32 %[[VAL_138]], 0
// CHECK:         br i1 %[[VAL_142]], label %[[VAL_143:.*]], label %[[VAL_45]]
// CHECK:       inter_warp_reduce-after:                          ; preds = %[[VAL_144:.*]], %[[VAL_141]]
// CHECK:         br label %[[VAL_44]]
// CHECK:       early_return:                                     ; preds = %[[VAL_43]]
// CHECK:         ret void
// CHECK:       is_full_tile-true:                                ; preds = %[[VAL_90]]
// CHECK:         store i32 0, ptr %[[VAL_34]], align 4
// CHECK:         br label %[[VAL_146:.*]]
// CHECK:       loop2.loop_header:                            ; preds = %[[VAL_147:.*]], %[[VAL_94]]
// CHECK:         %[[VAL_148:.*]] = load i32, ptr %[[VAL_34]], align 4
// CHECK:         %[[VAL_149:.*]] = icmp uge i32 %[[VAL_148]], 16
// CHECK:         br i1 %[[VAL_149]], label %[[VAL_97]], label %[[VAL_147]]
// CHECK:       loop2.loop_body:                              ; preds = %[[VAL_146]]
// CHECK:         %[[VAL_150:.*]] = add nuw nsw i32 %[[VAL_148]], 1
// CHECK:         store i32 %[[VAL_150]], ptr %[[VAL_34]], align 4
// CHECK:         %[[VAL_151:.*]] = icmp eq i32 %[[VAL_148]], 0
// CHECK:         %[[VAL_152:.*]] = mul i32 %[[VAL_148]], 32
// CHECK:         %[[VAL_153:.*]] = add i32 %[[VAL_152]], 0
// CHECK:         %[[VAL_154:.*]] = add i32 %[[VAL_153]], %[[THREAD_X]]
// CHECK:         %[[VAL_85:.*]] = add i32 %[[VAL_71]], %[[VAL_79]]
// CHECK:         %[[VAL_155:.*]] = add i32 %[[VAL_72]], %[[VAL_88]]
// CHECK:         %[[VAL_156:.*]] = add i32 %[[VAL_73]], %[[VAL_154]]
// CHECK:         %[[VAL_157:.*]] = getelementptr inbounds [5 x [200 x [300 x float]]], ptr %[[VAL_158:.*]], i32 0, i32 %[[VAL_85]], i32 %[[VAL_155]], i32 %[[VAL_156]]
// CHECK:         %[[VAL_159:.*]] = load float, ptr %[[VAL_157]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_159]], ptr %[[VAL_40]], align 4
// CHECK:         %[[VAL_161:.*]] = getelementptr inbounds [5 x [200 x [300 x float]]], ptr %[[VAL_162:.*]], i32 0, i32 %[[VAL_85]], i32 %[[VAL_155]], i32 %[[VAL_156]]
// CHECK:         %[[VAL_163:.*]] = load float, ptr %[[VAL_161]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_163]], ptr %[[VAL_38]], align 4
// CHECK:         %[[VAL_165:.*]] = getelementptr inbounds [2 x ptr], ptr %[[VAL_33]], i64 0, i64 0
// CHECK:         store ptr %[[VAL_31]], ptr %[[VAL_165]], align 8
// CHECK:         %[[VAL_166:.*]] = getelementptr inbounds [2 x ptr], ptr %[[VAL_33]], i64 0, i64 1
// CHECK:         store ptr %[[VAL_32]], ptr %[[VAL_166]], align 8
// CHECK:         call void @[[ADD]](ptr %[[VAL_39]], ptr %[[VAL_37]], ptr %[[VAL_40]], ptr %[[VAL_38]], ptr %[[VAL_33]])
// CHECK:         %[[VAL_167:.*]] = load float, ptr %[[VAL_31]], align 4
// CHECK:         %[[VAL_168:.*]] = load float, ptr %[[VAL_32]], align 4
// CHECK:         store float %[[VAL_167]], ptr %[[VAL_39]], align 4
// CHECK:         store float %[[VAL_168]], ptr %[[VAL_37]], align 4
// CHECK:         br label %[[VAL_146]], !llvm.loop !9
// CHECK:       loop2.loop_exit:                              ; preds = %[[VAL_146]]
// CHECK:         br label %[[VAL_87]]
// CHECK:       is_full_tile-false:                               ; preds = %[[VAL_90]]
// CHECK:         store i32 0, ptr %[[VAL_30]], align 4
// CHECK:         br label %[[VAL_170:.*]]
// CHECK:       loop2.loop_header9:                          ; preds = %[[VAL_171:.*]], %[[VAL_95]]
// CHECK:         %[[VAL_172:.*]] = load i32, ptr %[[VAL_30]], align 4
// CHECK:         %[[VAL_173:.*]] = icmp uge i32 %[[VAL_172]], 16
// CHECK:         br i1 %[[VAL_173]], label %[[VAL_96]], label %[[VAL_174:.*]]
// CHECK:       loop2.loop_body10:                            ; preds = %[[VAL_170]]
// CHECK:         %[[VAL_175:.*]] = add nuw nsw i32 %[[VAL_172]], 1
// CHECK:         store i32 %[[VAL_175]], ptr %[[VAL_30]], align 4
// CHECK:         %[[VAL_176:.*]] = icmp eq i32 %[[VAL_172]], 0
// CHECK:         %[[VAL_177:.*]] = mul i32 %[[VAL_172]], 32
// CHECK:         %[[VAL_178:.*]] = add i32 %[[VAL_177]], 0
// CHECK:         %[[VAL_179:.*]] = add i32 %[[VAL_178]], %[[THREAD_X]]
// CHECK:         %[[VAL_180:.*]] = icmp ult i32 %[[VAL_179]], %[[VAL_70]]
// CHECK:         br i1 %[[VAL_180]], label %[[VAL_181:.*]], label %[[VAL_171]]
// CHECK:       x_in_tile-after:                                  ; preds = %[[VAL_181]], %[[VAL_174]]
// CHECK:         br label %[[VAL_170]], !llvm.loop !11
// CHECK:       loop2.loop_exit8:                             ; preds = %[[VAL_170]]
// CHECK:         br label %[[VAL_87]]
// CHECK:       x_in_tile-true:                                   ; preds = %[[VAL_174]]
// CHECK:         %[[VAL_85:.*]] = add i32 %[[VAL_71]], %[[VAL_79]]
// CHECK:         %[[VAL_182:.*]] = add i32 %[[VAL_72]], %[[VAL_88]]
// CHECK:         %[[VAL_183:.*]] = add i32 %[[VAL_73]], %[[VAL_179]]
// CHECK:         %[[VAL_184:.*]] = getelementptr inbounds [5 x [200 x [300 x float]]], ptr %[[VAL_158]], i32 0, i32 %[[VAL_85]], i32 %[[VAL_182]], i32 %[[VAL_183]]
// CHECK:         %[[VAL_185:.*]] = load float, ptr %[[VAL_184]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_185]], ptr %[[VAL_40]], align 4
// CHECK:         %[[VAL_187:.*]] = getelementptr inbounds [5 x [200 x [300 x float]]], ptr %[[VAL_162]], i32 0, i32 %[[VAL_85]], i32 %[[VAL_182]], i32 %[[VAL_183]]
// CHECK:         %[[VAL_188:.*]] = load float, ptr %[[VAL_187]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_188]], ptr %[[VAL_38]], align 4
// CHECK:         %[[VAL_190:.*]] = getelementptr inbounds [2 x ptr], ptr %[[VAL_29]], i64 0, i64 0
// CHECK:         store ptr %[[VAL_27]], ptr %[[VAL_190]], align 8
// CHECK:         %[[VAL_191:.*]] = getelementptr inbounds [2 x ptr], ptr %[[VAL_29]], i64 0, i64 1
// CHECK:         store ptr %[[VAL_28]], ptr %[[VAL_191]], align 8
// CHECK:         call void @[[ADD]](ptr %[[VAL_39]], ptr %[[VAL_37]], ptr %[[VAL_40]], ptr %[[VAL_38]], ptr %[[VAL_29]])
// CHECK:         %[[VAL_192:.*]] = load float, ptr %[[VAL_27]], align 4
// CHECK:         %[[VAL_193:.*]] = load float, ptr %[[VAL_28]], align 4
// CHECK:         store float %[[VAL_192]], ptr %[[VAL_39]], align 4
// CHECK:         store float %[[VAL_193]], ptr %[[VAL_37]], align 4
// CHECK:         br label %[[VAL_171]]
// CHECK:       intra_warp_reduce_write-true:                     ; preds = %[[VAL_81]]
// CHECK:         %[[VAL_196:.*]] = load float, ptr %[[VAL_39]], align 4
// CHECK:         %[[VAL_194:.*]] = getelementptr inbounds [1 x [1 x float]], ptr addrspace(3) @shared_cache, i32 0, i32 %[[VAL_53]], i32 %[[VAL_138]]
// CHECK:         %[[VAL_195:.*]] = addrspacecast ptr addrspace(3) %[[VAL_194]] to ptr
// CHECK:         store float %[[VAL_196]], ptr %[[VAL_195]], align 4
// CHECK:         %[[VAL_199:.*]] = load float, ptr %[[VAL_37]], align 4
// CHECK:         %[[VAL_197:.*]] = getelementptr inbounds [1 x [1 x float]], ptr addrspace(3) @shared_cache1, i32 0, i32 %[[VAL_53]], i32 %[[VAL_138]]
// CHECK:         %[[VAL_198:.*]] = addrspacecast ptr addrspace(3) %[[VAL_197]] to ptr
// CHECK:         store float %[[VAL_199]], ptr %[[VAL_198]], align 4
// CHECK:         br label %[[VAL_141]]
// CHECK:       inter_warp_reduce-true:                           ; preds = %[[VAL_141]]
// CHECK:         %[[VAL_200:.*]] = getelementptr inbounds [1 x [1 x float]], ptr addrspace(3) @shared_cache, i32 0, i32 %[[VAL_53]], i32 %[[VAL_61]]
// CHECK:         %[[VAL_201:.*]] = addrspacecast ptr addrspace(3) %[[VAL_200]] to ptr
// CHECK:         store float %[[VAL_47]], ptr %[[VAL_1]], align 4
// CHECK:         %[[VAL_202:.*]] = icmp ult i32 %[[VAL_59]], 1
// CHECK:         %[[VAL_203:.*]] = select i1 %[[VAL_202]], ptr %[[VAL_201]], ptr %[[VAL_1]]
// CHECK:         %[[VAL_204:.*]] = getelementptr inbounds [1 x [1 x float]], ptr addrspace(3) @shared_cache1, i32 0, i32 %[[VAL_53]], i32 %[[VAL_61]]
// CHECK:         %[[VAL_205:.*]] = addrspacecast ptr addrspace(3) %[[VAL_204]] to ptr
// CHECK:         store float %[[VAL_49]], ptr %[[VAL_0]], align 4
// CHECK:         %[[VAL_206:.*]] = icmp ult i32 %[[VAL_59]], 1
// CHECK:         %[[VAL_207:.*]] = select i1 %[[VAL_206]], ptr %[[VAL_205]], ptr %[[VAL_0]]
// CHECK:         %[[VAL_208:.*]] = icmp eq i32 %[[VAL_59]], 0
// CHECK:         br i1 %[[VAL_208]], label %[[VAL_209:.*]], label %[[VAL_144]]
// CHECK:       reduction_write_output-after:                     ; preds = %[[VAL_209]], %[[VAL_143]]
// CHECK:         br label %[[VAL_45]]
// CHECK:       reduction_write_output-true:                      ; preds = %[[VAL_143]]
// CHECK:         %[[VAL_211:.*]] = add i32 %[[VAL_72]], %[[VAL_60]]
// CHECK:         %[[VAL_212:.*]] = add i32 %[[VAL_73]], %[[THREAD_X]]
// CHECK:         %[[VAL_213:.*]] = udiv i32 %[[VAL_211]], 1
// CHECK:         %[[VAL_214:.*]] = getelementptr inbounds [200 x float], ptr %[[VAL_215:.*]], i32 0, i32 %[[VAL_213]]
// CHECK:         %[[VAL_216:.*]] = load float, ptr %[[VAL_203]], align 4
// CHECK:         store float %[[VAL_216]], ptr %[[VAL_214]], align 4
// CHECK:         %[[VAL_218:.*]] = add i32 %[[VAL_72]], %[[VAL_60]]
// CHECK:         %[[VAL_219:.*]] = add i32 %[[VAL_73]], %[[THREAD_X]]
// CHECK:         %[[VAL_220:.*]] = udiv i32 %[[VAL_218]], 1
// CHECK:         %[[VAL_221:.*]] = getelementptr inbounds [200 x float], ptr %[[VAL_222:.*]], i32 0, i32 %[[VAL_220]]
// CHECK:         %[[VAL_223:.*]] = load float, ptr %[[VAL_207]], align 4
// CHECK:         store float %[[VAL_223]], ptr %[[VAL_221]], align 4
// CHECK:         br label %[[VAL_144]]
// CHECK:       entry:
// CHECK:         %[[VAL_224:.*]] = alloca float, align 4
// CHECK:         %[[VAL_225:.*]] = alloca float, align 4
// CHECK:         %[[VAL_226:.*]] = alloca [2 x ptr], align 8
// CHECK:         %[[VAL_227:.*]] = alloca [2 x ptr], align 8
// CHECK:         %[[VAL_228:.*]] = alloca [2 x ptr], align 8
// CHECK:         %[[VAL_229:.*]] = load float, ptr %[[VAL_230:.*]], align 4
// CHECK:         %[[VAL_231:.*]] = load float, ptr %[[VAL_232:.*]], align 4
// CHECK:         %[[VAL_233:.*]] = fadd float %[[VAL_229]], %[[VAL_231]]
// CHECK:         store float %[[VAL_233]], ptr %[[VAL_225]], align 4
// CHECK:         %[[VAL_234:.*]] = load float, ptr %[[VAL_235:.*]], align 4
// CHECK:         %[[VAL_236:.*]] = load float, ptr %[[VAL_237:.*]], align 4
// CHECK:         %[[VAL_238:.*]] = fadd float %[[VAL_234]], %[[VAL_236]]
// CHECK:         store float %[[VAL_238]], ptr %[[VAL_224]], align 4
// CHECK:         %[[VAL_239:.*]] = getelementptr inbounds [2 x ptr], ptr %[[VAL_228]], i64 0, i64 0
// CHECK:         store ptr %[[VAL_225]], ptr %[[VAL_239]], align 8
// CHECK:         %[[VAL_240:.*]] = getelementptr inbounds [2 x ptr], ptr %[[VAL_228]], i64 0, i64 1
// CHECK:         store ptr %[[VAL_224]], ptr %[[VAL_240]], align 8
// CHECK:         %[[VAL_241:.*]] = getelementptr inbounds [2 x ptr], ptr %[[VAL_242:.*]], i64 0, i64 0
// CHECK:         %[[VAL_243:.*]] = load ptr, ptr %[[VAL_241]], align 8, !dereferenceable !12, !align !13
// CHECK:         %[[VAL_244:.*]] = getelementptr inbounds [2 x ptr], ptr %[[VAL_228]], i64 0, i64 0
// CHECK:         %[[VAL_245:.*]] = load ptr, ptr %[[VAL_244]], align 8, !dereferenceable !12, !align !13
// CHECK:         %[[VAL_246:.*]] = load float, ptr %[[VAL_245]], align 4
// CHECK:         store float %[[VAL_246]], ptr %[[VAL_243]], align 4
// CHECK:         %[[VAL_247:.*]] = getelementptr inbounds [2 x ptr], ptr %[[VAL_242]], i64 0, i64 1
// CHECK:         %[[VAL_248:.*]] = load ptr, ptr %[[VAL_247]], align 8, !dereferenceable !12, !align !13
// CHECK:         %[[VAL_249:.*]] = getelementptr inbounds [2 x ptr], ptr %[[VAL_228]], i64 0, i64 1
// CHECK:         %[[VAL_250:.*]] = load ptr, ptr %[[VAL_249]], align 8, !dereferenceable !12, !align !13
// CHECK:         %[[VAL_251:.*]] = load float, ptr %[[VAL_250]], align 4
// CHECK:         store float %[[VAL_251]], ptr %[[VAL_248]], align 4
// CHECK:         ret void
