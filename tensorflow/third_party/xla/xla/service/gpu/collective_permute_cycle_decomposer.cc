/* Copyright 2024 The OpenXLA Authors.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

#include "xla/service/gpu/collective_permute_cycle_decomposer.h"

#include <cstdint>
#include <utility>
#include <vector>

#include "absl/container/flat_hash_set.h"
#include "absl/log/check.h"
#include "absl/strings/string_view.h"
#include "xla/comparison_util.h"
#include "xla/hlo/ir/hlo_casting_utils.h"
#include "xla/hlo/ir/hlo_computation.h"
#include "xla/hlo/ir/hlo_instruction.h"
#include "xla/hlo/ir/hlo_instructions.h"
#include "xla/hlo/ir/hlo_opcode.h"
#include "xla/hlo/utils/hlo_query.h"
#include "xla/literal_util.h"
#include "xla/service/gpu/backend_configs.pb.h"
#include "xla/shape.h"
#include "xla/shape_util.h"
#include "xla/status.h"
#include "xla/xla_data.pb.h"
#include "tsl/platform/errors.h"

namespace xla {

namespace {
using SourceTargetPair = std::pair<int64_t, int64_t>;
using SourceTargetPairs = std::vector<SourceTargetPair>;
enum class CycleType { kUnknown, kForward, kBackward };

// Returns true if the (source, target) pairs form a forward cycle with all
// participants in the cycle, such as {{0,1},{1,2},{2,3},{3,0}}. We assume that
// the (source, target) pairs are ordered as they are generated by SPMD
// partitioning.
//
bool IsForwardCycle(const SourceTargetPairs& pairs) {
  int64_t num_pairs = pairs.size();
  const SourceTargetPair& last_pair = pairs[num_pairs - 1];
  if (last_pair.first != num_pairs - 1 || last_pair.second != 0) {
    return false;
  }
  for (int64_t i = 0; i < num_pairs - 1; ++i) {
    const SourceTargetPair& pair = pairs[i];
    if (pair.first != i || pair.second != i + 1) {
      return false;
    }
  }
  return true;
}

// Returns true if the (source, target) pairs form a backward cycle with all
// participants in the cycle, such as {{0,3},{1,0},{2,1},{3,2}}. We assume that
// the (source, target) pairs are ordered as they are generated by SPMD
// partitioning.
//
bool IsBackwardCycle(const SourceTargetPairs& pairs) {
  int64_t num_pairs = pairs.size();
  const SourceTargetPair& first_pair = pairs[0];
  if (first_pair.first != 0 || first_pair.second != num_pairs - 1) {
    return false;
  }
  for (int64_t i = 1; i < num_pairs; ++i) {
    const SourceTargetPair& pair = pairs[i];
    if (pair.first != i || pair.second != i - 1) {
      return false;
    }
  }
  return true;
}

// Returns true if the CollectivePermute instruction has a cycle in its
// source-target pairs and should be decomposed.
CycleType ShouldDecomposeWithCycleType(
    const HloCollectivePermuteInstruction& collective_permute,
    int64_t threshold_in_bytes) {
  if (!collective_permute.channel_id().has_value()) {
    return CycleType::kUnknown;
  }

  auto backend_config =
      collective_permute.backend_config<xla::gpu::GpuBackendConfig>()
          ->collective_backend_config();
  if (backend_config.is_sync()) {
    return CycleType::kUnknown;
  }
  if (collective_permute.operand_count() != 1) {
    return CycleType::kUnknown;
  }

  const Shape& result_shape = collective_permute.shape();
  // Skip the transformation if there is any context data.
  if (result_shape.tuple_shapes_size() != 2) {
    return CycleType::kUnknown;
  }

  const Shape& shape = result_shape.tuple_shapes(0);
  CHECK(shape.IsArray());
  if (ShapeUtil::ByteSizeOf(shape) < threshold_in_bytes) {
    return CycleType::kUnknown;
  }

  const SourceTargetPairs& pairs = collective_permute.source_target_pairs();
  if (pairs.size() == 1) {
    return CycleType::kUnknown;
  }

  return IsForwardCycle(pairs)    ? CycleType::kForward
         : IsBackwardCycle(pairs) ? CycleType::kBackward
                                  : CycleType::kUnknown;
}

// Decomposes a CollectivePermute instruction with a cycle in its source-target
// pairs into two CollectivePermute instructions.
Status DecomposeCollectivePermuteCycle(HloCollectivePermuteInstruction* cp,
                                       HloComputation* computation,
                                       HloModule* module,
                                       int64_t next_channel_id,
                                       CycleType cycle_type) {
  const SourceTargetPairs& pairs = cp->source_target_pairs();
  int64_t num_pairs = pairs.size();
  // A forward cycle has its backedge at the end as in
  // {{0,1},{1,2},{2,3},{3,0}} while a backward cycle has its backedge at the
  // beginning as in {{0,3},{1,0},{2,1},{3,2}}.
  auto backedge_start = cycle_type == CycleType::kBackward
                            ? pairs.begin()
                            : pairs.begin() + num_pairs - 1;
  auto other_edges_start =
      cycle_type == CycleType::kBackward ? pairs.begin() + 1 : pairs.begin();
  SourceTargetPairs backedge(backedge_start, backedge_start + 1);
  SourceTargetPairs other_edges(other_edges_start,
                                other_edges_start + num_pairs - 1);
  const OpMetadata& metadata = cp->metadata();

  // Create the CollectivePermute instruction for the communication represented
  // by the backedge.
  HloInstruction* cp1 =
      computation->AddInstruction(HloInstruction::CreateCollectivePermute(
          cp->shape(), cp->mutable_operand(0), backedge,
          cp->channel_id().value()));
  HloInstruction* cp1_done =
      computation->AddInstruction(HloInstruction::CreateUnary(
          cp->shape().tuple_shapes(0), HloOpcode::kCollectivePermuteDone, cp1));
  cp1->set_metadata(metadata);
  int64_t cp1_receiver = backedge.back().second;

  // Create the CollectivePermute instruction for the communication represented
  // byt other edges.
  HloInstruction* cp2 =
      computation->AddInstruction(HloInstruction::CreateCollectivePermute(
          cp->shape(), cp->mutable_operand(0), other_edges, next_channel_id));
  HloInstruction* cp2_done =
      computation->AddInstruction(HloInstruction::CreateUnary(
          cp->shape().tuple_shapes(0), HloOpcode::kCollectivePermuteDone, cp2));
  cp2->set_metadata(metadata);

  // Calculate the received data as follows:
  //   partition = u32[] partition-id()
  //   constant = u32[] constant(cp1_receiver)
  //   compare0 = pred[] compare(partition, cp1_received), direction=EQ
  //   compare = pred[?] broadcast(compare0), dimensions={}
  //   recv-data = type[?] select(compare, cp1_done, cp2_done)
  HloInstruction* partition =
      computation->AddInstruction(HloInstruction::CreatePartitionId());
  HloInstruction* constant = computation->AddInstruction(
      HloInstruction::CreateConstant(LiteralUtil::CreateR0(U32, cp1_receiver)));
  HloInstruction* compare0 = computation->AddInstruction(
      HloInstruction::CreateCompare(ShapeUtil::MakeShape(PRED, {}), partition,
                                    constant, Comparison::Direction::kEq));
  HloInstruction* compare =
      computation->AddInstruction(HloInstruction::CreateBroadcast(
          ShapeUtil::MakeShape(PRED, cp1_done->shape().dimensions()), compare0,
          {}));
  HloInstruction* recv_data =
      computation->AddInstruction(HloInstruction::CreateTernary(
          cp1_done->shape(), HloOpcode::kSelect, compare, cp1_done, cp2_done));

  HloInstruction* cp_done = cp->users().front();
  TF_RETURN_IF_ERROR(cp_done->ReplaceAllUsesWith(recv_data));
  TF_RETURN_IF_ERROR(computation->RemoveInstructionAndUnusedOperands(cp_done));
  TF_RETURN_IF_ERROR(computation->RemoveInstructionAndUnusedOperands(cp));

  return OkStatus();
}
}  // namespace

absl::StatusOr<bool> CollectivePermuteCycleDecomposer::Run(
    HloModule* module,
    const absl::flat_hash_set<absl::string_view>& execution_threads) {
  bool changed = false;
  int64_t next_channel_id;
  for (auto comp : module->computations(execution_threads)) {
    for (auto hlo : comp->MakeInstructionPostOrder()) {
      if (hlo->opcode() != HloOpcode::kCollectivePermuteStart) {
        continue;
      }
      auto collective_permute = Cast<HloCollectivePermuteInstruction>(hlo);
      CycleType cycle_type = ShouldDecomposeWithCycleType(*collective_permute,
                                                          threshold_in_bytes_);
      if (cycle_type != CycleType::kUnknown) {
        if (changed == false) {
          next_channel_id = hlo_query::NextChannelId(*module);
          changed = true;
        }
        TF_RETURN_IF_ERROR(DecomposeCollectivePermuteCycle(
            collective_permute, comp, module, next_channel_id++, cycle_type));
      }
    }
  }
  return changed;
}

}  // namespace xla
