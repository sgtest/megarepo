// Protobuf messages for configuring StableHLO Quantizer.
syntax = "proto3";

package stablehlo.quantization;

option cc_enable_arenas = true;

// Represents a single TFRecord file. See
// https://www.tensorflow.org/tutorials/load_data/tfrecord for details on the
// TFRecord format.
// Next ID: 2
message TfRecordFile {
  string path = 1;
}

// Configures a single representative dataset used to calibrate a single
// function.
// Next ID: 3
message RepresentativeDatasetConfig {
  oneof file {
    // Represents representative dataset saved as a .tfrecord file format.
    TfRecordFile tf_record = 1;
  }

  // [TF SavedModel] Identifies a SignatureDef which represents a single
  // logical function in a graph.
  optional string signature_key = 2;
}

// Preset config for static-range post-training quantization (PTQ).
// Minimal user input about representative datasets is required. Representative
// datasets are required for static-range PTQ to retrieve quantization
// statistics via calibration.
// Next ID: 3
message StaticRangePtqPreset {
  // Configures representative dataset. Each item corresponds to a
  // representative dataset used to calibrate a function.
  repeated RepresentativeDatasetConfig representative_datasets = 1;

  // NOTE: This field will be deprecated.
  // Granularity should be controlled in custom configuration, deprecating
  // this field once available.
  // If set true, enable channel-wise quantization for all supported ops.
  // This value is true by default.
  bool enable_per_channel_quantization = 2;
}

// Metadata specific to the input TensorFlow SavedModel, which may be required
// to identify the specific MetaGraphDef to quantize, for example.
// Next ID: 2
message TfSavedModelConfig {
  // Set of tags that uniquely identify the `MetaGraphDef` existing in the
  // input SavedModel.
  repeated string tags = 1;
}

// Configures the graph transformation pipeline for quantization.
message PipelineConfig {
  // When set to True, unpacks ops with uniform quantized types into operations
  // without uniform quantized types (mostly i8 or i32). Useful when the target
  // hardware performs better with integer ops.
  // Default value: true
  optional bool unpack_quantized_types = 1;
}

// Quantization configuration for StableHLO Quantizer. This is the primary
// message containing all configurable options.
// Next ID: 4
message QuantizationConfig {
  oneof preset {
    // Performs best-effort static-range post-training quantization (PTQ).
    StaticRangePtqPreset static_range_ptq_preset = 1;
  }

  // TF SavedModel specific information for the input model.
  TfSavedModelConfig tf_saved_model = 2;

  // Configures the graph transformation pipeline for quantization.
  PipelineConfig pipeline_config = 3;
}
