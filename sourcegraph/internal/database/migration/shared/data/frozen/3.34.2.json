{
	"codeinsights": {
		"Definitions": [
			{
				"ID": -1000000000,
				"Name": "squashed migrations (privileged)",
				"UpQuery": "",
				"DownQuery": "",
				"Privileged": true,
				"NonIdempotent": false,
				"Parents": null,
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000000,
				"Name": "squashed migrations",
				"UpQuery": "-- empty migration",
				"DownQuery": "-- empty migration",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					-1000000000
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000001,
				"Name": "initial schema",
				"UpQuery": "CREATE EXTENSION IF NOT EXISTS timescaledb;\nCREATE EXTENSION IF NOT EXISTS pg_trgm;\nCREATE EXTENSION IF NOT EXISTS citext;\n\n-- Records repository names, both historical and present, using a unique repository _name_ ID\n-- (unrelated to the repository ID.)\nCREATE TABLE repo_names (\n    -- The repository _name_ ID.\n    id bigserial NOT NULL PRIMARY KEY,\n\n    -- The name, trigram-indexed for fast e.g. regexp filtering.\n    name citext NOT NULL,\n\n    CONSTRAINT check_name_nonempty CHECK ((name OPERATOR(\u003c\u003e) ''::citext))\n);\n\n-- Enforce that names are unique.\nCREATE UNIQUE INDEX repo_names_name_unique_idx ON repo_names(name);\n\n-- Create trigram indexes for repository name filtering based on e.g. regexps.\nCREATE INDEX repo_names_name_trgm ON repo_names USING gin (lower((name)::text) gin_trgm_ops);\n\n\n-- Records arbitrary metadata about events. Stored in a separate table as it is often repeated\n-- for multiple events.\nCREATE TABLE metadata (\n    -- The metadata ID.\n    id bigserial NOT NULL PRIMARY KEY,\n\n    -- Metadata about this event, this can be any arbitrary JSON metadata which will be returned\n    -- when querying events, and can be filtered on and grouped using jsonb operators ?, ?\u0026, ?|,\n    -- and @\u003e. This should be small data only, primary use case is small lists such as:\n    --\n    --  {\"java_versions\": [...]}\n    --  {\"languages\":     [...]}\n    --  {\"pull_requests\": [...]}\n    --  {\"annotations\":   [...]}\n    --\n    metadata jsonb NOT NULL\n);\n\n-- Enforce that metadata is unique.\nCREATE UNIQUE INDEX metadata_metadata_unique_idx ON metadata(metadata);\n\n-- Index metadata to optimize WHERE clauses with jsonb ?, ?\u0026, ?|, and @\u003e operators.\nCREATE INDEX metadata_metadata_gin ON metadata USING GIN (metadata);\n\n-- Records events over time associated with a repository (or none, i.e. globally) where a single\n-- numerical value is going arbitrarily up and down.\n--\n-- Repository association is based on both repository ID and name. The ID can be used to refer to\n-- a specific repository, or lookup the current name of a repository after it has been e.g. renamed.\n-- The name can be used to refer to the name of the repository at the time of the event's creation,\n-- for example to trace the change in a gauge back to a repository being renamed.\nCREATE TABLE series_points (\n    -- A unique identifier for the series of data being recorded. This is not an ID from another\n    -- table, but rather just a unique identifier.\n    series_id integer,\n\n    -- The timestamp of the recorded event.\n    time TIMESTAMPTZ NOT NULL,\n\n    -- The floating point value at the time of the event.\n    value double precision NOT NULL,\n\n    -- Associated metadata for this event, if any.\n    metadata_id integer,\n\n    -- The repository ID (from the main application DB) at the time the event was created. Note\n    -- that the repository may no longer exist / be valid at query time, however.\n    --\n    -- null if the event was not for a single repository (i.e. a global gauge).\n    repo_id integer,\n\n    -- The most recently known name for the repository, updated periodically to account for e.g.\n    -- repository renames. If the repository was deleted, this is still the most recently known\n    -- name.\n    --\n    -- null if the event was not for a single repository (i.e. a global gauge).\n    repo_name_id integer,\n\n    -- The repository name as it was known at the time the event was created. It may have been renamed\n    -- since.\n    original_repo_name_id integer,\n\n    -- Ensure if one repo association field is specified, all are.\n    CONSTRAINT check_repo_fields_specifity CHECK (\n        ((repo_id IS NULL) AND (repo_name_id IS NULL) AND (original_repo_name_id IS NULL))\n        OR\n        ((repo_id IS NOT NULL) AND (repo_name_id IS NOT NULL) AND (original_repo_name_id IS NOT NULL))\n    ),\n\n    FOREIGN KEY (metadata_id) REFERENCES metadata(id) ON DELETE CASCADE DEFERRABLE,\n    FOREIGN KEY (repo_name_id) REFERENCES repo_names(id) ON DELETE CASCADE DEFERRABLE,\n    FOREIGN KEY (original_repo_name_id) REFERENCES repo_names(id) ON DELETE CASCADE DEFERRABLE\n);\n\n-- Create hypertable, partitioning events by time.\n-- See https://docs.timescale.com/latest/using-timescaledb/hypertables\nSELECT create_hypertable('series_points', 'time');\n\n-- Create btree indexes for repository filtering.\nCREATE INDEX series_points_repo_id_btree ON series_points USING btree (repo_id);\nCREATE INDEX series_points_repo_name_id_btree ON series_points USING btree (repo_name_id);\nCREATE INDEX series_points_original_repo_name_id_btree ON series_points USING btree (original_repo_name_id);",
				"DownQuery": "DROP TABLE IF EXISTS series_points;\nDROP TABLE IF EXISTS repo_names;\nDROP TABLE IF EXISTS metadata;",
				"Privileged": true,
				"NonIdempotent": false,
				"Parents": [
					1000000000
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000002,
				"Name": "comments",
				"UpQuery": "COMMENT ON TABLE repo_names IS 'Records repository names, both historical and present, using a unique repository _name_ ID (unrelated to the repository ID.)';\nCOMMENT ON COLUMN repo_names.id IS 'The repository _name_ ID.';\nCOMMENT ON COLUMN repo_names.name IS 'The repository name string, with unique constraint for table entry deduplication and trigram index for e.g. regex filtering.';\n\nCOMMENT ON TABLE metadata IS 'Records arbitrary metadata about events. Stored in a separate table as it is often repeated for multiple events.';\nCOMMENT ON COLUMN metadata.id IS 'The metadata ID.';\nCOMMENT ON COLUMN metadata.metadata IS 'Metadata about some event, this can be any arbitrary JSON emtadata which will be returned when querying events, and can be filtered on and grouped using jsonb operators ?, ?\u0026, ?|, and @\u003e. This should be small data only.';\n\nCOMMENT ON TABLE series_points IS 'Records events over time associated with a repository (or none, i.e. globally) where a single numerical value is going arbitrarily up and down.  Repository association is based on both repository ID and name. The ID can be used to refer toa specific repository, or lookup the current name of a repository after it has been e.g. renamed. The name can be used to refer to the name of the repository at the time of the events creation, for example to trace the change in a gauge back to a repository being renamed.';\nCOMMENT ON COLUMN series_points.series_id IS 'A unique identifier for the series of data being recorded. This is not an ID from another table, but rather just a unique identifier.';\nCOMMENT ON COLUMN series_points.time IS 'The timestamp of the recorded event.';\nCOMMENT ON COLUMN series_points.value IS 'The floating point value at the time of the event.';\nCOMMENT ON COLUMN series_points.metadata_id IS 'Associated metadata for this event, if any.';\nCOMMENT ON COLUMN series_points.repo_id IS 'The repository ID (from the main application DB) at the time the event was created. Note that the repository may no longer exist / be valid at query time, however.';\nCOMMENT ON COLUMN series_points.repo_name_id IS 'The most recently known name for the repository, updated periodically to account for e.g. repository renames. If the repository was deleted, this is still the most recently known name.  null if the event was not for a single repository (i.e. a global gauge).';\nCOMMENT ON COLUMN series_points.original_repo_name_id IS 'The repository name as it was known at the time the event was created. It may have been renamed since.';",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000001
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000003,
				"Name": "insights series id",
				"UpQuery": "DELETE FROM series_points; -- affects dev environments only, others never had data in this table.\nALTER TABLE series_points ALTER COLUMN series_id TYPE text;\nALTER TABLE series_points ALTER COLUMN series_id SET NOT NULL;\n\n-- Give series_id a btree index since we'll be filtering on it very frequently.\nCREATE INDEX series_points_series_id_btree ON series_points USING btree (series_id);",
				"DownQuery": "",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000002
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000004,
				"Name": "no telemetry",
				"UpQuery": "-- Disables TimescaleDB telemetry, which we cannot easily ship with Sourcegraph\n-- in a reasonable way (requires fairly in-depth analysis of what gets sent, etc.)\n-- See https://docs.timescale.com/latest/using-timescaledb/telemetry\n--\n-- Cannot be run inside of a transaction block.",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000003
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000005,
				"Name": "wipe data",
				"UpQuery": "-- We changed the default timeframe that the historical insights builder produces from:\n--\n-- 1 data point per week, for the last 52 weeks\n--\n-- To:\n--\n-- 1 data point per month, for the last 6 months\n--\n-- To avoid any confusion and just start fresh, we wipe all data here for now. This isn't\n-- needed in general when making this change, but is useful in this specific situation.\nDELETE FROM series_points;",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000004
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000006,
				"Name": "commit index",
				"UpQuery": "CREATE TABLE commit_index\n(\n\tcommitted_at TIMESTAMPTZ NOT NULL,\n\trepo_id INT NOT NULL,\n\tcommit_bytea bytea NOT NULL,\n\n\tPRIMARY KEY (committed_at, repo_id, commit_bytea)\n);\n\nCREATE INDEX commit_index_repo_id_idx ON commit_index USING btree (repo_id, committed_at);\n\nCREATE TABLE commit_index_metadata\n(\n    repo_id INT NOT NULL PRIMARY KEY,\n    enabled BOOLEAN NOT NULL DEFAULT 'y',\n    last_indexed_at TIMESTAMPTZ NOT NULL DEFAULT '1900-01-01'\n);",
				"DownQuery": "DROP TABLE IF EXISTS commit_index;\nDROP TABLE IF EXISTS commit_index_metadata;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000005
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000007,
				"Name": "series points index",
				"UpQuery": "CREATE INDEX IF NOT EXISTS series_points_series_id_repo_id_time_idx ON series_points (series_id, repo_id, time);",
				"DownQuery": "DROP INDEX IF EXISTS series_points_series_id_repo_id_time_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000006
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000008,
				"Name": "insights views series",
				"UpQuery": "CREATE TABLE insight_series\n(\n    id                      SERIAL    NOT NULL PRIMARY KEY,\n    series_id               TEXT      NOT NULL,\n    query                   TEXT      NOT NULL,\n    created_at              TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,\n    oldest_historical_at    TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP - INTERVAL '1 year',\n    last_recorded_at        TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP - INTERVAL '10 year',\n    next_recording_after    TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,\n    recording_interval_days INT       NOT NULL DEFAULT 1,\n    deleted_at              TIMESTAMP\n);\n\ncomment on table insight_series is 'Data series that comprise code insights.';\n\ncomment on column insight_series.id is 'Primary key ID of this series';\ncomment on column insight_series.series_id is 'Unique Series ID represents a globally unique identifier for this series.';\ncomment on column insight_series.query is 'Query string that generates this series';\ncomment on column insight_series.created_at is 'Timestamp when this series was created';\ncomment on column insight_series.oldest_historical_at is 'Timestamp representing the oldest point of which this series is backfilled.';\ncomment on column insight_series.last_recorded_at is 'Timestamp when this series was last recorded (non-historical).';\ncomment on column insight_series.next_recording_after is 'Timestamp when this series should next record (non-historical).';\ncomment on column insight_series.recording_interval_days is 'Number of days that should pass between recordings (non-historical)';\ncomment on column insight_series.deleted_at is 'Timestamp of a soft-delete of this row.';\n\nCREATE UNIQUE INDEX insight_series_series_id_unique_idx ON insight_series (series_id);\nCREATE INDEX insight_series_deleted_at_idx ON insight_series (deleted_at);\nCREATE INDEX insight_series_next_recording_after_idx ON insight_series (next_recording_after);\n\nCREATE TABLE insight_view\n(\n    id          SERIAL NOT NULL PRIMARY KEY,\n    title       TEXT,\n    description TEXT,\n    unique_id   TEXT NOT NULL\n);\n\ncomment on table insight_view is 'Views for insight data series. An insight view is an abstraction on top of an insight data series that allows for lightweight modifications to filters or metadata without regenerating the underlying series.';\n\ncomment on column insight_view.id is 'Primary key ID for this view';\ncomment on column insight_view.title is 'Title of the view. This may render in a chart depending on the view type.';\ncomment on column insight_view.description is 'Description of the view. This may render in a chart depending on the view type.';\ncomment on column insight_view.unique_id is 'Globally unique identifier for this view that is externally referencable.';\n\nCREATE UNIQUE INDEX insight_view_unique_id_unique_idx ON insight_view (unique_id);\n\nCREATE TABLE insight_view_series\n(\n    insight_view_id   INT NOT NULL,\n    insight_series_id INT NOT NULL,\n    label             TEXT,\n    stroke            TEXT,\n    PRIMARY KEY (insight_view_id, insight_series_id)\n);\n\ncomment on table insight_view_series is 'Join table to correlate data series with insight views';\ncomment on column insight_view_series.insight_view_id is 'Foreign key to insight view.';\ncomment on column insight_view_series.insight_series_id is 'Foreign key to insight data series.';\ncomment on column insight_view_series.label is 'Label text for this data series. This may render in a chart depending on the view type.';\ncomment on column insight_view_series.stroke is 'Stroke color metadata for this data series. This may render in a chart depending on the view type.';\n\nALTER TABLE insight_view_series\n    ADD FOREIGN KEY (insight_view_id) REFERENCES insight_view (id);\n\nALTER TABLE insight_view_series\n    ADD FOREIGN KEY (insight_series_id) REFERENCES insight_series (id);",
				"DownQuery": "DROP TABLE IF EXISTS insight_view_series;\nDROP TABLE IF EXISTS insight_view;\nDROP TABLE IF EXISTS insight_series;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000007
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000009,
				"Name": "backfiller state",
				"UpQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nALTER TABLE insight_series ADD COLUMN backfill_queued_at TIMESTAMP;\nCOMMENT ON COLUMN insight_series.series_id IS\n    'Timestamp that this series completed a full repository iteration for backfill. This flag has limited semantic value, and only means it tried to queue up queries for each repository. It does not guarantee success on those queries.';",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nALTER TABLE insight_series DROP COLUMN IF EXISTS backfill_queued_at;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000008
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000010,
				"Name": "series points reset",
				"UpQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\n-- Prior to 3.31 this table stored points in two formats. Historical points were stored in a compressed\n-- format where samples were only recorded if the underlying repository changed. After 3.31 we are changing\n-- the semantic to require full vectors for each data point. To avoid any incompatibilities and to prepare for beta\n-- we are going to reset the stored data and all of the underlying Timescale chunks back to zero.\n-- Note: This data is by design reproducible, so there is no risk of permanent data loss here. Any and all data\n-- will be queued and regenerated as soon as code insights starts up.\n\n-- Drop all Timescale chunks prior to now. This will reduce a bloated number of partitions caused by old\n-- data generation patterns. This is a Timescale specific thing.\nSELECT drop_chunks('series_points', CURRENT_TIMESTAMP::DATE);\n\n-- Clean up the remaining records if any exist.\nTRUNCATE series_points CASCADE;\n\n-- There is the possibility that the commit index has fallen out of sync with the primary postgres database in 3.30 due\n-- to a data corruption issue. We will regenerate it to be sure it is healthy for beta.\nTRUNCATE commit_index;\nTRUNCATE commit_index_metadata;\n\n-- Update all of the underlying insights that may have been synced to reset metadata and rebuild their data.\nupdate insight_series set created_at = current_timestamp, backfill_queued_at = null, next_recording_after = date_trunc('month', current_date) + interval '1 month';",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000009
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000011,
				"Name": "insights dirty queries",
				"UpQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nCREATE TABLE insight_dirty_queries\n(\n    id                SERIAL NOT NULL,\n    insight_series_id INT,\n    query             TEXT NOT NULL,\n    dirty_at          TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,\n    reason            TEXT NOT NULL,\n    for_time          TIMESTAMP NOT NULL,\n    PRIMARY KEY (id),\n    FOREIGN KEY (insight_series_id) REFERENCES insight_series(id)\n);\n\nCREATE INDEX insight_dirty_queries_insight_series_id_fk_idx ON insight_dirty_queries (insight_series_id);\n\nCOMMENT ON TABLE insight_dirty_queries IS 'Stores queries that were unsuccessful or otherwise flagged as incomplete or incorrect.';\n\nCOMMENT ON COLUMN insight_dirty_queries.query IS 'Sourcegraph query string that was executed.';\nCOMMENT ON COLUMN insight_dirty_queries.dirty_at IS 'Timestamp when this query was marked dirty.';\nCOMMENT ON COLUMN insight_dirty_queries.reason IS 'Human readable string indicating the reason the query was marked dirty.';\nCOMMENT ON COLUMN insight_dirty_queries.for_time IS 'Timestamp for which the original data point was recorded or intended to be recorded.';",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\nDROP TABLE IF EXISTS insight_dirty_queries;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000010
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000012,
				"Name": "insights snapshots",
				"UpQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nCREATE TABLE series_points_snapshots\n(\n    LIKE series_points INCLUDING DEFAULTS INCLUDING CONSTRAINTS INCLUDING INDEXES\n);\n\nCOMMENT ON TABLE series_points_snapshots is 'Stores ephemeral snapshot data of insight recordings.';\n\nalter table insight_series\n    add last_snapshot_at timestamp default (CURRENT_TIMESTAMP - '10 years'::interval);\n\nalter table insight_series\n    add next_snapshot_after timestamp default CURRENT_TIMESTAMP;",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nDROP TABLE series_points_snapshots;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000011
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000013,
				"Name": "insights view grants",
				"UpQuery": "CREATE TABLE IF NOT EXISTS insight_view_grants\n(\n    id              SERIAL\n        CONSTRAINT insight_view_grants_pk\n            PRIMARY KEY,\n    insight_view_id INTEGER NOT NULL\n        CONSTRAINT insight_view_grants_insight_view_id_fk\n            REFERENCES insight_view\n            ON DELETE CASCADE, -- These grants only have meaning in the context of a parent view.\n    user_id         INTEGER,\n    org_id          INTEGER,\n    global          BOOLEAN\n);\n\nCOMMENT ON TABLE insight_view_grants IS 'Permission grants for insight views. Each row should represent a unique principal (user, org, etc).';\nCOMMENT ON COLUMN insight_view_grants.user_id IS 'User ID that that receives this grant.';\nCOMMENT ON COLUMN insight_view_grants.org_id IS 'Org ID that that receives this grant.';\nCOMMENT ON COLUMN insight_view_grants.global IS 'Grant that does not belong to any specific principal and is granted to all users.';\n\nCREATE INDEX IF NOT EXISTS insight_view_grants_insight_view_id_index\n    ON insight_view_grants (insight_view_id);\n\nCREATE INDEX IF NOT EXISTS insight_view_grants_user_id_idx\n    ON insight_view_grants (user_id);\n\nCREATE INDEX IF NOT EXISTS insight_view_grants_org_id_idx\n    ON insight_view_grants (org_id);\n\nCREATE INDEX IF NOT EXISTS insight_view_grants_global_idx\n    ON insight_view_grants (global) WHERE global IS TRUE;\n\n\n-- This series join table is completely dependent on the existence of a parent view. So to simplify db operations\n-- and avoid dangling rows, adding cascade deletes to the insight view FK.\nALTER TABLE insight_view_series\n    DROP CONSTRAINT IF EXISTS insight_view_series_insight_view_id_fkey;\n\nALTER TABLE insight_view_series\n    ADD CONSTRAINT insight_view_series_insight_view_id_fkey\n        FOREIGN KEY (insight_view_id) REFERENCES insight_view\n            ON DELETE CASCADE;",
				"DownQuery": "DROP TABLE IF EXISTS insight_view_grants;\n\nALTER TABLE insight_view_series\n    DROP CONSTRAINT IF EXISTS insight_view_series_insight_view_id_fkey;\n\nALTER TABLE insight_view_series\n    ADD CONSTRAINT insight_view_series_insight_view_id_fkey\n        FOREIGN KEY (insight_view_id) REFERENCES insight_view;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000012
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000014,
				"Name": "dashboards",
				"UpQuery": "CREATE TABLE IF NOT EXISTS dashboard\n(\n    id                 SERIAL                  NOT NULL CONSTRAINT dashboard_pk PRIMARY KEY,\n    title              TEXT,\n    created_at         TIMESTAMP DEFAULT NOW() NOT NULL,\n    created_by_user_id INT,\n    last_updated_at    TIMESTAMP DEFAULT NOW() NOT NULL,\n    deleted_at         TIMESTAMP\n);\n\nCOMMENT ON TABLE dashboard IS 'Metadata for dashboards of insights';\n\nCOMMENT ON COLUMN dashboard.title IS 'Title of the dashboard';\n\nCOMMENT ON COLUMN dashboard.created_at IS 'Timestamp the dashboard was initially created.';\n\nCOMMENT ON COLUMN dashboard.created_by_user_id IS 'User that created the dashboard, if available.';\n\nCOMMENT ON COLUMN dashboard.last_updated_at IS 'Time the dashboard was last updated, either metadata or insights.';\n\nCOMMENT ON COLUMN dashboard.deleted_at IS 'Set to the time the dashboard was soft deleted.';\n\n\n\nCREATE TABLE IF NOT EXISTS dashboard_grants\n(\n    id           SERIAL CONSTRAINT dashboard_grants_pk PRIMARY KEY,\n    dashboard_id INTEGER NOT NULL CONSTRAINT dashboard_grants_dashboard_id_fk REFERENCES dashboard ON DELETE CASCADE, -- These grants only have meaning in the context of a parent dashboard.\n    user_id      INTEGER,\n    org_id       INTEGER,\n    global       BOOLEAN\n);\n\nCOMMENT ON TABLE dashboard_grants IS 'Permission grants for dashboards. Each row should represent a unique principal (user, org, etc).';\nCOMMENT ON COLUMN dashboard_grants.user_id IS 'User ID that that receives this grant.';\nCOMMENT ON COLUMN dashboard_grants.org_id IS 'Org ID that that receives this grant.';\nCOMMENT ON COLUMN dashboard_grants.global IS 'Grant that does not belong to any specific principal and is granted to all users.';\n\nCREATE INDEX IF NOT EXISTS dashboard_grants_dashboard_id_index\n    ON dashboard_grants (dashboard_id);\n\nCREATE INDEX IF NOT EXISTS dashboard_grants_user_id_idx\n    ON dashboard_grants (user_id);\n\nCREATE INDEX IF NOT EXISTS dashboard_grants_org_id_idx\n    ON dashboard_grants (org_id);\n\nCREATE INDEX IF NOT EXISTS dashboard_grants_global_idx\n    ON dashboard_grants (global) WHERE global IS TRUE;\n\nCREATE TABLE dashboard_insight_view\n(\n    id              SERIAL NOT NULL CONSTRAINT dashboard_insight_view_pk PRIMARY KEY,\n    dashboard_id    INT    NOT NULL CONSTRAINT dashboard_insight_view_dashboard_id_fk REFERENCES dashboard (id) ON DELETE CASCADE,\n    insight_view_id INT    NOT NULL CONSTRAINT dashboard_insight_view_insight_view_id_fk REFERENCES insight_view (id) ON DELETE CASCADE\n);\n\nCREATE INDEX IF NOT EXISTS dashboard_insight_view_insight_view_id_fk_idx ON dashboard_insight_view (insight_view_id);\nCREATE INDEX IF NOT EXISTS dashboard_insight_view_dashboard_id_fk_idx ON dashboard_insight_view (dashboard_id);",
				"DownQuery": "DROP TABLE IF EXISTS dashboard_grants;\n\t\t\tDROP TABLE IF EXISTS dashboard_insight_view;\n\t\t\tDROP TABLE IF EXISTS dashboard;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000013
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000015,
				"Name": "dashboard save",
				"UpQuery": "ALTER TABLE dashboard ADD COLUMN IF NOT EXISTS save BOOLEAN NOT NULL DEFAULT FALSE;\n\nCOMMENT ON COLUMN dashboard.save IS 'TEMPORARY Do not delete this dashboard when migrating settings.';",
				"DownQuery": "ALTER TABLE dashboard\nDROP COLUMN IF EXISTS save;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000014
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000016,
				"Name": "unique insights on dashboard",
				"UpQuery": "-- Remove any already existing duplicates.\nDELETE FROM\n    dashboard_insight_view a\n        USING dashboard_insight_view b\nWHERE\n\ta.id \u003e b.id\n    AND a.dashboard_id = b.dashboard_id\n    AND a.insight_view_id = b.insight_view_id;\n\nALTER TABLE dashboard_insight_view\nADD CONSTRAINT unique_dashboard_id_insight_view_id\nUNIQUE (dashboard_id, insight_view_id);",
				"DownQuery": "ALTER TABLE dashboard_insight_view\nDROP CONSTRAINT unique_dashboard_id_insight_view_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000015
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000017,
				"Name": "insight api",
				"UpQuery": "CREATE TYPE time_unit AS ENUM ('HOUR', 'DAY', 'WEEK', 'MONTH', 'YEAR');\nALTER TABLE insight_series\n    DROP COLUMN IF EXISTS recording_interval_days,\n    ADD COLUMN repositories TEXT[],\n    ADD COLUMN sample_interval_unit time_unit,\n    ADD COLUMN sample_interval_value int\n;\n\nALTER TABLE insight_view\n    ADD COLUMN default_filter_include_repo_regex text,\n    ADD COLUMN default_filter_exclude_repo_regex text\n;",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nALTER TABLE insight_series\n    DROP COLUMN IF EXISTS repositories,\n    DROP COLUMN IF EXISTS sample_interval_unit,\n    DROP COLUMN IF EXISTS sample_interval_value,\n    ADD COLUMN IF NOT EXISTS recording_interval_days int;\n\nALTER TABLE insight_view\n    DROP COLUMN IF EXISTS default_filter_include_repo_regex,\n    DROP COLUMN IF EXISTS default_filter_exclude_repo_regex;\nDROP TYPE IF EXISTS time_unit;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000016
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000018,
				"Name": "interval defaults",
				"UpQuery": "UPDATE insight_series\nSET sample_interval_unit = 'MONTH'\nWHERE sample_interval_unit IS NULL;\n\nUPDATE insight_series\nSET sample_interval_value = 1\nWHERE sample_interval_value IS NULL;\n\nALTER TABLE insight_series\n    ALTER COLUMN sample_interval_unit SET DEFAULT 'MONTH',\n    ALTER COLUMN sample_interval_unit SET NOT NULL,\n    ALTER COLUMN sample_interval_value SET DEFAULT '1',\n    ALTER COLUMN sample_interval_value SET NOT NULL;",
				"DownQuery": "ALTER TABLE IF EXISTS insight_series\n    ALTER COLUMN sample_interval_unit DROP DEFAULT,\n    ALTER COLUMN sample_interval_unit DROP NOT NULL,\n    ALTER COLUMN sample_interval_value DROP DEFAULT,\n    ALTER COLUMN sample_interval_value DROP NOT NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000017
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000019,
				"Name": "other threshold",
				"UpQuery": "ALTER TABLE insight_view\n    ADD COLUMN IF NOT EXISTS other_threshold FLOAT4;\n\nCOMMENT ON COLUMN insight_view.other_threshold IS 'Percent threshold for grouping series under \"other\"';",
				"DownQuery": "ALTER TABLE insight_view\nDROP COLUMN IF EXISTS other_threshold;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000018
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000020,
				"Name": "presentation type",
				"UpQuery": "CREATE TYPE presentation_type_enum AS ENUM ('LINE', 'PIE');\nALTER TABLE insight_view\n    ADD COLUMN IF NOT EXISTS presentation_type presentation_type_enum NOT NULL DEFAULT 'LINE',\n    ALTER COLUMN other_threshold type FLOAT8; -- Changing this because the GraphQL float type is a float64.\n\nCOMMENT ON COLUMN insight_view.presentation_type IS 'The basic presentation type for the insight view. (e.g Line, Pie, etc.)';",
				"DownQuery": "ALTER TABLE insight_view\n    ALTER COLUMN other_threshold TYPE FLOAT4,\n    DROP COLUMN IF EXISTS presentation_type;\n\nDROP TYPE presentation_type_enum;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000019
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000021,
				"Name": "add dirty query cascade",
				"UpQuery": "ALTER TABLE insight_dirty_queries\n    DROP CONSTRAINT insight_dirty_queries_insight_series_id_fkey,\n    ADD CONSTRAINT insight_dirty_queries_insight_series_id_fkey FOREIGN KEY (insight_series_id) REFERENCES insight_series (id) ON DELETE CASCADE;",
				"DownQuery": "ALTER TABLE insight_dirty_queries\n    DROP CONSTRAINT insight_dirty_queries_insight_series_id_fkey,\n    ADD CONSTRAINT insight_dirty_queries_insight_series_id_fkey FOREIGN KEY (insight_series_id) REFERENCES insight_series (id);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000020
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			}
		],
		"BoundsByRev": {
			"3.34.2": {
				"RootID": -1000000000,
				"LeafIDs": [
					1000000021
				],
				"PreCreation": false
			}
		}
	},
	"codeintel": {
		"Definitions": [
			{
				"ID": -1000000015,
				"Name": "squashed migrations (privileged)",
				"UpQuery": "CREATE EXTENSION IF NOT EXISTS pg_stat_statements;\n\nCOMMENT ON EXTENSION pg_stat_statements IS 'track execution statistics of all SQL statements executed';",
				"DownQuery": "",
				"Privileged": true,
				"NonIdempotent": false,
				"Parents": null,
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000015,
				"Name": "squashed migrations",
				"UpQuery": "CREATE FUNCTION update_lsif_data_definitions_schema_versions_insert() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$ BEGIN\n    INSERT INTO\n        lsif_data_definitions_schema_versions\n    SELECT\n        dump_id,\n        MIN(schema_version) as min_schema_version,\n        MAX(schema_version) as max_schema_version\n    FROM\n        newtab\n    GROUP BY\n        dump_id\n    ON CONFLICT (dump_id) DO UPDATE SET\n        -- Update with min(old_min, new_min) and max(old_max, new_max)\n        min_schema_version = LEAST(lsif_data_definitions_schema_versions.min_schema_version, EXCLUDED.min_schema_version),\n        max_schema_version = GREATEST(lsif_data_definitions_schema_versions.max_schema_version, EXCLUDED.max_schema_version);\n\n    RETURN NULL;\nEND $$;\n\nCREATE FUNCTION update_lsif_data_documents_schema_versions_insert() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$ BEGIN\n    INSERT INTO\n        lsif_data_documents_schema_versions\n    SELECT\n        dump_id,\n        MIN(schema_version) as min_schema_version,\n        MAX(schema_version) as max_schema_version\n    FROM\n        newtab\n    GROUP BY\n        dump_id\n    ON CONFLICT (dump_id) DO UPDATE SET\n        -- Update with min(old_min, new_min) and max(old_max, new_max)\n        min_schema_version = LEAST(lsif_data_documents_schema_versions.min_schema_version, EXCLUDED.min_schema_version),\n        max_schema_version = GREATEST(lsif_data_documents_schema_versions.max_schema_version, EXCLUDED.max_schema_version);\n\n    RETURN NULL;\nEND $$;\n\nCREATE FUNCTION update_lsif_data_references_schema_versions_insert() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$ BEGIN\n    INSERT INTO\n        lsif_data_references_schema_versions\n    SELECT\n        dump_id,\n        MIN(schema_version) as min_schema_version,\n        MAX(schema_version) as max_schema_version\n    FROM\n        newtab\n    GROUP BY\n        dump_id\n    ON CONFLICT (dump_id) DO UPDATE SET\n        -- Update with min(old_min, new_min) and max(old_max, new_max)\n        min_schema_version = LEAST(lsif_data_references_schema_versions.min_schema_version, EXCLUDED.min_schema_version),\n        max_schema_version = GREATEST(lsif_data_references_schema_versions.max_schema_version, EXCLUDED.max_schema_version);\n\n    RETURN NULL;\nEND $$;\n\nCREATE TABLE lsif_data_definitions (\n    dump_id integer NOT NULL,\n    scheme text NOT NULL,\n    identifier text NOT NULL,\n    data bytea,\n    schema_version integer NOT NULL,\n    num_locations integer NOT NULL\n);\n\nCOMMENT ON TABLE lsif_data_definitions IS 'Associates (document, range) pairs with the import monikers attached to the range.';\n\nCOMMENT ON COLUMN lsif_data_definitions.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\n\nCOMMENT ON COLUMN lsif_data_definitions.scheme IS 'The moniker scheme.';\n\nCOMMENT ON COLUMN lsif_data_definitions.identifier IS 'The moniker identifier.';\n\nCOMMENT ON COLUMN lsif_data_definitions.data IS 'A gob-encoded payload conforming to an array of [LocationData](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.26/-/blob/enterprise/lib/codeintel/semantic/types.go#L106:6) types.';\n\nCOMMENT ON COLUMN lsif_data_definitions.schema_version IS 'The schema version of this row - used to determine presence and encoding of data.';\n\nCOMMENT ON COLUMN lsif_data_definitions.num_locations IS 'The number of locations stored in the data field.';\n\nCREATE TABLE lsif_data_definitions_schema_versions (\n    dump_id integer NOT NULL,\n    min_schema_version integer,\n    max_schema_version integer\n);\n\nCOMMENT ON TABLE lsif_data_definitions_schema_versions IS 'Tracks the range of schema_versions for each upload in the lsif_data_definitions table.';\n\nCOMMENT ON COLUMN lsif_data_definitions_schema_versions.dump_id IS 'The identifier of the associated dump in the lsif_uploads table.';\n\nCOMMENT ON COLUMN lsif_data_definitions_schema_versions.min_schema_version IS 'A lower-bound on the `lsif_data_definitions.schema_version` where `lsif_data_definitions.dump_id = dump_id`.';\n\nCOMMENT ON COLUMN lsif_data_definitions_schema_versions.max_schema_version IS 'An upper-bound on the `lsif_data_definitions.schema_version` where `lsif_data_definitions.dump_id = dump_id`.';\n\nCREATE TABLE lsif_data_documentation_pages (\n    dump_id integer NOT NULL,\n    path_id text NOT NULL,\n    data bytea\n);\n\nCOMMENT ON TABLE lsif_data_documentation_pages IS 'Associates documentation pathIDs to their documentation page hierarchy chunk.';\n\nCOMMENT ON COLUMN lsif_data_documentation_pages.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\n\nCOMMENT ON COLUMN lsif_data_documentation_pages.path_id IS 'The documentation page path ID, see see GraphQL codeintel.schema:documentationPage for what this is.';\n\nCOMMENT ON COLUMN lsif_data_documentation_pages.data IS 'A gob-encoded payload conforming to a `type DocumentationPageData struct` pointer (lib/codeintel/semantic/types.go)';\n\nCREATE TABLE lsif_data_documents (\n    dump_id integer NOT NULL,\n    path text NOT NULL,\n    data bytea,\n    schema_version integer NOT NULL,\n    num_diagnostics integer NOT NULL,\n    ranges bytea,\n    hovers bytea,\n    monikers bytea,\n    packages bytea,\n    diagnostics bytea\n);\n\nCOMMENT ON TABLE lsif_data_documents IS 'Stores reference, hover text, moniker, and diagnostic data about a particular text document witin a dump.';\n\nCOMMENT ON COLUMN lsif_data_documents.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\n\nCOMMENT ON COLUMN lsif_data_documents.path IS 'The path of the text document relative to the associated dump root.';\n\nCOMMENT ON COLUMN lsif_data_documents.data IS 'A gob-encoded payload conforming to the [DocumentData](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.26/-/blob/enterprise/lib/codeintel/semantic/types.go#L13:6) type. This field is being migrated across ranges, hovers, monikers, packages, and diagnostics columns and will be removed in a future release of Sourcegraph.';\n\nCOMMENT ON COLUMN lsif_data_documents.schema_version IS 'The schema version of this row - used to determine presence and encoding of data.';\n\nCOMMENT ON COLUMN lsif_data_documents.num_diagnostics IS 'The number of diagnostics stored in the data field.';\n\nCOMMENT ON COLUMN lsif_data_documents.ranges IS 'A gob-encoded payload conforming to the [Ranges](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.26/-/blob/enterprise/lib/codeintel/semantic/types.go#L14:2) field of the DocumentDatatype.';\n\nCOMMENT ON COLUMN lsif_data_documents.hovers IS 'A gob-encoded payload conforming to the [HoversResults](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.26/-/blob/enterprise/lib/codeintel/semantic/types.go#L15:2) field of the DocumentDatatype.';\n\nCOMMENT ON COLUMN lsif_data_documents.monikers IS 'A gob-encoded payload conforming to the [Monikers](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.26/-/blob/enterprise/lib/codeintel/semantic/types.go#L16:2) field of the DocumentDatatype.';\n\nCOMMENT ON COLUMN lsif_data_documents.packages IS 'A gob-encoded payload conforming to the [PackageInformation](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.26/-/blob/enterprise/lib/codeintel/semantic/types.go#L17:2) field of the DocumentDatatype.';\n\nCOMMENT ON COLUMN lsif_data_documents.diagnostics IS 'A gob-encoded payload conforming to the [Diagnostics](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.26/-/blob/enterprise/lib/codeintel/semantic/types.go#L18:2) field of the DocumentDatatype.';\n\nCREATE TABLE lsif_data_documents_schema_versions (\n    dump_id integer NOT NULL,\n    min_schema_version integer,\n    max_schema_version integer\n);\n\nCOMMENT ON TABLE lsif_data_documents_schema_versions IS 'Tracks the range of schema_versions for each upload in the lsif_data_documents table.';\n\nCOMMENT ON COLUMN lsif_data_documents_schema_versions.dump_id IS 'The identifier of the associated dump in the lsif_uploads table.';\n\nCOMMENT ON COLUMN lsif_data_documents_schema_versions.min_schema_version IS 'A lower-bound on the `lsif_data_documents.schema_version` where `lsif_data_documents.dump_id = dump_id`.';\n\nCOMMENT ON COLUMN lsif_data_documents_schema_versions.max_schema_version IS 'An upper-bound on the `lsif_data_documents.schema_version` where `lsif_data_documents.dump_id = dump_id`.';\n\nCREATE TABLE lsif_data_metadata (\n    dump_id integer NOT NULL,\n    num_result_chunks integer\n);\n\nCOMMENT ON TABLE lsif_data_metadata IS 'Stores the number of result chunks associated with a dump.';\n\nCOMMENT ON COLUMN lsif_data_metadata.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\n\nCOMMENT ON COLUMN lsif_data_metadata.num_result_chunks IS 'A bound of populated indexes in the lsif_data_result_chunks table for the associated dump. This value is used to hash identifiers into the result chunk index to which they belong.';\n\nCREATE TABLE lsif_data_references (\n    dump_id integer NOT NULL,\n    scheme text NOT NULL,\n    identifier text NOT NULL,\n    data bytea,\n    schema_version integer NOT NULL,\n    num_locations integer NOT NULL\n);\n\nCOMMENT ON TABLE lsif_data_references IS 'Associates (document, range) pairs with the export monikers attached to the range.';\n\nCOMMENT ON COLUMN lsif_data_references.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\n\nCOMMENT ON COLUMN lsif_data_references.scheme IS 'The moniker scheme.';\n\nCOMMENT ON COLUMN lsif_data_references.identifier IS 'The moniker identifier.';\n\nCOMMENT ON COLUMN lsif_data_references.data IS 'A gob-encoded payload conforming to an array of [LocationData](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.26/-/blob/enterprise/lib/codeintel/semantic/types.go#L106:6) types.';\n\nCOMMENT ON COLUMN lsif_data_references.schema_version IS 'The schema version of this row - used to determine presence and encoding of data.';\n\nCOMMENT ON COLUMN lsif_data_references.num_locations IS 'The number of locations stored in the data field.';\n\nCREATE TABLE lsif_data_references_schema_versions (\n    dump_id integer NOT NULL,\n    min_schema_version integer,\n    max_schema_version integer\n);\n\nCOMMENT ON TABLE lsif_data_references_schema_versions IS 'Tracks the range of schema_versions for each upload in the lsif_data_references table.';\n\nCOMMENT ON COLUMN lsif_data_references_schema_versions.dump_id IS 'The identifier of the associated dump in the lsif_uploads table.';\n\nCOMMENT ON COLUMN lsif_data_references_schema_versions.min_schema_version IS 'A lower-bound on the `lsif_data_references.schema_version` where `lsif_data_references.dump_id = dump_id`.';\n\nCOMMENT ON COLUMN lsif_data_references_schema_versions.max_schema_version IS 'An upper-bound on the `lsif_data_references.schema_version` where `lsif_data_references.dump_id = dump_id`.';\n\nCREATE TABLE lsif_data_result_chunks (\n    dump_id integer NOT NULL,\n    idx integer NOT NULL,\n    data bytea\n);\n\nCOMMENT ON TABLE lsif_data_result_chunks IS 'Associates result set identifiers with the (document path, range identifier) pairs that compose the set.';\n\nCOMMENT ON COLUMN lsif_data_result_chunks.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\n\nCOMMENT ON COLUMN lsif_data_result_chunks.idx IS 'The unique result chunk index within the associated dump. Every result set identifier present should hash to this index (modulo lsif_data_metadata.num_result_chunks).';\n\nCOMMENT ON COLUMN lsif_data_result_chunks.data IS 'A gob-encoded payload conforming to the [ResultChunkData](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.26/-/blob/enterprise/lib/codeintel/semantic/types.go#L76:6) type.';\n\nALTER TABLE ONLY lsif_data_definitions\n    ADD CONSTRAINT lsif_data_definitions_pkey PRIMARY KEY (dump_id, scheme, identifier);\n\nALTER TABLE ONLY lsif_data_definitions_schema_versions\n    ADD CONSTRAINT lsif_data_definitions_schema_versions_pkey PRIMARY KEY (dump_id);\n\nALTER TABLE ONLY lsif_data_documentation_pages\n    ADD CONSTRAINT lsif_data_documentation_pages_pkey PRIMARY KEY (dump_id, path_id);\n\nALTER TABLE ONLY lsif_data_documents\n    ADD CONSTRAINT lsif_data_documents_pkey PRIMARY KEY (dump_id, path);\n\nALTER TABLE ONLY lsif_data_documents_schema_versions\n    ADD CONSTRAINT lsif_data_documents_schema_versions_pkey PRIMARY KEY (dump_id);\n\nALTER TABLE ONLY lsif_data_metadata\n    ADD CONSTRAINT lsif_data_metadata_pkey PRIMARY KEY (dump_id);\n\nALTER TABLE ONLY lsif_data_references\n    ADD CONSTRAINT lsif_data_references_pkey PRIMARY KEY (dump_id, scheme, identifier);\n\nALTER TABLE ONLY lsif_data_references_schema_versions\n    ADD CONSTRAINT lsif_data_references_schema_versions_pkey PRIMARY KEY (dump_id);\n\nALTER TABLE ONLY lsif_data_result_chunks\n    ADD CONSTRAINT lsif_data_result_chunks_pkey PRIMARY KEY (dump_id, idx);\n\nCREATE INDEX lsif_data_definitions_dump_id_schema_version ON lsif_data_definitions USING btree (dump_id, schema_version);\n\nCREATE INDEX lsif_data_definitions_schema_versions_dump_id_schema_version_bo ON lsif_data_definitions_schema_versions USING btree (dump_id, min_schema_version, max_schema_version);\n\nCREATE INDEX lsif_data_documents_dump_id_schema_version ON lsif_data_documents USING btree (dump_id, schema_version);\n\nCREATE INDEX lsif_data_documents_schema_versions_dump_id_schema_version_boun ON lsif_data_documents_schema_versions USING btree (dump_id, min_schema_version, max_schema_version);\n\nCREATE INDEX lsif_data_references_dump_id_schema_version ON lsif_data_references USING btree (dump_id, schema_version);\n\nCREATE INDEX lsif_data_references_schema_versions_dump_id_schema_version_bou ON lsif_data_references_schema_versions USING btree (dump_id, min_schema_version, max_schema_version);\n\nCREATE TRIGGER lsif_data_definitions_schema_versions_insert AFTER INSERT ON lsif_data_definitions REFERENCING NEW TABLE AS newtab FOR EACH STATEMENT EXECUTE FUNCTION update_lsif_data_definitions_schema_versions_insert();\n\nCREATE TRIGGER lsif_data_documents_schema_versions_insert AFTER INSERT ON lsif_data_documents REFERENCING NEW TABLE AS newtab FOR EACH STATEMENT EXECUTE FUNCTION update_lsif_data_documents_schema_versions_insert();\n\nCREATE TRIGGER lsif_data_references_schema_versions_insert AFTER INSERT ON lsif_data_references REFERENCING NEW TABLE AS newtab FOR EACH STATEMENT EXECUTE FUNCTION update_lsif_data_references_schema_versions_insert();",
				"DownQuery": "-- Nothing",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					-1000000015
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000016,
				"Name": "apidocs clean",
				"UpQuery": "-- PR #22080 landed a number of backwards-incompatible API docs data changes and given how early\n-- stages API docs is, we don't care to maintain backwards compat with the old data and choose to\n-- instead start from scratch with indexing again (not many repos have been indexed with API docs,\n-- anyway.)\nTRUNCATE lsif_data_documentation_pages;",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000015
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000017,
				"Name": "lsif documentation path info",
				"UpQuery": "CREATE TABLE IF NOT EXISTS lsif_data_documentation_path_info (\n    dump_id integer NOT NULL,\n    path_id TEXT,\n    data bytea\n);\n\nALTER TABLE lsif_data_documentation_path_info ADD PRIMARY KEY (dump_id, path_id);\n\nCOMMENT ON TABLE lsif_data_documentation_path_info IS 'Associates documentation page pathIDs to information about what is at that pathID, its immediate children, etc.';\nCOMMENT ON COLUMN lsif_data_documentation_path_info.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\nCOMMENT ON COLUMN lsif_data_documentation_path_info.path_id IS 'The documentation page path ID, see see GraphQL codeintel.schema:documentationPage for what this is.';\nCOMMENT ON COLUMN lsif_data_documentation_path_info.data IS 'A gob-encoded payload conforming to a `type DocumentationPathInoData struct` pointer (lib/codeintel/semantic/types.go)';",
				"DownQuery": "DROP TABLE IF EXISTS lsif_data_documentation_path_info;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000016
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000018,
				"Name": "lsif documentation mappings",
				"UpQuery": "CREATE TABLE IF NOT EXISTS lsif_data_documentation_mappings (\n    dump_id integer NOT NULL,\n    path_id TEXT NOT NULL,\n    result_id integer NOT NULL\n);\n\nALTER TABLE lsif_data_documentation_mappings ADD PRIMARY KEY (dump_id, path_id);\n\nCREATE UNIQUE INDEX lsif_data_documentation_mappings_inverse_unique_idx ON lsif_data_documentation_mappings(dump_id, result_id);\n\nCOMMENT ON TABLE lsif_data_documentation_mappings IS 'Maps documentation path IDs to their corresponding integral documentationResult vertex IDs, which are unique within a dump.';\nCOMMENT ON COLUMN lsif_data_documentation_mappings.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\nCOMMENT ON COLUMN lsif_data_documentation_mappings.path_id IS 'The documentation page path ID, see see GraphQL codeintel.schema:documentationPage for what this is.';\nCOMMENT ON COLUMN lsif_data_documentation_mappings.result_id IS 'The documentationResult vertex ID.';",
				"DownQuery": "DROP TABLE IF EXISTS lsif_data_documentation_mappings;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000017
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000019,
				"Name": "documentation path mapping",
				"UpQuery": "-- Add nullable file_path column, for mapping documentationResult ID -\u003e file_path\nALTER TABLE lsif_data_documentation_mappings ADD COLUMN file_path text;\nCOMMENT ON COLUMN lsif_data_documentation_mappings.file_path IS 'The document file path for the documentationResult, if any. e.g. the path to the file where the symbol described by this documentationResult is located, if it is a symbol.';",
				"DownQuery": "ALTER TABLE lsif_data_documentation_mappings DROP COLUMN file_path;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000018
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000020,
				"Name": "lsif data documentation search",
				"UpQuery": "CREATE EXTENSION IF NOT EXISTS pg_trgm;\n\nALTER TABLE lsif_data_documentation_pages ADD COLUMN search_indexed boolean DEFAULT 'false';\n\n-- We're going to create the new lsif_data_documentation_search_* tables. These tables will have a\n-- trigram index and will be data decoded from the GOB encoded lsif_data_documentation_pages.data\n-- field, hence an OOB migration is needed as that table is quite large and not decodable in SQL\n-- alone.\nCREATE TABLE IF NOT EXISTS lsif_data_documentation_search_public (\n    -- Metadata fields\n    dump_id integer NOT NULL,\n    repo_id integer NOT NULL,\n    path_id TEXT NOT NULL,\n    detail TEXT NOT NULL,\n\n    -- FTS-enabled fields\n    lang TEXT NOT NULL,\n    repo_name TEXT NOT NULL,\n    search_key TEXT NOT NULL,\n    label TEXT NOT NULL,\n    tags TEXT NOT NULL\n);\n\nALTER TABLE lsif_data_documentation_search_public ADD PRIMARY KEY (dump_id, path_id);\n\nCREATE INDEX lsif_data_documentation_search_public_repo_id_idx ON lsif_data_documentation_search_public USING BTREE(repo_id);\nCREATE INDEX lsif_data_documentation_search_public_lang_trgm ON lsif_data_documentation_search_public USING gin(lang gin_trgm_ops);\nCREATE INDEX lsif_data_documentation_search_public_repo_name_trgm ON lsif_data_documentation_search_public USING gin(repo_name gin_trgm_ops);\nCREATE INDEX lsif_data_documentation_search_public_search_key_trgm ON lsif_data_documentation_search_public USING gin(search_key gin_trgm_ops);\nCREATE INDEX lsif_data_documentation_search_public_label_trgm ON lsif_data_documentation_search_public USING gin(label gin_trgm_ops);\nCREATE INDEX lsif_data_documentation_search_public_tags_trgm ON lsif_data_documentation_search_public USING gin(tags gin_trgm_ops);\n\nCOMMENT ON TABLE lsif_data_documentation_search_public IS 'A trigram index over documentation for search (public repos only)';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.repo_id IS 'The repo ID, from the main app DB repo table. Used to search over a select set of repos by ID.';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.path_id IS 'The fully qualified documentation page path ID, e.g. including \"#section\". See GraphQL codeintel.schema:documentationPage for what this is.';\n\nCOMMENT ON COLUMN lsif_data_documentation_search_public.lang IS 'The lowercase language name (go, java, etc.) OR, if unknown, the LSIF indexer name';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.repo_name IS 'The name of the repository containing this search key.';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.search_key IS 'The search key generated by the indexer, e.g. mux.Router.ServeHTTP. It is language-specific, and likely unique within a repository (but not always.) See protocol/documentation.go:Documentation.SearchKey';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.label IS 'The label string of the result, e.g. a one-line function signature. See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.detail IS 'The detail string (e.g. the full function signature and its docs). See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.tags IS 'A space separated list of tags from the documentation node. See protocol/documentation.go:Documentation';\n\n-- Same exact thing as above, but for \"_private\" repos.\nCREATE TABLE IF NOT EXISTS lsif_data_documentation_search_private (\n    -- Metadata fields\n    dump_id integer NOT NULL,\n    repo_id integer NOT NULL,\n    path_id TEXT NOT NULL,\n    detail TEXT NOT NULL,\n\n    -- FTS-enabled fields\n    lang TEXT NOT NULL,\n    repo_name TEXT NOT NULL,\n    search_key TEXT NOT NULL,\n    label TEXT NOT NULL,\n    tags TEXT NOT NULL\n);\n\nALTER TABLE lsif_data_documentation_search_private ADD PRIMARY KEY (dump_id, path_id);\n\nCREATE INDEX lsif_data_documentation_search_private_repo_id_idx ON lsif_data_documentation_search_private USING BTREE(repo_id);\nCREATE INDEX lsif_data_documentation_search_private_lang_trgm ON lsif_data_documentation_search_private USING gin(lang gin_trgm_ops);\nCREATE INDEX lsif_data_documentation_search_private_repo_name_trgm ON lsif_data_documentation_search_private USING gin(repo_name gin_trgm_ops);\nCREATE INDEX lsif_data_documentation_search_private_search_key_trgm ON lsif_data_documentation_search_private USING gin(search_key gin_trgm_ops);\nCREATE INDEX lsif_data_documentation_search_private_label_trgm ON lsif_data_documentation_search_private USING gin(label gin_trgm_ops);\nCREATE INDEX lsif_data_documentation_search_private_tags_trgm ON lsif_data_documentation_search_private USING gin(tags gin_trgm_ops);\n\nCOMMENT ON TABLE lsif_data_documentation_search_private IS 'A trigram index over documentation for search (private repos only)';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.repo_id IS 'The repo ID, from the main app DB repo table. Used to search over a select set of repos by ID.';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.path_id IS 'The fully qualified documentation page path ID, e.g. including \"#section\". See GraphQL codeintel.schema:documentationPage for what this is.';\n\nCOMMENT ON COLUMN lsif_data_documentation_search_private.lang IS 'The lowercase language name (go, java, etc.) OR, if unknown, the LSIF indexer name';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.repo_name IS 'The name of the repository containing this search key.';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.search_key IS 'The search key generated by the indexer, e.g. mux.Router.ServeHTTP. It is language-specific, and likely unique within a repository (but not always.) See protocol/documentation.go:Documentation.SearchKey';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.label IS 'The label string of the result, e.g. a one-line function signature. See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.detail IS 'The detail string (e.g. the full function signature and its docs). See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.tags IS 'A space separated list of tags from the documentation node. See protocol/documentation.go:Documentation';",
				"DownQuery": "ALTER TABLE lsif_data_documentation_pages DROP COLUMN search_indexed;\nDROP TABLE IF EXISTS lsif_data_documentation_search;",
				"Privileged": true,
				"NonIdempotent": false,
				"Parents": [
					1000000019
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000021,
				"Name": "reverted",
				"UpQuery": "-- Empty migration, this migration was reverted: https://github.com/sourcegraph/sourcegraph/pull/25715",
				"DownQuery": "-- Empty migration, this migration was reverted: https://github.com/sourcegraph/sourcegraph/pull/25715",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000020
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000022,
				"Name": "undo apidocs root column",
				"UpQuery": "-- Undo the changes corresponding to https://github.com/sourcegraph/sourcegraph/pull/25715\nALTER TABLE lsif_data_documentation_search_public DROP COLUMN IF EXISTS dump_root;\nALTER TABLE lsif_data_documentation_search_private DROP COLUMN IF EXISTS dump_root;",
				"DownQuery": "-- Nothing to do, the up migration undid changes previously made.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000021
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000023,
				"Name": "apidocs add dump root column",
				"UpQuery": "ALTER TABLE lsif_data_documentation_search_public ADD COLUMN dump_root TEXT NOT NULL DEFAULT '';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.dump_root IS 'Identical to lsif_dumps.root; The working directory of the indexer image relative to the repository root.';\nCREATE INDEX lsif_data_documentation_search_public_dump_root_idx ON lsif_data_documentation_search_public USING BTREE(dump_root);\n\nALTER TABLE lsif_data_documentation_search_private ADD COLUMN dump_root TEXT NOT NULL DEFAULT '';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.dump_root IS 'Identical to lsif_dumps.root; The working directory of the indexer image relative to the repository root.';\nCREATE INDEX lsif_data_documentation_search_private_dump_root_idx ON lsif_data_documentation_search_public USING BTREE(dump_root);\n\n-- Truncate both tables; we don't care about reindexing given so little has been indexed to date.\nTRUNCATE lsif_data_documentation_search_public;\nTRUNCATE lsif_data_documentation_search_private;",
				"DownQuery": "ALTER TABLE lsif_data_documentation_search_public DROP COLUMN IF EXISTS dump_root;\nALTER TABLE lsif_data_documentation_search_private DROP COLUMN IF EXISTS dump_root;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000022
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000024,
				"Name": "apidocs search to tsvector",
				"UpQuery": "-- We're completely changing the API docs search table schema, so we'll reindex everything\n-- from scratch. Reset our OOB migration's progress entirely.\n--\n-- IMPORTANT: Dropping the column and recreating it is nearly instant, updating the table\n-- to set the column to 'false' again can take several minutes.\nALTER TABLE lsif_data_documentation_pages DROP COLUMN search_indexed;\nALTER TABLE lsif_data_documentation_pages ADD COLUMN search_indexed boolean DEFAULT 'false';\n\n-- We're completely redefining the table.\nDROP TABLE IF EXISTS lsif_data_documentation_search_public;\n\n-- Each unique language name being stored in the search index.\n--\n-- Contains a tsvector index for matching a logical OR of query terms against the language name\n-- (e.g. \"http router go\" to match \"go\" without knowing if \"http\", \"router\", or \"go\" are actually\n-- a language name or not.)\nCREATE TABLE lsif_data_docs_search_lang_names_public (\n    id BIGSERIAL PRIMARY KEY,\n    lang_name TEXT NOT NULL UNIQUE,\n    tsv TSVECTOR NOT NULL\n);\nCREATE INDEX lsif_data_docs_search_lang_names_public_tsv_idx ON lsif_data_docs_search_lang_names_public USING GIN(tsv);\n\nCOMMENT ON TABLE lsif_data_docs_search_lang_names_public IS 'Each unique language name being stored in the API docs search index.';\nCOMMENT ON COLUMN lsif_data_docs_search_lang_names_public.id IS 'The ID of the language name.';\nCOMMENT ON COLUMN lsif_data_docs_search_lang_names_public.lang_name IS 'The lowercase language name (go, java, etc.) OR, if unknown, the LSIF indexer name.';\nCOMMENT ON COLUMN lsif_data_docs_search_lang_names_public.tsv IS 'Indexed tsvector for the lang_name field. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\n\n-- Each unique repository name being stored in the search index.\n--\n-- Contains a tsvector index for matching against repository names, with both prefix and suffix\n-- (reverse prefix) matching within lexemes (words).\nCREATE TABLE lsif_data_docs_search_repo_names_public (\n    id BIGSERIAL PRIMARY KEY,\n    repo_name TEXT NOT NULL UNIQUE,\n    tsv TSVECTOR NOT NULL,\n    reverse_tsv TSVECTOR NOT NULL\n);\nCREATE INDEX lsif_data_docs_search_repo_names_public_tsv_idx ON lsif_data_docs_search_repo_names_public USING GIN(tsv);\nCREATE INDEX lsif_data_docs_search_repo_names_public_reverse_tsv_idx ON lsif_data_docs_search_repo_names_public USING GIN(reverse_tsv);\n\nCOMMENT ON TABLE lsif_data_docs_search_repo_names_public IS 'Each unique repository name being stored in the API docs search index.';\nCOMMENT ON COLUMN lsif_data_docs_search_repo_names_public.id IS 'The ID of the repository name.';\nCOMMENT ON COLUMN lsif_data_docs_search_repo_names_public.repo_name IS 'The fully qualified name of the repository.';\nCOMMENT ON COLUMN lsif_data_docs_search_repo_names_public.tsv IS 'Indexed tsvector for the lang_name field. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\nCOMMENT ON COLUMN lsif_data_docs_search_repo_names_public.reverse_tsv IS 'Indexed tsvector for the reverse of the lang_name field, for suffix lexeme/word matching. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\n\n-- Each unique sequence of space-separated tags being stored in the search index. This could be as\n-- many rows as the search table itself, because in theory each result could have a unique string\n-- of tags. In practice, though, they are frequently similar sequences.\n--\n-- The space separated tags have a tsvector for matching a logcal OR of query terms against, for\n-- the same reason as the lang_names table. e.g. so that we can have a query for \"go private function net router\"\n-- match the tags string \"private function\" without knowing which query terms are tags or not.\n--\n-- The entire sequence of space-separated tags are stored, in part so that lookups in the search table\n-- are faster (single ID lookup rather than array ALL lookup) and partly to allow for more complex\n-- tag matching options in the future.\nCREATE TABLE lsif_data_docs_search_tags_public (\n    id BIGSERIAL PRIMARY KEY,\n    tags TEXT NOT NULL UNIQUE,\n    tsv TSVECTOR NOT NULL\n);\nCREATE INDEX lsif_data_docs_search_tags_public_tsv_idx ON lsif_data_docs_search_tags_public USING GIN(tsv);\n\nCOMMENT ON TABLE lsif_data_docs_search_tags_public IS 'Each uniques sequence of space-separated tags being stored in the API docs search index.';\nCOMMENT ON COLUMN lsif_data_docs_search_tags_public.id IS 'The ID of the tags.';\nCOMMENT ON COLUMN lsif_data_docs_search_tags_public.tags IS 'The full sequence of space-separated tags. See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_docs_search_tags_public.tsv IS 'Indexed tsvector for the tags field. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\n\n-- The actual search index over API docs, one entry per symbol/section of API docs.\nCREATE TABLE lsif_data_docs_search_public (\n    -- Metadata fields\n    id BIGSERIAL PRIMARY KEY,\n    repo_id INTEGER NOT NULL,\n    dump_id INTEGER NOT NULL,\n    dump_root TEXT NOT NULL,\n    path_id TEXT NOT NULL,\n    detail TEXT NOT NULL,\n    lang_name_id INTEGER NOT NULL,\n    repo_name_id INTEGER NOT NULL,\n    tags_id INTEGER NOT NULL,\n\n    -- FTS-enabled fields\n    search_key TEXT NOT NULL,\n    search_key_tsv TSVECTOR NOT NULL,\n    search_key_reverse_tsv TSVECTOR NOT NULL,\n\n    label TEXT NOT NULL,\n    label_tsv TSVECTOR NOT NULL,\n    label_reverse_tsv TSVECTOR NOT NULL,\n\n    CONSTRAINT lsif_data_docs_search_public_lang_name_id_fk FOREIGN KEY(lang_name_id) REFERENCES lsif_data_docs_search_lang_names_public(id),\n    CONSTRAINT lsif_data_docs_search_public_repo_name_id_fk FOREIGN KEY(repo_name_id) REFERENCES lsif_data_docs_search_repo_names_public(id),\n    CONSTRAINT lsif_data_docs_search_public_tags_id_fk FOREIGN KEY(tags_id) REFERENCES lsif_data_docs_search_tags_public(id)\n);\n\n-- This pair of fields is used to purge stale data from the search index, so use a btree index on it.\nCREATE INDEX lsif_data_docs_search_public_repo_id_idx ON lsif_data_docs_search_public USING BTREE(repo_id);\nCREATE INDEX lsif_data_docs_search_public_dump_id_idx ON lsif_data_docs_search_public USING BTREE(dump_id);\nCREATE INDEX lsif_data_docs_search_public_dump_root_idx ON lsif_data_docs_search_public USING BTREE(dump_root);\n\n-- tsvector indexes\nCREATE INDEX lsif_data_docs_search_public_search_key_tsv_idx ON lsif_data_docs_search_public USING BTREE(search_key_tsv);\nCREATE INDEX lsif_data_docs_search_public_search_key_reverse_tsv_idx ON lsif_data_docs_search_public USING BTREE(search_key_reverse_tsv);\nCREATE INDEX lsif_data_docs_search_public_label_tsv_idx ON lsif_data_docs_search_public USING BTREE(label_tsv);\nCREATE INDEX lsif_data_docs_search_public_label_reverse_tsv_idx ON lsif_data_docs_search_public USING BTREE(label_reverse_tsv);\n\nCOMMENT ON TABLE lsif_data_docs_search_public IS 'A tsvector search index over API documentation (public repos only)';\nCOMMENT ON COLUMN lsif_data_docs_search_public.id IS 'The row ID of the search result.';\nCOMMENT ON COLUMN lsif_data_docs_search_public.repo_id IS 'The repo ID, from the main app DB repo table. Used to search over a select set of repos by ID.';\nCOMMENT ON COLUMN lsif_data_docs_search_public.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\nCOMMENT ON COLUMN lsif_data_docs_search_public.dump_root IS 'Identical to lsif_dumps.root; The working directory of the indexer image relative to the repository root.';\nCOMMENT ON COLUMN lsif_data_docs_search_public.path_id IS 'The fully qualified documentation page path ID, e.g. including \"#section\". See GraphQL codeintel.schema:documentationPage for what this is.';\nCOMMENT ON COLUMN lsif_data_docs_search_public.detail IS 'The detail string (e.g. the full function signature and its docs). See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_docs_search_public.lang_name_id IS 'The programming language (or indexer name) that produced the result. Foreign key into lsif_data_docs_search_lang_names_public.';\nCOMMENT ON COLUMN lsif_data_docs_search_public.repo_name_id IS 'The repository name that produced the result. Foreign key into lsif_data_docs_search_repo_names_public.';\nCOMMENT ON COLUMN lsif_data_docs_search_public.tags_id IS 'The tags from the documentation node. Foreign key into lsif_data_docs_search_tags_public.';\n\nCOMMENT ON COLUMN lsif_data_docs_search_public.search_key IS 'The search key generated by the indexer, e.g. mux.Router.ServeHTTP. It is language-specific, and likely unique within a repository (but not always.) See protocol/documentation.go:Documentation.SearchKey';\nCOMMENT ON COLUMN lsif_data_docs_search_public.search_key_tsv IS 'Indexed tsvector for the search_key field. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\nCOMMENT ON COLUMN lsif_data_docs_search_public.search_key_reverse_tsv IS 'Indexed tsvector for the reverse of the search_key field, for suffix lexeme/word matching. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\n\nCOMMENT ON COLUMN lsif_data_docs_search_public.label IS 'The label string of the result, e.g. a one-line function signature. See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_docs_search_public.label_tsv IS 'Indexed tsvector for the label field. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\nCOMMENT ON COLUMN lsif_data_docs_search_public.label_reverse_tsv IS 'Indexed tsvector for the reverse of the label field, for suffix lexeme/word matching. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\n\n-- ************************************************************************************************\n-- Below here is a direct copy of the above, but with \"public\" replaced with \"private\" for the    *\n-- private variant of the table.                                                                  *\n-- ************************************************************************************************\n\n-- We're completely redefining the table.\nDROP TABLE IF EXISTS lsif_data_documentation_search_private;\n\n-- Each unique language name being stored in the search index.\n--\n-- Contains a tsvector index for matching a logical OR of query terms against the language name\n-- (e.g. \"http router go\" to match \"go\" without knowing if \"http\", \"router\", or \"go\" are actually\n-- a language name or not.)\nCREATE TABLE lsif_data_docs_search_lang_names_private (\n    id BIGSERIAL PRIMARY KEY,\n    lang_name TEXT NOT NULL UNIQUE,\n    tsv TSVECTOR NOT NULL\n);\nCREATE INDEX lsif_data_docs_search_lang_names_private_tsv_idx ON lsif_data_docs_search_lang_names_private USING GIN(tsv);\n\nCOMMENT ON TABLE lsif_data_docs_search_lang_names_private IS 'Each unique language name being stored in the API docs search index.';\nCOMMENT ON COLUMN lsif_data_docs_search_lang_names_private.id IS 'The ID of the language name.';\nCOMMENT ON COLUMN lsif_data_docs_search_lang_names_private.lang_name IS 'The lowercase language name (go, java, etc.) OR, if unknown, the LSIF indexer name.';\nCOMMENT ON COLUMN lsif_data_docs_search_lang_names_private.tsv IS 'Indexed tsvector for the lang_name field. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\n\n-- Each unique repository name being stored in the search index.\n--\n-- Contains a tsvector index for matching against repository names, with both prefix and suffix\n-- (reverse prefix) matching within lexemes (words).\nCREATE TABLE lsif_data_docs_search_repo_names_private (\n    id BIGSERIAL PRIMARY KEY,\n    repo_name TEXT NOT NULL UNIQUE,\n    tsv TSVECTOR NOT NULL,\n    reverse_tsv TSVECTOR NOT NULL\n);\nCREATE INDEX lsif_data_docs_search_repo_names_private_tsv_idx ON lsif_data_docs_search_repo_names_private USING GIN(tsv);\nCREATE INDEX lsif_data_docs_search_repo_names_private_reverse_tsv_idx ON lsif_data_docs_search_repo_names_private USING GIN(reverse_tsv);\n\nCOMMENT ON TABLE lsif_data_docs_search_repo_names_private IS 'Each unique repository name being stored in the API docs search index.';\nCOMMENT ON COLUMN lsif_data_docs_search_repo_names_private.id IS 'The ID of the repository name.';\nCOMMENT ON COLUMN lsif_data_docs_search_repo_names_private.repo_name IS 'The fully qualified name of the repository.';\nCOMMENT ON COLUMN lsif_data_docs_search_repo_names_private.tsv IS 'Indexed tsvector for the lang_name field. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\nCOMMENT ON COLUMN lsif_data_docs_search_repo_names_private.reverse_tsv IS 'Indexed tsvector for the reverse of the lang_name field, for suffix lexeme/word matching. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\n\n-- Each unique sequence of space-separated tags being stored in the search index. This could be as\n-- many rows as the search table itself, because in theory each result could have a unique string\n-- of tags. In practice, though, they are frequently similar sequences.\n--\n-- The space separated tags have a tsvector for matching a logcal OR of query terms against, for\n-- the same reason as the lang_names table. e.g. so that we can have a query for \"go private function net router\"\n-- match the tags string \"private function\" without knowing which query terms are tags or not.\n--\n-- The entire sequence of space-separated tags are stored, in part so that lookups in the search table\n-- are faster (single ID lookup rather than array ALL lookup) and partly to allow for more complex\n-- tag matching options in the future.\nCREATE TABLE lsif_data_docs_search_tags_private (\n    id BIGSERIAL PRIMARY KEY,\n    tags TEXT NOT NULL UNIQUE,\n    tsv TSVECTOR NOT NULL\n);\nCREATE INDEX lsif_data_docs_search_tags_private_tsv_idx ON lsif_data_docs_search_tags_private USING GIN(tsv);\n\nCOMMENT ON TABLE lsif_data_docs_search_tags_private IS 'Each uniques sequence of space-separated tags being stored in the API docs search index.';\nCOMMENT ON COLUMN lsif_data_docs_search_tags_private.id IS 'The ID of the tags.';\nCOMMENT ON COLUMN lsif_data_docs_search_tags_private.tags IS 'The full sequence of space-separated tags. See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_docs_search_tags_private.tsv IS 'Indexed tsvector for the tags field. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\n\n-- The actual search index over API docs, one entry per symbol/section of API docs.\nCREATE TABLE lsif_data_docs_search_private (\n    -- Metadata fields\n    id BIGSERIAL PRIMARY KEY,\n    repo_id INTEGER NOT NULL,\n    dump_id INTEGER NOT NULL,\n    dump_root TEXT NOT NULL,\n    path_id TEXT NOT NULL,\n    detail TEXT NOT NULL,\n    lang_name_id INTEGER NOT NULL,\n    repo_name_id INTEGER NOT NULL,\n    tags_id INTEGER NOT NULL,\n\n    -- FTS-enabled fields\n    search_key TEXT NOT NULL,\n    search_key_tsv TSVECTOR NOT NULL,\n    search_key_reverse_tsv TSVECTOR NOT NULL,\n\n    label TEXT NOT NULL,\n    label_tsv TSVECTOR NOT NULL,\n    label_reverse_tsv TSVECTOR NOT NULL,\n\n    CONSTRAINT lsif_data_docs_search_private_lang_name_id_fk FOREIGN KEY(lang_name_id) REFERENCES lsif_data_docs_search_lang_names_private(id),\n    CONSTRAINT lsif_data_docs_search_private_repo_name_id_fk FOREIGN KEY(repo_name_id) REFERENCES lsif_data_docs_search_repo_names_private(id),\n    CONSTRAINT lsif_data_docs_search_private_tags_id_fk FOREIGN KEY(tags_id) REFERENCES lsif_data_docs_search_tags_private(id)\n);\n\n-- This pair of fields is used to purge stale data from the search index, so use a btree index on it.\nCREATE INDEX lsif_data_docs_search_private_repo_id_idx ON lsif_data_docs_search_private USING BTREE(repo_id);\nCREATE INDEX lsif_data_docs_search_private_dump_id_idx ON lsif_data_docs_search_private USING BTREE(dump_id);\nCREATE INDEX lsif_data_docs_search_private_dump_root_idx ON lsif_data_docs_search_private USING BTREE(dump_root);\n\n-- tsvector indexes\nCREATE INDEX lsif_data_docs_search_private_search_key_tsv_idx ON lsif_data_docs_search_private USING BTREE(search_key_tsv);\nCREATE INDEX lsif_data_docs_search_private_search_key_reverse_tsv_idx ON lsif_data_docs_search_private USING BTREE(search_key_reverse_tsv);\nCREATE INDEX lsif_data_docs_search_private_label_tsv_idx ON lsif_data_docs_search_private USING BTREE(label_tsv);\nCREATE INDEX lsif_data_docs_search_private_label_reverse_tsv_idx ON lsif_data_docs_search_private USING BTREE(label_reverse_tsv);\n\nCOMMENT ON TABLE lsif_data_docs_search_private IS 'A tsvector search index over API documentation (private repos only)';\nCOMMENT ON COLUMN lsif_data_docs_search_private.id IS 'The row ID of the search result.';\nCOMMENT ON COLUMN lsif_data_docs_search_private.repo_id IS 'The repo ID, from the main app DB repo table. Used to search over a select set of repos by ID.';\nCOMMENT ON COLUMN lsif_data_docs_search_private.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\nCOMMENT ON COLUMN lsif_data_docs_search_private.dump_root IS 'Identical to lsif_dumps.root; The working directory of the indexer image relative to the repository root.';\nCOMMENT ON COLUMN lsif_data_docs_search_private.path_id IS 'The fully qualified documentation page path ID, e.g. including \"#section\". See GraphQL codeintel.schema:documentationPage for what this is.';\nCOMMENT ON COLUMN lsif_data_docs_search_private.detail IS 'The detail string (e.g. the full function signature and its docs). See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_docs_search_private.lang_name_id IS 'The programming language (or indexer name) that produced the result. Foreign key into lsif_data_docs_search_lang_names_private.';\nCOMMENT ON COLUMN lsif_data_docs_search_private.repo_name_id IS 'The repository name that produced the result. Foreign key into lsif_data_docs_search_repo_names_private.';\nCOMMENT ON COLUMN lsif_data_docs_search_private.tags_id IS 'The tags from the documentation node. Foreign key into lsif_data_docs_search_tags_private.';\n\nCOMMENT ON COLUMN lsif_data_docs_search_private.search_key IS 'The search key generated by the indexer, e.g. mux.Router.ServeHTTP. It is language-specific, and likely unique within a repository (but not always.) See protocol/documentation.go:Documentation.SearchKey';\nCOMMENT ON COLUMN lsif_data_docs_search_private.search_key_tsv IS 'Indexed tsvector for the search_key field. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\nCOMMENT ON COLUMN lsif_data_docs_search_private.search_key_reverse_tsv IS 'Indexed tsvector for the reverse of the search_key field, for suffix lexeme/word matching. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\n\nCOMMENT ON COLUMN lsif_data_docs_search_private.label IS 'The label string of the result, e.g. a one-line function signature. See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_docs_search_private.label_tsv IS 'Indexed tsvector for the label field. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\nCOMMENT ON COLUMN lsif_data_docs_search_private.label_reverse_tsv IS 'Indexed tsvector for the reverse of the label field, for suffix lexeme/word matching. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';",
				"DownQuery": "-- We've alterd tables beyond rollback in our up migration. The best we can do for a down migration\n-- is bring back the old schema so the previous version of Sourcegraph runs properly.\nDROP TABLE IF EXISTS lsif_data_docs_search_public;\nDROP TABLE IF EXISTS lsif_data_docs_search_lang_names_public;\nDROP TABLE IF EXISTS lsif_data_docs_search_repo_names_public;\nDROP TABLE IF EXISTS lsif_data_docs_search_tags_public;\n\nCREATE TABLE IF NOT EXISTS lsif_data_documentation_search_public (\n    -- Metadata fields\n    dump_id integer NOT NULL,\n    repo_id integer NOT NULL,\n    path_id TEXT NOT NULL,\n    detail TEXT NOT NULL,\n\n    -- FTS-enabled fields\n    lang TEXT NOT NULL,\n    repo_name TEXT NOT NULL,\n    search_key TEXT NOT NULL,\n    label TEXT NOT NULL,\n    tags TEXT NOT NULL\n);\n\nALTER TABLE lsif_data_documentation_search_public ADD PRIMARY KEY (dump_id, path_id);\n\nCREATE INDEX lsif_data_documentation_search_public_repo_id_idx ON lsif_data_documentation_search_public USING BTREE(repo_id);\nCREATE INDEX lsif_data_documentation_search_public_lang_trgm ON lsif_data_documentation_search_public USING gin(lang gin_trgm_ops);\nCREATE INDEX lsif_data_documentation_search_public_repo_name_trgm ON lsif_data_documentation_search_public USING gin(repo_name gin_trgm_ops);\nCREATE INDEX lsif_data_documentation_search_public_search_key_trgm ON lsif_data_documentation_search_public USING gin(search_key gin_trgm_ops);\nCREATE INDEX lsif_data_documentation_search_public_label_trgm ON lsif_data_documentation_search_public USING gin(label gin_trgm_ops);\nCREATE INDEX lsif_data_documentation_search_public_tags_trgm ON lsif_data_documentation_search_public USING gin(tags gin_trgm_ops);\n\nCOMMENT ON TABLE lsif_data_documentation_search_public IS 'A trigram index over documentation for search (public repos only)';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.repo_id IS 'The repo ID, from the main app DB repo table. Used to search over a select set of repos by ID.';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.path_id IS 'The fully qualified documentation page path ID, e.g. including \"#section\". See GraphQL codeintel.schema:documentationPage for what this is.';\n\nCOMMENT ON COLUMN lsif_data_documentation_search_public.lang IS 'The lowercase language name (go, java, etc.) OR, if unknown, the LSIF indexer name';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.repo_name IS 'The name of the repository containing this search key.';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.search_key IS 'The search key generated by the indexer, e.g. mux.Router.ServeHTTP. It is language-specific, and likely unique within a repository (but not always.) See protocol/documentation.go:Documentation.SearchKey';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.label IS 'The label string of the result, e.g. a one-line function signature. See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.detail IS 'The detail string (e.g. the full function signature and its docs). See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.tags IS 'A space separated list of tags from the documentation node. See protocol/documentation.go:Documentation';\n\nALTER TABLE lsif_data_documentation_search_public ADD COLUMN dump_root TEXT NOT NULL DEFAULT '';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.dump_root IS 'Identical to lsif_dumps.root; The working directory of the indexer image relative to the repository root.';\nCREATE INDEX lsif_data_documentation_search_public_dump_root_idx ON lsif_data_documentation_search_public USING BTREE(dump_root);\n\n-- ************************************************************************************************\n-- Below here is a direct copy of the above, but with \"public\" replaced with \"private\" for the    *\n-- private variant of the table.                                                                  *\n-- ************************************************************************************************\n\n-- We've alterd tables beyond rollback in our up migration. The best we can do for a down migration\n-- is bring back the old schema so the previous version of Sourcegraph runs properly.\nDROP TABLE IF EXISTS lsif_data_docs_search_private;\nDROP TABLE IF EXISTS lsif_data_docs_search_lang_names_private;\nDROP TABLE IF EXISTS lsif_data_docs_search_repo_names_private;\nDROP TABLE IF EXISTS lsif_data_docs_search_tags_private;\n\nCREATE TABLE IF NOT EXISTS lsif_data_documentation_search_private (\n    -- Metadata fields\n    dump_id integer NOT NULL,\n    repo_id integer NOT NULL,\n    path_id TEXT NOT NULL,\n    detail TEXT NOT NULL,\n\n    -- FTS-enabled fields\n    lang TEXT NOT NULL,\n    repo_name TEXT NOT NULL,\n    search_key TEXT NOT NULL,\n    label TEXT NOT NULL,\n    tags TEXT NOT NULL\n);\n\nALTER TABLE lsif_data_documentation_search_private ADD PRIMARY KEY (dump_id, path_id);\n\nCREATE INDEX lsif_data_documentation_search_private_repo_id_idx ON lsif_data_documentation_search_private USING BTREE(repo_id);\nCREATE INDEX lsif_data_documentation_search_private_lang_trgm ON lsif_data_documentation_search_private USING gin(lang gin_trgm_ops);\nCREATE INDEX lsif_data_documentation_search_private_repo_name_trgm ON lsif_data_documentation_search_private USING gin(repo_name gin_trgm_ops);\nCREATE INDEX lsif_data_documentation_search_private_search_key_trgm ON lsif_data_documentation_search_private USING gin(search_key gin_trgm_ops);\nCREATE INDEX lsif_data_documentation_search_private_label_trgm ON lsif_data_documentation_search_private USING gin(label gin_trgm_ops);\nCREATE INDEX lsif_data_documentation_search_private_tags_trgm ON lsif_data_documentation_search_private USING gin(tags gin_trgm_ops);\n\nCOMMENT ON TABLE lsif_data_documentation_search_private IS 'A trigram index over documentation for search (private repos only)';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.repo_id IS 'The repo ID, from the main app DB repo table. Used to search over a select set of repos by ID.';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.path_id IS 'The fully qualified documentation page path ID, e.g. including \"#section\". See GraphQL codeintel.schema:documentationPage for what this is.';\n\nCOMMENT ON COLUMN lsif_data_documentation_search_private.lang IS 'The lowercase language name (go, java, etc.) OR, if unknown, the LSIF indexer name';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.repo_name IS 'The name of the repository containing this search key.';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.search_key IS 'The search key generated by the indexer, e.g. mux.Router.ServeHTTP. It is language-specific, and likely unique within a repository (but not always.) See protocol/documentation.go:Documentation.SearchKey';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.label IS 'The label string of the result, e.g. a one-line function signature. See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.detail IS 'The detail string (e.g. the full function signature and its docs). See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.tags IS 'A space separated list of tags from the documentation node. See protocol/documentation.go:Documentation';\n\nALTER TABLE lsif_data_documentation_search_private ADD COLUMN dump_root TEXT NOT NULL DEFAULT '';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.dump_root IS 'Identical to lsif_dumps.root; The working directory of the indexer image relative to the repository root.';\nCREATE INDEX lsif_data_documentation_search_private_dump_root_idx ON lsif_data_documentation_search_private USING BTREE(dump_root);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000023
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000025,
				"Name": "apidocs materialized stats",
				"UpQuery": "--------------------------------------------------------\n-- Stats for the lsif_data_documentation_pages table. --\n--------------------------------------------------------\nCREATE TABLE lsif_data_apidocs_num_pages AS SELECT count(*) FROM lsif_data_documentation_pages;\nCREATE TABLE lsif_data_apidocs_num_dumps AS SELECT count(DISTINCT dump_id) FROM lsif_data_documentation_pages;\nCREATE TABLE lsif_data_apidocs_num_dumps_indexed AS SELECT count(DISTINCT dump_id) FROM lsif_data_documentation_pages WHERE search_indexed='true';\n\nCREATE OR REPLACE FUNCTION lsif_data_documentation_pages_delete()\nRETURNS TRIGGER LANGUAGE plpgsql\nAS $$\nBEGIN\nUPDATE lsif_data_apidocs_num_pages SET count = count - (select count(*) from oldtbl);\nUPDATE lsif_data_apidocs_num_dumps SET count = count - (select count(DISTINCT dump_id) from oldtbl);\nUPDATE lsif_data_apidocs_num_dumps_indexed SET count = count - (select count(DISTINCT dump_id) from oldtbl WHERE search_indexed='true');\nRETURN NULL;\nEND $$;\n\nCREATE TRIGGER lsif_data_documentation_pages_delete\nAFTER DELETE ON lsif_data_documentation_pages\nREFERENCING OLD TABLE AS oldtbl\nFOR EACH STATEMENT EXECUTE PROCEDURE lsif_data_documentation_pages_delete();\n\nCREATE OR REPLACE FUNCTION lsif_data_documentation_pages_insert()\nRETURNS TRIGGER LANGUAGE plpgsql\nAS $$\nBEGIN\nUPDATE lsif_data_apidocs_num_pages SET count = count + (select count(*) from newtbl);\nUPDATE lsif_data_apidocs_num_dumps SET count = count + (select count(DISTINCT dump_id) from newtbl);\nUPDATE lsif_data_apidocs_num_dumps_indexed SET count = count + (select count(DISTINCT dump_id) from newtbl WHERE search_indexed='true');\nRETURN NULL;\nEND $$;\n\nCREATE TRIGGER lsif_data_documentation_pages_insert\nAFTER INSERT ON lsif_data_documentation_pages\nREFERENCING NEW TABLE AS newtbl\nFOR EACH STATEMENT EXECUTE PROCEDURE lsif_data_documentation_pages_insert();\n\nCREATE OR REPLACE FUNCTION lsif_data_documentation_pages_update()\nRETURNS TRIGGER LANGUAGE plpgsql\nAS $$\nBEGIN\nWITH\n    beforeIndexed AS (SELECT count(DISTINCT dump_id) FROM oldtbl WHERE search_indexed='true'),\n    afterIndexed AS (SELECT count(DISTINCT dump_id) FROM newtbl WHERE search_indexed='true')\nUPDATE lsif_data_apidocs_num_dumps_indexed SET count=count + ((select * from afterIndexed) - (select * from beforeIndexed));\nRETURN NULL;\nEND $$;\n\nCREATE TRIGGER lsif_data_documentation_pages_update\nAFTER UPDATE ON lsif_data_documentation_pages\nREFERENCING OLD TABLE AS oldtbl NEW TABLE AS newtbl\nFOR EACH STATEMENT EXECUTE PROCEDURE lsif_data_documentation_pages_update();\n\n-------------------------------------------------------\n-- Stats for the lsif_data_docs_search_public table. --\n-------------------------------------------------------\nCREATE TABLE lsif_data_apidocs_num_search_results_public AS SELECT count(*) FROM lsif_data_docs_search_public;\n\nCREATE OR REPLACE FUNCTION lsif_data_docs_search_public_delete()\nRETURNS TRIGGER LANGUAGE plpgsql\nAS $$\nBEGIN\nUPDATE lsif_data_apidocs_num_search_results_public SET count = count - (select count(*) from oldtbl);\nRETURN NULL;\nEND $$;\n\nCREATE TRIGGER lsif_data_docs_search_public_delete\nAFTER DELETE\nON lsif_data_docs_search_public\nREFERENCING OLD TABLE AS oldtbl\nFOR EACH STATEMENT EXECUTE PROCEDURE lsif_data_docs_search_public_delete();\n\nCREATE OR REPLACE FUNCTION lsif_data_docs_search_public_insert()\nRETURNS TRIGGER LANGUAGE plpgsql\nAS $$\nBEGIN\nUPDATE lsif_data_apidocs_num_search_results_public SET count = count + (select count(*) from newtbl);\nRETURN NULL;\nEND $$;\n\nCREATE TRIGGER lsif_data_docs_search_public_insert\nAFTER INSERT\nON lsif_data_docs_search_public\nREFERENCING NEW TABLE AS newtbl\nFOR EACH STATEMENT EXECUTE PROCEDURE lsif_data_docs_search_public_insert();\n\n-------------------------------------------------------\n-- Stats for the lsif_data_docs_search_private table. --\n-------------------------------------------------------\nCREATE TABLE lsif_data_apidocs_num_search_results_private AS SELECT count(*) FROM lsif_data_docs_search_private;\n\nCREATE OR REPLACE FUNCTION lsif_data_docs_search_private_delete()\nRETURNS TRIGGER LANGUAGE plpgsql\nAS $$\nBEGIN\nUPDATE lsif_data_apidocs_num_search_results_private SET count = count - (select count(*) from oldtbl);\nRETURN NULL;\nEND $$;\n\nCREATE TRIGGER lsif_data_docs_search_private_delete\nAFTER DELETE\nON lsif_data_docs_search_private\nREFERENCING OLD TABLE AS oldtbl\nFOR EACH STATEMENT EXECUTE PROCEDURE lsif_data_docs_search_private_delete();\n\nCREATE OR REPLACE FUNCTION lsif_data_docs_search_private_insert()\nRETURNS TRIGGER LANGUAGE plpgsql\nAS $$\nBEGIN\nUPDATE lsif_data_apidocs_num_search_results_private SET count = count + (select count(*) from newtbl);\nRETURN NULL;\nEND $$;\n\nCREATE TRIGGER lsif_data_docs_search_private_insert\nAFTER INSERT\nON lsif_data_docs_search_private\nREFERENCING NEW TABLE AS newtbl\nFOR EACH STATEMENT EXECUTE PROCEDURE lsif_data_docs_search_private_insert();",
				"DownQuery": "DROP TABLE lsif_data_apidocs_num_pages;\nDROP TABLE lsif_data_apidocs_num_dumps;\nDROP TABLE lsif_data_apidocs_num_dumps_indexed;\nDROP TRIGGER lsif_data_documentation_pages_delete ON lsif_data_documentation_pages;\nDROP TRIGGER lsif_data_documentation_pages_insert ON lsif_data_documentation_pages;\nDROP TRIGGER lsif_data_documentation_pages_update ON lsif_data_documentation_pages;\nDROP FUNCTION lsif_data_documentation_pages_delete;\nDROP FUNCTION lsif_data_documentation_pages_insert;\nDROP FUNCTION lsif_data_documentation_pages_update;\n\nDROP TABLE lsif_data_apidocs_num_search_results_public;\nDROP TRIGGER lsif_data_docs_search_public_delete ON lsif_data_docs_search_public;\nDROP TRIGGER lsif_data_docs_search_public_insert ON lsif_data_docs_search_public;\nDROP FUNCTION lsif_data_docs_search_public_delete;\nDROP FUNCTION lsif_data_docs_search_public_insert;\n\nDROP TABLE lsif_data_apidocs_num_search_results_private;\nDROP TRIGGER lsif_data_docs_search_private_delete ON lsif_data_docs_search_private;\nDROP TRIGGER lsif_data_docs_search_private_insert ON lsif_data_docs_search_private;\nDROP FUNCTION lsif_data_docs_search_private_delete;\nDROP FUNCTION lsif_data_docs_search_private_insert;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000024
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000026,
				"Name": "add lsif data docs search current",
				"UpQuery": "CREATE TABLE IF NOT EXISTS lsif_data_docs_search_current_public (\n    repo_id INTEGER NOT NULL,\n    dump_root TEXT NOT NULL,\n    lang_name_id INTEGER NOT NULL,\n    dump_id INTEGER NOT NULL,\n    last_cleanup_scan_at timestamp with time zone NOT NULL,\n\n    PRIMARY KEY (repo_id, dump_root, lang_name_id)\n);\n\nCOMMENT ON TABLE lsif_data_docs_search_current_public IS 'A table indicating the most current search index for a unique repository, root, and language.';\nCOMMENT ON COLUMN lsif_data_docs_search_current_public.repo_id IS 'The repository identifier of the associated dump.';\nCOMMENT ON COLUMN lsif_data_docs_search_current_public.dump_root IS 'The root of the associated dump.';\nCOMMENT ON COLUMN lsif_data_docs_search_current_public.lang_name_id IS 'The interned index name of the associated dump.';\nCOMMENT ON COLUMN lsif_data_docs_search_current_public.dump_id IS 'The most recent dump identifier for this key. See associated content in the lsif_data_docs_search_public table.';\nCOMMENT ON COLUMN lsif_data_docs_search_current_public.last_cleanup_scan_at IS 'The last time outdated records in the lsif_data_docs_search_public table have been cleaned.';\n\nCREATE TABLE IF NOT EXISTS lsif_data_docs_search_current_private (\n    repo_id INTEGER NOT NULL,\n    dump_root TEXT NOT NULL,\n    lang_name_id INTEGER NOT NULL,\n    dump_id INTEGER NOT NULL,\n    last_cleanup_scan_at timestamp with time zone NOT NULL,\n\n    PRIMARY KEY (repo_id, dump_root, lang_name_id)\n);\n\nCOMMENT ON TABLE lsif_data_docs_search_current_private IS 'A table indicating the most current search index for a unique repository, root, and language.';\nCOMMENT ON COLUMN lsif_data_docs_search_current_private.repo_id IS 'The repository identifier of the associated dump.';\nCOMMENT ON COLUMN lsif_data_docs_search_current_private.dump_root IS 'The root of the associated dump.';\nCOMMENT ON COLUMN lsif_data_docs_search_current_private.lang_name_id IS 'The interned index name of the associated dump.';\nCOMMENT ON COLUMN lsif_data_docs_search_current_private.dump_id IS 'The most recent dump identifier for this key. See associated content in the lsif_data_docs_search_private table.';\nCOMMENT ON COLUMN lsif_data_docs_search_current_private.last_cleanup_scan_at IS 'The last time outdated records in the lsif_data_docs_search_private table have been cleaned.';",
				"DownQuery": "DROP TABLE IF EXISTS lsif_data_docs_search_current_public;\nDROP TABLE IF EXISTS lsif_data_docs_search_current_private;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000025
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000027,
				"Name": "add search repo names index",
				"UpQuery": "CREATE INDEX IF NOT EXISTS lsif_data_documentation_pages_dump_id_unindexed ON lsif_data_documentation_pages(dump_id) WHERE NOT search_indexed;",
				"DownQuery": "DROP INDEX lsif_data_documentation_pages_dump_id_unindexed;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000026
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000028,
				"Name": "lsif non unique docs search current tables",
				"UpQuery": "--\n-- Public\n\n-- Change comment\nCOMMENT ON COLUMN lsif_data_docs_search_current_public.dump_id IS 'The associated dump identifier.';\n\n-- Create new created_at column to decide a leader\nALTER TABLE lsif_data_docs_search_current_public ADD COLUMN IF NOT EXISTS created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW();\nCOMMENT ON COLUMN lsif_data_docs_search_current_public.created_at IS 'The time this record was inserted. The records with the latest created_at value for the same repository, root, and language is the only visible one and others will be deleted asynchronously.';\n\n-- Add default to last_cleanup_scan_at column\nALTER TABLE lsif_data_docs_search_current_public ALTER COLUMN last_cleanup_scan_at SET DEFAULT NOW();\nCOMMENT ON COLUMN lsif_data_docs_search_current_public.last_cleanup_scan_at IS 'The last time this record was checked as part of a data retention scan.';\n\n-- Create new indexes\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_current_public_lookup\nON lsif_data_docs_search_current_public(repo_id, dump_root, lang_name_id, created_at)\nINCLUDE (dump_id);\n\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_current_public_last_cleanup_scan_at ON lsif_data_docs_search_current_public(last_cleanup_scan_at);\n\n-- Drop existing primary key\nALTER TABLE lsif_data_docs_search_current_public DROP CONSTRAINT IF EXISTS lsif_data_docs_search_current_public_pkey;\n\n-- Create new serial primary key\nALTER TABLE lsif_data_docs_search_current_public ADD COLUMN IF NOT EXISTS id SERIAL PRIMARY KEY;\n\n--\n-- Private\n\n-- Change comment\nCOMMENT ON COLUMN lsif_data_docs_search_current_private.dump_id IS 'The associated dump identifier.';\n\n-- Create new created_at column to decide a leader\nALTER TABLE lsif_data_docs_search_current_private ADD COLUMN IF NOT EXISTS created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW();\nCOMMENT ON COLUMN lsif_data_docs_search_current_private.created_at IS 'The time this record was inserted. The records with the latest created_at value for the same repository, root, and language is the only visible one and others will be deleted asynchronously.';\n\n-- Add default to last_cleanup_scan_at column\nALTER TABLE lsif_data_docs_search_current_private ALTER COLUMN last_cleanup_scan_at SET DEFAULT NOW();\nCOMMENT ON COLUMN lsif_data_docs_search_current_private.last_cleanup_scan_at IS 'The last time this record was checked as part of a data retention scan.';\n\n-- Add index to last_cleanup_scan_at\n\n\n-- Create new indexes\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_current_private_lookup\nON lsif_data_docs_search_current_private(repo_id, dump_root, lang_name_id, created_at)\nINCLUDE (dump_id);\n\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_current_private_last_cleanup_scan_at ON lsif_data_docs_search_current_private(last_cleanup_scan_at);\n\n-- Drop existing primary key\nALTER TABLE lsif_data_docs_search_current_private DROP CONSTRAINT IF EXISTS lsif_data_docs_search_current_private_pkey;\n\n-- Create new serial primary key\nALTER TABLE lsif_data_docs_search_current_private ADD COLUMN IF NOT EXISTS id SERIAL PRIMARY KEY;",
				"DownQuery": "--\n-- Public\n\n-- De-duplicate records before adding the unique index\nDELETE FROM lsif_data_docs_search_current_public WHERE id NOT IN (\n    SELECT MAX(id) as max_id\n    FROM lsif_data_docs_search_current_public\n    GROUP BY repo_id, dump_root, lang_name_id\n);\n\n-- Drop new columns\nALTER TABLE lsif_data_docs_search_current_public DROP COLUMN IF EXISTS id;\nALTER TABLE lsif_data_docs_search_current_public DROP COLUMN IF EXISTS created_at;\n\n-- Drop new index\nDROP INDEX IF EXISTS lsif_data_docs_search_current_public_last_cleanup_scan_at;\n\n-- Re-create old primary key\nALTER TABLE lsif_data_docs_search_current_public ADD PRIMARY KEY (repo_id, dump_root, lang_name_id);\n\n-- Restore old comment\nCOMMENT ON COLUMN lsif_data_docs_search_current_public.dump_id IS 'The most recent dump identifier for this key. See associated content in the lsif_data_docs_search_public table.';\n\n-- Restore old last_cleanup_scan_at column\nCOMMENT ON COLUMN lsif_data_docs_search_current_public.last_cleanup_scan_at IS 'The last time outdated records in the lsif_data_docs_search_public table have been cleaned.';\nALTER TABLE lsif_data_docs_search_current_public ALTER COLUMN last_cleanup_scan_at DROP DEFAULT;\n\n--\n-- Private\n\n-- De-duplicate records before adding the unique index\nDELETE FROM lsif_data_docs_search_current_private WHERE id NOT IN (\n    SELECT MAX(id) as max_id\n    FROM lsif_data_docs_search_current_private\n    GROUP BY repo_id, dump_root, lang_name_id\n);\n\n-- Drop new columns\nALTER TABLE lsif_data_docs_search_current_private DROP COLUMN IF EXISTS id;\nALTER TABLE lsif_data_docs_search_current_private DROP COLUMN IF EXISTS created_at;\n\n-- Drop new index\nDROP INDEX IF EXISTS lsif_data_docs_search_current_private_last_cleanup_scan_at;\n\n-- Re-create old primary key\nALTER TABLE lsif_data_docs_search_current_private ADD PRIMARY KEY (repo_id, dump_root, lang_name_id);\n\n-- Restore old comment\nCOMMENT ON COLUMN lsif_data_docs_search_current_private.dump_id IS 'The most recent dump identifier for this key. See associated content in the lsif_data_docs_search_public table.';\n\n-- Restore old last_cleanup_scan_at column\nCOMMENT ON COLUMN lsif_data_docs_search_current_private.last_cleanup_scan_at IS 'The last time outdated records in the lsif_data_docs_search_public table have been cleaned.';\nALTER TABLE lsif_data_docs_search_current_private ALTER COLUMN last_cleanup_scan_at DROP DEFAULT;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000027
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000029,
				"Name": "apidocs missing fts indexes",
				"UpQuery": "-- Drop the btree indexes that we intended to be GIN indexes.\n-- btree indexes are no where near as performant for tsvector indexing.\nDROP INDEX IF EXISTS lsif_data_docs_search_public_search_key_tsv_idx;\nDROP INDEX IF EXISTS lsif_data_docs_search_public_search_key_reverse_tsv_idx;\nDROP INDEX IF EXISTS lsif_data_docs_search_public_label_tsv_idx;\nDROP INDEX IF EXISTS lsif_data_docs_search_public_label_reverse_tsv_idx;\n\nDROP INDEX IF EXISTS lsif_data_docs_search_private_search_key_tsv_idx;\nDROP INDEX IF EXISTS lsif_data_docs_search_private_search_key_reverse_tsv_idx;\nDROP INDEX IF EXISTS lsif_data_docs_search_private_label_tsv_idx;\nDROP INDEX IF EXISTS lsif_data_docs_search_private_label_reverse_tsv_idx;\n\n-- Recreate indexes with GIN instead.\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_public_search_key_tsv_idx ON lsif_data_docs_search_public USING GIN (search_key_tsv);\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_public_search_key_reverse_tsv_idx ON lsif_data_docs_search_public USING GIN (search_key_reverse_tsv);\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_public_label_tsv_idx ON lsif_data_docs_search_public USING GIN (label_tsv);\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_public_label_reverse_tsv_idx ON lsif_data_docs_search_public USING GIN (label_reverse_tsv);\n\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_private_search_key_tsv_idx ON lsif_data_docs_search_private USING GIN (search_key_tsv);\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_private_search_key_reverse_tsv_idx ON lsif_data_docs_search_private USING GIN (search_key_reverse_tsv);\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_private_label_tsv_idx ON lsif_data_docs_search_private USING GIN (label_tsv);\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_private_label_reverse_tsv_idx ON lsif_data_docs_search_private USING GIN (label_reverse_tsv);",
				"DownQuery": "DROP INDEX IF EXISTS lsif_data_docs_search_public_search_key_tsv_idx;\nDROP INDEX IF EXISTS lsif_data_docs_search_public_search_key_reverse_tsv_idx;\nDROP INDEX IF EXISTS lsif_data_docs_search_public_label_tsv_idx;\nDROP INDEX IF EXISTS lsif_data_docs_search_public_label_reverse_tsv_idx;\n\nDROP INDEX IF EXISTS lsif_data_docs_search_private_search_key_tsv_idx;\nDROP INDEX IF EXISTS lsif_data_docs_search_private_search_key_reverse_tsv_idx;\nDROP INDEX IF EXISTS lsif_data_docs_search_private_label_tsv_idx;\nDROP INDEX IF EXISTS lsif_data_docs_search_private_label_reverse_tsv_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000028
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000030,
				"Name": "lsif data implementations",
				"UpQuery": "CREATE TABLE lsif_data_implementations (\n    dump_id        INTEGER NOT NULL,\n    scheme         TEXT    NOT NULL,\n    identifier     TEXT    NOT NULL,\n    data           BYTEA           ,\n    schema_version INTEGER NOT NULL,\n    num_locations  INTEGER NOT NULL\n);\n\nCOMMENT ON TABLE  lsif_data_implementations                IS 'Associates (document, range) pairs with the implementation monikers attached to the range.';\nCOMMENT ON COLUMN lsif_data_implementations.dump_id        IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\nCOMMENT ON COLUMN lsif_data_implementations.scheme         IS 'The moniker scheme.';\nCOMMENT ON COLUMN lsif_data_implementations.identifier     IS 'The moniker identifier.';\nCOMMENT ON COLUMN lsif_data_implementations.data           IS 'A gob-encoded payload conforming to an array of [LocationData](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.26/-/blob/enterprise/lib/codeintel/semantic/types.go#L106:6) types.';\nCOMMENT ON COLUMN lsif_data_implementations.schema_version IS 'The schema version of this row - used to determine presence and encoding of data.';\nCOMMENT ON COLUMN lsif_data_implementations.num_locations  IS 'The number of locations stored in the data field.';\n\nALTER TABLE ONLY lsif_data_implementations ADD CONSTRAINT lsif_data_implementations_pkey PRIMARY KEY (dump_id, scheme, identifier);\n\nCREATE INDEX lsif_data_implementations_dump_id_schema_version ON lsif_data_implementations (dump_id, schema_version);\n\nCREATE TABLE lsif_data_implementations_schema_versions (\n    dump_id            INTEGER NOT NULL,\n    min_schema_version INTEGER         ,\n    max_schema_version INTEGER\n);\n\nCOMMENT ON TABLE lsif_data_implementations_schema_versions                     IS 'Tracks the range of schema_versions for each upload in the lsif_data_implementations table.';\nCOMMENT ON COLUMN lsif_data_implementations_schema_versions.dump_id            IS 'The identifier of the associated dump in the lsif_uploads table.';\nCOMMENT ON COLUMN lsif_data_implementations_schema_versions.min_schema_version IS 'A lower-bound on the `lsif_data_implementations.schema_version` where `lsif_data_implementations.dump_id = dump_id`.';\nCOMMENT ON COLUMN lsif_data_implementations_schema_versions.max_schema_version IS 'An upper-bound on the `lsif_data_implementations.schema_version` where `lsif_data_implementations.dump_id = dump_id`.';\n\nALTER TABLE ONLY lsif_data_implementations_schema_versions ADD CONSTRAINT lsif_data_implementations_schema_versions_pkey PRIMARY KEY (dump_id);\n\nCREATE INDEX lsif_data_implementations_schema_versions_dump_id_schema_version_bounds ON lsif_data_implementations_schema_versions (dump_id, min_schema_version, max_schema_version);\n\n-- On every insert into lsif_data_implementations, we need to make sure we have an associated row in the\n-- lsif_data_implementations_schema_versions table. We do not currently care about cleaning the table up\n-- (we will do this asynchronously).\n--\n-- We use FOR EACH STATEMENT here because we batch insert into this table. Running the trigger per\n-- statement rather than per row will save a ton of extra work. Running over batch inserts lets us\n-- do a GROUP BY on the new table and effectively upsert our new ranges.\n--\n-- Note that the only places where data is _modified_ in this database is during migrations, which\n-- will necessarily update this table's bounds for any migrated index records.\n\nCREATE OR REPLACE FUNCTION update_lsif_data_implementations_schema_versions_insert() RETURNS trigger AS $$ BEGIN\n    INSERT INTO\n        lsif_data_implementations_schema_versions\n    SELECT\n        dump_id,\n        MIN(schema_version) as min_schema_version,\n        MAX(schema_version) as max_schema_version\n    FROM\n        newtab\n    GROUP BY\n        dump_id\n    ON CONFLICT (dump_id) DO UPDATE SET\n        -- Update with min(old_min, new_min) and max(old_max, new_max)\n        min_schema_version = LEAST   (lsif_data_implementations_schema_versions.min_schema_version, EXCLUDED.min_schema_version),\n        max_schema_version = GREATEST(lsif_data_implementations_schema_versions.max_schema_version, EXCLUDED.max_schema_version);\n\n    RETURN NULL;\nEND $$ LANGUAGE plpgsql;\n\nCREATE TRIGGER lsif_data_implementations_schema_versions_insert\n    AFTER INSERT ON lsif_data_implementations REFERENCING NEW TABLE AS newtab\n    FOR EACH STATEMENT EXECUTE PROCEDURE update_lsif_data_implementations_schema_versions_insert();",
				"DownQuery": "DROP TABLE lsif_data_implementations_schema_versions;\nDROP TRIGGER lsif_data_implementations_schema_versions_insert ON lsif_data_implementations;\nDROP FUNCTION update_lsif_data_implementations_schema_versions_insert;\n\nDROP TABLE lsif_data_implementations;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000029
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			}
		],
		"BoundsByRev": {
			"3.34.2": {
				"RootID": -1000000015,
				"LeafIDs": [
					1000000030
				],
				"PreCreation": false
			}
		}
	},
	"frontend": {
		"Definitions": [
			{
				"ID": -1528395834,
				"Name": "squashed migrations (privileged)",
				"UpQuery": "CREATE EXTENSION IF NOT EXISTS citext;\n\nCOMMENT ON EXTENSION citext IS 'data type for case-insensitive character strings';\n\nCREATE EXTENSION IF NOT EXISTS hstore;\n\nCOMMENT ON EXTENSION hstore IS 'data type for storing sets of (key, value) pairs';\n\nCREATE EXTENSION IF NOT EXISTS intarray;\n\nCOMMENT ON EXTENSION intarray IS 'functions, operators, and index support for 1-D arrays of integers';\n\nCREATE EXTENSION IF NOT EXISTS pg_stat_statements;\n\nCOMMENT ON EXTENSION pg_stat_statements IS 'track execution statistics of all SQL statements executed';\n\nCREATE EXTENSION IF NOT EXISTS pg_trgm;\n\nCOMMENT ON EXTENSION pg_trgm IS 'text similarity measurement and index searching based on trigrams';",
				"DownQuery": "",
				"Privileged": true,
				"NonIdempotent": false,
				"Parents": null,
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395834,
				"Name": "squashed migrations",
				"UpQuery": "CREATE TYPE cm_email_priority AS ENUM (\n    'NORMAL',\n    'CRITICAL'\n);\n\nCREATE TYPE critical_or_site AS ENUM (\n    'critical',\n    'site'\n);\n\nCREATE TYPE feature_flag_type AS ENUM (\n    'bool',\n    'rollout'\n);\n\nCREATE TYPE lsif_index_state AS ENUM (\n    'queued',\n    'processing',\n    'completed',\n    'errored',\n    'failed'\n);\n\nCREATE TYPE lsif_upload_state AS ENUM (\n    'uploading',\n    'queued',\n    'processing',\n    'completed',\n    'errored',\n    'deleted',\n    'failed'\n);\n\nCREATE FUNCTION delete_batch_change_reference_on_changesets() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$\n    BEGIN\n        UPDATE\n          changesets\n        SET\n          batch_change_ids = changesets.batch_change_ids - OLD.id::text\n        WHERE\n          changesets.batch_change_ids ? OLD.id::text;\n\n        RETURN OLD;\n    END;\n$$;\n\nCREATE FUNCTION delete_repo_ref_on_external_service_repos() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$\n    BEGIN\n        -- if a repo is soft-deleted, delete every row that references that repo\n        IF (OLD.deleted_at IS NULL AND NEW.deleted_at IS NOT NULL) THEN\n        DELETE FROM\n            external_service_repos\n        WHERE\n            repo_id = OLD.id;\n        END IF;\n\n        RETURN OLD;\n    END;\n$$;\n\nCREATE FUNCTION invalidate_session_for_userid_on_password_change() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$\n    BEGIN\n        IF OLD.passwd != NEW.passwd THEN\n            NEW.invalidated_sessions_at = now() + (1 * interval '1 second');\n            RETURN NEW;\n        END IF;\n    RETURN NEW;\n    END;\n$$;\n\nCREATE FUNCTION soft_delete_orphan_repo_by_external_service_repos() RETURNS void\n    LANGUAGE plpgsql\n    AS $$\nBEGIN\n    -- When an external service is soft or hard-deleted,\n    -- performs a clean up to soft-delete orphan repositories.\n    UPDATE\n        repo\n    SET\n        name = soft_deleted_repository_name(name),\n        deleted_at = transaction_timestamp()\n    WHERE\n      deleted_at IS NULL\n      AND NOT EXISTS (\n        SELECT FROM external_service_repos WHERE repo_id = repo.id\n      );\nEND;\n$$;\n\nCREATE FUNCTION soft_delete_user_reference_on_external_service() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$\nBEGIN\n    -- If a user is soft-deleted, delete every row that references that user\n    IF (OLD.deleted_at IS NULL AND NEW.deleted_at IS NOT NULL) THEN\n        UPDATE external_services\n        SET deleted_at = NOW()\n        WHERE namespace_user_id = OLD.id;\n    END IF;\n\n    RETURN OLD;\nEND;\n$$;\n\nCREATE FUNCTION soft_deleted_repository_name(name text) RETURNS text\n    LANGUAGE plpgsql STRICT\n    AS $$\nBEGIN\n    RETURN 'DELETED-' || extract(epoch from transaction_timestamp()) || '-' || name;\nEND;\n$$;\n\nCREATE FUNCTION versions_insert_row_trigger() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$\nBEGIN\n    NEW.first_version = NEW.version;\n    RETURN NEW;\nEND $$;\n\nCREATE TABLE access_tokens (\n    id bigint NOT NULL,\n    subject_user_id integer NOT NULL,\n    value_sha256 bytea NOT NULL,\n    note text NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    last_used_at timestamp with time zone,\n    deleted_at timestamp with time zone,\n    creator_user_id integer NOT NULL,\n    scopes text[] NOT NULL\n);\n\nCREATE SEQUENCE access_tokens_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE access_tokens_id_seq OWNED BY access_tokens.id;\n\nCREATE TABLE batch_changes (\n    id bigint NOT NULL,\n    name text NOT NULL,\n    description text,\n    initial_applier_id integer,\n    namespace_user_id integer,\n    namespace_org_id integer,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    closed_at timestamp with time zone,\n    batch_spec_id bigint NOT NULL,\n    last_applier_id bigint,\n    last_applied_at timestamp with time zone NOT NULL,\n    CONSTRAINT batch_changes_has_1_namespace CHECK (((namespace_user_id IS NULL) \u003c\u003e (namespace_org_id IS NULL))),\n    CONSTRAINT batch_changes_name_not_blank CHECK ((name \u003c\u003e ''::text))\n);\n\nCREATE SEQUENCE batch_changes_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE batch_changes_id_seq OWNED BY batch_changes.id;\n\nCREATE TABLE batch_changes_site_credentials (\n    id bigint NOT NULL,\n    external_service_type text NOT NULL,\n    external_service_id text NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    credential bytea NOT NULL,\n    encryption_key_id text DEFAULT ''::text NOT NULL\n);\n\nCREATE SEQUENCE batch_changes_site_credentials_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE batch_changes_site_credentials_id_seq OWNED BY batch_changes_site_credentials.id;\n\nCREATE TABLE batch_specs (\n    id bigint NOT NULL,\n    rand_id text NOT NULL,\n    raw_spec text NOT NULL,\n    spec jsonb DEFAULT '{}'::jsonb NOT NULL,\n    namespace_user_id integer,\n    namespace_org_id integer,\n    user_id integer,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    CONSTRAINT batch_specs_has_1_namespace CHECK (((namespace_user_id IS NULL) \u003c\u003e (namespace_org_id IS NULL)))\n);\n\nCREATE SEQUENCE batch_specs_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE batch_specs_id_seq OWNED BY batch_specs.id;\n\nCREATE TABLE changeset_specs (\n    id bigint NOT NULL,\n    rand_id text NOT NULL,\n    raw_spec text NOT NULL,\n    spec jsonb DEFAULT '{}'::jsonb NOT NULL,\n    batch_spec_id bigint,\n    repo_id integer NOT NULL,\n    user_id integer,\n    diff_stat_added integer,\n    diff_stat_changed integer,\n    diff_stat_deleted integer,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    head_ref text,\n    title text,\n    external_id text\n);\n\nCREATE TABLE changesets (\n    id bigint NOT NULL,\n    batch_change_ids jsonb DEFAULT '{}'::jsonb NOT NULL,\n    repo_id integer NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    metadata jsonb DEFAULT '{}'::jsonb,\n    external_id text,\n    external_service_type text NOT NULL,\n    external_deleted_at timestamp with time zone,\n    external_branch text,\n    external_updated_at timestamp with time zone,\n    external_state text,\n    external_review_state text,\n    external_check_state text,\n    diff_stat_added integer,\n    diff_stat_changed integer,\n    diff_stat_deleted integer,\n    sync_state jsonb DEFAULT '{}'::jsonb NOT NULL,\n    current_spec_id bigint,\n    previous_spec_id bigint,\n    publication_state text DEFAULT 'UNPUBLISHED'::text,\n    owned_by_batch_change_id bigint,\n    reconciler_state text DEFAULT 'queued'::text,\n    failure_message text,\n    started_at timestamp with time zone,\n    finished_at timestamp with time zone,\n    process_after timestamp with time zone,\n    num_resets integer DEFAULT 0 NOT NULL,\n    closing boolean DEFAULT false NOT NULL,\n    num_failures integer DEFAULT 0 NOT NULL,\n    log_contents text,\n    execution_logs json[],\n    syncer_error text,\n    external_title text,\n    CONSTRAINT changesets_batch_change_ids_check CHECK ((jsonb_typeof(batch_change_ids) = 'object'::text)),\n    CONSTRAINT changesets_external_id_check CHECK ((external_id \u003c\u003e ''::text)),\n    CONSTRAINT changesets_external_service_type_not_blank CHECK ((external_service_type \u003c\u003e ''::text)),\n    CONSTRAINT changesets_metadata_check CHECK ((jsonb_typeof(metadata) = 'object'::text)),\n    CONSTRAINT external_branch_ref_prefix CHECK ((external_branch ~~ 'refs/heads/%'::text))\n);\n\nCOMMENT ON COLUMN changesets.external_title IS 'Normalized property generated on save using Changeset.Title()';\n\nCREATE TABLE repo (\n    id integer NOT NULL,\n    name citext NOT NULL,\n    description text,\n    fork boolean,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone,\n    external_id text,\n    external_service_type text,\n    external_service_id text,\n    archived boolean DEFAULT false NOT NULL,\n    uri citext,\n    deleted_at timestamp with time zone,\n    metadata jsonb DEFAULT '{}'::jsonb NOT NULL,\n    private boolean DEFAULT false NOT NULL,\n    cloned boolean DEFAULT false NOT NULL,\n    stars integer,\n    CONSTRAINT check_name_nonempty CHECK ((name OPERATOR(\u003c\u003e) ''::citext)),\n    CONSTRAINT repo_metadata_check CHECK ((jsonb_typeof(metadata) = 'object'::text))\n);\n\nCREATE VIEW branch_changeset_specs_and_changesets AS\n SELECT changeset_specs.id AS changeset_spec_id,\n    COALESCE(changesets.id, (0)::bigint) AS changeset_id,\n    changeset_specs.repo_id,\n    changeset_specs.batch_spec_id,\n    changesets.owned_by_batch_change_id AS owner_batch_change_id,\n    repo.name AS repo_name,\n    changeset_specs.title AS changeset_name,\n    changesets.external_state,\n    changesets.publication_state,\n    changesets.reconciler_state\n   FROM ((changeset_specs\n     LEFT JOIN changesets ON (((changesets.repo_id = changeset_specs.repo_id) AND (changesets.current_spec_id IS NOT NULL) AND (EXISTS ( SELECT 1\n           FROM changeset_specs changeset_specs_1\n          WHERE ((changeset_specs_1.id = changesets.current_spec_id) AND (changeset_specs_1.head_ref = changeset_specs.head_ref)))))))\n     JOIN repo ON ((changeset_specs.repo_id = repo.id)))\n  WHERE ((changeset_specs.external_id IS NULL) AND (repo.deleted_at IS NULL));\n\nCREATE TABLE changeset_events (\n    id bigint NOT NULL,\n    changeset_id bigint NOT NULL,\n    kind text NOT NULL,\n    key text NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    metadata jsonb DEFAULT '{}'::jsonb NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    CONSTRAINT changeset_events_key_check CHECK ((key \u003c\u003e ''::text)),\n    CONSTRAINT changeset_events_kind_check CHECK ((kind \u003c\u003e ''::text)),\n    CONSTRAINT changeset_events_metadata_check CHECK ((jsonb_typeof(metadata) = 'object'::text))\n);\n\nCREATE SEQUENCE changeset_events_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE changeset_events_id_seq OWNED BY changeset_events.id;\n\nCREATE TABLE changeset_jobs (\n    id bigint NOT NULL,\n    bulk_group text NOT NULL,\n    user_id integer NOT NULL,\n    batch_change_id integer NOT NULL,\n    changeset_id integer NOT NULL,\n    job_type text NOT NULL,\n    payload jsonb DEFAULT '{}'::jsonb,\n    state text DEFAULT 'queued'::text,\n    failure_message text,\n    started_at timestamp with time zone,\n    finished_at timestamp with time zone,\n    process_after timestamp with time zone,\n    num_resets integer DEFAULT 0 NOT NULL,\n    num_failures integer DEFAULT 0 NOT NULL,\n    execution_logs json[],\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    CONSTRAINT changeset_jobs_payload_check CHECK ((jsonb_typeof(payload) = 'object'::text))\n);\n\nCREATE SEQUENCE changeset_jobs_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE changeset_jobs_id_seq OWNED BY changeset_jobs.id;\n\nCREATE SEQUENCE changeset_specs_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE changeset_specs_id_seq OWNED BY changeset_specs.id;\n\nCREATE SEQUENCE changesets_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE changesets_id_seq OWNED BY changesets.id;\n\nCREATE TABLE cm_action_jobs (\n    id integer NOT NULL,\n    email bigint NOT NULL,\n    state text DEFAULT 'queued'::text,\n    failure_message text,\n    started_at timestamp with time zone,\n    finished_at timestamp with time zone,\n    process_after timestamp with time zone,\n    num_resets integer DEFAULT 0 NOT NULL,\n    num_failures integer DEFAULT 0 NOT NULL,\n    log_contents text,\n    trigger_event integer\n);\n\nCREATE SEQUENCE cm_action_jobs_id_seq\n    AS integer\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE cm_action_jobs_id_seq OWNED BY cm_action_jobs.id;\n\nCREATE TABLE cm_emails (\n    id bigint NOT NULL,\n    monitor bigint NOT NULL,\n    enabled boolean NOT NULL,\n    priority cm_email_priority NOT NULL,\n    header text NOT NULL,\n    created_by integer NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    changed_by integer NOT NULL,\n    changed_at timestamp with time zone DEFAULT now() NOT NULL\n);\n\nCREATE SEQUENCE cm_emails_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE cm_emails_id_seq OWNED BY cm_emails.id;\n\nCREATE TABLE cm_monitors (\n    id bigint NOT NULL,\n    created_by integer NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    description text NOT NULL,\n    changed_at timestamp with time zone DEFAULT now() NOT NULL,\n    changed_by integer NOT NULL,\n    enabled boolean DEFAULT true NOT NULL,\n    namespace_user_id integer,\n    namespace_org_id integer\n);\n\nCREATE SEQUENCE cm_monitors_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE cm_monitors_id_seq OWNED BY cm_monitors.id;\n\nCREATE TABLE cm_queries (\n    id bigint NOT NULL,\n    monitor bigint NOT NULL,\n    query text NOT NULL,\n    created_by integer NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    changed_by integer NOT NULL,\n    changed_at timestamp with time zone DEFAULT now() NOT NULL,\n    next_run timestamp with time zone DEFAULT now(),\n    latest_result timestamp with time zone\n);\n\nCREATE SEQUENCE cm_queries_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE cm_queries_id_seq OWNED BY cm_queries.id;\n\nCREATE TABLE cm_recipients (\n    id bigint NOT NULL,\n    email bigint NOT NULL,\n    namespace_user_id integer,\n    namespace_org_id integer\n);\n\nCREATE SEQUENCE cm_recipients_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE cm_recipients_id_seq OWNED BY cm_recipients.id;\n\nCREATE TABLE cm_trigger_jobs (\n    id integer NOT NULL,\n    query bigint NOT NULL,\n    state text DEFAULT 'queued'::text,\n    failure_message text,\n    started_at timestamp with time zone,\n    finished_at timestamp with time zone,\n    process_after timestamp with time zone,\n    num_resets integer DEFAULT 0 NOT NULL,\n    num_failures integer DEFAULT 0 NOT NULL,\n    log_contents text,\n    query_string text,\n    results boolean,\n    num_results integer\n);\n\nCREATE SEQUENCE cm_trigger_jobs_id_seq\n    AS integer\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE cm_trigger_jobs_id_seq OWNED BY cm_trigger_jobs.id;\n\nCREATE TABLE critical_and_site_config (\n    id integer NOT NULL,\n    type critical_or_site NOT NULL,\n    contents text NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL\n);\n\nCREATE SEQUENCE critical_and_site_config_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE critical_and_site_config_id_seq OWNED BY critical_and_site_config.id;\n\nCREATE TABLE default_repos (\n    repo_id integer NOT NULL\n);\n\nCREATE TABLE discussion_comments (\n    id bigint NOT NULL,\n    thread_id bigint NOT NULL,\n    author_user_id integer NOT NULL,\n    contents text NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    deleted_at timestamp with time zone,\n    reports text[] DEFAULT '{}'::text[] NOT NULL\n);\n\nCREATE SEQUENCE discussion_comments_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE discussion_comments_id_seq OWNED BY discussion_comments.id;\n\nCREATE TABLE discussion_mail_reply_tokens (\n    token text NOT NULL,\n    user_id integer NOT NULL,\n    thread_id bigint NOT NULL,\n    deleted_at timestamp with time zone\n);\n\nCREATE TABLE discussion_threads (\n    id bigint NOT NULL,\n    author_user_id integer NOT NULL,\n    title text,\n    target_repo_id bigint,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    archived_at timestamp with time zone,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    deleted_at timestamp with time zone\n);\n\nCREATE SEQUENCE discussion_threads_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE discussion_threads_id_seq OWNED BY discussion_threads.id;\n\nCREATE TABLE discussion_threads_target_repo (\n    id bigint NOT NULL,\n    thread_id bigint NOT NULL,\n    repo_id integer NOT NULL,\n    path text,\n    branch text,\n    revision text,\n    start_line integer,\n    end_line integer,\n    start_character integer,\n    end_character integer,\n    lines_before text,\n    lines text,\n    lines_after text\n);\n\nCREATE SEQUENCE discussion_threads_target_repo_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE discussion_threads_target_repo_id_seq OWNED BY discussion_threads_target_repo.id;\n\nCREATE TABLE event_logs (\n    id bigint NOT NULL,\n    name text NOT NULL,\n    url text NOT NULL,\n    user_id integer NOT NULL,\n    anonymous_user_id text NOT NULL,\n    source text NOT NULL,\n    argument jsonb NOT NULL,\n    version text NOT NULL,\n    \"timestamp\" timestamp with time zone NOT NULL,\n    feature_flags jsonb,\n    CONSTRAINT event_logs_check_has_user CHECK ((((user_id = 0) AND (anonymous_user_id \u003c\u003e ''::text)) OR ((user_id \u003c\u003e 0) AND (anonymous_user_id = ''::text)) OR ((user_id \u003c\u003e 0) AND (anonymous_user_id \u003c\u003e ''::text)))),\n    CONSTRAINT event_logs_check_name_not_empty CHECK ((name \u003c\u003e ''::text)),\n    CONSTRAINT event_logs_check_source_not_empty CHECK ((source \u003c\u003e ''::text)),\n    CONSTRAINT event_logs_check_version_not_empty CHECK ((version \u003c\u003e ''::text))\n);\n\nCREATE SEQUENCE event_logs_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE event_logs_id_seq OWNED BY event_logs.id;\n\nCREATE TABLE external_service_repos (\n    external_service_id bigint NOT NULL,\n    repo_id integer NOT NULL,\n    clone_url text NOT NULL,\n    user_id integer\n);\n\nCREATE SEQUENCE external_service_sync_jobs_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nCREATE TABLE external_service_sync_jobs (\n    id integer DEFAULT nextval('external_service_sync_jobs_id_seq'::regclass) NOT NULL,\n    state text DEFAULT 'queued'::text NOT NULL,\n    failure_message text,\n    started_at timestamp with time zone,\n    finished_at timestamp with time zone,\n    process_after timestamp with time zone,\n    num_resets integer DEFAULT 0 NOT NULL,\n    external_service_id bigint,\n    num_failures integer DEFAULT 0 NOT NULL,\n    log_contents text,\n    execution_logs json[]\n);\n\nCREATE TABLE external_services (\n    id bigint NOT NULL,\n    kind text NOT NULL,\n    display_name text NOT NULL,\n    config text NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    deleted_at timestamp with time zone,\n    last_sync_at timestamp with time zone,\n    next_sync_at timestamp with time zone,\n    namespace_user_id integer,\n    unrestricted boolean DEFAULT false NOT NULL,\n    cloud_default boolean DEFAULT false NOT NULL,\n    encryption_key_id text DEFAULT ''::text NOT NULL,\n    CONSTRAINT check_non_empty_config CHECK ((btrim(config) \u003c\u003e ''::text))\n);\n\nCREATE VIEW external_service_sync_jobs_with_next_sync_at AS\n SELECT j.id,\n    j.state,\n    j.failure_message,\n    j.started_at,\n    j.finished_at,\n    j.process_after,\n    j.num_resets,\n    j.num_failures,\n    j.execution_logs,\n    j.external_service_id,\n    e.next_sync_at\n   FROM (external_services e\n     JOIN external_service_sync_jobs j ON ((e.id = j.external_service_id)));\n\nCREATE SEQUENCE external_services_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE external_services_id_seq OWNED BY external_services.id;\n\nCREATE TABLE feature_flag_overrides (\n    namespace_org_id integer,\n    namespace_user_id integer,\n    flag_name text NOT NULL,\n    flag_value boolean NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    deleted_at timestamp with time zone,\n    CONSTRAINT feature_flag_overrides_has_org_or_user_id CHECK (((namespace_org_id IS NOT NULL) OR (namespace_user_id IS NOT NULL)))\n);\n\nCREATE TABLE feature_flags (\n    flag_name text NOT NULL,\n    flag_type feature_flag_type NOT NULL,\n    bool_value boolean,\n    rollout integer,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    deleted_at timestamp with time zone,\n    CONSTRAINT feature_flags_rollout_check CHECK (((rollout \u003e= 0) AND (rollout \u003c= 10000))),\n    CONSTRAINT required_bool_fields CHECK ((1 =\nCASE\n    WHEN ((flag_type = 'bool'::feature_flag_type) AND (bool_value IS NULL)) THEN 0\n    WHEN ((flag_type \u003c\u003e 'bool'::feature_flag_type) AND (bool_value IS NOT NULL)) THEN 0\n    ELSE 1\nEND)),\n    CONSTRAINT required_rollout_fields CHECK ((1 =\nCASE\n    WHEN ((flag_type = 'rollout'::feature_flag_type) AND (rollout IS NULL)) THEN 0\n    WHEN ((flag_type \u003c\u003e 'rollout'::feature_flag_type) AND (rollout IS NOT NULL)) THEN 0\n    ELSE 1\nEND))\n);\n\nCOMMENT ON COLUMN feature_flags.bool_value IS 'Bool value only defined when flag_type is bool';\n\nCOMMENT ON COLUMN feature_flags.rollout IS 'Rollout only defined when flag_type is rollout. Increments of 0.01%';\n\nCOMMENT ON CONSTRAINT required_bool_fields ON feature_flags IS 'Checks that bool_value is set IFF flag_type = bool';\n\nCOMMENT ON CONSTRAINT required_rollout_fields ON feature_flags IS 'Checks that rollout is set IFF flag_type = rollout';\n\nCREATE TABLE gitserver_repos (\n    repo_id integer NOT NULL,\n    clone_status text DEFAULT 'not_cloned'::text NOT NULL,\n    last_external_service bigint,\n    shard_id text NOT NULL,\n    last_error text,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL\n);\n\nCREATE TABLE global_state (\n    site_id uuid NOT NULL,\n    initialized boolean DEFAULT false NOT NULL\n);\n\nCREATE TABLE insights_query_runner_jobs (\n    id integer NOT NULL,\n    series_id text NOT NULL,\n    search_query text NOT NULL,\n    state text DEFAULT 'queued'::text,\n    failure_message text,\n    started_at timestamp with time zone,\n    finished_at timestamp with time zone,\n    process_after timestamp with time zone,\n    num_resets integer DEFAULT 0 NOT NULL,\n    num_failures integer DEFAULT 0 NOT NULL,\n    execution_logs json[],\n    record_time timestamp with time zone\n);\n\nCOMMENT ON TABLE insights_query_runner_jobs IS 'See [enterprise/internal/insights/background/queryrunner/worker.go:Job](https://sourcegraph.com/search?q=repo:%5Egithub%5C.com/sourcegraph/sourcegraph%24+file:enterprise/internal/insights/background/queryrunner/worker.go+type+Job\u0026patternType=literal)';\n\nCREATE SEQUENCE insights_query_runner_jobs_id_seq\n    AS integer\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE insights_query_runner_jobs_id_seq OWNED BY insights_query_runner_jobs.id;\n\nCREATE TABLE lsif_dependency_indexing_jobs (\n    id integer NOT NULL,\n    state text DEFAULT 'queued'::text NOT NULL,\n    failure_message text,\n    queued_at timestamp with time zone DEFAULT now() NOT NULL,\n    started_at timestamp with time zone,\n    finished_at timestamp with time zone,\n    process_after timestamp with time zone,\n    num_resets integer DEFAULT 0 NOT NULL,\n    num_failures integer DEFAULT 0 NOT NULL,\n    execution_logs json[],\n    upload_id integer\n);\n\nCOMMENT ON TABLE lsif_dependency_indexing_jobs IS 'Tracks jobs that scan imports of indexes to schedule auto-index jobs.';\n\nCOMMENT ON COLUMN lsif_dependency_indexing_jobs.upload_id IS 'The identifier of the triggering upload record.';\n\nCREATE SEQUENCE lsif_dependency_indexing_jobs_id_seq\n    AS integer\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE lsif_dependency_indexing_jobs_id_seq OWNED BY lsif_dependency_indexing_jobs.id;\n\nCREATE TABLE lsif_dirty_repositories (\n    repository_id integer NOT NULL,\n    dirty_token integer NOT NULL,\n    update_token integer NOT NULL,\n    updated_at timestamp with time zone\n);\n\nCOMMENT ON TABLE lsif_dirty_repositories IS 'Stores whether or not the nearest upload data for a repository is out of date (when update_token \u003e dirty_token).';\n\nCOMMENT ON COLUMN lsif_dirty_repositories.dirty_token IS 'Set to the value of update_token visible to the transaction that updates the commit graph. Updates of dirty_token during this time will cause a second update.';\n\nCOMMENT ON COLUMN lsif_dirty_repositories.update_token IS 'This value is incremented on each request to update the commit graph for the repository.';\n\nCOMMENT ON COLUMN lsif_dirty_repositories.updated_at IS 'The time the update_token value was last updated.';\n\nCREATE TABLE lsif_uploads (\n    id integer NOT NULL,\n    commit text NOT NULL,\n    root text DEFAULT ''::text NOT NULL,\n    uploaded_at timestamp with time zone DEFAULT now() NOT NULL,\n    state text DEFAULT 'queued'::text NOT NULL,\n    failure_message text,\n    started_at timestamp with time zone,\n    finished_at timestamp with time zone,\n    repository_id integer NOT NULL,\n    indexer text NOT NULL,\n    num_parts integer NOT NULL,\n    uploaded_parts integer[] NOT NULL,\n    process_after timestamp with time zone,\n    num_resets integer DEFAULT 0 NOT NULL,\n    upload_size bigint,\n    num_failures integer DEFAULT 0 NOT NULL,\n    associated_index_id bigint,\n    committed_at timestamp with time zone,\n    commit_last_checked_at timestamp with time zone,\n    CONSTRAINT lsif_uploads_commit_valid_chars CHECK ((commit ~ '^[a-z0-9]{40}$'::text))\n);\n\nCOMMENT ON TABLE lsif_uploads IS 'Stores metadata about an LSIF index uploaded by a user.';\n\nCOMMENT ON COLUMN lsif_uploads.id IS 'Used as a logical foreign key with the (disjoint) codeintel database.';\n\nCOMMENT ON COLUMN lsif_uploads.commit IS 'A 40-char revhash. Note that this commit may not be resolvable in the future.';\n\nCOMMENT ON COLUMN lsif_uploads.root IS 'The path for which the index can resolve code intelligence relative to the repository root.';\n\nCOMMENT ON COLUMN lsif_uploads.indexer IS 'The name of the indexer that produced the index file. If not supplied by the user it will be pulled from the index metadata.';\n\nCOMMENT ON COLUMN lsif_uploads.num_parts IS 'The number of parts src-cli split the upload file into.';\n\nCOMMENT ON COLUMN lsif_uploads.uploaded_parts IS 'The index of parts that have been successfully uploaded.';\n\nCOMMENT ON COLUMN lsif_uploads.upload_size IS 'The size of the index file (in bytes).';\n\nCREATE VIEW lsif_dumps AS\n SELECT u.id,\n    u.commit,\n    u.root,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.finished_at AS processed_at\n   FROM lsif_uploads u\n  WHERE (u.state = 'completed'::text);\n\nCREATE SEQUENCE lsif_dumps_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE lsif_dumps_id_seq OWNED BY lsif_uploads.id;\n\nCREATE VIEW lsif_dumps_with_repository_name AS\n SELECT u.id,\n    u.commit,\n    u.root,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.processed_at,\n    r.name AS repository_name\n   FROM (lsif_dumps u\n     JOIN repo r ON ((r.id = u.repository_id)))\n  WHERE (r.deleted_at IS NULL);\n\nCREATE TABLE lsif_index_configuration (\n    id bigint NOT NULL,\n    repository_id integer NOT NULL,\n    data bytea NOT NULL,\n    autoindex_enabled boolean DEFAULT true NOT NULL\n);\n\nCOMMENT ON TABLE lsif_index_configuration IS 'Stores the configuration used for code intel index jobs for a repository.';\n\nCOMMENT ON COLUMN lsif_index_configuration.data IS 'The raw user-supplied [configuration](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.23/-/blob/enterprise/internal/codeintel/autoindex/config/types.go#L3:6) (encoded in JSONC).';\n\nCOMMENT ON COLUMN lsif_index_configuration.autoindex_enabled IS 'Whether or not auto-indexing should be attempted on this repo. Index jobs may be inferred from the repository contents if data is empty.';\n\nCREATE SEQUENCE lsif_index_configuration_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE lsif_index_configuration_id_seq OWNED BY lsif_index_configuration.id;\n\nCREATE TABLE lsif_indexable_repositories (\n    id integer NOT NULL,\n    repository_id integer NOT NULL,\n    search_count integer DEFAULT 0 NOT NULL,\n    precise_count integer DEFAULT 0 NOT NULL,\n    last_index_enqueued_at timestamp with time zone,\n    last_updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    enabled boolean\n);\n\nCOMMENT ON TABLE lsif_indexable_repositories IS 'Stores the number of code intel events for repositories. Used for auto-index scheduling heursitics Sourcegraph Cloud.';\n\nCOMMENT ON COLUMN lsif_indexable_repositories.search_count IS 'The number of search-based code intel events for the repository in the past week.';\n\nCOMMENT ON COLUMN lsif_indexable_repositories.precise_count IS 'The number of precise code intel events for the repository in the past week.';\n\nCOMMENT ON COLUMN lsif_indexable_repositories.last_index_enqueued_at IS 'The last time an index for the repository was enqueued (for basic rate limiting).';\n\nCOMMENT ON COLUMN lsif_indexable_repositories.last_updated_at IS 'The last time the event counts were updated for this repository.';\n\nCOMMENT ON COLUMN lsif_indexable_repositories.enabled IS '**Column unused.**';\n\nCREATE SEQUENCE lsif_indexable_repositories_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE lsif_indexable_repositories_id_seq OWNED BY lsif_indexable_repositories.id;\n\nCREATE TABLE lsif_indexes (\n    id bigint NOT NULL,\n    commit text NOT NULL,\n    queued_at timestamp with time zone DEFAULT now() NOT NULL,\n    state text DEFAULT 'queued'::text NOT NULL,\n    failure_message text,\n    started_at timestamp with time zone,\n    finished_at timestamp with time zone,\n    repository_id integer NOT NULL,\n    process_after timestamp with time zone,\n    num_resets integer DEFAULT 0 NOT NULL,\n    num_failures integer DEFAULT 0 NOT NULL,\n    docker_steps jsonb[] NOT NULL,\n    root text NOT NULL,\n    indexer text NOT NULL,\n    indexer_args text[] NOT NULL,\n    outfile text NOT NULL,\n    log_contents text,\n    execution_logs json[],\n    local_steps text[] NOT NULL,\n    commit_last_checked_at timestamp with time zone,\n    CONSTRAINT lsif_uploads_commit_valid_chars CHECK ((commit ~ '^[a-z0-9]{40}$'::text))\n);\n\nCOMMENT ON TABLE lsif_indexes IS 'Stores metadata about a code intel index job.';\n\nCOMMENT ON COLUMN lsif_indexes.commit IS 'A 40-char revhash. Note that this commit may not be resolvable in the future.';\n\nCOMMENT ON COLUMN lsif_indexes.docker_steps IS 'An array of pre-index [steps](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.23/-/blob/enterprise/internal/codeintel/stores/dbstore/docker_step.go#L9:6) to run.';\n\nCOMMENT ON COLUMN lsif_indexes.root IS 'The working directory of the indexer image relative to the repository root.';\n\nCOMMENT ON COLUMN lsif_indexes.indexer IS 'The docker image used to run the index command (e.g. sourcegraph/lsif-go).';\n\nCOMMENT ON COLUMN lsif_indexes.indexer_args IS 'The command run inside the indexer image to produce the index file (e.g. [''lsif-node'', ''-p'', ''.''])';\n\nCOMMENT ON COLUMN lsif_indexes.outfile IS 'The path to the index file produced by the index command relative to the working directory.';\n\nCOMMENT ON COLUMN lsif_indexes.log_contents IS '**Column deprecated in favor of execution_logs.**';\n\nCOMMENT ON COLUMN lsif_indexes.execution_logs IS 'An array of [log entries](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.23/-/blob/internal/workerutil/store.go#L48:6) (encoded as JSON) from the most recent execution.';\n\nCOMMENT ON COLUMN lsif_indexes.local_steps IS 'A list of commands to run inside the indexer image prior to running the indexer command.';\n\nCREATE SEQUENCE lsif_indexes_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE lsif_indexes_id_seq OWNED BY lsif_indexes.id;\n\nCREATE VIEW lsif_indexes_with_repository_name AS\n SELECT u.id,\n    u.commit,\n    u.queued_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.process_after,\n    u.num_resets,\n    u.num_failures,\n    u.docker_steps,\n    u.root,\n    u.indexer,\n    u.indexer_args,\n    u.outfile,\n    u.log_contents,\n    u.execution_logs,\n    u.local_steps,\n    r.name AS repository_name\n   FROM (lsif_indexes u\n     JOIN repo r ON ((r.id = u.repository_id)))\n  WHERE (r.deleted_at IS NULL);\n\nCREATE TABLE lsif_nearest_uploads (\n    repository_id integer NOT NULL,\n    commit_bytea bytea NOT NULL,\n    uploads jsonb NOT NULL\n);\n\nCOMMENT ON TABLE lsif_nearest_uploads IS 'Associates commits with the complete set of uploads visible from that commit. Every commit with upload data is present in this table.';\n\nCOMMENT ON COLUMN lsif_nearest_uploads.commit_bytea IS 'A 40-char revhash. Note that this commit may not be resolvable in the future.';\n\nCOMMENT ON COLUMN lsif_nearest_uploads.uploads IS 'Encodes an {upload_id =\u003e distance} map that includes an entry for every upload visible from the commit. There is always at least one entry with a distance of zero.';\n\nCREATE TABLE lsif_nearest_uploads_links (\n    repository_id integer NOT NULL,\n    commit_bytea bytea NOT NULL,\n    ancestor_commit_bytea bytea NOT NULL,\n    distance integer NOT NULL\n);\n\nCOMMENT ON TABLE lsif_nearest_uploads_links IS 'Associates commits with the closest ancestor commit with usable upload data. Together, this table and lsif_nearest_uploads cover all commits with resolvable code intelligence.';\n\nCOMMENT ON COLUMN lsif_nearest_uploads_links.commit_bytea IS 'A 40-char revhash. Note that this commit may not be resolvable in the future.';\n\nCOMMENT ON COLUMN lsif_nearest_uploads_links.ancestor_commit_bytea IS 'The 40-char revhash of the ancestor. Note that this commit may not be resolvable in the future.';\n\nCOMMENT ON COLUMN lsif_nearest_uploads_links.distance IS 'The distance bewteen the commits. Parent = 1, Grandparent = 2, etc.';\n\nCREATE TABLE lsif_packages (\n    id integer NOT NULL,\n    scheme text NOT NULL,\n    name text NOT NULL,\n    version text,\n    dump_id integer NOT NULL\n);\n\nCOMMENT ON TABLE lsif_packages IS 'Associates an upload with the set of packages they provide within a given packages management scheme.';\n\nCOMMENT ON COLUMN lsif_packages.scheme IS 'The (export) moniker scheme.';\n\nCOMMENT ON COLUMN lsif_packages.name IS 'The package name.';\n\nCOMMENT ON COLUMN lsif_packages.version IS 'The package version.';\n\nCOMMENT ON COLUMN lsif_packages.dump_id IS 'The identifier of the upload that provides the package.';\n\nCREATE SEQUENCE lsif_packages_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE lsif_packages_id_seq OWNED BY lsif_packages.id;\n\nCREATE TABLE lsif_references (\n    id integer NOT NULL,\n    scheme text NOT NULL,\n    name text NOT NULL,\n    version text,\n    filter bytea NOT NULL,\n    dump_id integer NOT NULL\n);\n\nCOMMENT ON TABLE lsif_references IS 'Associates an upload with the set of packages they require within a given packages management scheme.';\n\nCOMMENT ON COLUMN lsif_references.scheme IS 'The (import) moniker scheme.';\n\nCOMMENT ON COLUMN lsif_references.name IS 'The package name.';\n\nCOMMENT ON COLUMN lsif_references.version IS 'The package version.';\n\nCOMMENT ON COLUMN lsif_references.filter IS 'A [bloom filter](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.23/-/blob/enterprise/internal/codeintel/bloomfilter/bloom_filter.go#L27:6) encoded as gzipped JSON. This bloom filter stores the set of identifiers imported from the package.';\n\nCOMMENT ON COLUMN lsif_references.dump_id IS 'The identifier of the upload that references the package.';\n\nCREATE SEQUENCE lsif_references_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE lsif_references_id_seq OWNED BY lsif_references.id;\n\nCREATE TABLE lsif_uploads_visible_at_tip (\n    repository_id integer NOT NULL,\n    upload_id integer NOT NULL\n);\n\nCOMMENT ON TABLE lsif_uploads_visible_at_tip IS 'Associates a repository with the set of LSIF upload identifiers that can serve intelligence for the tip of the default branch.';\n\nCOMMENT ON COLUMN lsif_uploads_visible_at_tip.upload_id IS 'The identifier of an upload visible at the tip of the default branch.';\n\nCREATE VIEW lsif_uploads_with_repository_name AS\n SELECT u.id,\n    u.commit,\n    u.root,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    r.name AS repository_name\n   FROM (lsif_uploads u\n     JOIN repo r ON ((r.id = u.repository_id)))\n  WHERE (r.deleted_at IS NULL);\n\nCREATE TABLE names (\n    name citext NOT NULL,\n    user_id integer,\n    org_id integer,\n    CONSTRAINT names_check CHECK (((user_id IS NOT NULL) OR (org_id IS NOT NULL)))\n);\n\nCREATE TABLE org_invitations (\n    id bigint NOT NULL,\n    org_id integer NOT NULL,\n    sender_user_id integer NOT NULL,\n    recipient_user_id integer NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    notified_at timestamp with time zone,\n    responded_at timestamp with time zone,\n    response_type boolean,\n    revoked_at timestamp with time zone,\n    deleted_at timestamp with time zone,\n    CONSTRAINT check_atomic_response CHECK (((responded_at IS NULL) = (response_type IS NULL))),\n    CONSTRAINT check_single_use CHECK ((((responded_at IS NULL) AND (response_type IS NULL)) OR (revoked_at IS NULL)))\n);\n\nCREATE SEQUENCE org_invitations_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE org_invitations_id_seq OWNED BY org_invitations.id;\n\nCREATE TABLE org_members (\n    id integer NOT NULL,\n    org_id integer NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    user_id integer NOT NULL\n);\n\nCREATE TABLE org_members_bkup_1514536731 (\n    id integer,\n    org_id integer,\n    user_id_old text,\n    created_at timestamp with time zone,\n    updated_at timestamp with time zone,\n    user_id integer\n);\n\nCREATE SEQUENCE org_members_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE org_members_id_seq OWNED BY org_members.id;\n\nCREATE TABLE orgs (\n    id integer NOT NULL,\n    name citext NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    display_name text,\n    slack_webhook_url text,\n    deleted_at timestamp with time zone,\n    CONSTRAINT orgs_display_name_max_length CHECK ((char_length(display_name) \u003c= 255)),\n    CONSTRAINT orgs_name_max_length CHECK ((char_length((name)::text) \u003c= 255)),\n    CONSTRAINT orgs_name_valid_chars CHECK ((name OPERATOR(~) '^[a-zA-Z0-9](?:[a-zA-Z0-9]|[-.](?=[a-zA-Z0-9]))*-?$'::citext))\n);\n\nCREATE SEQUENCE orgs_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE orgs_id_seq OWNED BY orgs.id;\n\nCREATE TABLE out_of_band_migrations (\n    id integer NOT NULL,\n    team text NOT NULL,\n    component text NOT NULL,\n    description text NOT NULL,\n    progress double precision DEFAULT 0 NOT NULL,\n    created timestamp with time zone DEFAULT now() NOT NULL,\n    last_updated timestamp with time zone,\n    non_destructive boolean NOT NULL,\n    apply_reverse boolean DEFAULT false NOT NULL,\n    is_enterprise boolean DEFAULT false NOT NULL,\n    introduced_version_major integer NOT NULL,\n    introduced_version_minor integer NOT NULL,\n    deprecated_version_major integer,\n    deprecated_version_minor integer,\n    CONSTRAINT out_of_band_migrations_component_nonempty CHECK ((component \u003c\u003e ''::text)),\n    CONSTRAINT out_of_band_migrations_description_nonempty CHECK ((description \u003c\u003e ''::text)),\n    CONSTRAINT out_of_band_migrations_progress_range CHECK (((progress \u003e= (0)::double precision) AND (progress \u003c= (1)::double precision))),\n    CONSTRAINT out_of_band_migrations_team_nonempty CHECK ((team \u003c\u003e ''::text))\n);\n\nCOMMENT ON TABLE out_of_band_migrations IS 'Stores metadata and progress about an out-of-band migration routine.';\n\nCOMMENT ON COLUMN out_of_band_migrations.id IS 'A globally unique primary key for this migration. The same key is used consistently across all Sourcegraph instances for the same migration.';\n\nCOMMENT ON COLUMN out_of_band_migrations.team IS 'The name of the engineering team responsible for the migration.';\n\nCOMMENT ON COLUMN out_of_band_migrations.component IS 'The name of the component undergoing a migration.';\n\nCOMMENT ON COLUMN out_of_band_migrations.description IS 'A brief description about the migration.';\n\nCOMMENT ON COLUMN out_of_band_migrations.progress IS 'The percentage progress in the up direction (0=0%, 1=100%).';\n\nCOMMENT ON COLUMN out_of_band_migrations.created IS 'The date and time the migration was inserted into the database (via an upgrade).';\n\nCOMMENT ON COLUMN out_of_band_migrations.last_updated IS 'The date and time the migration was last updated.';\n\nCOMMENT ON COLUMN out_of_band_migrations.non_destructive IS 'Whether or not this migration alters data so it can no longer be read by the previous Sourcegraph instance.';\n\nCOMMENT ON COLUMN out_of_band_migrations.apply_reverse IS 'Whether this migration should run in the opposite direction (to support an upcoming downgrade).';\n\nCOMMENT ON COLUMN out_of_band_migrations.is_enterprise IS 'When true, these migrations are invisible to OSS mode.';\n\nCOMMENT ON COLUMN out_of_band_migrations.introduced_version_major IS 'The Sourcegraph version (major component) in which this migration was first introduced.';\n\nCOMMENT ON COLUMN out_of_band_migrations.introduced_version_minor IS 'The Sourcegraph version (minor component) in which this migration was first introduced.';\n\nCOMMENT ON COLUMN out_of_band_migrations.deprecated_version_major IS 'The lowest Sourcegraph version (major component) that assumes the migration has completed.';\n\nCOMMENT ON COLUMN out_of_band_migrations.deprecated_version_minor IS 'The lowest Sourcegraph version (minor component) that assumes the migration has completed.';\n\nCREATE TABLE out_of_band_migrations_errors (\n    id integer NOT NULL,\n    migration_id integer NOT NULL,\n    message text NOT NULL,\n    created timestamp with time zone DEFAULT now() NOT NULL,\n    CONSTRAINT out_of_band_migrations_errors_message_nonempty CHECK ((message \u003c\u003e ''::text))\n);\n\nCOMMENT ON TABLE out_of_band_migrations_errors IS 'Stores errors that occurred while performing an out-of-band migration.';\n\nCOMMENT ON COLUMN out_of_band_migrations_errors.id IS 'A unique identifer.';\n\nCOMMENT ON COLUMN out_of_band_migrations_errors.migration_id IS 'The identifier of the migration.';\n\nCOMMENT ON COLUMN out_of_band_migrations_errors.message IS 'The error message.';\n\nCOMMENT ON COLUMN out_of_band_migrations_errors.created IS 'The date and time the error occurred.';\n\nCREATE SEQUENCE out_of_band_migrations_errors_id_seq\n    AS integer\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE out_of_band_migrations_errors_id_seq OWNED BY out_of_band_migrations_errors.id;\n\nCREATE SEQUENCE out_of_band_migrations_id_seq\n    AS integer\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE out_of_band_migrations_id_seq OWNED BY out_of_band_migrations.id;\n\nCREATE TABLE phabricator_repos (\n    id integer NOT NULL,\n    callsign citext NOT NULL,\n    repo_name citext NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    deleted_at timestamp with time zone,\n    url text DEFAULT ''::text NOT NULL\n);\n\nCREATE SEQUENCE phabricator_repos_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE phabricator_repos_id_seq OWNED BY phabricator_repos.id;\n\nCREATE TABLE product_licenses (\n    id uuid NOT NULL,\n    product_subscription_id uuid NOT NULL,\n    license_key text NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL\n);\n\nCREATE TABLE product_subscriptions (\n    id uuid NOT NULL,\n    user_id integer NOT NULL,\n    billing_subscription_id text,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    archived_at timestamp with time zone\n);\n\nCREATE TABLE query_runner_state (\n    query text,\n    last_executed timestamp with time zone,\n    latest_result timestamp with time zone,\n    exec_duration_ns bigint\n);\n\nCREATE TABLE users (\n    id integer NOT NULL,\n    username citext NOT NULL,\n    display_name text,\n    avatar_url text,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    deleted_at timestamp with time zone,\n    invite_quota integer DEFAULT 15 NOT NULL,\n    passwd text,\n    passwd_reset_code text,\n    passwd_reset_time timestamp with time zone,\n    site_admin boolean DEFAULT false NOT NULL,\n    page_views integer DEFAULT 0 NOT NULL,\n    search_queries integer DEFAULT 0 NOT NULL,\n    tags text[] DEFAULT '{}'::text[],\n    billing_customer_id text,\n    invalidated_sessions_at timestamp with time zone DEFAULT now() NOT NULL,\n    CONSTRAINT users_display_name_max_length CHECK ((char_length(display_name) \u003c= 255)),\n    CONSTRAINT users_username_max_length CHECK ((char_length((username)::text) \u003c= 255)),\n    CONSTRAINT users_username_valid_chars CHECK ((username OPERATOR(~) '^[a-zA-Z0-9](?:[a-zA-Z0-9]|[-.](?=[a-zA-Z0-9]))*-?$'::citext))\n);\n\nCREATE VIEW reconciler_changesets AS\n SELECT c.id,\n    c.batch_change_ids,\n    c.repo_id,\n    c.created_at,\n    c.updated_at,\n    c.metadata,\n    c.external_id,\n    c.external_service_type,\n    c.external_deleted_at,\n    c.external_branch,\n    c.external_updated_at,\n    c.external_state,\n    c.external_review_state,\n    c.external_check_state,\n    c.diff_stat_added,\n    c.diff_stat_changed,\n    c.diff_stat_deleted,\n    c.sync_state,\n    c.current_spec_id,\n    c.previous_spec_id,\n    c.publication_state,\n    c.owned_by_batch_change_id,\n    c.reconciler_state,\n    c.failure_message,\n    c.started_at,\n    c.finished_at,\n    c.process_after,\n    c.num_resets,\n    c.closing,\n    c.num_failures,\n    c.log_contents,\n    c.execution_logs,\n    c.syncer_error,\n    c.external_title\n   FROM (changesets c\n     JOIN repo r ON ((r.id = c.repo_id)))\n  WHERE ((r.deleted_at IS NULL) AND (EXISTS ( SELECT 1\n           FROM ((batch_changes\n             LEFT JOIN users namespace_user ON ((batch_changes.namespace_user_id = namespace_user.id)))\n             LEFT JOIN orgs namespace_org ON ((batch_changes.namespace_org_id = namespace_org.id)))\n          WHERE ((c.batch_change_ids ? (batch_changes.id)::text) AND (namespace_user.deleted_at IS NULL) AND (namespace_org.deleted_at IS NULL)))));\n\nCREATE TABLE registry_extension_releases (\n    id bigint NOT NULL,\n    registry_extension_id integer NOT NULL,\n    creator_user_id integer NOT NULL,\n    release_version citext,\n    release_tag citext NOT NULL,\n    manifest jsonb NOT NULL,\n    bundle text,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    deleted_at timestamp with time zone,\n    source_map text\n);\n\nCREATE SEQUENCE registry_extension_releases_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE registry_extension_releases_id_seq OWNED BY registry_extension_releases.id;\n\nCREATE TABLE registry_extensions (\n    id integer NOT NULL,\n    uuid uuid NOT NULL,\n    publisher_user_id integer,\n    publisher_org_id integer,\n    name citext NOT NULL,\n    manifest text,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    deleted_at timestamp with time zone,\n    CONSTRAINT registry_extensions_name_length CHECK (((char_length((name)::text) \u003e 0) AND (char_length((name)::text) \u003c= 128))),\n    CONSTRAINT registry_extensions_name_valid_chars CHECK ((name OPERATOR(~) '^[a-zA-Z0-9](?:[a-zA-Z0-9]|[_.-](?=[a-zA-Z0-9]))*$'::citext)),\n    CONSTRAINT registry_extensions_single_publisher CHECK (((publisher_user_id IS NULL) \u003c\u003e (publisher_org_id IS NULL)))\n);\n\nCREATE SEQUENCE registry_extensions_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE registry_extensions_id_seq OWNED BY registry_extensions.id;\n\nCREATE SEQUENCE repo_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE repo_id_seq OWNED BY repo.id;\n\nCREATE TABLE repo_pending_permissions (\n    repo_id integer NOT NULL,\n    permission text NOT NULL,\n    user_ids bytea DEFAULT '\\x'::bytea NOT NULL,\n    updated_at timestamp with time zone NOT NULL,\n    user_ids_ints integer[] DEFAULT '{}'::integer[] NOT NULL\n);\n\nCREATE TABLE repo_permissions (\n    repo_id integer NOT NULL,\n    permission text NOT NULL,\n    user_ids bytea DEFAULT '\\x'::bytea NOT NULL,\n    updated_at timestamp with time zone NOT NULL,\n    synced_at timestamp with time zone,\n    user_ids_ints integer[] DEFAULT '{}'::integer[] NOT NULL\n);\n\nCREATE TABLE saved_searches (\n    id integer NOT NULL,\n    description text NOT NULL,\n    query text NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    notify_owner boolean NOT NULL,\n    notify_slack boolean NOT NULL,\n    user_id integer,\n    org_id integer,\n    slack_webhook_url text,\n    CONSTRAINT user_or_org_id_not_null CHECK ((((user_id IS NOT NULL) AND (org_id IS NULL)) OR ((org_id IS NOT NULL) AND (user_id IS NULL))))\n);\n\nCREATE SEQUENCE saved_searches_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE saved_searches_id_seq OWNED BY saved_searches.id;\n\nCREATE TABLE search_context_repos (\n    search_context_id bigint NOT NULL,\n    repo_id integer NOT NULL,\n    revision text NOT NULL\n);\n\nCREATE TABLE search_contexts (\n    id bigint NOT NULL,\n    name citext NOT NULL,\n    description text NOT NULL,\n    public boolean NOT NULL,\n    namespace_user_id integer,\n    namespace_org_id integer,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    deleted_at timestamp with time zone,\n    CONSTRAINT search_contexts_has_one_or_no_namespace CHECK (((namespace_user_id IS NULL) OR (namespace_org_id IS NULL)))\n);\n\nCREATE SEQUENCE search_contexts_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE search_contexts_id_seq OWNED BY search_contexts.id;\n\nCREATE TABLE security_event_logs (\n    id bigint NOT NULL,\n    name text NOT NULL,\n    url text NOT NULL,\n    user_id integer NOT NULL,\n    anonymous_user_id text NOT NULL,\n    source text NOT NULL,\n    argument jsonb NOT NULL,\n    version text NOT NULL,\n    \"timestamp\" timestamp with time zone NOT NULL,\n    CONSTRAINT security_event_logs_check_has_user CHECK ((((user_id = 0) AND (anonymous_user_id \u003c\u003e ''::text)) OR ((user_id \u003c\u003e 0) AND (anonymous_user_id = ''::text)) OR ((user_id \u003c\u003e 0) AND (anonymous_user_id \u003c\u003e ''::text)))),\n    CONSTRAINT security_event_logs_check_name_not_empty CHECK ((name \u003c\u003e ''::text)),\n    CONSTRAINT security_event_logs_check_source_not_empty CHECK ((source \u003c\u003e ''::text)),\n    CONSTRAINT security_event_logs_check_version_not_empty CHECK ((version \u003c\u003e ''::text))\n);\n\nCOMMENT ON TABLE security_event_logs IS 'Contains security-relevant events with a long time horizon for storage.';\n\nCOMMENT ON COLUMN security_event_logs.name IS 'The event name as a CAPITALIZED_SNAKE_CASE string.';\n\nCOMMENT ON COLUMN security_event_logs.url IS 'The URL within the Sourcegraph app which generated the event.';\n\nCOMMENT ON COLUMN security_event_logs.user_id IS 'The ID of the actor associated with the event.';\n\nCOMMENT ON COLUMN security_event_logs.anonymous_user_id IS 'The UUID of the actor associated with the event.';\n\nCOMMENT ON COLUMN security_event_logs.source IS 'The site section (WEB, BACKEND, etc.) that generated the event.';\n\nCOMMENT ON COLUMN security_event_logs.argument IS 'An arbitrary JSON blob containing event data.';\n\nCOMMENT ON COLUMN security_event_logs.version IS 'The version of Sourcegraph which generated the event.';\n\nCREATE SEQUENCE security_event_logs_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE security_event_logs_id_seq OWNED BY security_event_logs.id;\n\nCREATE TABLE settings (\n    id integer NOT NULL,\n    org_id integer,\n    contents text,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    user_id integer,\n    author_user_id integer\n);\n\nCREATE TABLE settings_bkup_1514702776 (\n    id integer,\n    org_id integer,\n    author_user_id_old text,\n    contents text,\n    created_at timestamp with time zone,\n    user_id integer,\n    author_user_id integer\n);\n\nCREATE SEQUENCE settings_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE settings_id_seq OWNED BY settings.id;\n\nCREATE VIEW site_config AS\n SELECT global_state.site_id,\n    global_state.initialized\n   FROM global_state;\n\nCREATE TABLE survey_responses (\n    id bigint NOT NULL,\n    user_id integer,\n    email text,\n    score integer NOT NULL,\n    reason text,\n    better text,\n    created_at timestamp with time zone DEFAULT now() NOT NULL\n);\n\nCREATE SEQUENCE survey_responses_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE survey_responses_id_seq OWNED BY survey_responses.id;\n\nCREATE VIEW tracking_changeset_specs_and_changesets AS\n SELECT changeset_specs.id AS changeset_spec_id,\n    COALESCE(changesets.id, (0)::bigint) AS changeset_id,\n    changeset_specs.repo_id,\n    changeset_specs.batch_spec_id,\n    repo.name AS repo_name,\n    COALESCE((changesets.metadata -\u003e\u003e 'Title'::text), (changesets.metadata -\u003e\u003e 'title'::text)) AS changeset_name,\n    changesets.external_state,\n    changesets.publication_state,\n    changesets.reconciler_state\n   FROM ((changeset_specs\n     LEFT JOIN changesets ON (((changesets.repo_id = changeset_specs.repo_id) AND (changesets.external_id = changeset_specs.external_id))))\n     JOIN repo ON ((changeset_specs.repo_id = repo.id)))\n  WHERE ((changeset_specs.external_id IS NOT NULL) AND (repo.deleted_at IS NULL));\n\nCREATE TABLE user_credentials (\n    id bigint NOT NULL,\n    domain text NOT NULL,\n    user_id integer NOT NULL,\n    external_service_type text NOT NULL,\n    external_service_id text NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    credential bytea NOT NULL,\n    ssh_migration_applied boolean DEFAULT false NOT NULL,\n    encryption_key_id text DEFAULT ''::text NOT NULL\n);\n\nCREATE SEQUENCE user_credentials_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE user_credentials_id_seq OWNED BY user_credentials.id;\n\nCREATE TABLE user_emails (\n    user_id integer NOT NULL,\n    email citext NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    verification_code text,\n    verified_at timestamp with time zone,\n    last_verification_sent_at timestamp with time zone,\n    is_primary boolean DEFAULT false NOT NULL\n);\n\nCREATE TABLE user_external_accounts (\n    id integer NOT NULL,\n    user_id integer NOT NULL,\n    service_type text NOT NULL,\n    service_id text NOT NULL,\n    account_id text NOT NULL,\n    auth_data text,\n    account_data text,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    deleted_at timestamp with time zone,\n    client_id text NOT NULL,\n    expired_at timestamp with time zone,\n    last_valid_at timestamp with time zone,\n    encryption_key_id text DEFAULT ''::text NOT NULL\n);\n\nCREATE SEQUENCE user_external_accounts_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE user_external_accounts_id_seq OWNED BY user_external_accounts.id;\n\nCREATE TABLE user_pending_permissions (\n    id integer NOT NULL,\n    bind_id text NOT NULL,\n    permission text NOT NULL,\n    object_type text NOT NULL,\n    object_ids bytea DEFAULT '\\x'::bytea NOT NULL,\n    updated_at timestamp with time zone NOT NULL,\n    service_type text NOT NULL,\n    service_id text NOT NULL,\n    object_ids_ints integer[] DEFAULT '{}'::integer[] NOT NULL\n);\n\nCREATE SEQUENCE user_pending_permissions_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE user_pending_permissions_id_seq OWNED BY user_pending_permissions.id;\n\nCREATE TABLE user_permissions (\n    user_id integer NOT NULL,\n    permission text NOT NULL,\n    object_type text NOT NULL,\n    object_ids bytea DEFAULT '\\x'::bytea NOT NULL,\n    updated_at timestamp with time zone NOT NULL,\n    synced_at timestamp with time zone,\n    object_ids_ints integer[] DEFAULT '{}'::integer[] NOT NULL\n);\n\nCREATE TABLE user_public_repos (\n    user_id integer NOT NULL,\n    repo_uri text NOT NULL,\n    repo_id integer NOT NULL\n);\n\nCREATE SEQUENCE users_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE users_id_seq OWNED BY users.id;\n\nCREATE TABLE versions (\n    service text NOT NULL,\n    version text NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    first_version text NOT NULL\n);\n\nALTER TABLE ONLY access_tokens ALTER COLUMN id SET DEFAULT nextval('access_tokens_id_seq'::regclass);\n\nALTER TABLE ONLY batch_changes ALTER COLUMN id SET DEFAULT nextval('batch_changes_id_seq'::regclass);\n\nALTER TABLE ONLY batch_changes_site_credentials ALTER COLUMN id SET DEFAULT nextval('batch_changes_site_credentials_id_seq'::regclass);\n\nALTER TABLE ONLY batch_specs ALTER COLUMN id SET DEFAULT nextval('batch_specs_id_seq'::regclass);\n\nALTER TABLE ONLY changeset_events ALTER COLUMN id SET DEFAULT nextval('changeset_events_id_seq'::regclass);\n\nALTER TABLE ONLY changeset_jobs ALTER COLUMN id SET DEFAULT nextval('changeset_jobs_id_seq'::regclass);\n\nALTER TABLE ONLY changeset_specs ALTER COLUMN id SET DEFAULT nextval('changeset_specs_id_seq'::regclass);\n\nALTER TABLE ONLY changesets ALTER COLUMN id SET DEFAULT nextval('changesets_id_seq'::regclass);\n\nALTER TABLE ONLY cm_action_jobs ALTER COLUMN id SET DEFAULT nextval('cm_action_jobs_id_seq'::regclass);\n\nALTER TABLE ONLY cm_emails ALTER COLUMN id SET DEFAULT nextval('cm_emails_id_seq'::regclass);\n\nALTER TABLE ONLY cm_monitors ALTER COLUMN id SET DEFAULT nextval('cm_monitors_id_seq'::regclass);\n\nALTER TABLE ONLY cm_queries ALTER COLUMN id SET DEFAULT nextval('cm_queries_id_seq'::regclass);\n\nALTER TABLE ONLY cm_recipients ALTER COLUMN id SET DEFAULT nextval('cm_recipients_id_seq'::regclass);\n\nALTER TABLE ONLY cm_trigger_jobs ALTER COLUMN id SET DEFAULT nextval('cm_trigger_jobs_id_seq'::regclass);\n\nALTER TABLE ONLY critical_and_site_config ALTER COLUMN id SET DEFAULT nextval('critical_and_site_config_id_seq'::regclass);\n\nALTER TABLE ONLY discussion_comments ALTER COLUMN id SET DEFAULT nextval('discussion_comments_id_seq'::regclass);\n\nALTER TABLE ONLY discussion_threads ALTER COLUMN id SET DEFAULT nextval('discussion_threads_id_seq'::regclass);\n\nALTER TABLE ONLY discussion_threads_target_repo ALTER COLUMN id SET DEFAULT nextval('discussion_threads_target_repo_id_seq'::regclass);\n\nALTER TABLE ONLY event_logs ALTER COLUMN id SET DEFAULT nextval('event_logs_id_seq'::regclass);\n\nALTER TABLE ONLY external_services ALTER COLUMN id SET DEFAULT nextval('external_services_id_seq'::regclass);\n\nALTER TABLE ONLY insights_query_runner_jobs ALTER COLUMN id SET DEFAULT nextval('insights_query_runner_jobs_id_seq'::regclass);\n\nALTER TABLE ONLY lsif_dependency_indexing_jobs ALTER COLUMN id SET DEFAULT nextval('lsif_dependency_indexing_jobs_id_seq'::regclass);\n\nALTER TABLE ONLY lsif_index_configuration ALTER COLUMN id SET DEFAULT nextval('lsif_index_configuration_id_seq'::regclass);\n\nALTER TABLE ONLY lsif_indexable_repositories ALTER COLUMN id SET DEFAULT nextval('lsif_indexable_repositories_id_seq'::regclass);\n\nALTER TABLE ONLY lsif_indexes ALTER COLUMN id SET DEFAULT nextval('lsif_indexes_id_seq'::regclass);\n\nALTER TABLE ONLY lsif_packages ALTER COLUMN id SET DEFAULT nextval('lsif_packages_id_seq'::regclass);\n\nALTER TABLE ONLY lsif_references ALTER COLUMN id SET DEFAULT nextval('lsif_references_id_seq'::regclass);\n\nALTER TABLE ONLY lsif_uploads ALTER COLUMN id SET DEFAULT nextval('lsif_dumps_id_seq'::regclass);\n\nALTER TABLE ONLY org_invitations ALTER COLUMN id SET DEFAULT nextval('org_invitations_id_seq'::regclass);\n\nALTER TABLE ONLY org_members ALTER COLUMN id SET DEFAULT nextval('org_members_id_seq'::regclass);\n\nALTER TABLE ONLY orgs ALTER COLUMN id SET DEFAULT nextval('orgs_id_seq'::regclass);\n\nALTER TABLE ONLY out_of_band_migrations ALTER COLUMN id SET DEFAULT nextval('out_of_band_migrations_id_seq'::regclass);\n\nALTER TABLE ONLY out_of_band_migrations_errors ALTER COLUMN id SET DEFAULT nextval('out_of_band_migrations_errors_id_seq'::regclass);\n\nALTER TABLE ONLY phabricator_repos ALTER COLUMN id SET DEFAULT nextval('phabricator_repos_id_seq'::regclass);\n\nALTER TABLE ONLY registry_extension_releases ALTER COLUMN id SET DEFAULT nextval('registry_extension_releases_id_seq'::regclass);\n\nALTER TABLE ONLY registry_extensions ALTER COLUMN id SET DEFAULT nextval('registry_extensions_id_seq'::regclass);\n\nALTER TABLE ONLY repo ALTER COLUMN id SET DEFAULT nextval('repo_id_seq'::regclass);\n\nALTER TABLE ONLY saved_searches ALTER COLUMN id SET DEFAULT nextval('saved_searches_id_seq'::regclass);\n\nALTER TABLE ONLY search_contexts ALTER COLUMN id SET DEFAULT nextval('search_contexts_id_seq'::regclass);\n\nALTER TABLE ONLY security_event_logs ALTER COLUMN id SET DEFAULT nextval('security_event_logs_id_seq'::regclass);\n\nALTER TABLE ONLY settings ALTER COLUMN id SET DEFAULT nextval('settings_id_seq'::regclass);\n\nALTER TABLE ONLY survey_responses ALTER COLUMN id SET DEFAULT nextval('survey_responses_id_seq'::regclass);\n\nALTER TABLE ONLY user_credentials ALTER COLUMN id SET DEFAULT nextval('user_credentials_id_seq'::regclass);\n\nALTER TABLE ONLY user_external_accounts ALTER COLUMN id SET DEFAULT nextval('user_external_accounts_id_seq'::regclass);\n\nALTER TABLE ONLY user_pending_permissions ALTER COLUMN id SET DEFAULT nextval('user_pending_permissions_id_seq'::regclass);\n\nALTER TABLE ONLY users ALTER COLUMN id SET DEFAULT nextval('users_id_seq'::regclass);\n\nALTER TABLE ONLY access_tokens\n    ADD CONSTRAINT access_tokens_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY access_tokens\n    ADD CONSTRAINT access_tokens_value_sha256_key UNIQUE (value_sha256);\n\nALTER TABLE ONLY batch_changes\n    ADD CONSTRAINT batch_changes_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY batch_changes_site_credentials\n    ADD CONSTRAINT batch_changes_site_credentials_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY batch_specs\n    ADD CONSTRAINT batch_specs_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY changeset_events\n    ADD CONSTRAINT changeset_events_changeset_id_kind_key_unique UNIQUE (changeset_id, kind, key);\n\nALTER TABLE ONLY changeset_events\n    ADD CONSTRAINT changeset_events_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY changeset_jobs\n    ADD CONSTRAINT changeset_jobs_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY changeset_specs\n    ADD CONSTRAINT changeset_specs_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY changesets\n    ADD CONSTRAINT changesets_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY changesets\n    ADD CONSTRAINT changesets_repo_external_id_unique UNIQUE (repo_id, external_id);\n\nALTER TABLE ONLY cm_action_jobs\n    ADD CONSTRAINT cm_action_jobs_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY cm_emails\n    ADD CONSTRAINT cm_emails_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY cm_monitors\n    ADD CONSTRAINT cm_monitors_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY cm_queries\n    ADD CONSTRAINT cm_queries_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY cm_recipients\n    ADD CONSTRAINT cm_recipients_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY cm_trigger_jobs\n    ADD CONSTRAINT cm_trigger_jobs_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY critical_and_site_config\n    ADD CONSTRAINT critical_and_site_config_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY default_repos\n    ADD CONSTRAINT default_repos_pkey PRIMARY KEY (repo_id);\n\nALTER TABLE ONLY discussion_comments\n    ADD CONSTRAINT discussion_comments_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY discussion_mail_reply_tokens\n    ADD CONSTRAINT discussion_mail_reply_tokens_pkey PRIMARY KEY (token);\n\nALTER TABLE ONLY discussion_threads\n    ADD CONSTRAINT discussion_threads_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY discussion_threads_target_repo\n    ADD CONSTRAINT discussion_threads_target_repo_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY event_logs\n    ADD CONSTRAINT event_logs_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY external_service_repos\n    ADD CONSTRAINT external_service_repos_repo_id_external_service_id_unique UNIQUE (repo_id, external_service_id);\n\nALTER TABLE ONLY external_services\n    ADD CONSTRAINT external_services_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY feature_flag_overrides\n    ADD CONSTRAINT feature_flag_overrides_unique_org_flag UNIQUE (namespace_org_id, flag_name);\n\nALTER TABLE ONLY feature_flag_overrides\n    ADD CONSTRAINT feature_flag_overrides_unique_user_flag UNIQUE (namespace_user_id, flag_name);\n\nALTER TABLE ONLY feature_flags\n    ADD CONSTRAINT feature_flags_pkey PRIMARY KEY (flag_name);\n\nALTER TABLE ONLY gitserver_repos\n    ADD CONSTRAINT gitserver_repos_pkey PRIMARY KEY (repo_id);\n\nALTER TABLE ONLY global_state\n    ADD CONSTRAINT global_state_pkey PRIMARY KEY (site_id);\n\nALTER TABLE ONLY insights_query_runner_jobs\n    ADD CONSTRAINT insights_query_runner_jobs_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY lsif_dependency_indexing_jobs\n    ADD CONSTRAINT lsif_dependency_indexing_jobs_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY lsif_dirty_repositories\n    ADD CONSTRAINT lsif_dirty_repositories_pkey PRIMARY KEY (repository_id);\n\nALTER TABLE ONLY lsif_index_configuration\n    ADD CONSTRAINT lsif_index_configuration_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY lsif_index_configuration\n    ADD CONSTRAINT lsif_index_configuration_repository_id_key UNIQUE (repository_id);\n\nALTER TABLE ONLY lsif_indexable_repositories\n    ADD CONSTRAINT lsif_indexable_repositories_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY lsif_indexable_repositories\n    ADD CONSTRAINT lsif_indexable_repositories_repository_id_key UNIQUE (repository_id);\n\nALTER TABLE ONLY lsif_indexes\n    ADD CONSTRAINT lsif_indexes_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY lsif_packages\n    ADD CONSTRAINT lsif_packages_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY lsif_references\n    ADD CONSTRAINT lsif_references_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY lsif_uploads\n    ADD CONSTRAINT lsif_uploads_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY names\n    ADD CONSTRAINT names_pkey PRIMARY KEY (name);\n\nALTER TABLE ONLY org_invitations\n    ADD CONSTRAINT org_invitations_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY org_members\n    ADD CONSTRAINT org_members_org_id_user_id_key UNIQUE (org_id, user_id);\n\nALTER TABLE ONLY org_members\n    ADD CONSTRAINT org_members_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY orgs\n    ADD CONSTRAINT orgs_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY out_of_band_migrations_errors\n    ADD CONSTRAINT out_of_band_migrations_errors_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY out_of_band_migrations\n    ADD CONSTRAINT out_of_band_migrations_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY phabricator_repos\n    ADD CONSTRAINT phabricator_repos_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY phabricator_repos\n    ADD CONSTRAINT phabricator_repos_repo_name_key UNIQUE (repo_name);\n\nALTER TABLE ONLY product_licenses\n    ADD CONSTRAINT product_licenses_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY product_subscriptions\n    ADD CONSTRAINT product_subscriptions_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY registry_extension_releases\n    ADD CONSTRAINT registry_extension_releases_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY registry_extensions\n    ADD CONSTRAINT registry_extensions_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY repo\n    ADD CONSTRAINT repo_name_unique UNIQUE (name) DEFERRABLE;\n\nALTER TABLE ONLY repo_pending_permissions\n    ADD CONSTRAINT repo_pending_permissions_perm_unique UNIQUE (repo_id, permission);\n\nALTER TABLE ONLY repo_permissions\n    ADD CONSTRAINT repo_permissions_perm_unique UNIQUE (repo_id, permission);\n\nALTER TABLE ONLY repo\n    ADD CONSTRAINT repo_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY saved_searches\n    ADD CONSTRAINT saved_searches_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY search_context_repos\n    ADD CONSTRAINT search_context_repos_search_context_id_repo_id_revision_unique UNIQUE (search_context_id, repo_id, revision);\n\nALTER TABLE ONLY search_contexts\n    ADD CONSTRAINT search_contexts_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY security_event_logs\n    ADD CONSTRAINT security_event_logs_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY settings\n    ADD CONSTRAINT settings_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY survey_responses\n    ADD CONSTRAINT survey_responses_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY user_credentials\n    ADD CONSTRAINT user_credentials_domain_user_id_external_service_type_exter_key UNIQUE (domain, user_id, external_service_type, external_service_id);\n\nALTER TABLE ONLY user_credentials\n    ADD CONSTRAINT user_credentials_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY user_emails\n    ADD CONSTRAINT user_emails_no_duplicates_per_user UNIQUE (user_id, email);\n\nALTER TABLE ONLY user_emails\n    ADD CONSTRAINT user_emails_unique_verified_email EXCLUDE USING btree (email WITH OPERATOR(=)) WHERE ((verified_at IS NOT NULL));\n\nALTER TABLE ONLY user_external_accounts\n    ADD CONSTRAINT user_external_accounts_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY user_pending_permissions\n    ADD CONSTRAINT user_pending_permissions_service_perm_object_unique UNIQUE (service_type, service_id, permission, object_type, bind_id);\n\nALTER TABLE ONLY user_permissions\n    ADD CONSTRAINT user_permissions_perm_object_unique UNIQUE (user_id, permission, object_type);\n\nALTER TABLE ONLY user_public_repos\n    ADD CONSTRAINT user_public_repos_user_id_repo_id_key UNIQUE (user_id, repo_id);\n\nALTER TABLE ONLY users\n    ADD CONSTRAINT users_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY versions\n    ADD CONSTRAINT versions_pkey PRIMARY KEY (service);\n\nCREATE INDEX access_tokens_lookup ON access_tokens USING hash (value_sha256) WHERE (deleted_at IS NULL);\n\nCREATE INDEX batch_changes_namespace_org_id ON batch_changes USING btree (namespace_org_id);\n\nCREATE INDEX batch_changes_namespace_user_id ON batch_changes USING btree (namespace_user_id);\n\nCREATE INDEX batch_changes_site_credentials_credential_idx ON batch_changes_site_credentials USING btree (((encryption_key_id = ANY (ARRAY[''::text, 'previously-migrated'::text]))));\n\nCREATE UNIQUE INDEX batch_changes_site_credentials_unique ON batch_changes_site_credentials USING btree (external_service_type, external_service_id);\n\nCREATE INDEX batch_specs_rand_id ON batch_specs USING btree (rand_id);\n\nCREATE INDEX changeset_jobs_bulk_group_idx ON changeset_jobs USING btree (bulk_group);\n\nCREATE INDEX changeset_jobs_state_idx ON changeset_jobs USING btree (state);\n\nCREATE INDEX changeset_specs_external_id ON changeset_specs USING btree (external_id);\n\nCREATE INDEX changeset_specs_head_ref ON changeset_specs USING btree (head_ref);\n\nCREATE INDEX changeset_specs_rand_id ON changeset_specs USING btree (rand_id);\n\nCREATE INDEX changeset_specs_title ON changeset_specs USING btree (title);\n\nCREATE INDEX changesets_batch_change_ids ON changesets USING gin (batch_change_ids);\n\nCREATE INDEX changesets_external_state_idx ON changesets USING btree (external_state);\n\nCREATE INDEX changesets_external_title_idx ON changesets USING btree (external_title);\n\nCREATE INDEX changesets_publication_state_idx ON changesets USING btree (publication_state);\n\nCREATE INDEX changesets_reconciler_state_idx ON changesets USING btree (reconciler_state);\n\nCREATE UNIQUE INDEX critical_and_site_config_unique ON critical_and_site_config USING btree (id, type);\n\nCREATE INDEX discussion_comments_author_user_id_idx ON discussion_comments USING btree (author_user_id);\n\nCREATE INDEX discussion_comments_reports_array_length_idx ON discussion_comments USING btree (array_length(reports, 1));\n\nCREATE INDEX discussion_comments_thread_id_idx ON discussion_comments USING btree (thread_id);\n\nCREATE INDEX discussion_mail_reply_tokens_user_id_thread_id_idx ON discussion_mail_reply_tokens USING btree (user_id, thread_id);\n\nCREATE INDEX discussion_threads_author_user_id_idx ON discussion_threads USING btree (author_user_id);\n\nCREATE INDEX discussion_threads_target_repo_repo_id_path_idx ON discussion_threads_target_repo USING btree (repo_id, path);\n\nCREATE INDEX event_logs_anonymous_user_id ON event_logs USING btree (anonymous_user_id);\n\nCREATE INDEX event_logs_name ON event_logs USING btree (name);\n\nCREATE INDEX event_logs_source ON event_logs USING btree (source);\n\nCREATE INDEX event_logs_timestamp ON event_logs USING btree (\"timestamp\");\n\nCREATE INDEX event_logs_timestamp_at_utc ON event_logs USING btree (date(timezone('UTC'::text, \"timestamp\")));\n\nCREATE INDEX event_logs_user_id ON event_logs USING btree (user_id);\n\nCREATE INDEX external_service_repos_external_service_id ON external_service_repos USING btree (external_service_id);\n\nCREATE INDEX external_service_repos_idx ON external_service_repos USING btree (external_service_id, repo_id);\n\nCREATE INDEX external_service_sync_jobs_state_idx ON external_service_sync_jobs USING btree (state);\n\nCREATE INDEX external_service_user_repos_idx ON external_service_repos USING btree (user_id, repo_id) WHERE (user_id IS NOT NULL);\n\nCREATE INDEX external_services_namespace_user_id_idx ON external_services USING btree (namespace_user_id);\n\nCREATE INDEX feature_flag_overrides_org_id ON feature_flag_overrides USING btree (namespace_org_id) WHERE (namespace_org_id IS NOT NULL);\n\nCREATE INDEX feature_flag_overrides_user_id ON feature_flag_overrides USING btree (namespace_user_id) WHERE (namespace_user_id IS NOT NULL);\n\nCREATE INDEX gitserver_repos_cloned_status_idx ON gitserver_repos USING btree (repo_id) WHERE (clone_status = 'cloned'::text);\n\nCREATE INDEX gitserver_repos_cloning_status_idx ON gitserver_repos USING btree (repo_id) WHERE (clone_status = 'cloning'::text);\n\nCREATE INDEX gitserver_repos_last_error_idx ON gitserver_repos USING btree (last_error) WHERE (last_error IS NOT NULL);\n\nCREATE INDEX gitserver_repos_not_cloned_status_idx ON gitserver_repos USING btree (repo_id) WHERE (clone_status = 'not_cloned'::text);\n\nCREATE INDEX insights_query_runner_jobs_state_btree ON insights_query_runner_jobs USING btree (state);\n\nCREATE UNIQUE INDEX kind_cloud_default ON external_services USING btree (kind, cloud_default) WHERE ((cloud_default = true) AND (deleted_at IS NULL));\n\nCREATE INDEX lsif_indexes_commit_last_checked_at ON lsif_indexes USING btree (commit_last_checked_at) WHERE (state \u003c\u003e 'deleted'::text);\n\nCREATE INDEX lsif_nearest_uploads_links_repository_id_commit_bytea ON lsif_nearest_uploads_links USING btree (repository_id, commit_bytea);\n\nCREATE INDEX lsif_nearest_uploads_repository_id_commit_bytea ON lsif_nearest_uploads USING btree (repository_id, commit_bytea);\n\nCREATE INDEX lsif_packages_scheme_name_version ON lsif_packages USING btree (scheme, name, version);\n\nCREATE INDEX lsif_references_package ON lsif_references USING btree (scheme, name, version);\n\nCREATE INDEX lsif_uploads_associated_index_id ON lsif_uploads USING btree (associated_index_id);\n\nCREATE INDEX lsif_uploads_commit_last_checked_at ON lsif_uploads USING btree (commit_last_checked_at) WHERE (state \u003c\u003e 'deleted'::text);\n\nCREATE INDEX lsif_uploads_committed_at ON lsif_uploads USING btree (committed_at) WHERE (state = 'completed'::text);\n\nCREATE UNIQUE INDEX lsif_uploads_repository_id_commit_root_indexer ON lsif_uploads USING btree (repository_id, commit, root, indexer) WHERE (state = 'completed'::text);\n\nCREATE INDEX lsif_uploads_state ON lsif_uploads USING btree (state);\n\nCREATE INDEX lsif_uploads_uploaded_at ON lsif_uploads USING btree (uploaded_at);\n\nCREATE INDEX lsif_uploads_visible_at_tip_repository_id_upload_id ON lsif_uploads_visible_at_tip USING btree (repository_id, upload_id);\n\nCREATE INDEX org_invitations_org_id ON org_invitations USING btree (org_id) WHERE (deleted_at IS NULL);\n\nCREATE INDEX org_invitations_recipient_user_id ON org_invitations USING btree (recipient_user_id) WHERE (deleted_at IS NULL);\n\nCREATE UNIQUE INDEX org_invitations_singleflight ON org_invitations USING btree (org_id, recipient_user_id) WHERE ((responded_at IS NULL) AND (revoked_at IS NULL) AND (deleted_at IS NULL));\n\nCREATE UNIQUE INDEX orgs_name ON orgs USING btree (name) WHERE (deleted_at IS NULL);\n\nCREATE INDEX registry_extension_releases_registry_extension_id ON registry_extension_releases USING btree (registry_extension_id, release_tag, created_at DESC) WHERE (deleted_at IS NULL);\n\nCREATE UNIQUE INDEX registry_extension_releases_version ON registry_extension_releases USING btree (registry_extension_id, release_version) WHERE (release_version IS NOT NULL);\n\nCREATE UNIQUE INDEX registry_extensions_publisher_name ON registry_extensions USING btree (COALESCE(publisher_user_id, 0), COALESCE(publisher_org_id, 0), name) WHERE (deleted_at IS NULL);\n\nCREATE UNIQUE INDEX registry_extensions_uuid ON registry_extensions USING btree (uuid);\n\nCREATE INDEX repo_archived ON repo USING btree (archived);\n\nCREATE INDEX repo_cloned ON repo USING btree (cloned);\n\nCREATE INDEX repo_created_at ON repo USING btree (created_at);\n\nCREATE UNIQUE INDEX repo_external_unique_idx ON repo USING btree (external_service_type, external_service_id, external_id);\n\nCREATE INDEX repo_fork ON repo USING btree (fork);\n\nCREATE INDEX repo_metadata_gin_idx ON repo USING gin (metadata);\n\nCREATE INDEX repo_name_idx ON repo USING btree (lower((name)::text) COLLATE \"C\");\n\nCREATE INDEX repo_name_trgm ON repo USING gin (lower((name)::text) gin_trgm_ops);\n\nCREATE INDEX repo_private ON repo USING btree (private);\n\nCREATE INDEX repo_stars_idx ON repo USING btree (stars DESC NULLS LAST);\n\nCREATE INDEX repo_uri_idx ON repo USING btree (uri);\n\nCREATE UNIQUE INDEX search_contexts_name_namespace_org_id_unique ON search_contexts USING btree (name, namespace_org_id) WHERE (namespace_org_id IS NOT NULL);\n\nCREATE UNIQUE INDEX search_contexts_name_namespace_user_id_unique ON search_contexts USING btree (name, namespace_user_id) WHERE (namespace_user_id IS NOT NULL);\n\nCREATE UNIQUE INDEX search_contexts_name_without_namespace_unique ON search_contexts USING btree (name) WHERE ((namespace_user_id IS NULL) AND (namespace_org_id IS NULL));\n\nCREATE INDEX security_event_logs_anonymous_user_id ON security_event_logs USING btree (anonymous_user_id);\n\nCREATE INDEX security_event_logs_name ON security_event_logs USING btree (name);\n\nCREATE INDEX security_event_logs_source ON security_event_logs USING btree (source);\n\nCREATE INDEX security_event_logs_timestamp ON security_event_logs USING btree (\"timestamp\");\n\nCREATE INDEX security_event_logs_timestamp_at_utc ON security_event_logs USING btree (date(timezone('UTC'::text, \"timestamp\")));\n\nCREATE INDEX security_event_logs_user_id ON security_event_logs USING btree (user_id);\n\nCREATE INDEX settings_org_id_idx ON settings USING btree (org_id);\n\nCREATE INDEX user_credentials_credential_idx ON user_credentials USING btree (((encryption_key_id = ANY (ARRAY[''::text, 'previously-migrated'::text]))));\n\nCREATE UNIQUE INDEX user_emails_user_id_is_primary_idx ON user_emails USING btree (user_id, is_primary) WHERE (is_primary = true);\n\nCREATE UNIQUE INDEX user_external_accounts_account ON user_external_accounts USING btree (service_type, service_id, client_id, account_id) WHERE (deleted_at IS NULL);\n\nCREATE INDEX user_external_accounts_user_id ON user_external_accounts USING btree (user_id) WHERE (deleted_at IS NULL);\n\nCREATE UNIQUE INDEX users_billing_customer_id ON users USING btree (billing_customer_id) WHERE (deleted_at IS NULL);\n\nCREATE INDEX users_created_at_idx ON users USING btree (created_at);\n\nCREATE UNIQUE INDEX users_username ON users USING btree (username) WHERE (deleted_at IS NULL);\n\nCREATE TRIGGER trig_delete_batch_change_reference_on_changesets AFTER DELETE ON batch_changes FOR EACH ROW EXECUTE FUNCTION delete_batch_change_reference_on_changesets();\n\nCREATE TRIGGER trig_delete_repo_ref_on_external_service_repos AFTER UPDATE OF deleted_at ON repo FOR EACH ROW EXECUTE FUNCTION delete_repo_ref_on_external_service_repos();\n\nCREATE TRIGGER trig_invalidate_session_on_password_change BEFORE UPDATE OF passwd ON users FOR EACH ROW EXECUTE FUNCTION invalidate_session_for_userid_on_password_change();\n\nCREATE TRIGGER trig_soft_delete_user_reference_on_external_service AFTER UPDATE OF deleted_at ON users FOR EACH ROW EXECUTE FUNCTION soft_delete_user_reference_on_external_service();\n\nCREATE TRIGGER versions_insert BEFORE INSERT ON versions FOR EACH ROW EXECUTE FUNCTION versions_insert_row_trigger();\n\nALTER TABLE ONLY access_tokens\n    ADD CONSTRAINT access_tokens_creator_user_id_fkey FOREIGN KEY (creator_user_id) REFERENCES users(id);\n\nALTER TABLE ONLY access_tokens\n    ADD CONSTRAINT access_tokens_subject_user_id_fkey FOREIGN KEY (subject_user_id) REFERENCES users(id);\n\nALTER TABLE ONLY batch_changes\n    ADD CONSTRAINT batch_changes_batch_spec_id_fkey FOREIGN KEY (batch_spec_id) REFERENCES batch_specs(id) DEFERRABLE;\n\nALTER TABLE ONLY batch_changes\n    ADD CONSTRAINT batch_changes_initial_applier_id_fkey FOREIGN KEY (initial_applier_id) REFERENCES users(id) ON DELETE SET NULL DEFERRABLE;\n\nALTER TABLE ONLY batch_changes\n    ADD CONSTRAINT batch_changes_last_applier_id_fkey FOREIGN KEY (last_applier_id) REFERENCES users(id) ON DELETE SET NULL DEFERRABLE;\n\nALTER TABLE ONLY batch_changes\n    ADD CONSTRAINT batch_changes_namespace_org_id_fkey FOREIGN KEY (namespace_org_id) REFERENCES orgs(id) ON DELETE CASCADE DEFERRABLE;\n\nALTER TABLE ONLY batch_changes\n    ADD CONSTRAINT batch_changes_namespace_user_id_fkey FOREIGN KEY (namespace_user_id) REFERENCES users(id) ON DELETE CASCADE DEFERRABLE;\n\nALTER TABLE ONLY batch_specs\n    ADD CONSTRAINT batch_specs_user_id_fkey FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE SET NULL DEFERRABLE;\n\nALTER TABLE ONLY changeset_events\n    ADD CONSTRAINT changeset_events_changeset_id_fkey FOREIGN KEY (changeset_id) REFERENCES changesets(id) ON DELETE CASCADE DEFERRABLE;\n\nALTER TABLE ONLY changeset_jobs\n    ADD CONSTRAINT changeset_jobs_batch_change_id_fkey FOREIGN KEY (batch_change_id) REFERENCES batch_changes(id) ON DELETE CASCADE DEFERRABLE;\n\nALTER TABLE ONLY changeset_jobs\n    ADD CONSTRAINT changeset_jobs_changeset_id_fkey FOREIGN KEY (changeset_id) REFERENCES changesets(id) ON DELETE CASCADE DEFERRABLE;\n\nALTER TABLE ONLY changeset_jobs\n    ADD CONSTRAINT changeset_jobs_user_id_fkey FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE DEFERRABLE;\n\nALTER TABLE ONLY changeset_specs\n    ADD CONSTRAINT changeset_specs_batch_spec_id_fkey FOREIGN KEY (batch_spec_id) REFERENCES batch_specs(id) DEFERRABLE;\n\nALTER TABLE ONLY changeset_specs\n    ADD CONSTRAINT changeset_specs_repo_id_fkey FOREIGN KEY (repo_id) REFERENCES repo(id) DEFERRABLE;\n\nALTER TABLE ONLY changeset_specs\n    ADD CONSTRAINT changeset_specs_user_id_fkey FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE SET NULL DEFERRABLE;\n\nALTER TABLE ONLY changesets\n    ADD CONSTRAINT changesets_changeset_spec_id_fkey FOREIGN KEY (current_spec_id) REFERENCES changeset_specs(id) DEFERRABLE;\n\nALTER TABLE ONLY changesets\n    ADD CONSTRAINT changesets_owned_by_batch_spec_id_fkey FOREIGN KEY (owned_by_batch_change_id) REFERENCES batch_changes(id) ON DELETE SET NULL DEFERRABLE;\n\nALTER TABLE ONLY changesets\n    ADD CONSTRAINT changesets_previous_spec_id_fkey FOREIGN KEY (previous_spec_id) REFERENCES changeset_specs(id) DEFERRABLE;\n\nALTER TABLE ONLY changesets\n    ADD CONSTRAINT changesets_repo_id_fkey FOREIGN KEY (repo_id) REFERENCES repo(id) ON DELETE CASCADE DEFERRABLE;\n\nALTER TABLE ONLY cm_action_jobs\n    ADD CONSTRAINT cm_action_jobs_email_fk FOREIGN KEY (email) REFERENCES cm_emails(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY cm_action_jobs\n    ADD CONSTRAINT cm_action_jobs_trigger_event_fk FOREIGN KEY (trigger_event) REFERENCES cm_trigger_jobs(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY cm_emails\n    ADD CONSTRAINT cm_emails_changed_by_fk FOREIGN KEY (changed_by) REFERENCES users(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY cm_emails\n    ADD CONSTRAINT cm_emails_created_by_fk FOREIGN KEY (created_by) REFERENCES users(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY cm_emails\n    ADD CONSTRAINT cm_emails_monitor FOREIGN KEY (monitor) REFERENCES cm_monitors(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY cm_monitors\n    ADD CONSTRAINT cm_monitors_changed_by_fk FOREIGN KEY (changed_by) REFERENCES users(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY cm_monitors\n    ADD CONSTRAINT cm_monitors_created_by_fk FOREIGN KEY (created_by) REFERENCES users(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY cm_monitors\n    ADD CONSTRAINT cm_monitors_org_id_fk FOREIGN KEY (namespace_org_id) REFERENCES orgs(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY cm_monitors\n    ADD CONSTRAINT cm_monitors_user_id_fk FOREIGN KEY (namespace_user_id) REFERENCES users(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY cm_recipients\n    ADD CONSTRAINT cm_recipients_emails FOREIGN KEY (email) REFERENCES cm_emails(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY cm_recipients\n    ADD CONSTRAINT cm_recipients_org_id_fk FOREIGN KEY (namespace_org_id) REFERENCES orgs(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY cm_recipients\n    ADD CONSTRAINT cm_recipients_user_id_fk FOREIGN KEY (namespace_user_id) REFERENCES users(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY cm_trigger_jobs\n    ADD CONSTRAINT cm_trigger_jobs_query_fk FOREIGN KEY (query) REFERENCES cm_queries(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY cm_queries\n    ADD CONSTRAINT cm_triggers_changed_by_fk FOREIGN KEY (changed_by) REFERENCES users(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY cm_queries\n    ADD CONSTRAINT cm_triggers_created_by_fk FOREIGN KEY (created_by) REFERENCES users(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY cm_queries\n    ADD CONSTRAINT cm_triggers_monitor FOREIGN KEY (monitor) REFERENCES cm_monitors(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY default_repos\n    ADD CONSTRAINT default_repos_repo_id_fkey FOREIGN KEY (repo_id) REFERENCES repo(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY discussion_comments\n    ADD CONSTRAINT discussion_comments_author_user_id_fkey FOREIGN KEY (author_user_id) REFERENCES users(id) ON DELETE RESTRICT;\n\nALTER TABLE ONLY discussion_comments\n    ADD CONSTRAINT discussion_comments_thread_id_fkey FOREIGN KEY (thread_id) REFERENCES discussion_threads(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY discussion_mail_reply_tokens\n    ADD CONSTRAINT discussion_mail_reply_tokens_thread_id_fkey FOREIGN KEY (thread_id) REFERENCES discussion_threads(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY discussion_mail_reply_tokens\n    ADD CONSTRAINT discussion_mail_reply_tokens_user_id_fkey FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE RESTRICT;\n\nALTER TABLE ONLY discussion_threads\n    ADD CONSTRAINT discussion_threads_author_user_id_fkey FOREIGN KEY (author_user_id) REFERENCES users(id) ON DELETE RESTRICT;\n\nALTER TABLE ONLY discussion_threads\n    ADD CONSTRAINT discussion_threads_target_repo_id_fk FOREIGN KEY (target_repo_id) REFERENCES discussion_threads_target_repo(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY discussion_threads_target_repo\n    ADD CONSTRAINT discussion_threads_target_repo_repo_id_fkey FOREIGN KEY (repo_id) REFERENCES repo(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY discussion_threads_target_repo\n    ADD CONSTRAINT discussion_threads_target_repo_thread_id_fkey FOREIGN KEY (thread_id) REFERENCES discussion_threads(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY external_service_repos\n    ADD CONSTRAINT external_service_repos_external_service_id_fkey FOREIGN KEY (external_service_id) REFERENCES external_services(id) ON DELETE CASCADE DEFERRABLE;\n\nALTER TABLE ONLY external_service_repos\n    ADD CONSTRAINT external_service_repos_repo_id_fkey FOREIGN KEY (repo_id) REFERENCES repo(id) ON DELETE CASCADE DEFERRABLE;\n\nALTER TABLE ONLY external_service_repos\n    ADD CONSTRAINT external_service_repos_user_id_fkey FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE DEFERRABLE;\n\nALTER TABLE ONLY external_service_sync_jobs\n    ADD CONSTRAINT external_services_id_fk FOREIGN KEY (external_service_id) REFERENCES external_services(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY external_services\n    ADD CONSTRAINT external_services_namepspace_user_id_fkey FOREIGN KEY (namespace_user_id) REFERENCES users(id) ON DELETE CASCADE DEFERRABLE;\n\nALTER TABLE ONLY feature_flag_overrides\n    ADD CONSTRAINT feature_flag_overrides_flag_name_fkey FOREIGN KEY (flag_name) REFERENCES feature_flags(flag_name) ON DELETE CASCADE;\n\nALTER TABLE ONLY feature_flag_overrides\n    ADD CONSTRAINT feature_flag_overrides_namespace_org_id_fkey FOREIGN KEY (namespace_org_id) REFERENCES orgs(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY feature_flag_overrides\n    ADD CONSTRAINT feature_flag_overrides_namespace_user_id_fkey FOREIGN KEY (namespace_user_id) REFERENCES users(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY gitserver_repos\n    ADD CONSTRAINT gitserver_repos_repo_id_fkey FOREIGN KEY (repo_id) REFERENCES repo(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY lsif_dependency_indexing_jobs\n    ADD CONSTRAINT lsif_dependency_indexing_jobs_upload_id_fkey FOREIGN KEY (upload_id) REFERENCES lsif_uploads(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY lsif_index_configuration\n    ADD CONSTRAINT lsif_index_configuration_repository_id_fkey FOREIGN KEY (repository_id) REFERENCES repo(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY lsif_packages\n    ADD CONSTRAINT lsif_packages_dump_id_fkey FOREIGN KEY (dump_id) REFERENCES lsif_uploads(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY lsif_references\n    ADD CONSTRAINT lsif_references_dump_id_fkey FOREIGN KEY (dump_id) REFERENCES lsif_uploads(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY names\n    ADD CONSTRAINT names_org_id_fkey FOREIGN KEY (org_id) REFERENCES orgs(id) ON UPDATE CASCADE ON DELETE CASCADE;\n\nALTER TABLE ONLY names\n    ADD CONSTRAINT names_user_id_fkey FOREIGN KEY (user_id) REFERENCES users(id) ON UPDATE CASCADE ON DELETE CASCADE;\n\nALTER TABLE ONLY org_invitations\n    ADD CONSTRAINT org_invitations_org_id_fkey FOREIGN KEY (org_id) REFERENCES orgs(id);\n\nALTER TABLE ONLY org_invitations\n    ADD CONSTRAINT org_invitations_recipient_user_id_fkey FOREIGN KEY (recipient_user_id) REFERENCES users(id);\n\nALTER TABLE ONLY org_invitations\n    ADD CONSTRAINT org_invitations_sender_user_id_fkey FOREIGN KEY (sender_user_id) REFERENCES users(id);\n\nALTER TABLE ONLY org_members\n    ADD CONSTRAINT org_members_references_orgs FOREIGN KEY (org_id) REFERENCES orgs(id) ON DELETE RESTRICT;\n\nALTER TABLE ONLY org_members\n    ADD CONSTRAINT org_members_user_id_fkey FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE RESTRICT;\n\nALTER TABLE ONLY out_of_band_migrations_errors\n    ADD CONSTRAINT out_of_band_migrations_errors_migration_id_fkey FOREIGN KEY (migration_id) REFERENCES out_of_band_migrations(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY product_licenses\n    ADD CONSTRAINT product_licenses_product_subscription_id_fkey FOREIGN KEY (product_subscription_id) REFERENCES product_subscriptions(id);\n\nALTER TABLE ONLY product_subscriptions\n    ADD CONSTRAINT product_subscriptions_user_id_fkey FOREIGN KEY (user_id) REFERENCES users(id);\n\nALTER TABLE ONLY registry_extension_releases\n    ADD CONSTRAINT registry_extension_releases_creator_user_id_fkey FOREIGN KEY (creator_user_id) REFERENCES users(id);\n\nALTER TABLE ONLY registry_extension_releases\n    ADD CONSTRAINT registry_extension_releases_registry_extension_id_fkey FOREIGN KEY (registry_extension_id) REFERENCES registry_extensions(id) ON UPDATE CASCADE ON DELETE CASCADE;\n\nALTER TABLE ONLY registry_extensions\n    ADD CONSTRAINT registry_extensions_publisher_org_id_fkey FOREIGN KEY (publisher_org_id) REFERENCES orgs(id);\n\nALTER TABLE ONLY registry_extensions\n    ADD CONSTRAINT registry_extensions_publisher_user_id_fkey FOREIGN KEY (publisher_user_id) REFERENCES users(id);\n\nALTER TABLE ONLY saved_searches\n    ADD CONSTRAINT saved_searches_org_id_fkey FOREIGN KEY (org_id) REFERENCES orgs(id);\n\nALTER TABLE ONLY saved_searches\n    ADD CONSTRAINT saved_searches_user_id_fkey FOREIGN KEY (user_id) REFERENCES users(id);\n\nALTER TABLE ONLY search_context_repos\n    ADD CONSTRAINT search_context_repos_repo_id_fk FOREIGN KEY (repo_id) REFERENCES repo(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY search_context_repos\n    ADD CONSTRAINT search_context_repos_search_context_id_fk FOREIGN KEY (search_context_id) REFERENCES search_contexts(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY search_contexts\n    ADD CONSTRAINT search_contexts_namespace_org_id_fk FOREIGN KEY (namespace_org_id) REFERENCES orgs(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY search_contexts\n    ADD CONSTRAINT search_contexts_namespace_user_id_fk FOREIGN KEY (namespace_user_id) REFERENCES users(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY settings\n    ADD CONSTRAINT settings_author_user_id_fkey FOREIGN KEY (author_user_id) REFERENCES users(id) ON DELETE RESTRICT;\n\nALTER TABLE ONLY settings\n    ADD CONSTRAINT settings_references_orgs FOREIGN KEY (org_id) REFERENCES orgs(id) ON DELETE RESTRICT;\n\nALTER TABLE ONLY settings\n    ADD CONSTRAINT settings_user_id_fkey FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE RESTRICT;\n\nALTER TABLE ONLY survey_responses\n    ADD CONSTRAINT survey_responses_user_id_fkey FOREIGN KEY (user_id) REFERENCES users(id);\n\nALTER TABLE ONLY user_credentials\n    ADD CONSTRAINT user_credentials_user_id_fkey FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE DEFERRABLE;\n\nALTER TABLE ONLY user_emails\n    ADD CONSTRAINT user_emails_user_id_fkey FOREIGN KEY (user_id) REFERENCES users(id);\n\nALTER TABLE ONLY user_external_accounts\n    ADD CONSTRAINT user_external_accounts_user_id_fkey FOREIGN KEY (user_id) REFERENCES users(id);\n\nALTER TABLE ONLY user_public_repos\n    ADD CONSTRAINT user_public_repos_repo_id_fkey FOREIGN KEY (repo_id) REFERENCES repo(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY user_public_repos\n    ADD CONSTRAINT user_public_repos_user_id_fkey FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE;\n\nINSERT INTO out_of_band_migrations VALUES (3, 'core-application', 'frontend-db.external-services', 'Encrypt configuration', 0, '2021-10-08 16:09:36.889968+00', NULL, true, false, false, 3, 26, NULL, NULL);\nINSERT INTO out_of_band_migrations VALUES (6, 'core-application', 'frontend-db.external-accounts', 'Encrypt auth data', 0, '2021-10-08 16:09:36.986936+00', NULL, true, false, false, 3, 26, NULL, NULL);\nINSERT INTO out_of_band_migrations VALUES (1, 'code-intelligence', 'codeintel-db.lsif_data_documents', 'Populate num_diagnostics from gob-encoded payload', 0, '2021-06-03 23:21:34.031614+00', NULL, true, false, true, 3, 25, NULL, NULL);\nINSERT INTO out_of_band_migrations VALUES (2, 'campaigns', 'frontend-db.authenticators', 'Prepare for SSH pushes to code hosts', 0, '2021-10-08 16:09:36.662797+00', NULL, true, false, true, 3, 26, NULL, NULL);\nINSERT INTO out_of_band_migrations VALUES (4, 'code-intelligence', 'codeintel-db.lsif_data_definitions', 'Populate num_locations from gob-encoded payload', 0, '2021-10-08 16:09:36.958858+00', NULL, true, false, true, 3, 26, NULL, NULL);\nINSERT INTO out_of_band_migrations VALUES (5, 'code-intelligence', 'codeintel-db.lsif_data_references', 'Populate num_locations from gob-encoded payload', 0, '2021-10-08 16:09:36.958858+00', NULL, true, false, true, 3, 26, NULL, NULL);\nINSERT INTO out_of_band_migrations VALUES (7, 'code-intelligence', 'codeintel-db.lsif_data_documents', 'Split payload into multiple columns', 0, '2021-10-08 16:09:36.999803+00', NULL, false, false, true, 3, 27, NULL, NULL);\nINSERT INTO out_of_band_migrations VALUES (8, 'code-intelligence', 'frontend-db.lsif_uploads', 'Backfill committed_at', 0, '2021-10-08 16:09:37.097218+00', NULL, true, false, true, 3, 28, NULL, NULL);\nINSERT INTO out_of_band_migrations VALUES (9, 'batch-changes', 'frontend-db.user-credentials', 'Encrypt batch changes user credentials', 0, '2021-10-08 16:09:37.127756+00', NULL, false, false, true, 3, 28, NULL, NULL);\nINSERT INTO out_of_band_migrations VALUES (10, 'batch-changes', 'frontend-db.site-credentials', 'Encrypt batch changes site credentials', 0, '2021-10-08 16:09:37.157552+00', NULL, false, false, true, 3, 28, NULL, NULL);\n\nSELECT pg_catalog.setval('out_of_band_migrations_id_seq', 1, false);",
				"DownQuery": "-- Nothing",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					-1528395834
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395835,
				"Name": "cohort id",
				"UpQuery": "ALTER TABLE event_logs\nADD COLUMN cohort_id date;",
				"DownQuery": "ALTER TABLE event_logs\nDROP COLUMN cohort_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395834
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395836,
				"Name": "dbworkers worker hostname",
				"UpQuery": "-- Note that we have to regenerate the reconciler_changesets view, as the SELECT\n-- c.* in the view definition isn't refreshed when the fields change within the\n-- changesets table.\nDROP VIEW IF EXISTS\n    reconciler_changesets;\n\nALTER TABLE changesets ADD COLUMN IF NOT EXISTS worker_hostname text NOT NULL DEFAULT '';\n\nCREATE VIEW reconciler_changesets AS\n    SELECT c.* FROM changesets c\n    INNER JOIN repo r on r.id = c.repo_id\n    WHERE\n        r.deleted_at IS NULL AND\n        EXISTS (\n            SELECT 1 FROM batch_changes\n            LEFT JOIN users namespace_user ON batch_changes.namespace_user_id = namespace_user.id\n            LEFT JOIN orgs namespace_org ON batch_changes.namespace_org_id = namespace_org.id\n            WHERE\n                c.batch_change_ids ? batch_changes.id::text AND\n                namespace_user.deleted_at IS NULL AND\n                namespace_org.deleted_at IS NULL\n        )\n;\n\nALTER TABLE changeset_jobs ADD COLUMN worker_hostname text NOT NULL DEFAULT '';\nALTER TABLE cm_action_jobs ADD COLUMN IF NOT EXISTS worker_hostname text NOT NULL DEFAULT '';\nALTER TABLE cm_trigger_jobs ADD COLUMN IF NOT EXISTS worker_hostname text NOT NULL DEFAULT '';\nALTER TABLE external_service_sync_jobs ADD COLUMN IF NOT EXISTS worker_hostname text NOT NULL DEFAULT '';\nALTER TABLE insights_query_runner_jobs ADD COLUMN IF NOT EXISTS worker_hostname text NOT NULL DEFAULT '';\nALTER TABLE lsif_dependency_indexing_jobs ADD COLUMN IF NOT EXISTS worker_hostname text NOT NULL DEFAULT '';\nALTER TABLE lsif_indexes ADD COLUMN IF NOT EXISTS worker_hostname text NOT NULL DEFAULT '';\nALTER TABLE lsif_uploads ADD COLUMN IF NOT EXISTS worker_hostname text NOT NULL DEFAULT '';",
				"DownQuery": "-- Note that we have to regenerate the reconciler_changesets view, as the SELECT\n-- c.* in the view definition isn't refreshed when the fields change within the\n-- changesets table.\nDROP VIEW IF EXISTS\n    reconciler_changesets;\n\nALTER TABLE changesets DROP COLUMN IF EXISTS worker_hostname;\n\nCREATE VIEW reconciler_changesets AS\n    SELECT c.* FROM changesets c\n    INNER JOIN repo r on r.id = c.repo_id\n    WHERE\n        r.deleted_at IS NULL AND\n        EXISTS (\n            SELECT 1 FROM batch_changes\n            LEFT JOIN users namespace_user ON batch_changes.namespace_user_id = namespace_user.id\n            LEFT JOIN orgs namespace_org ON batch_changes.namespace_org_id = namespace_org.id\n            WHERE\n                c.batch_change_ids ? batch_changes.id::text AND\n                namespace_user.deleted_at IS NULL AND\n                namespace_org.deleted_at IS NULL\n        )\n;\n\nALTER TABLE changeset_jobs DROP COLUMN IF EXISTS worker_hostname;\nALTER TABLE cm_action_jobs DROP COLUMN IF EXISTS worker_hostname;\nALTER TABLE cm_trigger_jobs DROP COLUMN IF EXISTS worker_hostname;\nALTER TABLE external_service_sync_jobs DROP COLUMN IF EXISTS worker_hostname;\nALTER TABLE insights_query_runner_jobs DROP COLUMN IF EXISTS worker_hostname;\nALTER TABLE lsif_dependency_indexing_jobs DROP COLUMN IF EXISTS worker_hostname;\nALTER TABLE lsif_indexes DROP COLUMN IF EXISTS worker_hostname;\nALTER TABLE lsif_uploads DROP COLUMN IF EXISTS worker_hostname;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395835
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395837,
				"Name": "mark unmigrated credentials",
				"UpQuery": "-- Previously, we conflated unmigrated user and site credentials with\n-- unencrypted ones. Instead, we should separate these states with a placeholder\n-- so the out of band migration responsible for encrypting credentials reports\n-- its progress correctly.\n\nUPDATE\n    user_credentials\nSET\n    encryption_key_id = 'unmigrated'\nWHERE\n    encryption_key_id = '';\n\nUPDATE\n    batch_changes_site_credentials\nSET\n    encryption_key_id = 'unmigrated'\nWHERE\n    encryption_key_id = '';",
				"DownQuery": "UPDATE\n    user_credentials\nSET\n    encryption_key_id = ''\nWHERE\n    encryption_key_id = 'unmigrated';\n\nUPDATE\n    batch_changes_site_credentials\nSET\n    encryption_key_id = ''\nWHERE\n    encryption_key_id = 'unmigrated';",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395836
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395838,
				"Name": "add blocked column to repo table",
				"UpQuery": "ALTER TABLE IF EXISTS repo ADD COLUMN blocked jsonb;\n\nCREATE OR REPLACE FUNCTION repo_block(reason text, at timestamptz) RETURNS jsonb AS\n$$\nSELECT jsonb_build_object(\n    'reason', reason,\n    'at', extract(epoch from timezone('utc', at))::bigint\n);\n$$ LANGUAGE SQL STRICT IMMUTABLE;\n\nCREATE INDEX repo_blocked_idx ON repo USING BTREE ((blocked IS NOT NULL));\nCREATE INDEX repo_is_not_blocked_idx ON repo USING BTREE ((blocked IS NULL));",
				"DownQuery": "DROP INDEX IF EXISTS repo_is_blocked_idx;\nDROP INDEX IF EXISTS repo_is_not_blocked_idx;\n\nDROP FUNCTION IF EXISTS repo_block;\n\nALTER TABLE IF EXISTS repo DROP COLUMN IF EXISTS blocked;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395837
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395839,
				"Name": "ui publish state",
				"UpQuery": "CREATE TYPE\n    batch_changes_changeset_ui_publication_state\nAS ENUM (\n    'UNPUBLISHED',\n    'DRAFT',\n    'PUBLISHED'\n);\n\n-- Note that we have to regenerate the reconciler_changesets view, as the SELECT\n-- c.* in the view definition isn't refreshed when the fields change within the\n-- changesets table.\nDROP VIEW IF EXISTS\n    reconciler_changesets;\n\nALTER TABLE\n    changesets\nADD COLUMN IF NOT EXISTS\n    ui_publication_state batch_changes_changeset_ui_publication_state NULL DEFAULT NULL;\n\nCREATE VIEW reconciler_changesets AS\n    SELECT c.* FROM changesets c\n    INNER JOIN repo r on r.id = c.repo_id\n    WHERE\n        r.deleted_at IS NULL AND\n        EXISTS (\n            SELECT 1 FROM batch_changes\n            LEFT JOIN users namespace_user ON batch_changes.namespace_user_id = namespace_user.id\n            LEFT JOIN orgs namespace_org ON batch_changes.namespace_org_id = namespace_org.id\n            WHERE\n                c.batch_change_ids ? batch_changes.id::text AND\n                namespace_user.deleted_at IS NULL AND\n                namespace_org.deleted_at IS NULL\n        )\n;",
				"DownQuery": "-- Note that we have to regenerate the reconciler_changesets view, as the SELECT\n-- c.* in the view definition isn't refreshed when the fields change within the\n-- changesets table.\nDROP VIEW IF EXISTS\n    reconciler_changesets;\n\nALTER TABLE\n    changesets\nDROP COLUMN IF EXISTS\n    ui_publication_state;\n\nDROP TYPE IF EXISTS\n    batch_changes_changeset_ui_publication_state;\n\nCREATE VIEW reconciler_changesets AS\n    SELECT c.* FROM changesets c\n    INNER JOIN repo r on r.id = c.repo_id\n    WHERE\n        r.deleted_at IS NULL AND\n        EXISTS (\n            SELECT 1 FROM batch_changes\n            LEFT JOIN users namespace_user ON batch_changes.namespace_user_id = namespace_user.id\n            LEFT JOIN orgs namespace_org ON batch_changes.namespace_org_id = namespace_org.id\n            WHERE\n                c.batch_change_ids ? batch_changes.id::text AND\n                namespace_user.deleted_at IS NULL AND\n                namespace_org.deleted_at IS NULL\n        )\n;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395838
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395840,
				"Name": "create sg service role",
				"UpQuery": "-- We encountered performance issues for our use cases when we deployed\n-- RLS to production. We made the decision to back that approach out and\n-- solve the security concerns in application-level code instead.\n--\n-- ref migrations/frontend/1528395860_remove_repo_table_policy.up.sql\n-- ref migrations/frontend/1528395861_remove_sg_service_grants.up.sql\n-- ref migrations/frontend/1528395862_remove_sg_service_role.up.sql",
				"DownQuery": "-- We encountered performance issues for our use cases when we deployed\n-- RLS to production. We made the decision to back that approach out and\n-- solve the security concerns in application-level code instead.\n--\n-- ref migrations/frontend/1528395860_remove_repo_table_policy.up.sql\n-- ref migrations/frontend/1528395861_remove_sg_service_grants.up.sql\n-- ref migrations/frontend/1528395862_remove_sg_service_role.up.sql",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395839
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395841,
				"Name": "add repo table policy",
				"UpQuery": "-- We encountered performance issues for our use cases when we deployed\n-- RLS to production. We made the decision to back that approach out and\n-- solve the security concerns in application-level code instead.\n--\n-- ref migrations/frontend/1528395860_remove_repo_table_policy.up.sql\n-- ref migrations/frontend/1528395861_remove_sg_service_grants.up.sql\n-- ref migrations/frontend/1528395862_remove_sg_service_role.up.sql",
				"DownQuery": "-- We encountered performance issues for our use cases when we deployed\n-- RLS to production. We made the decision to back that approach out and\n-- solve the security concerns in application-level code instead.\n--\n-- ref migrations/frontend/1528395860_remove_repo_table_policy.up.sql\n-- ref migrations/frontend/1528395861_remove_sg_service_grants.up.sql\n-- ref migrations/frontend/1528395862_remove_sg_service_role.up.sql",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395840
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395842,
				"Name": "add settings user id index",
				"UpQuery": "CREATE INDEX IF NOT EXISTS settings_user_id_idx ON settings USING BTREE (user_id);",
				"DownQuery": "DROP INDEX IF EXISTS settings_user_id_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395841
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395843,
				"Name": "batch spec executions table",
				"UpQuery": "CREATE TABLE IF NOT EXISTS batch_spec_executions (\n  id              BIGSERIAL PRIMARY KEY,\n  state           TEXT DEFAULT 'queued',\n  failure_message TEXT,\n  started_at      TIMESTAMP WITH TIME ZONE,\n  finished_at     TIMESTAMP WITH TIME ZONE,\n  process_after   TIMESTAMP WITH TIME ZONE,\n  num_resets      INTEGER NOT NULL DEFAULT 0,\n  num_failures    INTEGER NOT NULL DEFAULT 0,\n  execution_logs  JSON[],\n  worker_hostname TEXT NOT NULL DEFAULT '',\n\n  created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n  updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n\n  batch_spec TEXT NOT NULL,\n  batch_spec_id integer REFERENCES batch_specs(id)\n);",
				"DownQuery": "DROP TABLE IF EXISTS batch_spec_executions;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395842
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395844,
				"Name": "add user id to bach spec executions",
				"UpQuery": "ALTER TABLE IF EXISTS batch_spec_executions ADD COLUMN IF NOT EXISTS user_id int REFERENCES users(id) DEFERRABLE;",
				"DownQuery": "ALTER TABLE IF EXISTS batch_spec_executions DROP COLUMN IF EXISTS user_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395843
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395845,
				"Name": "batch spec execution namespace",
				"UpQuery": "ALTER TABLE IF EXISTS batch_spec_executions ADD COLUMN IF NOT EXISTS namespace_user_id integer REFERENCES users(id) DEFERRABLE;\nALTER TABLE IF EXISTS batch_spec_executions ADD COLUMN IF NOT EXISTS namespace_org_id integer REFERENCES orgs(id) DEFERRABLE;\nUPDATE batch_spec_executions SET namespace_user_id = user_id;\nALTER TABLE IF EXISTS batch_spec_executions ADD CONSTRAINT batch_spec_executions_has_1_namespace CHECK ((namespace_user_id IS NULL) \u003c\u003e (namespace_org_id IS NULL));",
				"DownQuery": "ALTER TABLE IF EXISTS batch_spec_executions DROP CONSTRAINT batch_spec_executions_has_1_namespace;\nALTER TABLE IF EXISTS batch_spec_executions DROP COLUMN IF EXISTS namespace_user_id;\nALTER TABLE IF EXISTS batch_spec_executions DROP COLUMN IF EXISTS namespace_org_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395844
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395846,
				"Name": "expand visible lsif uploads",
				"UpQuery": "ALTER TABLE lsif_uploads_visible_at_tip ADD COLUMN branch_or_tag_name text NOT NULL DEFAULT '';\nALTER TABLE lsif_uploads_visible_at_tip ADD COLUMN is_default_branch boolean NOT NULL DEFAULT false;\n\nCOMMENT ON COLUMN lsif_uploads_visible_at_tip.upload_id IS 'The identifier of the upload visible from the tip of the specified branch or tag.';\nCOMMENT ON COLUMN lsif_uploads_visible_at_tip.branch_or_tag_name IS 'The name of the branch or tag.';\nCOMMENT ON COLUMN lsif_uploads_visible_at_tip.is_default_branch IS  'Whether the specified branch is the default of the repository. Always false for tags.';\n\n-- Update all existing visible uploads to be the default branch, which is true until\n-- we start recalcaulting the commit graph with tags and non-default branches.\nUPDATE lsif_uploads_visible_at_tip SET is_default_branch = true;\n\n-- Mark every graph as dirty so we recalculate retention correctly once the instance\n-- boots up.\nUPDATE lsif_dirty_repositories SET dirty_token = dirty_token + 1;",
				"DownQuery": "ALTER TABLE lsif_uploads_visible_at_tip DROP COLUMN branch_or_tag_name;\nALTER TABLE lsif_uploads_visible_at_tip DROP COLUMN is_default_branch;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395845
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395847,
				"Name": "codeintel eviction ages",
				"UpQuery": "CREATE TABLE lsif_retention_configuration (\n    id serial PRIMARY KEY,\n    repository_id integer UNIQUE NOT NULL REFERENCES repo(id) ON DELETE CASCADE,\n    max_age_for_non_stale_branches_seconds integer NOT NULL,\n    max_age_for_non_stale_tags_seconds integer NOT NULL\n);\n\nCOMMENT ON TABLE lsif_retention_configuration IS 'Stores the retention policy of code intellience data for a repository.';\nCOMMENT ON COLUMN lsif_retention_configuration.max_age_for_non_stale_branches_seconds IS 'The number of seconds since the last modification of a branch until it is considered stale.';\nCOMMENT ON COLUMN lsif_retention_configuration.max_age_for_non_stale_tags_seconds IS 'The nujmber of seconds since the commit date of a tagged commit until it is considered stale.';",
				"DownQuery": "DROP TABLE lsif_retention_configuration;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395846
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395848,
				"Name": "drop default repos",
				"UpQuery": "DROP TABLE IF EXISTS default_repos;",
				"DownQuery": "CREATE TABLE default_repos (\n    repo_id integer NOT NULL\n);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395847
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395849,
				"Name": "drop unused indexes",
				"UpQuery": "-- Covered by external_service_repos_idx (external_service_id, repo_id)\nDROP INDEX IF EXISTS external_service_repos_external_service_id;",
				"DownQuery": "CREATE INDEX external_service_repos_external_service_id ON external_service_repos USING btree (external_service_id);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395848
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395850,
				"Name": "add rand id to batch spec executions",
				"UpQuery": "ALTER TABLE IF EXISTS batch_spec_executions ADD COLUMN IF NOT EXISTS rand_id text NOT NULL;\n\nCREATE INDEX batch_spec_executions_rand_id ON batch_spec_executions USING btree (rand_id);",
				"DownQuery": "DROP INDEX IF EXISTS batch_spec_executions_rand_id;\n\nALTER TABLE IF EXISTS batch_spec_executions DROP COLUMN IF EXISTS rand_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395849
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395851,
				"Name": "workerutil last updated at",
				"UpQuery": "ALTER TABLE batch_spec_executions ADD COLUMN last_heartbeat_at timestamp with time zone;\nALTER TABLE changeset_jobs ADD COLUMN last_heartbeat_at timestamp with time zone;\nALTER TABLE changesets ADD COLUMN last_heartbeat_at timestamp with time zone;\nALTER TABLE cm_action_jobs ADD COLUMN last_heartbeat_at timestamp with time zone;\nALTER TABLE cm_trigger_jobs ADD COLUMN last_heartbeat_at timestamp with time zone;\nALTER TABLE external_service_sync_jobs ADD COLUMN last_heartbeat_at timestamp with time zone;\nALTER TABLE insights_query_runner_jobs ADD COLUMN last_heartbeat_at timestamp with time zone;\nALTER TABLE lsif_dependency_indexing_jobs ADD COLUMN last_heartbeat_at timestamp with time zone;\nALTER TABLE lsif_indexes ADD COLUMN last_heartbeat_at timestamp with time zone;\nALTER TABLE lsif_uploads ADD COLUMN last_heartbeat_at timestamp with time zone;",
				"DownQuery": "ALTER TABLE batch_spec_executions DROP COLUMN last_heartbeat_at;\nALTER TABLE changeset_jobs DROP COLUMN last_heartbeat_at;\nALTER TABLE changesets DROP COLUMN last_heartbeat_at;\nALTER TABLE cm_action_jobs DROP COLUMN last_heartbeat_at;\nALTER TABLE cm_trigger_jobs DROP COLUMN last_heartbeat_at;\nALTER TABLE external_service_sync_jobs DROP COLUMN last_heartbeat_at;\nALTER TABLE insights_query_runner_jobs DROP COLUMN last_heartbeat_at;\nALTER TABLE lsif_dependency_indexing_jobs DROP COLUMN last_heartbeat_at;\nALTER TABLE lsif_indexes DROP COLUMN last_heartbeat_at;\nALTER TABLE lsif_uploads DROP COLUMN last_heartbeat_at;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395850
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395852,
				"Name": "lsif add covering index",
				"UpQuery": "CREATE INDEX lsif_packages_scheme_name_version_dump_id ON lsif_packages(scheme, name, version, dump_id);\nDROP INDEX lsif_packages_scheme_name_version;\n\nCREATE INDEX lsif_references_scheme_name_version_dump_id ON lsif_references(scheme, name, version, dump_id);\nDROP INDEX lsif_references_package;",
				"DownQuery": "CREATE INDEX lsif_packages_scheme_name_version ON lsif_packages(scheme, name, version);\nDROP INDEX lsif_packages_scheme_name_version_dump_id;\n\nCREATE INDEX lsif_references_package ON lsif_references(scheme, name, version);\nDROP INDEX lsif_references_scheme_name_version_dump_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395851
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395853,
				"Name": "add deleting state",
				"UpQuery": "DROP VIEW lsif_dumps_with_repository_name;\nDROP VIEW lsif_dumps;\n\nCREATE VIEW lsif_dumps AS SELECT u.id,\n    u.commit,\n    u.root,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.finished_at AS processed_at\nFROM lsif_uploads u\nWHERE u.state = 'completed'::text OR u.state = 'deleting';\n\nCREATE VIEW lsif_dumps_with_repository_name AS SELECT u.id,\n    u.commit,\n    u.root,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.processed_at,\n    r.name AS repository_name\nFROM lsif_dumps u\nJOIN repo r ON r.id = u.repository_id\nWHERE r.deleted_at IS NULL;",
				"DownQuery": "DROP VIEW lsif_dumps_with_repository_name;\nDROP VIEW lsif_dumps;\n\nCREATE VIEW lsif_dumps AS SELECT u.id,\n    u.commit,\n    u.root,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.finished_at AS processed_at\nFROM lsif_uploads u WHERE u.state = 'completed'::text;\n\nCREATE VIEW lsif_dumps_with_repository_name AS SELECT u.id,\n    u.commit,\n    u.root,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.processed_at,\n    r.name AS repository_name\nFROM lsif_dumps u JOIN repo r ON r.id = u.repository_id WHERE r.deleted_at IS NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395852
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395854,
				"Name": "add priority insights queryrunner",
				"UpQuery": "ALTER TABLE insights_query_runner_jobs\n    ADD COLUMN priority INT NOT NULL DEFAULT 1;\n\nALTER TABLE insights_query_runner_jobs\n    ADD COLUMN cost INT NOT NULL DEFAULT 500;\n\nCOMMENT ON COLUMN insights_query_runner_jobs.priority IS 'Integer representing a category of priority for this query. Priority in this context is ambiguously defined for consumers to decide an interpretation.';\nCOMMENT ON COLUMN insights_query_runner_jobs.cost IS 'Integer representing a cost approximation of executing this search query.';\n\nCREATE INDEX insights_query_runner_jobs_priority_idx on insights_query_runner_jobs(priority);\nCREATE INDEX insights_query_runner_jobs_cost_idx on insights_query_runner_jobs(cost);",
				"DownQuery": "ALTER TABLE insights_query_runner_jobs\n    DROP COLUMN priority;\n\nALTER TABLE insights_query_runner_jobs\n    DROP COLUMN cost;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395853
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395855,
				"Name": "add-missing-execution-logs-cols",
				"UpQuery": "ALTER TABLE IF EXISTS cm_trigger_jobs ADD COLUMN IF NOT EXISTS execution_logs JSON[];\nALTER TABLE IF EXISTS cm_action_jobs  ADD COLUMN IF NOT EXISTS execution_logs JSON[];",
				"DownQuery": "ALTER TABLE IF EXISTS cm_trigger_jobs DROP COLUMN IF EXISTS execution_logs;\nALTER TABLE IF EXISTS cm_action_jobs  DROP COLUMN IF EXISTS execution_logs;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395854
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395856,
				"Name": "add missing execution logs cols for real",
				"UpQuery": "ALTER TABLE IF EXISTS lsif_uploads ADD COLUMN IF NOT EXISTS execution_logs JSON[];",
				"DownQuery": "ALTER TABLE IF EXISTS lsif_uploads DROP COLUMN IF EXISTS execution_logs;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395855
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395857,
				"Name": "last fetched",
				"UpQuery": "ALTER TABLE gitserver_repos ADD COLUMN last_fetched TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT now();",
				"DownQuery": "ALTER TABLE gitserver_repos DROP COLUMN last_fetched;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395856
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395858,
				"Name": "drop lsif indexable repositories",
				"UpQuery": "DROP TABLE IF EXISTS lsif_indexable_repositories;",
				"DownQuery": "CREATE TABLE lsif_indexable_repositories (\n    id SERIAL PRIMARY KEY NOT NULL,\n    repository_id integer NOT NULL,\n    search_count integer DEFAULT 0 NOT NULL,\n    precise_count integer DEFAULT 0 NOT NULL,\n    last_index_enqueued_at timestamp with time zone,\n    last_updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    enabled boolean\n);\n\nCREATE UNIQUE INDEX lsif_indexable_repositories_repository_id_key ON lsif_indexable_repositories (repository_id);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395857
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395859,
				"Name": "make batch spec executions batch spec id deferrable",
				"UpQuery": "ALTER TABLE IF EXISTS batch_spec_executions ALTER CONSTRAINT batch_spec_executions_batch_spec_id_fkey DEFERRABLE;",
				"DownQuery": "ALTER TABLE IF EXISTS batch_spec_executions ALTER CONSTRAINT batch_spec_executions_batch_spec_id_fkey NOT DEFERRABLE;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395858
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395860,
				"Name": "remove repo table policy",
				"UpQuery": "-- This removes the row-level security policy (if present), and disables RLS on\n-- the repo table. Both operations are idempotent.\nDROP POLICY IF EXISTS sg_repo_access_policy ON repo;\nALTER TABLE repo DISABLE ROW LEVEL SECURITY;",
				"DownQuery": "-- We do not recreate the policy, as we've shifted our strategy away from row-\n-- level security to application-level code. Prior migrations that created the\n-- policy have also been removed.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395859
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395861,
				"Name": "remove sg service grants",
				"UpQuery": "DO $$\nBEGIN\n    REVOKE ALL PRIVILEGES ON ALL SEQUENCES IN SCHEMA public FROM sg_service;\n    REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA public FROM sg_service;\n    REVOKE USAGE ON SCHEMA public FROM sg_service;\nEXCEPTION WHEN undefined_object THEN\n    -- Roles are visible across databases within a server, and we use templated\n    -- databases for test parallelism, so it's possible in some cases for the\n    -- tests to hit a case where the role can't be dropped because one of the\n    -- test databases still has objects that depend on it.\nEND;\n$$;",
				"DownQuery": "-- We do not recreate the grants, as we've shifted our strategy away from row-\n-- level security to application-level code. Prior migrations that created the\n-- grants have also been removed.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395860
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395862,
				"Name": "remove sg service role",
				"UpQuery": "DO $$\nBEGIN\n    DROP ROLE IF EXISTS sg_service;\nEXCEPTION WHEN dependent_objects_still_exist THEN\n    -- Roles are visible across databases within a server, and we use templated\n    -- databases for test parallelism, so it's possible in some cases for the\n    -- tests to hit a case where the role can't be dropped because one of the\n    -- test databases still has objects that depend on it.\nEND;\n$$;",
				"DownQuery": "-- We do not recreate the role, as we've shifted our strategy away from row-\n-- level security to application-level code. Prior migrations that created the\n-- role have also been removed.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395861
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395863,
				"Name": "event logs public properties column",
				"UpQuery": "ALTER TABLE IF EXISTS event_logs ADD COLUMN IF NOT EXISTS public_argument JSONB DEFAULT '{}'::jsonb NOT NULL;",
				"DownQuery": "ALTER TABLE IF EXISTS event_logs DROP COLUMN IF EXISTS public_argument;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395862
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395864,
				"Name": "create temporary settings",
				"UpQuery": "CREATE TABLE IF NOT EXISTS temporary_settings (\n    id serial NOT NULL PRIMARY KEY,\n    user_id integer NOT NULL UNIQUE,\n    contents jsonb,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n\n    FOREIGN KEY (user_id) REFERENCES users (id) ON DELETE CASCADE\n);\n\nCOMMENT ON TABLE temporary_settings IS 'Stores per-user temporary settings used in the UI, for example, which modals have been dimissed or what theme is preferred.';\nCOMMENT ON COLUMN temporary_settings.user_id IS 'The ID of the user the settings will be saved for.';\nCOMMENT ON COLUMN temporary_settings.contents IS 'JSON-encoded temporary settings.';",
				"DownQuery": "DROP TABLE IF EXISTS temporary_settings;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395863
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395865,
				"Name": "insights job dependencies",
				"UpQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nCREATE TABLE insights_query_runner_jobs_dependencies\n(\n    id             SERIAL    NOT NULL,\n    job_id         INT       NOT NULL,\n    recording_time TIMESTAMP NOT NULL,\n    PRIMARY KEY (id),\n    --  The delete cascade is intentional, these records only have meaning in context of the related job row.\n    CONSTRAINT insights_query_runner_jobs_dependencies_fk_job_id FOREIGN KEY (job_id) REFERENCES insights_query_runner_jobs (id) ON DELETE CASCADE\n);\n\nCOMMENT ON TABLE insights_query_runner_jobs_dependencies IS 'Stores data points for a code insight that do not need to be queried directly, but depend on the result of a query at a different point';\n\nCOMMENT ON COLUMN insights_query_runner_jobs_dependencies.job_id IS 'Foreign key to the job that owns this record.';\nCOMMENT ON COLUMN insights_query_runner_jobs_dependencies.recording_time IS 'The time for which this dependency should be recorded at using the parents value.';",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nDROP TABLE IF EXISTS insights_query_runner_jobs_dependencies;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395864
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395866,
				"Name": "insights queue reset",
				"UpQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\n-- This table is a queue of records that need processing for code insights. Historically this queue grows\n-- unbounded because the historical backfiller operated without state - every time it executed it would\n-- requeue all of the work again. Since then we have added enough state to the backfiller to remove this problem,\n-- but customer instances are going to be full of millions of records that will need processing before we can start\n-- fresh. To avoid this problem, we are going to ship a 'reset' in 3.31 that will clear this queue entirely.\n-- Note: This data is by design ephemeral, so there is no risk of permanent data loss here.\n\nTRUNCATE insights_query_runner_jobs CASCADE;",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395865
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395867,
				"Name": "batch-spec-executions-cancel",
				"UpQuery": "ALTER TABLE IF EXISTS batch_spec_executions ADD COLUMN IF NOT EXISTS cancel BOOL DEFAULT FALSE;",
				"DownQuery": "ALTER TABLE IF EXISTS batch_spec_executions DROP COLUMN IF EXISTS cancel;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395866
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395868,
				"Name": "insights queue dependencies index",
				"UpQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nCREATE INDEX insights_query_runner_jobs_dependencies_job_id_fk_idx ON insights_query_runner_jobs_dependencies(job_id);",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nDROP INDEX IF EXISTS insights_query_runner_jobs_dependencies_job_id_fk_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395867
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395869,
				"Name": "add lsif configuration policy",
				"UpQuery": "CREATE TABLE lsif_configuration_policies (\n    id SERIAL PRIMARY KEY,\n    repository_id int,\n    name text,\n    type text NOT NULL,\n    pattern text NOT NULL,\n    retention_enabled boolean NOT NULL,\n    retention_duration_hours int,\n    retain_intermediate_commits boolean NOT NULL,\n    indexing_enabled boolean NOT NULL,\n    index_commit_max_age_hours int,\n    index_intermediate_commits boolean NOT NULL\n);\n\nCREATE INDEX lsif_configuration_policies_repository_id ON lsif_configuration_policies(repository_id);\n\nCOMMENT ON COLUMN lsif_configuration_policies.repository_id IS 'The identifier of the repository to which this configuration policy applies. If absent, this policy is applied globally.';\nCOMMENT ON COLUMN lsif_configuration_policies.type IS 'The type of Git object (e.g., COMMIT, BRANCH, TAG).';\nCOMMENT ON COLUMN lsif_configuration_policies.pattern IS 'A pattern used to match` names of the associated Git object type.';\nCOMMENT ON COLUMN lsif_configuration_policies.retention_enabled IS 'Whether or not this configuration policy affects data retention rules.';\nCOMMENT ON COLUMN lsif_configuration_policies.retention_duration_hours IS 'The max age of data retained by this configuration policy. If null, the age is unbounded.';\nCOMMENT ON COLUMN lsif_configuration_policies.retain_intermediate_commits IS 'If the matching Git object is a branch, setting this value to true will also retain all data used to resolve queries for any commit on the matching branches. Setting this value to false will only consider the tip of the branch.';\nCOMMENT ON COLUMN lsif_configuration_policies.indexing_enabled IS 'Whether or not this configuration policy affects auto-indexing schedules.';\nCOMMENT ON COLUMN lsif_configuration_policies.index_commit_max_age_hours IS 'The max age of commits indexed by this configuration policy. If null, the age is unbounded.';\nCOMMENT ON COLUMN lsif_configuration_policies.index_intermediate_commits IS 'If the matching Git object is a branch, setting this value to true will also index all commits on the matching branches. Setting this value to false will only consider the tip of the branch.';",
				"DownQuery": "DROP TABLE IF EXISTS lsif_configuration_policies;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395868
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395870,
				"Name": "codeintel dependency repos",
				"UpQuery": "CREATE TABLE IF NOT EXISTS lsif_dependency_repos (\n    id bigserial NOT NULL PRIMARY KEY,\n    name text NOT NULL,\n    version text NOT NULL,\n    scheme text NOT NULL,\n    CONSTRAINT lsif_dependency_repos_unique_triplet\n        UNIQUE (scheme, name, version)\n);",
				"DownQuery": "DROP TABLE IF EXISTS lsif_dependency_repos;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395869
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395871,
				"Name": "insights queue state index",
				"UpQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\nCREATE INDEX IF NOT EXISTS insights_query_runner_jobs_processable_priority_id ON insights_query_runner_jobs (priority, id) WHERE state = 'queued' OR state = 'errored';",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\ndrop index if exists insights_query_runner_jobs_processable_priority_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395870
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395872,
				"Name": "lsif upload reference counts",
				"UpQuery": "ALTER TABLE lsif_uploads ADD COLUMN num_references int;\nCOMMENT ON COLUMN lsif_uploads.num_references IS 'The number of references to this upload data from other upload records (via lsif_references).';",
				"DownQuery": "ALTER TABLE lsif_uploads DROP COLUMN num_references;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395871
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395873,
				"Name": "lsif upload reference counts oob migration",
				"UpQuery": "INSERT INTO out_of_band_migrations (id, team, component, description, introduced_version_major, introduced_version_minor, non_destructive)\nVALUES (11, 'code-intelligence', 'lsif_uploads.num_references', 'Backfill LSIF upload reference counts', 3, 22, true)\nON CONFLICT DO NOTHING;",
				"DownQuery": "-- Do not remove oob migration when downgrading",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395872
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395874,
				"Name": "lsif nearest uploads indexes",
				"UpQuery": "-- Allow for lookup from upload id to commits that the upload can resolve queries for.\nCREATE INDEX lsif_nearest_uploads_uploads ON lsif_nearest_uploads USING GIN(uploads);\n\n-- Allow for lookup from commit to the set of commits that have analogous nearest uploads.\nCREATE INDEX lsif_nearest_uploads_links_repository_id_ancestor_commit_bytea ON lsif_nearest_uploads_links(repository_id, ancestor_commit_bytea);",
				"DownQuery": "DROP INDEX lsif_nearest_uploads_uploads;\nDROP INDEX lsif_nearest_uploads_links_repository_id_ancestor_commit_bytea;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395873
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395875,
				"Name": "lsif upload expired flag",
				"UpQuery": "-- Drop dependent views\nDROP VIEW lsif_dumps_with_repository_name;\nDROP VIEW lsif_dumps;\nDROP VIEW lsif_uploads_with_repository_name;\n\n-- Add new column\nALTER TABLE lsif_uploads ADD COLUMN expired boolean not null default false;\nCOMMENT ON COLUMN lsif_uploads.expired IS 'Whether or not this upload data is no longer protected by any data retention policy.';\n\n-- Update view definitions to include new fields\nCREATE VIEW lsif_uploads_with_repository_name AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.expired,\n        r.name AS repository_name\n    FROM lsif_uploads u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_dumps AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.expired,\n        u.finished_at AS processed_at\n    FROM lsif_uploads u\n    WHERE u.state = 'completed'::text OR u.state = 'deleting'::text;\n\nCREATE VIEW lsif_dumps_with_repository_name AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.expired,\n        u.processed_at,\n        r.name AS repository_name\n    FROM lsif_dumps u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;",
				"DownQuery": "-- Drop dependent views\nDROP VIEW lsif_dumps_with_repository_name;\nDROP VIEW lsif_dumps;\nDROP VIEW lsif_uploads_with_repository_name;\n\n-- Drop new column\nALTER TABLE lsif_uploads DROP COLUMN expired;\n\n-- Restore old views\nCREATE VIEW lsif_uploads_with_repository_name AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        r.name AS repository_name\n    FROM lsif_uploads u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_dumps AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.finished_at AS processed_at\n    FROM lsif_uploads u\n    WHERE u.state = 'completed'::text OR u.state = 'deleting'::text;\n\nCREATE VIEW lsif_dumps_with_repository_name AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.processed_at,\n        r.name AS repository_name\n    FROM lsif_dumps u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395874
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395876,
				"Name": "lsif last retention scan",
				"UpQuery": "-- Drop dependent views\nDROP VIEW lsif_dumps_with_repository_name;\nDROP VIEW lsif_dumps;\nDROP VIEW lsif_uploads_with_repository_name;\n\n-- Create table to rate limit data retention scans of a repository\nCREATE TABLE lsif_last_retention_scan (\n    repository_id int NOT NULL,\n    last_retention_scan_at timestamp with time zone NOT NULL,\n\n    PRIMARY KEY(repository_id)\n);\nCOMMENT ON TABLE lsif_last_retention_scan IS 'Tracks the last time uploads a repository were checked against data retention policies.';\nCOMMENT ON COLUMN lsif_last_retention_scan.last_retention_scan_at IS 'The last time uploads of this repository were checked against data retention policies.';\n\n-- Add column to rate limit scanning of individual upload records\nALTER TABLE lsif_uploads ADD COLUMN last_retention_scan_at timestamp with time zone;\nCOMMENT ON COLUMN lsif_uploads.last_retention_scan_at IS 'The last time this upload was checked against data retention policies.';\n\n-- Update view definitions to include new fields\nCREATE VIEW lsif_uploads_with_repository_name AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.expired,\n        r.name AS repository_name\n    FROM lsif_uploads u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_dumps AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.expired,\n        u.finished_at AS processed_at\n    FROM lsif_uploads u\n    WHERE u.state = 'completed'::text OR u.state = 'deleting'::text;\n\nCREATE VIEW lsif_dumps_with_repository_name AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.expired,\n        u.processed_at,\n        r.name AS repository_name\n    FROM lsif_dumps u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;",
				"DownQuery": "-- Drop dependent views\nDROP VIEW lsif_dumps_with_repository_name;\nDROP VIEW lsif_dumps;\nDROP VIEW lsif_uploads_with_repository_name;\n\n-- Drop new column and table\nALTER TABLE lsif_uploads DROP COLUMN last_retention_scan_at;\nDROP TABLE lsif_last_retention_scan;\n\n-- Restore old views\nCREATE VIEW lsif_uploads_with_repository_name AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        r.name AS repository_name\n    FROM lsif_uploads u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_dumps AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.finished_at AS processed_at\n    FROM lsif_uploads u\n    WHERE u.state = 'completed'::text OR u.state = 'deleting'::text;\n\nCREATE VIEW lsif_dumps_with_repository_name AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.processed_at,\n        r.name AS repository_name\n    FROM lsif_dumps u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395875
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395877,
				"Name": "index-lsif-uploads-repo",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS lsif_uploads_repository_id ON lsif_uploads (repository_id);",
				"DownQuery": "DROP INDEX IF EXISTS lsif_uploads_repository_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395876
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "lsif_uploads",
					"IndexName": "lsif_uploads_repository_id"
				}
			},
			{
				"ID": 1528395878,
				"Name": "index-lsif-indexes-repo",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS lsif_indexes_repository_id_commit ON lsif_indexes (repository_id, commit);",
				"DownQuery": "DROP INDEX IF EXISTS lsif_indexes_repository_id_commit;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395877
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "lsif_indexes",
					"IndexName": "lsif_indexes_repository_id_commit"
				}
			},
			{
				"ID": 1528395879,
				"Name": "repair lsif configuration policies",
				"UpQuery": "DROP TABLE lsif_configuration_policies;\n\nCREATE TABLE lsif_configuration_policies (\n    id SERIAL PRIMARY KEY,\n    repository_id int,\n    name text,\n    type text NOT NULL,\n    pattern text NOT NULL,\n    retention_enabled boolean NOT NULL,\n    retention_duration_hours int,\n    retain_intermediate_commits boolean NOT NULL,\n    indexing_enabled boolean NOT NULL,\n    index_commit_max_age_hours int,\n    index_intermediate_commits boolean NOT NULL\n);\n\nCREATE INDEX lsif_configuration_policies_repository_id ON lsif_configuration_policies(repository_id);\n\nCOMMENT ON COLUMN lsif_configuration_policies.repository_id IS 'The identifier of the repository to which this configuration policy applies. If absent, this policy is applied globally.';\nCOMMENT ON COLUMN lsif_configuration_policies.type IS 'The type of Git object (e.g., COMMIT, BRANCH, TAG).';\nCOMMENT ON COLUMN lsif_configuration_policies.pattern IS 'A pattern used to match` names of the associated Git object type.';\nCOMMENT ON COLUMN lsif_configuration_policies.retention_enabled IS 'Whether or not this configuration policy affects data retention rules.';\nCOMMENT ON COLUMN lsif_configuration_policies.retention_duration_hours IS 'The max age of data retained by this configuration policy. If null, the age is unbounded.';\nCOMMENT ON COLUMN lsif_configuration_policies.retain_intermediate_commits IS 'If the matching Git object is a branch, setting this value to true will also retain all data used to resolve queries for any commit on the matching branches. Setting this value to false will only consider the tip of the branch.';\nCOMMENT ON COLUMN lsif_configuration_policies.indexing_enabled IS 'Whether or not this configuration policy affects auto-indexing schedules.';\nCOMMENT ON COLUMN lsif_configuration_policies.index_commit_max_age_hours IS 'The max age of commits indexed by this configuration policy. If null, the age is unbounded.';\nCOMMENT ON COLUMN lsif_configuration_policies.index_intermediate_commits IS 'If the matching Git object is a branch, setting this value to true will also index all commits on the matching branches. Setting this value to false will only consider the tip of the branch.';",
				"DownQuery": "-- Nothing on down",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395878
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395880,
				"Name": "insights queue persist mode",
				"UpQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nCREATE TYPE PersistMode AS ENUM ('record', 'snapshot');\n\nALTER TABLE insights_query_runner_jobs\n    ADD persist_mode PersistMode DEFAULT 'record' NOT NULL;\n\nCOMMENT ON COLUMN insights_query_runner_jobs.persist_mode IS 'The persistence level for this query. This value will determine the lifecycle of the resulting value.';",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nALTER TABLE insights_query_runner_jobs\n    DROP COLUMN persist_mode;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395879
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395881,
				"Name": "add batch spec workspaces",
				"UpQuery": "CREATE TABLE IF NOT EXISTS batch_spec_resolution_jobs (\n  id              BIGSERIAL PRIMARY KEY,\n\n  batch_spec_id     INTEGER REFERENCES batch_specs(id) ON DELETE CASCADE DEFERRABLE,\n  allow_unsupported BOOLEAN NOT NULL DEFAULT FALSE,\n  allow_ignored     BOOLEAN NOT NULL DEFAULT FALSE,\n\n  state             TEXT DEFAULT 'queued',\n  failure_message   TEXT,\n  started_at        TIMESTAMP WITH TIME ZONE,\n  finished_at       TIMESTAMP WITH TIME ZONE,\n  process_after     TIMESTAMP WITH TIME ZONE,\n  num_resets        INTEGER NOT NULL DEFAULT 0,\n  num_failures      INTEGER NOT NULL DEFAULT 0,\n  execution_logs    JSON[],\n  worker_hostname   TEXT NOT NULL DEFAULT '',\n  last_heartbeat_at TIMESTAMP WITH TIME ZONE,\n\n  created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n  updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()\n);\n\nCREATE TABLE IF NOT EXISTS batch_spec_workspaces (\n  id              BIGSERIAL PRIMARY KEY,\n\n  batch_spec_id      INTEGER REFERENCES batch_specs(id) ON DELETE CASCADE DEFERRABLE,\n  changeset_spec_ids JSONB DEFAULT '{}'::jsonb,\n\n  repo_id integer      REFERENCES repo(id) DEFERRABLE,\n  branch               TEXT NOT NULL,\n  commit               TEXT NOT NULL,\n  path                 TEXT NOT NULL,\n  file_matches         TEXT[] NOT NULL,\n  only_fetch_workspace BOOLEAN NOT NULL DEFAULT FALSE,\n  steps                JSONB DEFAULT '[]'::jsonb CHECK (jsonb_typeof(steps) = 'array'),\n\n  created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n  updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()\n);\n\nCREATE TABLE IF NOT EXISTS batch_spec_workspace_execution_jobs (\n  id              BIGSERIAL PRIMARY KEY,\n\n  batch_spec_workspace_id  INTEGER REFERENCES batch_spec_workspaces(id) ON DELETE CASCADE DEFERRABLE,\n\n  state             TEXT DEFAULT 'queued',\n  failure_message   TEXT,\n  started_at        TIMESTAMP WITH TIME ZONE,\n  finished_at       TIMESTAMP WITH TIME ZONE,\n  process_after     TIMESTAMP WITH TIME ZONE,\n  num_resets        INTEGER NOT NULL DEFAULT 0,\n  num_failures      INTEGER NOT NULL DEFAULT 0,\n  execution_logs    JSON[],\n  worker_hostname   TEXT NOT NULL DEFAULT '',\n  last_heartbeat_at TIMESTAMP WITH TIME ZONE,\n\n  created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n  updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()\n);",
				"DownQuery": "DROP TABLE IF EXISTS batch_spec_workspace_execution_jobs;\nDROP TABLE IF EXISTS batch_spec_workspaces;\nDROP TABLE IF EXISTS batch_spec_resolution_jobs;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395880
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395882,
				"Name": "lsif configuration protected policies",
				"UpQuery": "ALTER TABLE lsif_configuration_policies ADD COLUMN protected boolean DEFAULT false;\nUPDATE lsif_configuration_policies SET protected = false;\nALTER TABLE lsif_configuration_policies ALTER COLUMN protected SET NOT NULL;\n\nCOMMENT ON COLUMN lsif_configuration_policies.protected IS 'Whether or not this configuration policy is protected from modification of its data retention behavior (except for duration).';",
				"DownQuery": "ALTER TABLE lsif_configuration_policies DROP COLUMN protected;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395881
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395883,
				"Name": "default lsif configuration policies",
				"UpQuery": "INSERT INTO lsif_configuration_policies\n    (\n        name,\n        protected, pattern, type,\n        retention_enabled, retain_intermediate_commits, retention_duration_hours,\n        indexing_enabled, index_intermediate_commits, index_commit_max_age_hours\n    )\nVALUES\n    (\n        'Default tip-of-branch retention policy',\n        true, '*', 'GIT_TREE',\n        true, false, 2016, -- 3 months ~= 2016 hours = 1 week (168 hours) * 4 * 3\n        false, false, 0\n    ), (\n        'Default tag retention policy',\n        true, '*', 'GIT_TAG',\n        true, false, 8064, -- 12 months ~= 8064 hours = 1 week (168 hours) * 4 * 12\n        false, false, 0\n    );",
				"DownQuery": "-- Nothing on down",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395882
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395884,
				"Name": "add cancel to batch spec workspace execution jobs",
				"UpQuery": "ALTER TABLE IF EXISTS batch_spec_workspace_execution_jobs\n  ADD COLUMN IF NOT EXISTS cancel boolean DEFAULT false NOT NULL;\n\nCREATE INDEX IF NOT EXISTS batch_spec_workspace_execution_jobs_cancel\n  ON batch_spec_workspace_execution_jobs (cancel);",
				"DownQuery": "DROP INDEX IF EXISTS batch_spec_workspace_execution_jobs_cancel;\n\nALTER TABLE IF EXISTS batch_spec_workspace_execution_jobs\n  DROP COLUMN IF EXISTS cancel;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395883
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395885,
				"Name": "lsif last retention scan views",
				"UpQuery": "DROP VIEW lsif_dumps_with_repository_name;\nDROP VIEW lsif_dumps;\nDROP VIEW lsif_uploads_with_repository_name;\n\nCREATE VIEW lsif_uploads_with_repository_name AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.expired,\n        u.last_retention_scan_at,\n        r.name AS repository_name\n    FROM lsif_uploads u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_dumps AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.expired,\n        u.last_retention_scan_at,\n        u.finished_at AS processed_at\n    FROM lsif_uploads u\n    WHERE u.state = 'completed'::text OR u.state = 'deleting'::text;\n\nCREATE VIEW lsif_dumps_with_repository_name AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.expired,\n        u.last_retention_scan_at,\n        u.processed_at,\n        r.name AS repository_name\n    FROM lsif_dumps u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;",
				"DownQuery": "DROP VIEW lsif_dumps_with_repository_name;\nDROP VIEW lsif_dumps;\nDROP VIEW lsif_uploads_with_repository_name;\n\nCREATE VIEW lsif_uploads_with_repository_name AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.expired,\n        r.name AS repository_name\n    FROM lsif_uploads u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_dumps AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.expired,\n        u.finished_at AS processed_at\n    FROM lsif_uploads u\n    WHERE u.state = 'completed'::text OR u.state = 'deleting'::text;\n\nCREATE VIEW lsif_dumps_with_repository_name AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.expired,\n        u.processed_at,\n        r.name AS repository_name\n    FROM lsif_dumps u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395884
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395886,
				"Name": "add missing fk indexes1",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS lsif_dependency_indexing_jobs_upload_id ON lsif_dependency_indexing_jobs(upload_id);",
				"DownQuery": "DROP INDEX IF EXISTS lsif_dependency_indexing_jobs_upload_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395885
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "lsif_dependency_indexing_jobs",
					"IndexName": "lsif_dependency_indexing_jobs_upload_id"
				}
			},
			{
				"ID": 1528395887,
				"Name": "add missing fk indexes2",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS lsif_packages_dump_id ON lsif_packages(dump_id);",
				"DownQuery": "DROP INDEX IF EXISTS lsif_packages_dump_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395886
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "lsif_packages",
					"IndexName": "lsif_packages_dump_id"
				}
			},
			{
				"ID": 1528395888,
				"Name": "add missing fk indexes3",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS lsif_references_dump_id ON lsif_references(dump_id);",
				"DownQuery": "DROP INDEX IF EXISTS lsif_references_dump_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395887
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "lsif_references",
					"IndexName": "lsif_references_dump_id"
				}
			},
			{
				"ID": 1528395889,
				"Name": "add metadata column to oobmigration",
				"UpQuery": "ALTER TABLE\n    out_of_band_migrations\nADD COLUMN IF NOT EXISTS\n    metadata jsonb NOT NULL DEFAULT '{}'::jsonb;",
				"DownQuery": "ALTER TABLE\n    out_of_band_migrations\nDROP COLUMN IF EXISTS metadata;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395888
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395890,
				"Name": "drop repo cloned",
				"UpQuery": "ALTER TABLE\n    repo\nDROP COLUMN IF EXISTS cloned;",
				"DownQuery": "-- This migration is destructive since the column has been\n-- deprecated since 3.26\nALTER TABLE\n    repo\nADD COLUMN IF NOT EXISTS\n    cloned bool NOT NULL DEFAULT false;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395889
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395891,
				"Name": "lsif dependency indexing queueing",
				"UpQuery": "ALTER TABLE lsif_dependency_indexing_jobs\nRENAME TO lsif_dependency_syncing_jobs;\n\nCREATE TABLE IF NOT EXISTS lsif_dependency_indexing_jobs (\n    id serial PRIMARY KEY,\n    state text DEFAULT 'queued' NOT NULL,\n    failure_message text,\n    queued_at timestamp with time zone DEFAULT NOW() NOT NULL,\n    started_at timestamp with time zone,\n    finished_at timestamp with time zone,\n    process_after timestamp with time zone,\n    num_resets integer DEFAULT 0 NOT NULL,\n    num_failures integer DEFAULT 0 NOT NULL,\n    execution_logs json[],\n    last_heartbeat_at timestamp with time zone,\n    worker_hostname text NOT NULL DEFAULT '',\n    upload_id integer REFERENCES lsif_uploads(id) ON DELETE CASCADE,\n    external_service_kind text NOT NULL DEFAULT '',\n    external_service_sync timestamp with time zone\n);\n\nCOMMENT ON COLUMN lsif_dependency_indexing_jobs.external_service_kind IS 'Filter the external services for this kind to wait to have synced. If empty, external_service_sync is ignored and no external services are polled for their last sync time.';\nCOMMENT ON COLUMN lsif_dependency_indexing_jobs.external_service_sync IS 'The sync time after which external services of the given kind will have synced/created any repositories referenced by the LSIF upload that are resolvable.';",
				"DownQuery": "DROP TABLE IF EXISTS lsif_dependency_indexing_jobs;\n\nALTER TABLE lsif_dependency_syncing_jobs\nRENAME TO lsif_dependency_indexing_jobs;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395890
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395892,
				"Name": "drop batch spec executions",
				"UpQuery": "DROP TABLE IF EXISTS batch_spec_executions;",
				"DownQuery": "CREATE TABLE IF NOT EXISTS batch_spec_executions (\n  id              BIGSERIAL PRIMARY KEY,\n  rand_id         TEXT NOT NULL,\n\n  state           TEXT DEFAULT 'queued',\n  failure_message TEXT,\n  process_after   TIMESTAMP WITH TIME ZONE,\n  started_at      TIMESTAMP WITH TIME ZONE,\n  finished_at     TIMESTAMP WITH TIME ZONE,\n  last_heartbeat_at TIMESTAMP WITH TIME ZONE,\n  num_resets      INTEGER NOT NULL DEFAULT 0,\n  num_failures    INTEGER NOT NULL DEFAULT 0,\n  execution_logs  JSON[],\n  worker_hostname TEXT NOT NULL DEFAULT '',\n  cancel          BOOL DEFAULT FALSE,\n\n  created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n  updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n\n  batch_spec TEXT NOT NULL,\n  batch_spec_id integer REFERENCES batch_specs(id) DEFERRABLE,\n\n  user_id INTEGER REFERENCES users(id),\n  namespace_org_id INTEGER REFERENCES orgs(id),\n  namespace_user_id INTEGER REFERENCES users(id)\n);\n\nALTER TABLE IF EXISTS batch_spec_executions ADD CONSTRAINT batch_spec_executions_has_1_namespace CHECK ((namespace_user_id IS NULL) \u003c\u003e (namespace_org_id IS NULL));\nCREATE INDEX IF NOT EXISTS batch_spec_executions_rand_id ON batch_spec_executions USING btree (rand_id);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395891
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395893,
				"Name": "fix repo index part one",
				"UpQuery": "-- We have a hand-created but non-codified index in our Cloud environment\n-- called repo_deleted_at_idx which is a partial btree index over deleted_at\n-- where deleted_at is null. This effectively creates a btree index whose only\n-- value is NULL.\n--\n-- Instead, we'll make a partial index on useful fields that can at least help\n-- cover queries that select only/filter by id and/or name.\n\nCREATE INDEX CONCURRENTLY IF NOT EXISTS repo_non_deleted_id_name_idx ON repo(id, name) WHERE deleted_at IS NULL;",
				"DownQuery": "DROP INDEX IF EXISTS repo_non_deleted_id_name_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395892
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "repo",
					"IndexName": "repo_non_deleted_id_name_idx"
				}
			},
			{
				"ID": 1528395894,
				"Name": "gitserver repo shard id index",
				"UpQuery": "-- This speeds up IterateRepoGitserverStatus\nCREATE INDEX CONCURRENTLY IF NOT EXISTS gitserver_repos_shard_id ON gitserver_repos(shard_id, repo_id);",
				"DownQuery": "DROP INDEX IF EXISTS gitserver_repos_shard_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395893
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "gitserver_repos",
					"IndexName": "gitserver_repos_shard_id"
				}
			},
			{
				"ID": 1528395895,
				"Name": "gitserver repos lasterror idx",
				"UpQuery": "DROP INDEX IF EXISTS gitserver_repos_last_error_idx;",
				"DownQuery": "CREATE INDEX gitserver_repos_last_error_idx ON gitserver_repos(last_error) WHERE last_error IS NOT NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395894
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395896,
				"Name": "gitserver repos new lasterror idx",
				"UpQuery": "CREATE INDEX CONCURRENTLY gitserver_repos_last_error_idx ON gitserver_repos(repo_id) WHERE last_error IS NOT NULL;",
				"DownQuery": "DROP INDEX IF EXISTS gitserver_repos_last_error_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395895
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "gitserver_repos",
					"IndexName": "gitserver_repos_last_error_idx"
				}
			},
			{
				"ID": 1528395897,
				"Name": "extensions list missing index",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS registry_extension_releases_registry_extension_id_created_at ON registry_extension_releases(registry_extension_id, created_at) WHERE deleted_at IS NULL;",
				"DownQuery": "DROP INDEX IF EXISTS registry_extension_releases_registry_extension_id_created_at;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395896
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "registry_extension_releases",
					"IndexName": "registry_extension_releases_registry_extension_id_created_at"
				}
			},
			{
				"ID": 1528395898,
				"Name": "codehost connection owned by org",
				"UpQuery": "-- Adds support for organization owning a codehost connection\nBEGIN;\n\nALTER TABLE IF EXISTS external_services ADD COLUMN IF NOT EXISTS namespace_org_id integer REFERENCES orgs(id) ON DELETE CASCADE DEFERRABLE;\nALTER TABLE IF EXISTS external_services ADD CONSTRAINT external_services_max_1_namespace CHECK ((namespace_user_id IS NULL AND namespace_org_id IS NULL) OR ((namespace_user_id IS NULL) \u003c\u003e (namespace_org_id IS NULL)));\nCREATE INDEX external_services_namespace_org_id_idx ON external_services USING btree (namespace_org_id);\n\nEND;",
				"DownQuery": "ALTER TABLE IF EXISTS external_services DROP COLUMN IF EXISTS namespace_org_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395897
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395899,
				"Name": "add index for lsif indexes state",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS lsif_indexes_state ON lsif_indexes(state);",
				"DownQuery": "DROP INDEX IF EXISTS lsif_indexes_state;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395898
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "lsif_indexes",
					"IndexName": "lsif_indexes_state"
				}
			},
			{
				"ID": 1528395900,
				"Name": "add commit to lsif uploads repository index",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS lsif_uploads_repository_id_commit ON lsif_uploads(repository_id, commit);",
				"DownQuery": "DROP INDEX IF EXISTS lsif_uploads_repository_id_commit;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395899
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "lsif_uploads",
					"IndexName": "lsif_uploads_repository_id_commit"
				}
			},
			{
				"ID": 1528395901,
				"Name": "remove duplicate index",
				"UpQuery": "DROP INDEX IF EXISTS lsif_uploads_repository_id;",
				"DownQuery": "CREATE INDEX IF NOT EXISTS lsif_uploads_repository_id ON lsif_uploads(repository_id);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395900
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395902,
				"Name": "drop unused security events index 0",
				"UpQuery": "DROP INDEX IF EXISTS security_event_logs_anonymous_user_id;",
				"DownQuery": "CREATE INDEX IF NOT EXISTS security_event_logs_anonymous_user_id ON security_event_logs USING btree (anonymous_user_id);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395901
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395903,
				"Name": "drop unused security events index 1",
				"UpQuery": "DROP INDEX IF EXISTS security_event_logs_user_id;",
				"DownQuery": "CREATE INDEX IF NOT EXISTS security_event_logs_user_id ON security_event_logs USING btree (user_id);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395902
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395904,
				"Name": "drop unused security events index 2",
				"UpQuery": "DROP INDEX IF EXISTS security_event_logs_name;",
				"DownQuery": "CREATE INDEX IF NOT EXISTS security_event_logs_name ON security_event_logs USING btree (name);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395903
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395905,
				"Name": "drop unused security events index 3",
				"UpQuery": "DROP INDEX IF EXISTS security_event_logs_source;",
				"DownQuery": "CREATE INDEX IF NOT EXISTS security_event_logs_source ON security_event_logs USING btree (source);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395904
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395906,
				"Name": "drop unused security events index 4",
				"UpQuery": "DROP INDEX IF EXISTS security_event_logs_timestamp_at_utc;",
				"DownQuery": "CREATE INDEX IF NOT EXISTS security_event_logs_timestamp_at_utc ON security_event_logs USING btree (date(timezone('UTC'::text, \"timestamp\")));",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395905
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395907,
				"Name": "more default lsif configuration policies",
				"UpQuery": "INSERT INTO lsif_configuration_policies\n    (\n        name,\n        protected, pattern, type,\n        retention_enabled, retain_intermediate_commits, retention_duration_hours,\n        indexing_enabled, index_intermediate_commits, index_commit_max_age_hours\n    )\nVALUES\n    (\n        'Default commit retention policy',\n        true, '*', 'GIT_TREE',\n        true, true, 168, -- 1 week (168 hours) * 4 * 3\n        false, false, 0\n    );",
				"DownQuery": "-- Nothing on down",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395906
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395908,
				"Name": "reverted",
				"UpQuery": "-- Empty migration, this migration was reverted: https://github.com/sourcegraph/sourcegraph/pull/25715",
				"DownQuery": "-- Empty migration, this migration was reverted: https://github.com/sourcegraph/sourcegraph/pull/25715",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395907
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395909,
				"Name": "undo apidocs oob migration",
				"UpQuery": "-- Undo the changes corresponding to https://github.com/sourcegraph/sourcegraph/pull/25715\nDELETE FROM out_of_band_migrations WHERE id=12 AND team='apidocs';",
				"DownQuery": "-- Nothing to do, the up migration undid changes previously made.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395908
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395910,
				"Name": "gitserver last changed",
				"UpQuery": "ALTER TABLE gitserver_repos ADD COLUMN IF NOT EXISTS last_changed TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT now();",
				"DownQuery": "ALTER TABLE gitserver_repos DROP COLUMN last_changed;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395909
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395911,
				"Name": "add access token id to batch spec workspace execution jobs",
				"UpQuery": "ALTER TABLE IF EXISTS batch_spec_workspace_execution_jobs\n  ADD COLUMN IF NOT EXISTS access_token_id bigint REFERENCES access_tokens(id) ON DELETE SET NULL DEFERRABLE DEFAULT NULL;\n\nALTER TABLE IF EXISTS access_tokens\n  ADD COLUMN IF NOT EXISTS internal boolean DEFAULT FALSE;",
				"DownQuery": "ALTER TABLE IF EXISTS batch_spec_workspace_execution_jobs\n  DROP COLUMN IF EXISTS access_token_id;\n\nALTER TABLE IF EXISTS access_tokens\n  DROP COLUMN IF EXISTS internal;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395910
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395912,
				"Name": "apidocs oob search indexing",
				"UpQuery": "-- Create the OOB migration according to doc/dev/background-information/oobmigrations.md\nINSERT INTO out_of_band_migrations (id, team, component, description, introduced_version_major, introduced_version_minor, non_destructive)\nVALUES (\n    12,                                             -- This must be consistent across all Sourcegraph instances\n    'apidocs',                                      -- Team owning migration\n    'codeintel-db.lsif_data_documentation_search',  -- Component being migrated\n    'Index API docs for search',                    -- Description\n    3,                                              -- The next minor release (major version)\n    32,                                             -- The next minor release (minor version)\n    true                                            -- Can be read with previous version without down migration\n)\nON CONFLICT DO NOTHING;",
				"DownQuery": "-- The OOB migration doesn't add any new tables or columns or anything, so we don't need to do\n-- anything on down migration. It migrates data from lsif_data_documentation_pages -\u003e the new\n-- lsif_data_documentation_search_* tables - but it's fine to just leave those.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395911
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395913,
				"Name": "add unique constraint on batch spec resolution jobs",
				"UpQuery": "ALTER TABLE IF EXISTS batch_spec_resolution_jobs\n  ADD CONSTRAINT batch_spec_resolution_jobs_batch_spec_id_unique UNIQUE (batch_spec_id);",
				"DownQuery": "ALTER TABLE IF EXISTS batch_spec_resolution_jobs\n  DROP CONSTRAINT IF EXISTS batch_spec_resolution_jobs_batch_spec_id_unique;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395912
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395914,
				"Name": "add created from raw to batch specs",
				"UpQuery": "ALTER TABLE batch_specs\n  ADD COLUMN IF NOT EXISTS created_from_raw boolean DEFAULT FALSE NOT NULL;",
				"DownQuery": "ALTER TABLE batch_specs\n  DROP COLUMN IF EXISTS created_from_raw;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395913
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395915,
				"Name": "remove raw changeset spec",
				"UpQuery": "ALTER TABLE\n    changeset_specs\nDROP COLUMN IF EXISTS\n    raw_spec;",
				"DownQuery": "-- We don't need to reconstruct the contents of the raw_spec column (and,\n-- indeed, we can't), so we'll just leave it with empty strings.\n\nALTER TABLE\n    changeset_specs\nADD COLUMN IF NOT EXISTS\n    raw_spec TEXT NOT NULL DEFAULT '';",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395914
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395916,
				"Name": "add external service repos org id",
				"UpQuery": "ALTER TABLE external_service_repos ADD COLUMN IF NOT EXISTS org_id INTEGER REFERENCES orgs(id) ON DELETE CASCADE;",
				"DownQuery": "ALTER TABLE external_service_repos DROP COLUMN IF EXISTS org_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395915
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395917,
				"Name": "add index rate limit",
				"UpQuery": "-- Create table to rate limit indexing scans of a repository\nCREATE TABLE lsif_last_index_scan (\n    repository_id int NOT NULL,\n    last_index_scan_at timestamp with time zone NOT NULL,\n\n    PRIMARY KEY(repository_id)\n);\nCOMMENT ON TABLE lsif_last_index_scan IS 'Tracks the last time repository was checked for auto-indexing job scheduling.';\nCOMMENT ON COLUMN lsif_last_index_scan.last_index_scan_at IS 'The last time uploads of this repository were considered for auto-indexing job scheduling.';",
				"DownQuery": "DROP TABLE IF EXISTS lsif_last_index_scan;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395916
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395918,
				"Name": "update batch spec workspaces to persist all",
				"UpQuery": "ALTER TABLE batch_spec_workspaces\n  ADD COLUMN IF NOT EXISTS ignored BOOLEAN NOT NULL DEFAULT FALSE,\n  ADD COLUMN IF NOT EXISTS unsupported BOOLEAN NOT NULL DEFAULT FALSE,\n  ADD COLUMN IF NOT EXISTS skipped BOOLEAN NOT NULL DEFAULT FALSE;\n\nALTER TABLE batch_specs\n  ADD COLUMN IF NOT EXISTS allow_unsupported BOOLEAN NOT NULL DEFAULT FALSE,\n  ADD COLUMN IF NOT EXISTS allow_ignored BOOLEAN NOT NULL DEFAULT FALSE;\n\nALTER TABLE batch_spec_resolution_jobs\n  DROP COLUMN IF EXISTS allow_unsupported,\n  DROP COLUMN IF EXISTS allow_ignored;",
				"DownQuery": "ALTER TABLE batch_spec_workspaces\n  DROP COLUMN IF EXISTS ignored,\n  DROP COLUMN IF EXISTS unsupported,\n  DROP COLUMN IF EXISTS skipped;\n\nALTER TABLE batch_specs\n  DROP COLUMN IF EXISTS allow_unsupported,\n  DROP COLUMN IF EXISTS allow_ignored;\n\nALTER TABLE batch_spec_resolution_jobs\n  ADD COLUMN IF NOT EXISTS allow_unsupported BOOLEAN NOT NULL DEFAULT FALSE,\n  ADD COLUMN IF NOT EXISTS allow_ignored BOOLEAN NOT NULL DEFAULT FALSE;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395917
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395919,
				"Name": "drop soft delete search contexts",
				"UpQuery": "DELETE FROM search_contexts WHERE deleted_at IS NOT NULL;\n\nCOMMENT ON COLUMN search_contexts.deleted_at IS 'This column is unused as of Sourcegraph 3.34. Do not refer to it anymore. It will be dropped in a future version.';\n\nALTER TABLE search_context_repos ADD CONSTRAINT search_context_repos_unique UNIQUE (repo_id, search_context_id, revision);\n\nALTER TABLE search_context_repos DROP CONSTRAINT IF EXISTS search_context_repos_search_context_id_repo_id_revision_unique;",
				"DownQuery": "ALTER TABLE search_context_repos ADD CONSTRAINT search_context_repos_search_context_id_repo_id_revision_unique UNIQUE (search_context_id, repo_id, revision);\n\nALTER TABLE search_context_repos DROP CONSTRAINT IF EXISTS search_context_repos_unique;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395918
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395920,
				"Name": "create sub repo permissions table",
				"UpQuery": "create table sub_repo_permissions\n(\n    repo_id       integer       not null\n        constraint sub_repo_permissions_repo_id_fk\n            references repo\n            on delete cascade,\n    user_id       integer       not null\n        constraint sub_repo_permissions_users_id_fk\n            references users\n            on delete cascade,\n    version       int default 1 not null,\n    path_includes text[],\n    path_excludes text[],\n    updated_at timestamp with time zone default now() not null\n);\n\ncomment on table sub_repo_permissions is 'Responsible for storing permissions at a finer granularity than repo';\n\ncreate unique index sub_repo_permissions_repo_id_user_id_uindex\n    on sub_repo_permissions (repo_id, user_id);\n\ncreate index sub_repo_perms_user_id ON sub_repo_permissions (user_id);\ncreate index sub_repo_perms_repo_id ON sub_repo_permissions (repo_id);",
				"DownQuery": "DROP TABLE IF EXISTS sub_repo_permissions;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395919
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395921,
				"Name": "add version index sub repo permissions",
				"UpQuery": "drop index if exists sub_repo_permissions_repo_id_user_id_uindex;\n\ncreate unique index sub_repo_permissions_repo_id_user_id_version_uindex\n    on sub_repo_permissions (repo_id, user_id, version);\n\ncreate index sub_repo_perms_version ON sub_repo_permissions (version);",
				"DownQuery": "drop index if exists sub_repo_permissions_repo_id_user_id_version_uindex;\ndrop index if exists sub_repo_perms_version;\n\ncreate unique index sub_repo_permissions_repo_id_user_id_uindex\n    on sub_repo_permissions (repo_id, user_id);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395920
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395922,
				"Name": "add external service repos org id index",
				"UpQuery": "CREATE INDEX IF NOT EXISTS external_service_repos_org_id_idx ON external_service_repos USING btree (org_id) WHERE org_id IS NOT NULL;",
				"DownQuery": "DROP INDEX IF EXISTS external_service_repos_org_id_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395921
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395923,
				"Name": "add has webhooks",
				"UpQuery": "ALTER TABLE\n    external_services\nADD COLUMN IF NOT EXISTS\n    has_webhooks BOOLEAN NULL DEFAULT NULL;\n\nCREATE INDEX\n    external_services_has_webhooks_idx\nON\n    external_services (has_webhooks);\n\nINSERT INTO\n    out_of_band_migrations (\n        id,\n        team,\n        component,\n        description,\n        introduced_version_major,\n        introduced_version_minor,\n        non_destructive\n    )\nVALUES (\n    13,\n    'batch-changes',\n    'frontend-db.external_services',\n    'Calculate the webhook state of each external service',\n    3,\n    34,\n    true\n)\nON CONFLICT\n    DO NOTHING\n;",
				"DownQuery": "-- We don't remove the out of band migration when moving down.\n\nALTER TABLE\n    external_services\nDROP COLUMN IF EXISTS\n    has_webhooks;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395922
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395924,
				"Name": "lsif configuration policies repository pattern lookup",
				"UpQuery": "-- Create lookup table for repository pattern matching\nCREATE TABLE IF NOT EXISTS lsif_configuration_policies_repository_pattern_lookup (\n    policy_id INTEGER NOT NULL,\n    repo_id INTEGER NOT NULL,\n    PRIMARY KEY (policy_id, repo_id)\n);\n\nCOMMENT ON TABLE lsif_configuration_policies_repository_pattern_lookup IS 'A lookup table to get all the repository patterns by repository id that apply to a configuration policy.';\nCOMMENT ON COLUMN lsif_configuration_policies_repository_pattern_lookup.policy_id IS 'The policy identifier associated with the repository.';\nCOMMENT ON COLUMN lsif_configuration_policies_repository_pattern_lookup.repo_id IS 'The repository identifier associated with the policy.';\n\n-- Add glob pattern column\nALTER TABLE lsif_configuration_policies ADD COLUMN repository_patterns TEXT[];\nCOMMENT ON COLUMN lsif_configuration_policies.repository_patterns IS 'The name pattern matching repositories to which this configuration policy applies. If absent, all repositories are matched.';\n\n-- Add column to determine the last update of the associated records in lsif_configuration_policies_repository_pattern_lookup\nALTER TABLE lsif_configuration_policies ADD COLUMN last_resolved_at TIMESTAMP WITH TIME ZONE DEFAULT NULL;",
				"DownQuery": "-- Drop new table\nDROP TABLE IF EXISTS lsif_configuration_policies_repository_pattern_lookup;\n\n-- Drop new columns\nALTER TABLE lsif_configuration_policies DROP COLUMN last_resolved_at;\nALTER TABLE lsif_configuration_policies DROP COLUMN repository_patterns;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395923
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395925,
				"Name": "settings global index",
				"UpQuery": "CREATE INDEX IF NOT EXISTS settings_global_id ON settings (id DESC) WHERE user_id IS NULL AND org_id IS NULL;",
				"DownQuery": "DROP INDEX IF EXISTS settings_global_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395924
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395926,
				"Name": "drop redundant sub repo perms index",
				"UpQuery": "DROP INDEX IF EXISTS sub_repo_perms_repo_id;\n\nDROP INDEX IF EXISTS sub_repo_perms_user_id;\n\nDROP INDEX IF EXISTS sub_repo_perms_version;",
				"DownQuery": "CREATE INDEX sub_repo_perms_repo_id ON sub_repo_permissions (repo_id);\n\nCREATE INDEX sub_repo_perms_user_id ON sub_repo_permissions (user_id);\n\nCREATE INDEX sub_repo_perms_version ON sub_repo_permissions (version);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395925
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395927,
				"Name": "webhook logs",
				"UpQuery": "CREATE TABLE IF NOT EXISTS webhook_logs (\n    id BIGSERIAL PRIMARY KEY,\n    received_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n    external_service_id INTEGER NULL REFERENCES external_services (id) ON DELETE CASCADE ON UPDATE CASCADE,\n    status_code INTEGER NOT NULL,\n    request BYTEA NOT NULL,\n    response BYTEA NOT NULL,\n    encryption_key_id TEXT NOT NULL\n);\n\nCREATE INDEX IF NOT EXISTS\n    webhook_logs_received_at_idx\nON\n    webhook_logs (received_at);\n\nCREATE INDEX IF NOT EXISTS\n    webhook_logs_external_service_id_idx\nON\n    webhook_logs (external_service_id);\n\nCREATE INDEX IF NOT EXISTS\n    webhook_logs_status_code_idx\nON\n    webhook_logs (status_code);",
				"DownQuery": "DROP TABLE IF EXISTS webhook_logs;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395926
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395928,
				"Name": "add batch spec execution cache entries",
				"UpQuery": "CREATE TABLE IF NOT EXISTS batch_spec_execution_cache_entries (\n  id           BIGSERIAL PRIMARY KEY,\n\n  key          TEXT NOT NULL,\n  value        TEXT NOT NULL,\n\n  version      INTEGER NOT NULL,\n\n  last_used_at TIMESTAMP WITH TIME ZONE,\n  created_at   TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()\n);",
				"DownQuery": "DROP TABLE IF EXISTS batch_spec_execution_cache_entries;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395927
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395929,
				"Name": "external service repos clone url",
				"UpQuery": "CREATE INDEX IF NOT EXISTS external_service_repos_clone_url_idx ON external_service_repos (clone_url);",
				"DownQuery": "DROP INDEX IF EXISTS external_service_repos_clone_url_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395928
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395930,
				"Name": "drop unused column object ids from user permissions table",
				"UpQuery": "ALTER TABLE IF EXISTS user_permissions DROP COLUMN IF EXISTS object_ids;",
				"DownQuery": "ALTER TABLE IF EXISTS user_permissions ADD COLUMN object_ids bytea NOT NULL default '\\x';",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395929
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395931,
				"Name": "drop unused column user ids from repo permissions table",
				"UpQuery": "ALTER TABLE IF EXISTS repo_permissions DROP COLUMN IF EXISTS user_ids;",
				"DownQuery": "ALTER TABLE IF EXISTS repo_permissions ADD COLUMN user_ids bytea NOT NULL default '\\x';",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395930
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395932,
				"Name": "add cache entry id to batch spec workspaces",
				"UpQuery": "ALTER TABLE batch_spec_workspaces\n  ADD COLUMN IF NOT EXISTS batch_spec_execution_cache_entry_id INTEGER REFERENCES batch_spec_execution_cache_entries(id) DEFERRABLE;",
				"DownQuery": "ALTER TABLE batch_spec_workspaces\n  DROP COLUMN IF EXISTS batch_spec_execution_cache_entry_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395931
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395933,
				"Name": "add cached result found to batch spec workspaces",
				"UpQuery": "ALTER TABLE batch_spec_workspaces\n  ADD COLUMN IF NOT EXISTS cached_result_found BOOLEAN NOT NULL DEFAULT FALSE;\n\nUPDATE\n  batch_spec_workspaces\nSET\n  cached_result_found = true\nWHERE\n  batch_spec_execution_cache_entry_id IS NOT NULL;\n\nALTER TABLE batch_spec_workspaces\n  DROP COLUMN IF EXISTS batch_spec_execution_cache_entry_id;\n\nDELETE FROM\n  batch_spec_execution_cache_entries e1\nWHERE\n  EXISTS (SELECT 1 FROM batch_spec_execution_cache_entries e2 WHERE e1.key = e2.key AND e1.id != e2.id);\n\nALTER TABLE batch_spec_execution_cache_entries\n  ADD CONSTRAINT batch_spec_execution_cache_entries_key_unique UNIQUE (key);",
				"DownQuery": "ALTER TABLE batch_spec_workspaces\n  ADD COLUMN IF NOT EXISTS batch_spec_execution_cache_entry_id INTEGER REFERENCES batch_spec_execution_cache_entries(id) DEFERRABLE;\n\nALTER TABLE batch_spec_workspaces\n  DROP COLUMN IF EXISTS cached_result_found;\n\nALTER TABLE batch_spec_execution_cache_entries\n  DROP CONSTRAINT IF EXISTS batch_spec_execution_cache_entries_key_unique;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395932
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395934,
				"Name": "lsif upload reference counts",
				"UpQuery": "ALTER TABLE lsif_uploads ADD COLUMN reference_count int;\nCOMMENT ON COLUMN lsif_uploads.reference_count IS 'The number of references to this upload data from other upload records (via lsif_references).';\nCOMMENT ON COLUMN lsif_uploads.num_references IS 'Deprecated in favor of reference_count.';",
				"DownQuery": "-- Drop new column\nALTER TABLE lsif_uploads DROP COLUMN reference_count;\n\n-- Restore old comment on deprecated column\nCOMMENT ON COLUMN lsif_uploads.num_references IS 'The number of references to this upload data from other upload records (via lsif_references).';",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395933
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395935,
				"Name": "repo stars desc id desc index",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS repo_stars_desc_id_desc_idx\n    ON repo USING btree (stars DESC NULLS LAST, id DESC) WHERE deleted_at IS NULL AND blocked IS NULL;",
				"DownQuery": "DROP INDEX IF EXISTS repo_stars_desc_id_desc_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395934
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "repo",
					"IndexName": "repo_stars_desc_id_desc_idx"
				}
			},
			{
				"ID": 1528395936,
				"Name": "repo name case sensitive trgm idx",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS repo_name_case_sensitive_trgm_idx ON repo USING gin ((name::text) gin_trgm_ops);",
				"DownQuery": "DROP INDEX IF EXISTS repo_name_case_sensitive_trgm_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395935
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "repo",
					"IndexName": "repo_name_case_sensitive_trgm_idx"
				}
			},
			{
				"ID": 1528395937,
				"Name": "codemonitor webhooks",
				"UpQuery": "-- Begin cm_webhooks\nCREATE TABLE IF NOT EXISTS cm_webhooks (\n\tid BIGSERIAL PRIMARY KEY,\n\tmonitor BIGINT NOT NULL REFERENCES cm_monitors(id) ON DELETE CASCADE,\n\turl TEXT NOT NULL,\n\tenabled BOOLEAN NOT NULL,\n\tcreated_by INTEGER NOT NULL REFERENCES users(id) ON DELETE CASCADE,\n\tcreated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n\tchanged_by INTEGER NOT NULL REFERENCES users(id) ON DELETE CASCADE,\n\tchanged_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()\n);\n\nCREATE INDEX IF NOT EXISTS cm_webhooks_monitor ON cm_webhooks (monitor);\n\nCOMMENT ON TABLE cm_webhooks IS 'Webhook actions configured on code monitors';\nCOMMENT ON COLUMN cm_webhooks.monitor IS 'The code monitor that the action is defined on';\nCOMMENT ON COLUMN cm_webhooks.url IS 'The webhook URL we send the code monitor event to';\nCOMMENT ON COLUMN cm_webhooks.enabled IS 'Whether this webhook action is enabled. When not enabled, the action will not be run when its code monitor generates events';\n-- End cm_webhooks\n\n-- Begin cm_slack_webhooks\nCREATE TABLE IF NOT EXISTS cm_slack_webhooks (\n\tid BIGSERIAL PRIMARY KEY,\n\tmonitor BIGINT NOT NULL REFERENCES cm_monitors(id) ON DELETE CASCADE,\n\turl TEXT NOT NULL,\n\tenabled BOOLEAN NOT NULL,\n\tcreated_by INTEGER NOT NULL REFERENCES users(id) ON DELETE CASCADE,\n\tcreated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n\tchanged_by INTEGER NOT NULL REFERENCES users(id) ON DELETE CASCADE,\n\tchanged_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()\n);\n\nCREATE INDEX IF NOT EXISTS cm_slack_webhooks_monitor ON cm_slack_webhooks (monitor);\n\nCOMMENT ON TABLE cm_slack_webhooks IS 'Slack webhook actions configured on code monitors';\nCOMMENT ON COLUMN cm_slack_webhooks.monitor IS 'The code monitor that the action is defined on';\nCOMMENT ON COLUMN cm_slack_webhooks.url IS 'The Slack webhook URL we send the code monitor event to';\nCOMMENT ON COLUMN cm_webhooks.enabled IS 'Whether this Slack webhook action is enabled. When not enabled, the action will not be run when its code monitor generates events';\n-- End cm_slack_webhooks\n\n-- Begin add non-email actions to cm_triggers\nALTER TABLE cm_action_jobs\n\tALTER COLUMN email DROP NOT NULL, -- make email nullable (drop the not null constraint)\n\tADD COLUMN IF NOT EXISTS webhook BIGINT -- create a nullable webhook column\n\t\tREFERENCES cm_webhooks(id) ON DELETE CASCADE,\n\tADD COLUMN IF NOT EXISTS slack_webhook BIGINT  --create a nullable slack webhook column\n\t\tREFERENCES cm_slack_webhooks(id) ON DELETE CASCADE,\n\tADD CONSTRAINT cm_action_jobs_only_one_action_type CHECK ( -- constrain that only one of email, webhook, and slack_webhook is non-null\n\t\t( \n\t\t\tCASE WHEN email IS NULL THEN 0 ELSE 1 END\n\t\t\t+ CASE WHEN webhook IS NULL THEN 0 ELSE 1 END \n\t\t\t+ CASE WHEN slack_webhook IS NULL THEN 0 ELSE 1 END \n\t\t) = 1\n\t);\n\nCOMMENT ON COLUMN cm_action_jobs.email IS 'The ID of the cm_emails action to execute if this is an email job. Mutually exclusive with webhook and slack_webhook';\nCOMMENT ON COLUMN cm_action_jobs.webhook IS 'The ID of the cm_webhooks action to execute if this is a webhook job. Mutually exclusive with email and slack_webhook';\nCOMMENT ON COLUMN cm_action_jobs.slack_webhook IS 'The ID of the cm_slack_webhook action to execute if this is a slack webhook job. Mutually exclusive with email and webhook';\nCOMMENT ON CONSTRAINT cm_action_jobs_only_one_action_type ON cm_action_jobs IS 'Constrains that each queued code monitor action has exactly one action type';\n-- End add non-email actions to cm_triggers",
				"DownQuery": "ALTER TABLE cm_action_jobs\n\tDROP CONSTRAINT IF EXISTS cm_action_jobs_only_one_action_type,\n\tDROP COLUMN IF EXISTS slack_webhook,\n\tDROP COLUMN IF EXISTS webhook,\n\tALTER COLUMN email SET NOT NULL;\n\nDROP TABLE IF EXISTS cm_slack_webhooks;\nDROP TABLE IF EXISTS cm_webhooks;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395936
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395938,
				"Name": "batch spec no cache",
				"UpQuery": "ALTER TABLE batch_specs ADD COLUMN IF NOT EXISTS no_cache BOOLEAN NOT NULL DEFAULT FALSE;",
				"DownQuery": "ALTER TABLE batch_specs DROP COLUMN IF EXISTS no_cache;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395937
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395939,
				"Name": "batch specs changeset specs delete cascade",
				"UpQuery": "ALTER TABLE changeset_specs\n    DROP CONSTRAINT changeset_specs_batch_spec_id_fkey,\n    ADD CONSTRAINT changeset_specs_batch_spec_id_fkey FOREIGN KEY (batch_spec_id) REFERENCES batch_specs (id) ON DELETE CASCADE DEFERRABLE;",
				"DownQuery": "ALTER TABLE changeset_specs\n    DROP CONSTRAINT changeset_specs_batch_spec_id_fkey,\n    ADD CONSTRAINT changeset_specs_batch_spec_id_fkey FOREIGN KEY (batch_spec_id) REFERENCES batch_specs (id) DEFERRABLE;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395938
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395940,
				"Name": "executor heartbeats",
				"UpQuery": "CREATE TABLE IF NOT EXISTS executor_heartbeats (\n    id SERIAL PRIMARY KEY,\n    hostname TEXT NOT NULL UNIQUE,\n    queue_name TEXT NOT NULL,\n    os TEXT NOT NULL,\n    architecture TEXT NOT NULL,\n    docker_version TEXT NOT NULL,\n    executor_version TEXT NOT NULL,\n    git_version TEXT NOT NULL,\n    ignite_version TEXT NOT NULL,\n    src_cli_version TEXT NOT NULL,\n    first_seen_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n    last_seen_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()\n);\n\nCOMMENT ON TABLE executor_heartbeats IS 'Tracks the most recent activity of executors attached to this Sourcegraph instance.';\nCOMMENT ON COLUMN executor_heartbeats.hostname IS 'The uniquely identifying name of the executor.';\nCOMMENT ON COLUMN executor_heartbeats.queue_name IS 'The queue name that the executor polls for work.';\nCOMMENT ON COLUMN executor_heartbeats.os IS 'The operating system running the executor.';\nCOMMENT ON COLUMN executor_heartbeats.architecture IS 'The machine architure running the executor.';\nCOMMENT ON COLUMN executor_heartbeats.docker_version IS 'The version of Docker used by the executor.';\nCOMMENT ON COLUMN executor_heartbeats.executor_version IS 'The version of the executor.';\nCOMMENT ON COLUMN executor_heartbeats.git_version IS 'The version of Git used by the executor.';\nCOMMENT ON COLUMN executor_heartbeats.ignite_version IS 'The version of Ignite used by the executor.';\nCOMMENT ON COLUMN executor_heartbeats.src_cli_version IS 'The version of src-cli used by the executor.';\nCOMMENT ON COLUMN executor_heartbeats.first_seen_at IS 'The first time a heartbeat from the executor was received.';\nCOMMENT ON COLUMN executor_heartbeats.last_seen_at IS 'The last time a heartbeat from the executor was received.';",
				"DownQuery": "DROP TABLE IF EXISTS executor_heartbeats;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395939
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395941,
				"Name": "remove-org-monitors",
				"UpQuery": "DELETE FROM cm_monitors WHERE namespace_user_id IS NULL;\nCOMMENT ON COLUMN cm_monitors.namespace_org_id IS 'DEPRECATED: code monitors cannot be owned by an org';\n\nALTER TABLE cm_monitors \n\tALTER COLUMN namespace_user_id SET NOT NULL;",
				"DownQuery": "ALTER TABLE cm_monitors\n\tALTER COLUMN namespace_user_id DROP NOT NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395940
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395942,
				"Name": "remove-org-saved-searches",
				"UpQuery": "-- NOTE: this migration deleted saved searches belonging to orgs when what we should have done\n-- was remove notifications from saved searches. Saved searches are still used (and useful) as\n-- a bookmarking feature, and are not deprecated. Saved search notifications, however, are\n-- deprecated, and will be removed in v3.34.0 by removing the query runner service. \n\n-- DELETE FROM saved_searches WHERE user_id IS NULL;\n\n-- ALTER TABLE saved_searches\n-- \tALTER COLUMN user_id SET NOT NULL;\n\n-- COMMENT ON COLUMN saved_searches.org_id IS 'DEPRECATED: saved searches must be owned by a user';",
				"DownQuery": "-- ALTER TABLE saved_searches\n-- \tALTER COLUMN user_id DROP NOT NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395941
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395943,
				"Name": "disable-saved-search-notifications",
				"UpQuery": "UPDATE saved_searches\nSET (notify_owner, notify_slack) = (false, false);\n\nALTER TABLE saved_searches\n\tADD CONSTRAINT saved_searches_notifications_disabled CHECK (\n\t\tnotify_owner = false\n\t\tAND notify_slack = false\n\t);\n\nALTER TABLE IF EXISTS saved_searches\n\tALTER COLUMN user_id DROP NOT NULL;",
				"DownQuery": "ALTER TABLE IF EXISTS saved_searches\n\tDROP CONSTRAINT IF EXISTS saved_searches_notifications_disabled;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395942
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395944,
				"Name": "reenable-code-monitors",
				"UpQuery": "-- If code monitors were disabled by a manual step, make\n\t-- it possible to re-enable them by removing the constraint.\n\t-- If an admin wants to restore the previous enabled state\n\t-- from the backup table, they can run something like the following:\n\t--     UPDATE cm_monitors\n\t--     SET enabled = cm_monitors_enabled_backup.enabled\n\t--     FROM cm_monitors_enabled_backup\n\t--     WHERE cm_monitors.id = cm_monitors_enabled_backup.id;\n\tALTER TABLE cm_monitors\n\tDROP CONSTRAINT IF EXISTS cm_monitors_cannot_be_enabled;",
				"DownQuery": "",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395943
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395945,
				"Name": "repo stars null to zero",
				"UpQuery": "CREATE OR REPLACE PROCEDURE set_repo_stars_null_to_zero() AS\n$BODY$\nDECLARE\n  done boolean;\n  total integer = 0;\n  updated integer = 0;\n\nBEGIN\n  SELECT COUNT(*) INTO total FROM repo WHERE stars IS NULL;\n\n  RAISE NOTICE 'repo_stars_null_to_zero: updating % rows', total;\n\n  done := total = 0;\n\n  WHILE NOT done LOOP\n    UPDATE repo SET stars = 0\n    FROM (\n      SELECT id FROM repo\n      WHERE stars IS NULL\n      LIMIT 10000\n      FOR UPDATE SKIP LOCKED\n    ) s\n    WHERE repo.id = s.id;\n\n    COMMIT;\n\n    SELECT COUNT(*) = 0 INTO done FROM repo WHERE stars IS NULL LIMIT 1;\n\n    updated := updated + 10000;\n\n    RAISE NOTICE 'repo_stars_null_to_zero: updated % of % rows', updated, total;\n  END LOOP;\nEND\n$BODY$\nLANGUAGE plpgsql;",
				"DownQuery": "DROP PROCEDURE IF EXISTS set_repo_stars_null_to_zero;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395944
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395946,
				"Name": "repo stars call nulls to zero",
				"UpQuery": "CALL set_repo_stars_null_to_zero();",
				"DownQuery": "",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395945
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395947,
				"Name": "repo stars not null",
				"UpQuery": "ALTER TABLE repo\n  ALTER COLUMN stars SET NOT NULL,\n  ALTER COLUMN stars SET DEFAULT 0;",
				"DownQuery": "ALTER TABLE repo\n  ALTER COLUMN stars DROP NOT NULL,\n  ALTER COLUMN stars DROP DEFAULT;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395946
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			}
		],
		"BoundsByRev": {
			"3.34.2": {
				"RootID": -1528395834,
				"LeafIDs": [
					1528395947
				],
				"PreCreation": false
			}
		}
	}
}
