{
	"codeinsights": {
		"Definitions": [
			{
				"ID": -1000000000,
				"Name": "squashed migrations (privileged)",
				"UpQuery": "",
				"DownQuery": "",
				"Privileged": true,
				"NonIdempotent": false,
				"Parents": null,
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000000,
				"Name": "squashed migrations",
				"UpQuery": "-- empty migration",
				"DownQuery": "-- empty migration",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					-1000000000
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000001,
				"Name": "initial schema",
				"UpQuery": "CREATE EXTENSION IF NOT EXISTS pg_trgm;\nCREATE EXTENSION IF NOT EXISTS citext;\n\n-- Records repository names, both historical and present, using a unique repository _name_ ID\n-- (unrelated to the repository ID.)\nCREATE TABLE repo_names (\n    -- The repository _name_ ID.\n    id bigserial NOT NULL PRIMARY KEY,\n\n    -- The name, trigram-indexed for fast e.g. regexp filtering.\n    name citext NOT NULL,\n\n    CONSTRAINT check_name_nonempty CHECK ((name OPERATOR(\u003c\u003e) ''::citext))\n);\n\n-- Enforce that names are unique.\nCREATE UNIQUE INDEX repo_names_name_unique_idx ON repo_names(name);\n\n-- Create trigram indexes for repository name filtering based on e.g. regexps.\nCREATE INDEX repo_names_name_trgm ON repo_names USING gin (lower((name)::text) gin_trgm_ops);\n\n\n-- Records arbitrary metadata about events. Stored in a separate table as it is often repeated\n-- for multiple events.\nCREATE TABLE metadata (\n    -- The metadata ID.\n    id bigserial NOT NULL PRIMARY KEY,\n\n    -- Metadata about this event, this can be any arbitrary JSON metadata which will be returned\n    -- when querying events, and can be filtered on and grouped using jsonb operators ?, ?\u0026, ?|,\n    -- and @\u003e. This should be small data only, primary use case is small lists such as:\n    --\n    --  {\"java_versions\": [...]}\n    --  {\"languages\":     [...]}\n    --  {\"pull_requests\": [...]}\n    --  {\"annotations\":   [...]}\n    --\n    metadata jsonb NOT NULL\n);\n\n-- Enforce that metadata is unique.\nCREATE UNIQUE INDEX metadata_metadata_unique_idx ON metadata(metadata);\n\n-- Index metadata to optimize WHERE clauses with jsonb ?, ?\u0026, ?|, and @\u003e operators.\nCREATE INDEX metadata_metadata_gin ON metadata USING GIN (metadata);\n\n-- Records events over time associated with a repository (or none, i.e. globally) where a single\n-- numerical value is going arbitrarily up and down.\n--\n-- Repository association is based on both repository ID and name. The ID can be used to refer to\n-- a specific repository, or lookup the current name of a repository after it has been e.g. renamed.\n-- The name can be used to refer to the name of the repository at the time of the event's creation,\n-- for example to trace the change in a gauge back to a repository being renamed.\nCREATE TABLE series_points (\n    -- A unique identifier for the series of data being recorded. This is not an ID from another\n    -- table, but rather just a unique identifier.\n    series_id integer,\n\n    -- The timestamp of the recorded event.\n    time TIMESTAMPTZ NOT NULL,\n\n    -- The floating point value at the time of the event.\n    value double precision NOT NULL,\n\n    -- Associated metadata for this event, if any.\n    metadata_id integer,\n\n    -- The repository ID (from the main application DB) at the time the event was created. Note\n    -- that the repository may no longer exist / be valid at query time, however.\n    --\n    -- null if the event was not for a single repository (i.e. a global gauge).\n    repo_id integer,\n\n    -- The most recently known name for the repository, updated periodically to account for e.g.\n    -- repository renames. If the repository was deleted, this is still the most recently known\n    -- name.\n    --\n    -- null if the event was not for a single repository (i.e. a global gauge).\n    repo_name_id integer,\n\n    -- The repository name as it was known at the time the event was created. It may have been renamed\n    -- since.\n    original_repo_name_id integer,\n\n    -- Ensure if one repo association field is specified, all are.\n    CONSTRAINT check_repo_fields_specifity CHECK (\n        ((repo_id IS NULL) AND (repo_name_id IS NULL) AND (original_repo_name_id IS NULL))\n        OR\n        ((repo_id IS NOT NULL) AND (repo_name_id IS NOT NULL) AND (original_repo_name_id IS NOT NULL))\n    ),\n\n    FOREIGN KEY (metadata_id) REFERENCES metadata(id) ON DELETE CASCADE DEFERRABLE,\n    FOREIGN KEY (repo_name_id) REFERENCES repo_names(id) ON DELETE CASCADE DEFERRABLE,\n    FOREIGN KEY (original_repo_name_id) REFERENCES repo_names(id) ON DELETE CASCADE DEFERRABLE\n);\n\n-- Create btree indexes for repository filtering.\nCREATE INDEX series_points_repo_id_btree ON series_points USING btree (repo_id);\nCREATE INDEX series_points_repo_name_id_btree ON series_points USING btree (repo_name_id);\nCREATE INDEX series_points_original_repo_name_id_btree ON series_points USING btree (original_repo_name_id);",
				"DownQuery": "DROP TABLE IF EXISTS series_points;\nDROP TABLE IF EXISTS repo_names;\nDROP TABLE IF EXISTS metadata;",
				"Privileged": true,
				"NonIdempotent": false,
				"Parents": [
					1000000000
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000002,
				"Name": "comments",
				"UpQuery": "COMMENT ON TABLE repo_names IS 'Records repository names, both historical and present, using a unique repository _name_ ID (unrelated to the repository ID.)';\nCOMMENT ON COLUMN repo_names.id IS 'The repository _name_ ID.';\nCOMMENT ON COLUMN repo_names.name IS 'The repository name string, with unique constraint for table entry deduplication and trigram index for e.g. regex filtering.';\n\nCOMMENT ON TABLE metadata IS 'Records arbitrary metadata about events. Stored in a separate table as it is often repeated for multiple events.';\nCOMMENT ON COLUMN metadata.id IS 'The metadata ID.';\nCOMMENT ON COLUMN metadata.metadata IS 'Metadata about some event, this can be any arbitrary JSON emtadata which will be returned when querying events, and can be filtered on and grouped using jsonb operators ?, ?\u0026, ?|, and @\u003e. This should be small data only.';\n\nCOMMENT ON TABLE series_points IS 'Records events over time associated with a repository (or none, i.e. globally) where a single numerical value is going arbitrarily up and down.  Repository association is based on both repository ID and name. The ID can be used to refer toa specific repository, or lookup the current name of a repository after it has been e.g. renamed. The name can be used to refer to the name of the repository at the time of the events creation, for example to trace the change in a gauge back to a repository being renamed.';\nCOMMENT ON COLUMN series_points.series_id IS 'A unique identifier for the series of data being recorded. This is not an ID from another table, but rather just a unique identifier.';\nCOMMENT ON COLUMN series_points.time IS 'The timestamp of the recorded event.';\nCOMMENT ON COLUMN series_points.value IS 'The floating point value at the time of the event.';\nCOMMENT ON COLUMN series_points.metadata_id IS 'Associated metadata for this event, if any.';\nCOMMENT ON COLUMN series_points.repo_id IS 'The repository ID (from the main application DB) at the time the event was created. Note that the repository may no longer exist / be valid at query time, however.';\nCOMMENT ON COLUMN series_points.repo_name_id IS 'The most recently known name for the repository, updated periodically to account for e.g. repository renames. If the repository was deleted, this is still the most recently known name.  null if the event was not for a single repository (i.e. a global gauge).';\nCOMMENT ON COLUMN series_points.original_repo_name_id IS 'The repository name as it was known at the time the event was created. It may have been renamed since.';",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000001
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000003,
				"Name": "insights series id",
				"UpQuery": "DELETE FROM series_points; -- affects dev environments only, others never had data in this table.\nALTER TABLE series_points ALTER COLUMN series_id TYPE text;\nALTER TABLE series_points ALTER COLUMN series_id SET NOT NULL;\n\n-- Give series_id a btree index since we'll be filtering on it very frequently.\nCREATE INDEX series_points_series_id_btree ON series_points USING btree (series_id);",
				"DownQuery": "",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000002
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000004,
				"Name": "no telemetry",
				"UpQuery": "-- This file is empty because it used to contain TimescaleDB specific migrations that have seen been deprecated.",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000003
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000005,
				"Name": "wipe data",
				"UpQuery": "-- We changed the default timeframe that the historical insights builder produces from:\n--\n-- 1 data point per week, for the last 52 weeks\n--\n-- To:\n--\n-- 1 data point per month, for the last 6 months\n--\n-- To avoid any confusion and just start fresh, we wipe all data here for now. This isn't\n-- needed in general when making this change, but is useful in this specific situation.\nDELETE FROM series_points;",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000004
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000006,
				"Name": "commit index",
				"UpQuery": "CREATE TABLE commit_index\n(\n\tcommitted_at TIMESTAMPTZ NOT NULL,\n\trepo_id INT NOT NULL,\n\tcommit_bytea bytea NOT NULL,\n\n\tPRIMARY KEY (committed_at, repo_id, commit_bytea)\n);\n\nCREATE INDEX commit_index_repo_id_idx ON commit_index USING btree (repo_id, committed_at);\n\nCREATE TABLE commit_index_metadata\n(\n    repo_id INT NOT NULL PRIMARY KEY,\n    enabled BOOLEAN NOT NULL DEFAULT 'y',\n    last_indexed_at TIMESTAMPTZ NOT NULL DEFAULT '1900-01-01'\n);",
				"DownQuery": "DROP TABLE IF EXISTS commit_index;\nDROP TABLE IF EXISTS commit_index_metadata;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000005
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000007,
				"Name": "series points index",
				"UpQuery": "CREATE INDEX IF NOT EXISTS series_points_series_id_repo_id_time_idx ON series_points (series_id, repo_id, time);",
				"DownQuery": "DROP INDEX IF EXISTS series_points_series_id_repo_id_time_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000006
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000008,
				"Name": "insights views series",
				"UpQuery": "CREATE TABLE insight_series\n(\n    id                      SERIAL    NOT NULL PRIMARY KEY,\n    series_id               TEXT      NOT NULL,\n    query                   TEXT      NOT NULL,\n    created_at              TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,\n    oldest_historical_at    TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP - INTERVAL '1 year',\n    last_recorded_at        TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP - INTERVAL '10 year',\n    next_recording_after    TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,\n    recording_interval_days INT       NOT NULL DEFAULT 1,\n    deleted_at              TIMESTAMP\n);\n\ncomment on table insight_series is 'Data series that comprise code insights.';\n\ncomment on column insight_series.id is 'Primary key ID of this series';\ncomment on column insight_series.series_id is 'Unique Series ID represents a globally unique identifier for this series.';\ncomment on column insight_series.query is 'Query string that generates this series';\ncomment on column insight_series.created_at is 'Timestamp when this series was created';\ncomment on column insight_series.oldest_historical_at is 'Timestamp representing the oldest point of which this series is backfilled.';\ncomment on column insight_series.last_recorded_at is 'Timestamp when this series was last recorded (non-historical).';\ncomment on column insight_series.next_recording_after is 'Timestamp when this series should next record (non-historical).';\ncomment on column insight_series.recording_interval_days is 'Number of days that should pass between recordings (non-historical)';\ncomment on column insight_series.deleted_at is 'Timestamp of a soft-delete of this row.';\n\nCREATE UNIQUE INDEX insight_series_series_id_unique_idx ON insight_series (series_id);\nCREATE INDEX insight_series_deleted_at_idx ON insight_series (deleted_at);\nCREATE INDEX insight_series_next_recording_after_idx ON insight_series (next_recording_after);\n\nCREATE TABLE insight_view\n(\n    id          SERIAL NOT NULL PRIMARY KEY,\n    title       TEXT,\n    description TEXT,\n    unique_id   TEXT NOT NULL\n);\n\ncomment on table insight_view is 'Views for insight data series. An insight view is an abstraction on top of an insight data series that allows for lightweight modifications to filters or metadata without regenerating the underlying series.';\n\ncomment on column insight_view.id is 'Primary key ID for this view';\ncomment on column insight_view.title is 'Title of the view. This may render in a chart depending on the view type.';\ncomment on column insight_view.description is 'Description of the view. This may render in a chart depending on the view type.';\ncomment on column insight_view.unique_id is 'Globally unique identifier for this view that is externally referencable.';\n\nCREATE UNIQUE INDEX insight_view_unique_id_unique_idx ON insight_view (unique_id);\n\nCREATE TABLE insight_view_series\n(\n    insight_view_id   INT NOT NULL,\n    insight_series_id INT NOT NULL,\n    label             TEXT,\n    stroke            TEXT,\n    PRIMARY KEY (insight_view_id, insight_series_id)\n);\n\ncomment on table insight_view_series is 'Join table to correlate data series with insight views';\ncomment on column insight_view_series.insight_view_id is 'Foreign key to insight view.';\ncomment on column insight_view_series.insight_series_id is 'Foreign key to insight data series.';\ncomment on column insight_view_series.label is 'Label text for this data series. This may render in a chart depending on the view type.';\ncomment on column insight_view_series.stroke is 'Stroke color metadata for this data series. This may render in a chart depending on the view type.';\n\nALTER TABLE insight_view_series\n    ADD FOREIGN KEY (insight_view_id) REFERENCES insight_view (id);\n\nALTER TABLE insight_view_series\n    ADD FOREIGN KEY (insight_series_id) REFERENCES insight_series (id);",
				"DownQuery": "DROP TABLE IF EXISTS insight_view_series;\nDROP TABLE IF EXISTS insight_view;\nDROP TABLE IF EXISTS insight_series;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000007
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000009,
				"Name": "backfiller state",
				"UpQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nALTER TABLE insight_series ADD COLUMN backfill_queued_at TIMESTAMP;\nCOMMENT ON COLUMN insight_series.series_id IS\n    'Timestamp that this series completed a full repository iteration for backfill. This flag has limited semantic value, and only means it tried to queue up queries for each repository. It does not guarantee success on those queries.';",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nALTER TABLE insight_series DROP COLUMN IF EXISTS backfill_queued_at;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000008
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000010,
				"Name": "series points reset",
				"UpQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\n-- Prior to 3.31 this table stored points in two formats. Historical points were stored in a compressed\n-- format where samples were only recorded if the underlying repository changed. After 3.31 we are changing\n-- the semantic to require full vectors for each data point. To avoid any incompatibilities and to prepare for beta\n-- we are going to reset the stored data and all of the underlying Timescale chunks back to zero.\n-- Note: This data is by design reproducible, so there is no risk of permanent data loss here. Any and all data\n-- will be queued and regenerated as soon as code insights starts up.\n\n-- Clean up the remaining records if any exist.\nTRUNCATE series_points CASCADE;\n\n-- There is the possibility that the commit index has fallen out of sync with the primary postgres database in 3.30 due\n-- to a data corruption issue. We will regenerate it to be sure it is healthy for beta.\nTRUNCATE commit_index;\nTRUNCATE commit_index_metadata;\n\n-- Update all of the underlying insights that may have been synced to reset metadata and rebuild their data.\nupdate insight_series set created_at = current_timestamp, backfill_queued_at = null, next_recording_after = date_trunc('month', current_date) + interval '1 month';\nCOMMIT;\n\n-- This file used to contain TimescaleDB specific migrations that have seen been deprecated.",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000009
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000011,
				"Name": "insights dirty queries",
				"UpQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nCREATE TABLE insight_dirty_queries\n(\n    id                SERIAL NOT NULL,\n    insight_series_id INT,\n    query             TEXT NOT NULL,\n    dirty_at          TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,\n    reason            TEXT NOT NULL,\n    for_time          TIMESTAMP NOT NULL,\n    PRIMARY KEY (id),\n    FOREIGN KEY (insight_series_id) REFERENCES insight_series(id)\n);\n\nCREATE INDEX insight_dirty_queries_insight_series_id_fk_idx ON insight_dirty_queries (insight_series_id);\n\nCOMMENT ON TABLE insight_dirty_queries IS 'Stores queries that were unsuccessful or otherwise flagged as incomplete or incorrect.';\n\nCOMMENT ON COLUMN insight_dirty_queries.query IS 'Sourcegraph query string that was executed.';\nCOMMENT ON COLUMN insight_dirty_queries.dirty_at IS 'Timestamp when this query was marked dirty.';\nCOMMENT ON COLUMN insight_dirty_queries.reason IS 'Human readable string indicating the reason the query was marked dirty.';\nCOMMENT ON COLUMN insight_dirty_queries.for_time IS 'Timestamp for which the original data point was recorded or intended to be recorded.';",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\nDROP TABLE IF EXISTS insight_dirty_queries;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000010
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000012,
				"Name": "insights snapshots",
				"UpQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nCREATE TABLE series_points_snapshots\n(\n    LIKE series_points INCLUDING DEFAULTS INCLUDING CONSTRAINTS INCLUDING INDEXES\n);\n\nCOMMENT ON TABLE series_points_snapshots is 'Stores ephemeral snapshot data of insight recordings.';\n\nalter table insight_series\n    add last_snapshot_at timestamp default (CURRENT_TIMESTAMP - '10 years'::interval);\n\nalter table insight_series\n    add next_snapshot_after timestamp default CURRENT_TIMESTAMP;",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nDROP TABLE series_points_snapshots;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000011
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000013,
				"Name": "insights view grants",
				"UpQuery": "CREATE TABLE IF NOT EXISTS insight_view_grants\n(\n    id              SERIAL\n        CONSTRAINT insight_view_grants_pk\n            PRIMARY KEY,\n    insight_view_id INTEGER NOT NULL\n        CONSTRAINT insight_view_grants_insight_view_id_fk\n            REFERENCES insight_view\n            ON DELETE CASCADE, -- These grants only have meaning in the context of a parent view.\n    user_id         INTEGER,\n    org_id          INTEGER,\n    global          BOOLEAN\n);\n\nCOMMENT ON TABLE insight_view_grants IS 'Permission grants for insight views. Each row should represent a unique principal (user, org, etc).';\nCOMMENT ON COLUMN insight_view_grants.user_id IS 'User ID that that receives this grant.';\nCOMMENT ON COLUMN insight_view_grants.org_id IS 'Org ID that that receives this grant.';\nCOMMENT ON COLUMN insight_view_grants.global IS 'Grant that does not belong to any specific principal and is granted to all users.';\n\nCREATE INDEX IF NOT EXISTS insight_view_grants_insight_view_id_index\n    ON insight_view_grants (insight_view_id);\n\nCREATE INDEX IF NOT EXISTS insight_view_grants_user_id_idx\n    ON insight_view_grants (user_id);\n\nCREATE INDEX IF NOT EXISTS insight_view_grants_org_id_idx\n    ON insight_view_grants (org_id);\n\nCREATE INDEX IF NOT EXISTS insight_view_grants_global_idx\n    ON insight_view_grants (global) WHERE global IS TRUE;\n\n\n-- This series join table is completely dependent on the existence of a parent view. So to simplify db operations\n-- and avoid dangling rows, adding cascade deletes to the insight view FK.\nALTER TABLE insight_view_series\n    DROP CONSTRAINT IF EXISTS insight_view_series_insight_view_id_fkey;\n\nALTER TABLE insight_view_series\n    ADD CONSTRAINT insight_view_series_insight_view_id_fkey\n        FOREIGN KEY (insight_view_id) REFERENCES insight_view\n            ON DELETE CASCADE;",
				"DownQuery": "DROP TABLE IF EXISTS insight_view_grants;\n\nALTER TABLE insight_view_series\n    DROP CONSTRAINT IF EXISTS insight_view_series_insight_view_id_fkey;\n\nALTER TABLE insight_view_series\n    ADD CONSTRAINT insight_view_series_insight_view_id_fkey\n        FOREIGN KEY (insight_view_id) REFERENCES insight_view;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000012
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000014,
				"Name": "dashboards",
				"UpQuery": "CREATE TABLE IF NOT EXISTS dashboard\n(\n    id                 SERIAL                  NOT NULL CONSTRAINT dashboard_pk PRIMARY KEY,\n    title              TEXT,\n    created_at         TIMESTAMP DEFAULT NOW() NOT NULL,\n    created_by_user_id INT,\n    last_updated_at    TIMESTAMP DEFAULT NOW() NOT NULL,\n    deleted_at         TIMESTAMP\n);\n\nCOMMENT ON TABLE dashboard IS 'Metadata for dashboards of insights';\n\nCOMMENT ON COLUMN dashboard.title IS 'Title of the dashboard';\n\nCOMMENT ON COLUMN dashboard.created_at IS 'Timestamp the dashboard was initially created.';\n\nCOMMENT ON COLUMN dashboard.created_by_user_id IS 'User that created the dashboard, if available.';\n\nCOMMENT ON COLUMN dashboard.last_updated_at IS 'Time the dashboard was last updated, either metadata or insights.';\n\nCOMMENT ON COLUMN dashboard.deleted_at IS 'Set to the time the dashboard was soft deleted.';\n\n\n\nCREATE TABLE IF NOT EXISTS dashboard_grants\n(\n    id           SERIAL CONSTRAINT dashboard_grants_pk PRIMARY KEY,\n    dashboard_id INTEGER NOT NULL CONSTRAINT dashboard_grants_dashboard_id_fk REFERENCES dashboard ON DELETE CASCADE, -- These grants only have meaning in the context of a parent dashboard.\n    user_id      INTEGER,\n    org_id       INTEGER,\n    global       BOOLEAN\n);\n\nCOMMENT ON TABLE dashboard_grants IS 'Permission grants for dashboards. Each row should represent a unique principal (user, org, etc).';\nCOMMENT ON COLUMN dashboard_grants.user_id IS 'User ID that that receives this grant.';\nCOMMENT ON COLUMN dashboard_grants.org_id IS 'Org ID that that receives this grant.';\nCOMMENT ON COLUMN dashboard_grants.global IS 'Grant that does not belong to any specific principal and is granted to all users.';\n\nCREATE INDEX IF NOT EXISTS dashboard_grants_dashboard_id_index\n    ON dashboard_grants (dashboard_id);\n\nCREATE INDEX IF NOT EXISTS dashboard_grants_user_id_idx\n    ON dashboard_grants (user_id);\n\nCREATE INDEX IF NOT EXISTS dashboard_grants_org_id_idx\n    ON dashboard_grants (org_id);\n\nCREATE INDEX IF NOT EXISTS dashboard_grants_global_idx\n    ON dashboard_grants (global) WHERE global IS TRUE;\n\nCREATE TABLE dashboard_insight_view\n(\n    id              SERIAL NOT NULL CONSTRAINT dashboard_insight_view_pk PRIMARY KEY,\n    dashboard_id    INT    NOT NULL CONSTRAINT dashboard_insight_view_dashboard_id_fk REFERENCES dashboard (id) ON DELETE CASCADE,\n    insight_view_id INT    NOT NULL CONSTRAINT dashboard_insight_view_insight_view_id_fk REFERENCES insight_view (id) ON DELETE CASCADE\n);\n\nCREATE INDEX IF NOT EXISTS dashboard_insight_view_insight_view_id_fk_idx ON dashboard_insight_view (insight_view_id);\nCREATE INDEX IF NOT EXISTS dashboard_insight_view_dashboard_id_fk_idx ON dashboard_insight_view (dashboard_id);",
				"DownQuery": "DROP TABLE IF EXISTS dashboard_grants;\n\t\t\tDROP TABLE IF EXISTS dashboard_insight_view;\n\t\t\tDROP TABLE IF EXISTS dashboard;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000013
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000015,
				"Name": "dashboard save",
				"UpQuery": "ALTER TABLE dashboard ADD COLUMN IF NOT EXISTS save BOOLEAN NOT NULL DEFAULT FALSE;\n\nCOMMENT ON COLUMN dashboard.save IS 'TEMPORARY Do not delete this dashboard when migrating settings.';",
				"DownQuery": "ALTER TABLE dashboard\nDROP COLUMN IF EXISTS save;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000014
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000016,
				"Name": "unique insights on dashboard",
				"UpQuery": "-- Remove any already existing duplicates.\nDELETE FROM\n    dashboard_insight_view a\n        USING dashboard_insight_view b\nWHERE\n\ta.id \u003e b.id\n    AND a.dashboard_id = b.dashboard_id\n    AND a.insight_view_id = b.insight_view_id;\n\nALTER TABLE dashboard_insight_view\nADD CONSTRAINT unique_dashboard_id_insight_view_id\nUNIQUE (dashboard_id, insight_view_id);",
				"DownQuery": "ALTER TABLE dashboard_insight_view\nDROP CONSTRAINT unique_dashboard_id_insight_view_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000015
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000017,
				"Name": "insight api",
				"UpQuery": "CREATE TYPE time_unit AS ENUM ('HOUR', 'DAY', 'WEEK', 'MONTH', 'YEAR');\nALTER TABLE insight_series\n    DROP COLUMN IF EXISTS recording_interval_days,\n    ADD COLUMN repositories TEXT[],\n    ADD COLUMN sample_interval_unit time_unit,\n    ADD COLUMN sample_interval_value int\n;\n\nALTER TABLE insight_view\n    ADD COLUMN default_filter_include_repo_regex text,\n    ADD COLUMN default_filter_exclude_repo_regex text\n;",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nALTER TABLE insight_series\n    DROP COLUMN IF EXISTS repositories,\n    DROP COLUMN IF EXISTS sample_interval_unit,\n    DROP COLUMN IF EXISTS sample_interval_value,\n    ADD COLUMN IF NOT EXISTS recording_interval_days int;\n\nALTER TABLE insight_view\n    DROP COLUMN IF EXISTS default_filter_include_repo_regex,\n    DROP COLUMN IF EXISTS default_filter_exclude_repo_regex;\nDROP TYPE IF EXISTS time_unit;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000016
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000018,
				"Name": "interval defaults",
				"UpQuery": "UPDATE insight_series\nSET sample_interval_unit = 'MONTH'\nWHERE sample_interval_unit IS NULL;\n\nUPDATE insight_series\nSET sample_interval_value = 1\nWHERE sample_interval_value IS NULL;\n\nALTER TABLE insight_series\n    ALTER COLUMN sample_interval_unit SET DEFAULT 'MONTH',\n    ALTER COLUMN sample_interval_unit SET NOT NULL,\n    ALTER COLUMN sample_interval_value SET DEFAULT '1',\n    ALTER COLUMN sample_interval_value SET NOT NULL;",
				"DownQuery": "ALTER TABLE IF EXISTS insight_series\n    ALTER COLUMN sample_interval_unit DROP DEFAULT,\n    ALTER COLUMN sample_interval_unit DROP NOT NULL,\n    ALTER COLUMN sample_interval_value DROP DEFAULT,\n    ALTER COLUMN sample_interval_value DROP NOT NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000017
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000019,
				"Name": "other threshold",
				"UpQuery": "ALTER TABLE insight_view\n    ADD COLUMN IF NOT EXISTS other_threshold FLOAT4;\n\nCOMMENT ON COLUMN insight_view.other_threshold IS 'Percent threshold for grouping series under \"other\"';",
				"DownQuery": "ALTER TABLE insight_view\nDROP COLUMN IF EXISTS other_threshold;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000018
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000020,
				"Name": "presentation type",
				"UpQuery": "CREATE TYPE presentation_type_enum AS ENUM ('LINE', 'PIE');\nALTER TABLE insight_view\n    ADD COLUMN IF NOT EXISTS presentation_type presentation_type_enum NOT NULL DEFAULT 'LINE',\n    ALTER COLUMN other_threshold type FLOAT8; -- Changing this because the GraphQL float type is a float64.\n\nCOMMENT ON COLUMN insight_view.presentation_type IS 'The basic presentation type for the insight view. (e.g Line, Pie, etc.)';",
				"DownQuery": "ALTER TABLE insight_view\n    ALTER COLUMN other_threshold TYPE FLOAT4,\n    DROP COLUMN IF EXISTS presentation_type;\n\nDROP TYPE presentation_type_enum;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000019
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000021,
				"Name": "add dirty query cascade",
				"UpQuery": "ALTER TABLE insight_dirty_queries\n    DROP CONSTRAINT insight_dirty_queries_insight_series_id_fkey,\n    ADD CONSTRAINT insight_dirty_queries_insight_series_id_fkey FOREIGN KEY (insight_series_id) REFERENCES insight_series (id) ON DELETE CASCADE;",
				"DownQuery": "ALTER TABLE insight_dirty_queries\n    DROP CONSTRAINT insight_dirty_queries_insight_series_id_fkey,\n    ADD CONSTRAINT insight_dirty_queries_insight_series_id_fkey FOREIGN KEY (insight_series_id) REFERENCES insight_series (id);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000020
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000022,
				"Name": "settings migration wipe definition tables",
				"UpQuery": "-- This will reset the state of the insight definition tables to empty so that the OOB migration can fully\n-- replicate and migrate all of the insights from settings without any duplication.\n\nTRUNCATE insight_view CASCADE;\nTRUNCATE insight_series CASCADE;\nTRUNCATE dashboard CASCADE;",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000021
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000023,
				"Name": "generate from query",
				"UpQuery": "ALTER TABLE IF EXISTS insight_series\n    ADD COLUMN IF NOT EXISTS generated_from_capture_groups BOOL NOT NULL DEFAULT FALSE;",
				"DownQuery": "ALTER TABLE IF EXISTS insight_series\n    DROP COLUMN IF EXISTS generated_from_capture_groups;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000022
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000024,
				"Name": "insight series expanded type info",
				"UpQuery": "ALTER TABLE IF EXISTS insight_series\n    ADD COLUMN IF NOT EXISTS generation_method TEXT,\n    ADD COLUMN IF NOT EXISTS just_in_time      BOOL;\n\nCOMMENT ON COLUMN insight_series.generation_method is 'Specifies the execution method for how this series is generated. This helps the system understand how to generate the time series data.';\nCOMMENT ON COLUMN insight_series.just_in_time is 'Specifies if the series should be resolved just in time at query time, or recorded in background processing.';\n\n-- This is just formalizing some of the logic that exists. It seems a little brittle, but that's why we are doing this now :)\nUPDATE insight_series\nSET generation_method =\n        CASE\n            WHEN (sample_interval_unit = 'MONTH' AND sample_interval_value = 0) THEN 'language-stats'\n            WHEN (generated_from_capture_groups IS TRUE) THEN 'search-compute'\n            ELSE 'search'\n            END;\n\nALTER TABLE IF EXISTS insight_series\n    ALTER COLUMN generation_method SET NOT NULL;\n\n-- This is using some slightly funky logic to ensure we are setting the just_in_time flag appropriately based on any existing series.\nUPDATE insight_series\nSET just_in_time =\n        CASE\n            WHEN (generation_method = 'search' AND (CARDINALITY(repositories) = 0 OR repositories IS NULL)) THEN FALSE\n            WHEN (generation_method = 'search' AND (CARDINALITY(repositories) \u003e 0)) THEN TRUE\n            WHEN (generation_method = 'language-stats' AND (CARDINALITY(repositories) \u003e 0)) THEN TRUE\n            WHEN (generation_method = 'search-compute' AND (CARDINALITY(repositories) = 0 OR repositories IS NULL))\n                THEN FALSE\n            WHEN (generation_method = 'search-compute' AND (CARDINALITY(repositories) \u003e 0)) THEN TRUE\n            ELSE FALSE\n            END;\n\nALTER TABLE IF EXISTS insight_series\n    ALTER COLUMN just_in_time SET NOT NULL,\n    ALTER COLUMN just_in_time SET DEFAULT FALSE;",
				"DownQuery": "ALTER TABLE insight_series\n    DROP COLUMN IF EXISTS generation_method;\nALTER TABLE insight_series\n    DROP COLUMN IF EXISTS just_in_time;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000023
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000025,
				"Name": "captured values series points",
				"UpQuery": "ALTER TABLE IF EXISTS series_points\n    ADD COLUMN IF NOT EXISTS capture TEXT;\n\nALTER TABLE IF EXISTS series_points_snapshots\n    ADD COLUMN IF NOT EXISTS capture TEXT;",
				"DownQuery": "ALTER TABLE IF EXISTS series_points\n    DROP COLUMN IF EXISTS capture;\n\nALTER TABLE IF EXISTS series_points_snapshots\n    DROP COLUMN IF EXISTS capture;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000024
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000026,
				"Name": "commit indexer debug fields",
				"UpQuery": "ALTER TABLE IF EXISTS commit_index\n    ADD COLUMN IF NOT EXISTS indexed_at  TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    ADD COLUMN IF NOT EXISTS debug_field TEXT;",
				"DownQuery": "ALTER TABLE IF EXISTS commit_index\n    DROP COLUMN IF EXISTS indexed_at,\n    DROP COLUMN IF EXISTS debug_field;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000025
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000027,
				"Name": "deprecate_timescale_tables",
				"UpQuery": "DO\n$$\n    DECLARE\n        tsdb_ext PG_EXTENSION%ROWTYPE;\n    BEGIN\n        -- To ensure we only excute this once (in case of manual executions) we will check if the TimescaleDB extension exists, and only if so\n        -- perform this table migration\n        SELECT * FROM pg_extension WHERE extname = 'timescaledb' LIMIT 1 INTO tsdb_ext;\n        IF NOT found THEN\n        ELSE\n            -- Perform a table swap - create a new table and rename the hypertable\n            CREATE TABLE series_points_vanilla\n            (\n                LIKE series_points INCLUDING ALL\n            );\n            ALTER    TABLE series_points\n                RENAME TO series_points_timescale;\n            ALTER TABLE series_points_vanilla\n                RENAME TO series_points;\n\n            -- Copy all of the data and insert into the new table.\n            INSERT INTO series_points (SELECT * FROM series_points_timescale);\n\n            -- Drop the old hypertable (the extension will propagate and drop all of the hypertable stuff)\n            DROP TABLE series_points_timescale CASCADE;\n\n            -- Last, remove the extension\n            DROP EXTENSION IF EXISTS timescaledb;\n        END IF;\n    END\n$$;",
				"DownQuery": "-- Nothing to do, actually. Even if we go backwards we aren't going to restore the Timescale tables.",
				"Privileged": true,
				"NonIdempotent": false,
				"Parents": [
					1000000026
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1646761143,
				"Name": "frozen_insights",
				"UpQuery": "ALTER TABLE IF EXISTS insight_view ADD COLUMN IF NOT EXISTS is_frozen BOOL NOT NULL DEFAULT FALSE;",
				"DownQuery": "ALTER TABLE IF EXISTS insight_view DROP COLUMN IF EXISTS is_frozen;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000027
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1647894746,
				"Name": "dashboard_type",
				"UpQuery": "ALTER TABLE IF EXISTS dashboard ADD COLUMN IF NOT EXISTS type TEXT DEFAULT 'standard'::text NOT NULL;",
				"DownQuery": "ALTER TABLE IF EXISTS dashboard DROP COLUMN IF EXISTS type;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1646761143
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1649801281,
				"Name": "context_filters",
				"UpQuery": "ALTER TABLE IF EXISTS insight_view ADD COLUMN IF NOT EXISTS default_filter_search_contexts TEXT[];",
				"DownQuery": "ALTER TABLE IF EXISTS insight_view DROP COLUMN IF EXISTS default_filter_search_contexts;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1647894746
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1651021000,
				"Name": "sort_series",
				"UpQuery": "DO $$\nBEGIN\n    CREATE TYPE series_sort_mode_enum AS ENUM (\n        'RESULT_COUNT',\n        'LEXICOGRAPHICAL',\n        'DATE_ADDED'\n    );\nEXCEPTION\n    WHEN duplicate_object THEN null;\nEND $$;\n\nDO $$\nBEGIN\n    CREATE TYPE series_sort_direction_enum AS ENUM (\n        'ASC',\n        'DESC'\n    );\nEXCEPTION\n    WHEN duplicate_object THEN null;\nEND $$;\n\nALTER TABLE IF EXISTS insight_view\n    ADD COLUMN IF NOT EXISTS series_sort_mode series_sort_mode_enum,\n    ADD COLUMN IF NOT EXISTS series_sort_direction series_sort_direction_enum,\n    ADD COLUMN IF NOT EXISTS series_limit INT;",
				"DownQuery": "ALTER TABLE IF EXISTS insight_view\n    DROP COLUMN IF EXISTS series_sort_mode,\n    DROP COLUMN IF EXISTS series_sort_direction,\n    DROP COLUMN IF EXISTS series_limit;\n\nDROP TYPE IF EXISTS series_sort_mode_enum;\nDROP TYPE IF EXISTS series_sort_direction_enum;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1649801281
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1652289966,
				"Name": "deprecate-search-stream-generation-method",
				"UpQuery": "UPDATE insight_series\n    SET generation_method = 'search'\n    WHERE generation_method = 'search-stream';",
				"DownQuery": "-- Update cannot be reverted, but this has minimal impact.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1649801281
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1656517037,
				"Name": "group_by",
				"UpQuery": "ALTER TABLE IF EXISTS insight_series ADD COLUMN IF NOT EXISTS group_by TEXT;",
				"DownQuery": "ALTER TABLE IF EXISTS insight_series DROP COLUMN IF EXISTS group_by;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1651021000,
					1652289966
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1656608833,
				"Name": "track_backfill_attempts",
				"UpQuery": "-- Perform migration here.\n--\nALTER TABLE IF EXISTS insight_series\n    ADD COLUMN IF NOT EXISTS backfill_attempts INT NOT NULL DEFAULT 0;",
				"DownQuery": "-- Undo the changes made in the up migration\nALTER TABLE IF EXISTS insight_series DROP COLUMN IF EXISTS backfill_attempts;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1651021000,
					1652289966
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1659572248,
				"Name": "refresh_scoped_insights",
				"UpQuery": "ALTER TABLE IF EXISTS insight_series\n    ADD COLUMN IF NOT EXISTS needs_migration bool;\n\n\nupdate insight_series\nset needs_migration = true\nwhere cardinality(repositories) \u003e 0 AND generation_method in ('search', 'search-compute') AND needs_migration is NULL;",
				"DownQuery": "-- take no action on down so that the next up will not trigger another refreshing of series data.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1656517037,
					1656608833
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1663626068,
				"Name": "backfill_completed_at",
				"UpQuery": "ALTER TABLE IF EXISTS insight_series\n    ADD COLUMN IF NOT EXISTS backfill_completed_at TIMESTAMP;",
				"DownQuery": "ALTER TABLE IF EXISTS insight_series DROP COLUMN IF EXISTS backfill_completed_at;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1659572248
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1664984848,
				"Name": "insights_scheduler_table",
				"UpQuery": "CREATE TABLE IF NOT EXISTS insights_background_jobs (\n                              id                SERIAL PRIMARY KEY,\n                              state             text DEFAULT 'queued',\n                              failure_message   text,\n                              queued_at         timestamp with time zone DEFAULT NOW(),\n                              started_at        timestamp with time zone,\n                              finished_at       timestamp with time zone,\n                              process_after     timestamp with time zone,\n                              num_resets        integer not null default 0,\n                              num_failures      integer not null default 0,\n                              last_heartbeat_at timestamp with time zone,\n                              execution_logs    json[],\n                              worker_hostname   text not null default '',\n                              cancel            boolean not null default false\n);\n\nCREATE INDEX IF NOT EXISTS insights_jobs_state_idx ON insights_background_jobs(state);",
				"DownQuery": "DROP TABLE IF EXISTS insights_background_jobs;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1663626068
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1665003565,
				"Name": "insights_backfill_scheduler_state",
				"UpQuery": "CREATE TABLE IF NOT EXISTS repo_iterator\n(\n    id               SERIAL\n        CONSTRAINT repo_iterator_pk PRIMARY KEY,\n    created_at       TIMESTAMP          DEFAULT NOW(),\n    started_at       TIMESTAMP,\n    completed_at     TIMESTAMP,\n    last_updated_at  TIMESTAMP NOT NULL DEFAULT NOW(),\n    runtime_duration BIGINT NOT NULL DEFAULT 0,\n    percent_complete DOUBLE PRECISION NOT NULL DEFAULT 0,\n    total_count            INT NOT NULL DEFAULT 0,\n    success_count INT NOT NULL DEFAULT 0,\n    repos            INT[],\n    repo_cursor      INT                DEFAULT 0\n);\n\nCREATE TABLE IF NOT EXISTS repo_iterator_errors\n(\n    id               SERIAL\n        CONSTRAINT repo_iterator_errors_pk PRIMARY KEY,\n    repo_iterator_id INT    NOT NULL,\n    repo_id          INT    NOT NULL,\n    error_message    TEXT[] NOT NULL,\n    failure_count    INT DEFAULT 1,\n\n    CONSTRAINT repo_iterator_fk FOREIGN KEY (repo_iterator_id) REFERENCES repo_iterator (id)\n);\n\nCREATE INDEX IF NOT EXISTS repo_iterator_errors_fk_idx\n    ON repo_iterator_errors (repo_iterator_id);",
				"DownQuery": "drop table if exists repo_iterator CASCADE;\ndrop table if exists repo_iterator_errors;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1664984848
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1665616961,
				"Name": "backfill_table",
				"UpQuery": "CREATE TABLE IF NOT EXISTS insight_series_backfill\n(\n    id               SERIAL\n        CONSTRAINT insight_series_backfill_pk PRIMARY KEY,\n    series_id        INT  NOT NULL,\n    repo_iterator_id INT,\n    estimated_cost   DOUBLE PRECISION,\n    state            TEXT NOT NULL DEFAULT 'new',\n\n    CONSTRAINT insight_series_backfill_series_id_fk\n        FOREIGN KEY (series_id) REFERENCES insight_series (id) ON DELETE CASCADE\n);\n\nALTER TABLE insights_background_jobs\n    ADD COLUMN IF NOT EXISTS backfill_id INT REFERENCES insight_series_backfill(id) ON DELETE CASCADE;\n\nCREATE OR REPLACE VIEW insights_jobs_backfill_in_progress AS\nSELECT jobs.*, isb.state AS backfill_state, isb.estimated_cost\nFROM insights_background_jobs jobs\n         JOIN insight_series_backfill isb ON jobs.backfill_id = isb.id\nWHERE isb.state = 'processing';\n\nCREATE OR REPLACE VIEW insights_jobs_backfill_new AS\nSELECT jobs.*, isb.state AS backfill_state, isb.estimated_cost\nFROM insights_background_jobs jobs\n         JOIN insight_series_backfill isb ON jobs.backfill_id = isb.id\nWHERE isb.state = 'new';",
				"DownQuery": "DROP VIEW IF EXISTS insights_jobs_backfill_in_progress;\n\nDROP VIEW IF EXISTS insights_jobs_backfill_new;\n\nALTER TABLE insights_background_jobs\n    DROP COLUMN IF EXISTS backfill_id;\n\nDROP TABLE IF EXISTS insight_series_backfill;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1665003565
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1665053848,
				"Name": "add_insight_series_recording_times",
				"UpQuery": "CREATE TABLE IF NOT EXISTS insight_series_recording_times (\n\tinsight_series_id int,\n\trecording_time timestamptz,\n\tsnapshot bool,\n\tUNIQUE (insight_series_id, recording_time),\n\tCONSTRAINT insight_series_id_fkey FOREIGN KEY (insight_series_id) REFERENCES insight_series (id) ON DELETE CASCADE\n);",
				"DownQuery": "DROP TABLE IF EXISTS insight_series_recording_times;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1664984848
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1666632478,
				"Name": "add_supports_augmentation_column",
				"UpQuery": "ALTER TABLE IF EXISTS insight_series\n\tADD COLUMN IF NOT EXISTS supports_augmentation BOOLEAN NOT NULL DEFAULT TRUE;\n\nUPDATE insight_series SET supports_augmentation = FALSE;",
				"DownQuery": "ALTER TABLE IF EXISTS insight_series DROP COLUMN IF EXISTS supports_augmentation;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1665053848,
					1665616961
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1666729025,
				"Name": "incomplete_points",
				"UpQuery": "CREATE TABLE IF NOT EXISTS insight_series_incomplete_points\n(\n    id        SERIAL CONSTRAINT insight_series_incomplete_points_pk PRIMARY KEY,\n    series_id INT                         NOT NULL,\n    reason    TEXT                        NOT NULL,\n    time      TIMESTAMP WITHOUT TIME ZONE NOT NULL,\n    repo_id   INT,\n\n    CONSTRAINT insight_series_incomplete_points_series_id_fk\n        FOREIGN KEY (series_id) REFERENCES insight_series (id) ON DELETE CASCADE\n);\n\nCREATE UNIQUE INDEX IF NOT EXISTS insight_series_incomplete_points_unique_idx\n    ON insight_series_incomplete_points (series_id, reason, time, repo_id);",
				"DownQuery": "DROP TABLE IF EXISTS insight_series_incomplete_points;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1666632478
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1667309737,
				"Name": "backfill cost groups",
				"UpQuery": "CREATE OR REPLACE VIEW insights_jobs_backfill_in_progress AS\nSELECT\n    jobs.*,\n    isb.state AS backfill_state,\n    isb.estimated_cost,\n    width_bucket(isb.estimated_cost, 0, max(isb.estimated_cost+1) over (), 4) cost_bucket\nFROM insights_background_jobs jobs\n         JOIN insight_series_backfill isb ON jobs.backfill_id = isb.id\nWHERE isb.state = 'processing';",
				"DownQuery": "-- Undo the changes made in the up migration\ndrop view if exists insights_jobs_backfill_in_progress;\n\nCREATE OR REPLACE VIEW insights_jobs_backfill_in_progress AS\nSELECT jobs.*, isb.state AS backfill_state, isb.estimated_cost\nFROM insights_background_jobs jobs\n         JOIN insight_series_backfill isb ON jobs.backfill_id = isb.id\nWHERE isb.state = 'processing';",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1666632478
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1670253074,
				"Name": "insight series repo criteria",
				"UpQuery": "ALTER TABLE IF EXISTS insight_series\n\tADD COLUMN IF NOT EXISTS repository_criteria text;\n\nCOMMENT ON COLUMN insight_series.repository_criteria IS 'The search criteria used to determine the repositories that are included in this series.';",
				"DownQuery": "ALTER TABLE IF EXISTS insight_series DROP COLUMN IF EXISTS repository_criteria;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1666729025,
					1667309737
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1672740238,
				"Name": "add_insights_data_pruning_jobs",
				"UpQuery": "CREATE TABLE IF NOT EXISTS insights_data_retention_jobs (\n       id                SERIAL PRIMARY KEY,\n       state             text DEFAULT 'queued',\n       failure_message   text,\n       queued_at         timestamp with time zone DEFAULT NOW(),\n       started_at        timestamp with time zone,\n       finished_at       timestamp with time zone,\n       process_after     timestamp with time zone,\n       num_resets        integer not null default 0,\n       num_failures      integer not null default 0,\n       last_heartbeat_at timestamp with time zone,\n       execution_logs    json[],\n       worker_hostname   text not null default '',\n       cancel            boolean not null default false,\n\n       series_id int not null\n);",
				"DownQuery": "DROP TABLE IF EXISTS insights_data_retention_jobs;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1670253074
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1672917501,
				"Name": "add_retention_tables",
				"UpQuery": "CREATE TABLE IF NOT EXISTS archived_series_points (\n    series_id text NOT NULL,\n    \"time\" timestamp with time zone NOT NULL,\n    value double precision NOT NULL,\n    repo_id integer,\n    repo_name_id integer,\n    original_repo_name_id integer,\n    capture text,\n    CONSTRAINT check_repo_fields_specifity CHECK ((((repo_id IS NULL) AND (repo_name_id IS NULL) AND (original_repo_name_id IS NULL)) OR ((repo_id IS NOT NULL) AND (repo_name_id IS NOT NULL) AND (original_repo_name_id IS NOT NULL)))),\n    CONSTRAINT insight_series_series_id_fkey FOREIGN KEY (series_id) REFERENCES insight_series (series_id) ON DELETE CASCADE \n); -- any new column added to series_points should be added here too. we add a foreign key constraint for deletion.\n\nCREATE TABLE IF NOT EXISTS archived_insight_series_recording_times (\n    insight_series_id integer not null,\n    recording_time timestamp with time zone not null,\n    snapshot boolean not null,\n    UNIQUE (insight_series_id, recording_time),\n    CONSTRAINT insight_series_id_fkey FOREIGN KEY (insight_series_id) REFERENCES insight_series (id) ON DELETE CASCADE\n); -- this structure should be kept the same as insight_series_recording_times.",
				"DownQuery": "DROP TABLE IF EXISTS archived_series_points;\nDROP TABLE IF EXISTS archived_insight_series_recording_times;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1672740238
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1672921606,
				"Name": "data_retention_jobs_series_metadata",
				"UpQuery": "ALTER TABLE IF EXISTS insights_data_retention_jobs\nADD COLUMN IF NOT EXISTS series_id_string text not null default '';",
				"DownQuery": "ALTER TABLE IF EXISTS insight_data_retention_jobs\nDROP COLUMN IF EXISTS series_id_string;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1672917501
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1674474174,
				"Name": "remove_dirty_queries_table",
				"UpQuery": "DROP TABLE IF EXISTS insight_dirty_queries;",
				"DownQuery": "CREATE TABLE IF NOT EXISTS insight_dirty_queries (\n    id integer PRIMARY KEY,\n    insight_series_id integer,\n    query text NOT NULL,\n    dirty_at timestamp without time zone DEFAULT CURRENT_TIMESTAMP NOT NULL,\n    reason text NOT NULL,\n    for_time timestamp without time zone NOT NULL\n);\n\n\nCREATE SEQUENCE IF NOT EXISTS insight_dirty_queries_id_seq\n    AS integer\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE IF EXISTS insight_dirty_queries_id_seq OWNED BY insight_dirty_queries.id;\n\nALTER TABLE IF EXISTS insight_dirty_queries ALTER COLUMN id SET DEFAULT nextval('insight_dirty_queries_id_seq'::regclass);\n\nALTER TABLE IF EXISTS insight_dirty_queries DROP CONSTRAINT IF EXISTS insight_dirty_queries_insight_series_id_fkey;\nALTER TABLE IF EXISTS insight_dirty_queries\n    ADD CONSTRAINT insight_dirty_queries_insight_series_id_fkey FOREIGN KEY (insight_series_id) REFERENCES insight_series(id) ON DELETE CASCADE;\n\nCREATE INDEX IF NOT EXISTS insight_dirty_queries_insight_series_id_fk_idx ON insight_dirty_queries USING btree (insight_series_id);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1672921606
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1675113463,
				"Name": "backfill_repo_query_selector",
				"UpQuery": "UPDATE insight_series\nSET repository_criteria = 'repo:.*'\nWHERE (CARDINALITY(repositories) = 0 AND generation_method != 'lang_stats' AND repository_criteria IS NULL);",
				"DownQuery": "-- no need for a down migration, this is entirely new data",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1674474174
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1675347548,
				"Name": "add_insight_view_num_samples",
				"UpQuery": "ALTER TABLE IF EXISTS insight_view\n\tADD COLUMN IF NOT EXISTS series_num_samples INT;",
				"DownQuery": "ALTER TABLE IF EXISTS insight_view\n\tDROP COLUMN IF EXISTS series_num_samples;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1675113463
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			}
		],
		"BoundsByRev": {
			"v3.20.0": {
				"RootID": 0,
				"LeafIDs": null,
				"PreCreation": true
			},
			"v3.21.0": {
				"RootID": 0,
				"LeafIDs": null,
				"PreCreation": true
			},
			"v3.22.0": {
				"RootID": 0,
				"LeafIDs": null,
				"PreCreation": true
			},
			"v3.23.0": {
				"RootID": 0,
				"LeafIDs": null,
				"PreCreation": true
			},
			"v3.24.0": {
				"RootID": 0,
				"LeafIDs": null,
				"PreCreation": true
			},
			"v3.25.0": {
				"RootID": -1000000000,
				"LeafIDs": [
					1000000004
				],
				"PreCreation": false
			},
			"v3.26.0": {
				"RootID": -1000000000,
				"LeafIDs": [
					1000000005
				],
				"PreCreation": false
			},
			"v3.27.0": {
				"RootID": -1000000000,
				"LeafIDs": [
					1000000005
				],
				"PreCreation": false
			},
			"v3.28.0": {
				"RootID": -1000000000,
				"LeafIDs": [
					1000000005
				],
				"PreCreation": false
			},
			"v3.29.0": {
				"RootID": -1000000000,
				"LeafIDs": [
					1000000006
				],
				"PreCreation": false
			},
			"v3.30.0": {
				"RootID": -1000000000,
				"LeafIDs": [
					1000000008
				],
				"PreCreation": false
			},
			"v3.31.0": {
				"RootID": -1000000000,
				"LeafIDs": [
					1000000011
				],
				"PreCreation": false
			},
			"v3.32.0": {
				"RootID": -1000000000,
				"LeafIDs": [
					1000000013
				],
				"PreCreation": false
			},
			"v3.33.0": {
				"RootID": -1000000000,
				"LeafIDs": [
					1000000016
				],
				"PreCreation": false
			},
			"v3.34.0": {
				"RootID": -1000000000,
				"LeafIDs": [
					1000000021
				],
				"PreCreation": false
			},
			"v3.35.0": {
				"RootID": -1000000000,
				"LeafIDs": [
					1000000024
				],
				"PreCreation": false
			},
			"v3.36.0": {
				"RootID": -1000000000,
				"LeafIDs": [
					1000000025
				],
				"PreCreation": false
			},
			"v3.37.0": {
				"RootID": -1000000000,
				"LeafIDs": [
					1000000027
				],
				"PreCreation": false
			},
			"v3.38.0": {
				"RootID": 1000000020,
				"LeafIDs": [
					1646761143
				],
				"PreCreation": false
			},
			"v3.39.0": {
				"RootID": 1000000020,
				"LeafIDs": [
					1649801281
				],
				"PreCreation": false
			},
			"v3.40.0": {
				"RootID": 1000000020,
				"LeafIDs": [
					1652289966
				],
				"PreCreation": false
			},
			"v3.41.0": {
				"RootID": 1000000026,
				"LeafIDs": [
					1651021000,
					1652289966
				],
				"PreCreation": false
			},
			"v3.42.0": {
				"RootID": 1000000027,
				"LeafIDs": [
					1656517037,
					1656608833
				],
				"PreCreation": false
			},
			"v3.43.0": {
				"RootID": 1000000027,
				"LeafIDs": [
					1659572248
				],
				"PreCreation": false
			},
			"v4.0.0": {
				"RootID": 1000000027,
				"LeafIDs": [
					1659572248
				],
				"PreCreation": false
			},
			"v4.1.0": {
				"RootID": 1000000027,
				"LeafIDs": [
					1665616961
				],
				"PreCreation": false
			},
			"v4.2.0": {
				"RootID": 1000000027,
				"LeafIDs": [
					1666729025,
					1667309737
				],
				"PreCreation": false
			},
			"v4.3.0": {
				"RootID": 1000000027,
				"LeafIDs": [
					1666729025,
					1667309737
				],
				"PreCreation": false
			},
			"v4.4.0": {
				"RootID": 1000000027,
				"LeafIDs": [
					1672921606
				],
				"PreCreation": false
			},
			"v4.5.0": {
				"RootID": 1000000027,
				"LeafIDs": [
					1675347548
				],
				"PreCreation": false
			}
		}
	},
	"codeintel": {
		"Definitions": [
			{
				"ID": -1000000000,
				"Name": "squashed migrations (privileged)",
				"UpQuery": "",
				"DownQuery": "",
				"Privileged": true,
				"NonIdempotent": false,
				"Parents": null,
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000000,
				"Name": "squashed migrations",
				"UpQuery": "-- empty migration",
				"DownQuery": "-- empty migration",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					-1000000000
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000001,
				"Name": "init",
				"UpQuery": "CREATE TABLE IF NOT EXISTS lsif_data_metadata (dump_id integer NOT NULL, num_result_chunks integer);\nCREATE TABLE IF NOT EXISTS lsif_data_documents (dump_id integer NOT NULL, path text NOT NULL, data bytea);\nCREATE TABLE IF NOT EXISTS lsif_data_result_chunks (dump_id integer NOT NULL, idx integer NOT NULL, data bytea);\nCREATE TABLE IF NOT EXISTS lsif_data_definitions (dump_id integer NOT NULL, scheme text NOT NULL, identifier text NOT NULL, data bytea);\nCREATE TABLE IF NOT EXISTS lsif_data_references (dump_id integer NOT NULL, scheme text NOT NULL, identifier text NOT NULL, data bytea);",
				"DownQuery": "DROP TABLE IF EXISTS lsif_data_metadata;\nDROP TABLE IF EXISTS lsif_data_documents;\nDROP TABLE IF EXISTS lsif_data_result_chunks;\nDROP TABLE IF EXISTS lsif_data_definitions;\nDROP TABLE IF EXISTS lsif_data_references;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000000
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000002,
				"Name": "add indexes",
				"UpQuery": "ALTER TABLE lsif_data_metadata ADD PRIMARY KEY (dump_id);\nALTER TABLE lsif_data_documents ADD PRIMARY KEY (dump_id, path);\nALTER TABLE lsif_data_result_chunks ADD PRIMARY KEY (dump_id, idx);\nALTER TABLE lsif_data_definitions ADD PRIMARY KEY (dump_id, scheme, identifier);\nALTER TABLE lsif_data_references ADD PRIMARY KEY (dump_id, scheme, identifier);",
				"DownQuery": "ALTER TABLE lsif_data_metadata DROP CONSTRAINT lsif_data_metadata_pkey;\nALTER TABLE lsif_data_documents DROP CONSTRAINT lsif_data_documents_pkey;\nALTER TABLE lsif_data_result_chunks DROP CONSTRAINT lsif_data_result_chunks_pkey;\nALTER TABLE lsif_data_definitions DROP CONSTRAINT lsif_data_definitions_pkey;\nALTER TABLE lsif_data_references DROP CONSTRAINT lsif_data_references_pkey;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000001
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000003,
				"Name": "pg stat statement ext",
				"UpQuery": "CREATE EXTENSION IF NOT EXISTS pg_stat_statements;",
				"DownQuery": "DROP EXTENSION IF EXISTS pg_stat_statements;",
				"Privileged": true,
				"NonIdempotent": false,
				"Parents": [
					1000000002
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000004,
				"Name": "comments",
				"UpQuery": "-- Comments removed\n-- Comments removed\n-- Comments removed\n\nCOMMENT ON TABLE lsif_data_documents IS 'Stores reference, hover text, moniker, and diagnostic data about a particular text document witin a dump.';\nCOMMENT ON COLUMN lsif_data_documents.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\nCOMMENT ON COLUMN lsif_data_documents.path IS 'The path of the text document relative to the associated dump root.';\nCOMMENT ON COLUMN lsif_data_documents.data IS 'A gob-encoded payload conforming to the [DocumentData](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.23/-/blob/enterprise/internal/codeintel/stores/lsifstore/types.go#L13:6) type.';\n\nCOMMENT ON TABLE lsif_data_metadata IS 'Stores the number of result chunks associated with a dump.';\nCOMMENT ON COLUMN lsif_data_metadata.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\nCOMMENT ON COLUMN lsif_data_metadata.num_result_chunks IS 'A bound of populated indexes in the lsif_data_result_chunks table for the associated dump. This value is used to hash identifiers into the result chunk index to which they belong.';\n\nCOMMENT ON TABLE lsif_data_result_chunks IS 'Associates result set identifiers with the (document path, range identifier) pairs that compose the set.';\nCOMMENT ON COLUMN lsif_data_result_chunks.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\nCOMMENT ON COLUMN lsif_data_result_chunks.idx IS 'The unique result chunk index within the associated dump. Every result set identifier present should hash to this index (modulo lsif_data_metadata.num_result_chunks).';\nCOMMENT ON COLUMN lsif_data_result_chunks.data IS 'A gob-encoded payload conforming to the [ResultChunkData](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.23/-/blob/enterprise/internal/codeintel/stores/lsifstore/types.go#L70:6) type.';\n\nCOMMENT ON TABLE lsif_data_definitions IS 'Associates (document, range) pairs with the import monikers attached to the range.';\nCOMMENT ON COLUMN lsif_data_definitions.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\nCOMMENT ON COLUMN lsif_data_definitions.scheme IS 'The moniker scheme.';\nCOMMENT ON COLUMN lsif_data_definitions.identifier IS 'The moniker identifier.';\nCOMMENT ON COLUMN lsif_data_definitions.data IS 'A gob-encoded payload conforming to an array of [LocationData](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.23/-/blob/enterprise/internal/codeintel/stores/lsifstore/types.go#L100:6) types.';\n\nCOMMENT ON TABLE lsif_data_references IS 'Associates (document, range) pairs with the export monikers attached to the range.';\nCOMMENT ON COLUMN lsif_data_references.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\nCOMMENT ON COLUMN lsif_data_references.scheme IS 'The moniker scheme.';\nCOMMENT ON COLUMN lsif_data_references.identifier IS 'The moniker identifier.';\nCOMMENT ON COLUMN lsif_data_references.data IS 'A gob-encoded payload conforming to an array of [LocationData](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.23/-/blob/enterprise/internal/codeintel/stores/lsifstore/types.go#L100:6) types.';",
				"DownQuery": "",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000003
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000005,
				"Name": "diagnostic counts",
				"UpQuery": "-- faster to supply default than manual update\nALTER TABLE lsif_data_documents ADD COLUMN schema_version int DEFAULT 1 NOT NULL;\nALTER TABLE lsif_data_documents ADD COLUMN num_diagnostics int DEFAULT 0 NOT NULL;\n\n-- drop default after all existing columns have been set\nALTER TABLE lsif_data_documents ALTER COLUMN schema_version DROP DEFAULT;\nALTER TABLE lsif_data_documents ALTER COLUMN num_diagnostics DROP DEFAULT;\n\nCOMMENT ON COLUMN lsif_data_documents.schema_version IS 'The schema version of this row - used to determine presence and encoding of data.';\nCOMMENT ON COLUMN lsif_data_documents.num_diagnostics IS 'The number of diagnostics stored in the data field.';",
				"DownQuery": "ALTER TABLE lsif_data_documents DROP COLUMN IF EXISTS schema_version;\nALTER TABLE lsif_data_documents DROP COLUMN IF EXISTS num_diagnostics;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000004
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000006,
				"Name": "document versions",
				"UpQuery": "CREATE TABLE lsif_data_documents_schema_versions (\n    dump_id integer NOT NULL,\n    min_schema_version integer,\n    max_schema_version integer\n);\nALTER TABLE lsif_data_documents_schema_versions ADD PRIMARY KEY (dump_id);\n\nCOMMENT ON TABLE lsif_data_documents_schema_versions IS 'Tracks the range of schema_versions for each upload in the lsif_data_documents table.';\nCOMMENT ON COLUMN lsif_data_documents_schema_versions.dump_id IS 'The identifier of the associated dump in the lsif_uploads table.';\nCOMMENT ON COLUMN lsif_data_documents_schema_versions.min_schema_version IS 'A lower-bound on the `lsif_data_documents.schema_version` where `lsif_data_documents.dump_id = dump_id`.';\nCOMMENT ON COLUMN lsif_data_documents_schema_versions.max_schema_version IS 'An upper-bound on the `lsif_data_documents.schema_version` where `lsif_data_documents.dump_id = dump_id`.';\n\n-- Ensure that there is a lsif_data_documents_schema_versions record for each distinct dump_id in\n-- the lsif_data_documents table. We are denormalizing schema counts here, but unfortunately we\n-- have already started the migration and don't have a known schema version to put here. This will\n-- preclude us from doing a distinct on dump_id, or reading from the smaller metadata table.\n--\n-- We'll group these now. This query takes around 8 seconds on the Cloud database, so this should\n-- not cause a problem in any known instance.\nINSERT INTO lsif_data_documents_schema_versions\n    SELECT\n        dump_id,\n        min(schema_version) as min_schema_version,\n        max(schema_version) as max_schema_version\n    FROM\n        lsif_data_documents\n    GROUP BY\n        dump_id\n    ORDER BY\n        dump_id;\n\n-- On every insert into lsif_data_documents, we need to make sure we have an associated row in the\n-- lsif_data_documents_schema_versions table. We do not currently care about cleaning the table up\n-- (we will do this asynchronously).\n--\n-- We use FOR EACH STATEMENT here because we batch insert into this table. Running the trigger per\n-- statement rather than per row will save a ton of extra work. Running over batch inserts lets us\n-- do a GROUP BY on the new table and effectively upsert our new ranges.\n--\n-- Note that the only places where data is _modified_ in this database is during migrations, which\n-- will necessarily update this table's bounds for any migrated index records.\n\nCREATE OR REPLACE FUNCTION update_lsif_data_documents_schema_versions_insert() RETURNS trigger AS $$ BEGIN\n    INSERT INTO\n        lsif_data_documents_schema_versions\n    SELECT\n        dump_id,\n        MIN(schema_version) as min_schema_version,\n        MAX(schema_version) as max_schema_version\n    FROM\n        newtab\n    GROUP BY\n        dump_id\n    ON CONFLICT (dump_id) DO UPDATE SET\n        -- Update with min(old_min, new_min) and max(old_max, new_max)\n        min_schema_version = LEAST(lsif_data_documents_schema_versions.min_schema_version, EXCLUDED.min_schema_version),\n        max_schema_version = GREATEST(lsif_data_documents_schema_versions.max_schema_version, EXCLUDED.max_schema_version);\n\n    RETURN NULL;\nEND $$ LANGUAGE plpgsql;\n\nCREATE TRIGGER lsif_data_documents_schema_versions_insert\nAFTER INSERT ON lsif_data_documents REFERENCING NEW TABLE AS newtab\nFOR EACH STATEMENT EXECUTE PROCEDURE update_lsif_data_documents_schema_versions_insert();",
				"DownQuery": "DROP TABLE lsif_data_documents_schema_versions;\nDROP TRIGGER lsif_data_documents_schema_versions_insert ON lsif_data_documents;\nDROP FUNCTION update_lsif_data_documents_schema_versions_insert;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000005
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000007,
				"Name": "definitions locations counts",
				"UpQuery": "-- faster to supply default than manual update\nALTER TABLE lsif_data_definitions ADD COLUMN schema_version int DEFAULT 1 NOT NULL;\nALTER TABLE lsif_data_definitions ADD COLUMN num_locations int DEFAULT 0 NOT NULL;\n\n-- drop default after all existing columns have been set\nALTER TABLE lsif_data_definitions ALTER COLUMN schema_version DROP DEFAULT;\nALTER TABLE lsif_data_definitions ALTER COLUMN num_locations DROP DEFAULT;\n\nCOMMENT ON COLUMN lsif_data_definitions.schema_version IS 'The schema version of this row - used to determine presence and encoding of data.';\nCOMMENT ON COLUMN lsif_data_definitions.num_locations IS 'The number of locations stored in the data field.';\n\nCREATE TABLE lsif_data_definitions_schema_versions (\n    dump_id integer NOT NULL,\n    min_schema_version integer,\n    max_schema_version integer\n);\nALTER TABLE lsif_data_definitions_schema_versions ADD PRIMARY KEY (dump_id);\n\nCOMMENT ON TABLE lsif_data_definitions_schema_versions IS 'Tracks the range of schema_versions for each upload in the lsif_data_definitions table.';\nCOMMENT ON COLUMN lsif_data_definitions_schema_versions.dump_id IS 'The identifier of the associated dump in the lsif_uploads table.';\nCOMMENT ON COLUMN lsif_data_definitions_schema_versions.min_schema_version IS 'A lower-bound on the `lsif_data_definitions.schema_version` where `lsif_data_definitions.dump_id = dump_id`.';\nCOMMENT ON COLUMN lsif_data_definitions_schema_versions.max_schema_version IS 'An upper-bound on the `lsif_data_definitions.schema_version` where `lsif_data_definitions.dump_id = dump_id`.';\n\n-- Ensure that there is a lsif_data_definitions_schema_versions record for each distinct dump_id in\n-- the lsif_data_definitions table. All definition versions in the database at this point necessarily\n-- have a schema_version of 1, so we can gather all of the dump ids quickly by scanning the metadata\n-- table. Grouping the definitions table directly would take too much time in a migration.\n\nINSERT INTO lsif_data_definitions_schema_versions\n    SELECT\n        dump_id,\n        1 AS min_schema_version,\n        1 AS max_schema_version\n    FROM\n        lsif_data_metadata\n    ORDER BY\n        lsif_data_metadata;\n\n-- On every insert into lsif_data_definitions, we need to make sure we have an associated row in the\n-- lsif_data_definitions_schema_versions table. We do not currently care about cleaning the table up\n-- (we will do this asynchronously).\n--\n-- We use FOR EACH STATEMENT here because we batch insert into this table. Running the trigger per\n-- statement rather than per row will save a ton of extra work. Running over batch inserts lets us\n-- do a GROUP BY on the new table and effectively upsert our new ranges.\n--\n-- Note that the only places where data is _modified_ in this database is during migrations, which\n-- will necessarily update this table's bounds for any migrated index records.\n\nCREATE OR REPLACE FUNCTION update_lsif_data_definitions_schema_versions_insert() RETURNS trigger AS $$ BEGIN\n    INSERT INTO\n        lsif_data_definitions_schema_versions\n    SELECT\n        dump_id,\n        MIN(schema_version) as min_schema_version,\n        MAX(schema_version) as max_schema_version\n    FROM\n        newtab\n    GROUP BY\n        dump_id\n    ON CONFLICT (dump_id) DO UPDATE SET\n        -- Update with min(old_min, new_min) and max(old_max, new_max)\n        min_schema_version = LEAST(lsif_data_definitions_schema_versions.min_schema_version, EXCLUDED.min_schema_version),\n        max_schema_version = GREATEST(lsif_data_definitions_schema_versions.max_schema_version, EXCLUDED.max_schema_version);\n\n    RETURN NULL;\nEND $$ LANGUAGE plpgsql;\n\nCREATE TRIGGER lsif_data_definitions_schema_versions_insert\nAFTER INSERT ON lsif_data_definitions REFERENCING NEW TABLE AS newtab\nFOR EACH STATEMENT EXECUTE PROCEDURE update_lsif_data_definitions_schema_versions_insert();",
				"DownQuery": "DROP TABLE lsif_data_definitions_schema_versions;\nDROP TRIGGER lsif_data_definitions_schema_versions_insert ON lsif_data_definitions;\nDROP FUNCTION update_lsif_data_definitions_schema_versions_insert;\n\nALTER TABLE lsif_data_definitions DROP COLUMN IF EXISTS schema_version;\nALTER TABLE lsif_data_definitions DROP COLUMN IF EXISTS num_locations;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000006
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000008,
				"Name": "references locations counts",
				"UpQuery": "-- faster to supply default than manual update\nALTER TABLE lsif_data_references ADD COLUMN schema_version int DEFAULT 1 NOT NULL;\nALTER TABLE lsif_data_references ADD COLUMN num_locations int DEFAULT 0 NOT NULL;\n\n-- drop default after all existing columns have been set\nALTER TABLE lsif_data_references ALTER COLUMN schema_version DROP DEFAULT;\nALTER TABLE lsif_data_references ALTER COLUMN num_locations DROP DEFAULT;\n\nCOMMENT ON COLUMN lsif_data_references.schema_version IS 'The schema version of this row - used to determine presence and encoding of data.';\nCOMMENT ON COLUMN lsif_data_references.num_locations IS 'The number of locations stored in the data field.';\n\nCREATE TABLE lsif_data_references_schema_versions (\n    dump_id integer NOT NULL,\n    min_schema_version integer,\n    max_schema_version integer\n);\nALTER TABLE lsif_data_references_schema_versions ADD PRIMARY KEY (dump_id);\n\nCOMMENT ON TABLE lsif_data_references_schema_versions IS 'Tracks the range of schema_versions for each upload in the lsif_data_references table.';\nCOMMENT ON COLUMN lsif_data_references_schema_versions.dump_id IS 'The identifier of the associated dump in the lsif_uploads table.';\nCOMMENT ON COLUMN lsif_data_references_schema_versions.min_schema_version IS 'A lower-bound on the `lsif_data_references.schema_version` where `lsif_data_references.dump_id = dump_id`.';\nCOMMENT ON COLUMN lsif_data_references_schema_versions.max_schema_version IS 'An upper-bound on the `lsif_data_references.schema_version` where `lsif_data_references.dump_id = dump_id`.';\n\n-- Ensure that there is a lsif_data_references_schema_versions record for each distinct dump_id in\n-- the lsif_data_references table. All reference versions in the database at this point necessarily\n-- have a schema_version of 1, so we can gather all of the dump ids quickly by scanning the metadata\n-- table. Grouping the references table directly would take too much time in a migration.\n\nINSERT INTO lsif_data_references_schema_versions\n    SELECT\n        dump_id,\n        1 AS min_schema_version,\n        1 AS max_schema_version\n    FROM\n        lsif_data_metadata\n    ORDER BY\n        lsif_data_metadata;\n\n-- On every insert into lsif_data_references, we need to make sure we have an associated row in the\n-- lsif_data_references_schema_versions table. We do not currently care about cleaning the table up\n-- (we will do this asynchronously).\n--\n-- We use FOR EACH STATEMENT here because we batch insert into this table. Running the trigger per\n-- statement rather than per row will save a ton of extra work. Running over batch inserts lets us\n-- do a GROUP BY on the new table and effectively upsert our new ranges.\n--\n-- Note that the only places where data is _modified_ in this database is during migrations, which\n-- will necessarily update this table's bounds for any migrated index records.\n\nCREATE OR REPLACE FUNCTION update_lsif_data_references_schema_versions_insert() RETURNS trigger AS $$ BEGIN\n    INSERT INTO\n        lsif_data_references_schema_versions\n    SELECT\n        dump_id,\n        MIN(schema_version) as min_schema_version,\n        MAX(schema_version) as max_schema_version\n    FROM\n        newtab\n    GROUP BY\n        dump_id\n    ON CONFLICT (dump_id) DO UPDATE SET\n        -- Update with min(old_min, new_min) and max(old_max, new_max)\n        min_schema_version = LEAST(lsif_data_references_schema_versions.min_schema_version, EXCLUDED.min_schema_version),\n        max_schema_version = GREATEST(lsif_data_references_schema_versions.max_schema_version, EXCLUDED.max_schema_version);\n\n    RETURN NULL;\nEND $$ LANGUAGE plpgsql;\n\nCREATE TRIGGER lsif_data_references_schema_versions_insert\nAFTER INSERT ON lsif_data_references REFERENCING NEW TABLE AS newtab\nFOR EACH STATEMENT EXECUTE PROCEDURE update_lsif_data_references_schema_versions_insert();",
				"DownQuery": "DROP TABLE lsif_data_references_schema_versions;\nDROP TRIGGER lsif_data_references_schema_versions_insert ON lsif_data_references;\nDROP FUNCTION update_lsif_data_references_schema_versions_insert;\n\nALTER TABLE lsif_data_references DROP COLUMN IF EXISTS schema_version;\nALTER TABLE lsif_data_references DROP COLUMN IF EXISTS num_locations;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000007
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000009,
				"Name": "documents schema version index",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS lsif_data_documents_dump_id_schema_version ON lsif_data_documents (dump_id, schema_version);",
				"DownQuery": "DROP INDEX IF EXISTS lsif_data_documents_dump_id_schema_version;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000008
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "lsif_data_documents",
					"IndexName": "lsif_data_documents_dump_id_schema_version"
				}
			},
			{
				"ID": 1000000010,
				"Name": "definitions schema version index",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS lsif_data_definitions_dump_id_schema_version ON lsif_data_definitions (dump_id, schema_version);",
				"DownQuery": "DROP INDEX IF EXISTS lsif_data_definitions_dump_id_schema_version;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000009
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "lsif_data_definitions",
					"IndexName": "lsif_data_definitions_dump_id_schema_version"
				}
			},
			{
				"ID": 1000000011,
				"Name": "references schema version index",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS lsif_data_references_dump_id_schema_version ON lsif_data_references (dump_id, schema_version);",
				"DownQuery": "DROP INDEX IF EXISTS lsif_data_references_dump_id_schema_version;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000010
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "lsif_data_references",
					"IndexName": "lsif_data_references_dump_id_schema_version"
				}
			},
			{
				"ID": 1000000012,
				"Name": "delete missing schema versions",
				"UpQuery": "-- Delete data from the schema version count tables that was inserted from the metadata table but does\n-- not actually exist in the table that it shadows. This should only delete some records that we inserted\n-- in 1000000007_definitions_locations_counts.up.sql and 1000000008_references_locations_counts.up.sql.\n\nDELETE FROM lsif_data_documents_schema_versions sv WHERE NOT EXISTS (SELECT 1 FROM lsif_data_documents d WHERE d.dump_id = sv.dump_id);\nDELETE FROM lsif_data_definitions_schema_versions sv WHERE NOT EXISTS (SELECT 1 FROM lsif_data_definitions d WHERE d.dump_id = sv.dump_id);\nDELETE FROM lsif_data_references_schema_versions sv WHERE NOT EXISTS (SELECT 1 FROM lsif_data_references r WHERE r.dump_id = sv.dump_id);",
				"DownQuery": "-- Nothing to do.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000011
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000013,
				"Name": "split document payload",
				"UpQuery": "-- Add new nullable columns\nALTER TABLE lsif_data_documents ADD COLUMN ranges bytea;\nALTER TABLE lsif_data_documents ADD COLUMN hovers bytea;\nALTER TABLE lsif_data_documents ADD COLUMN monikers bytea;\nALTER TABLE lsif_data_documents ADD COLUMN packages bytea;\nALTER TABLE lsif_data_documents ADD COLUMN diagnostics bytea;\n\n-- Add new comments\nCOMMENT ON COLUMN lsif_data_documents.ranges IS 'A gob-encoded payload conforming to the [Ranges](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.26/-/blob/enterprise/lib/codeintel/semantic/types.go#L14:2) field of the DocumentDatatype.';\nCOMMENT ON COLUMN lsif_data_documents.hovers IS 'A gob-encoded payload conforming to the [HoversResults](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.26/-/blob/enterprise/lib/codeintel/semantic/types.go#L15:2) field of the DocumentDatatype.';\nCOMMENT ON COLUMN lsif_data_documents.monikers IS 'A gob-encoded payload conforming to the [Monikers](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.26/-/blob/enterprise/lib/codeintel/semantic/types.go#L16:2) field of the DocumentDatatype.';\nCOMMENT ON COLUMN lsif_data_documents.packages IS 'A gob-encoded payload conforming to the [PackageInformation](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.26/-/blob/enterprise/lib/codeintel/semantic/types.go#L17:2) field of the DocumentDatatype.';\nCOMMENT ON COLUMN lsif_data_documents.diagnostics IS 'A gob-encoded payload conforming to the [Diagnostics](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.26/-/blob/enterprise/lib/codeintel/semantic/types.go#L18:2) field of the DocumentDatatype.';\n\n-- Update outdated comments\nCOMMENT ON COLUMN lsif_data_documents.data IS 'A gob-encoded payload conforming to the [DocumentData](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.26/-/blob/enterprise/lib/codeintel/semantic/types.go#L13:6) type. This field is being migrated across ranges, hovers, monikers, packages, and diagnostics columns and will be removed in a future release of Sourcegraph.';\nCOMMENT ON COLUMN lsif_data_result_chunks.data IS 'A gob-encoded payload conforming to the [ResultChunkData](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.26/-/blob/enterprise/lib/codeintel/semantic/types.go#L76:6) type.';\nCOMMENT ON COLUMN lsif_data_definitions.data IS 'A gob-encoded payload conforming to an array of [LocationData](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.26/-/blob/enterprise/lib/codeintel/semantic/types.go#L106:6) types.';\nCOMMENT ON COLUMN lsif_data_references.data IS 'A gob-encoded payload conforming to an array of [LocationData](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.26/-/blob/enterprise/lib/codeintel/semantic/types.go#L106:6) types.';",
				"DownQuery": "ALTER TABLE lsif_data_documents DROP COLUMN ranges;\nALTER TABLE lsif_data_documents DROP COLUMN hovers;\nALTER TABLE lsif_data_documents DROP COLUMN monikers;\nALTER TABLE lsif_data_documents DROP COLUMN packages;\nALTER TABLE lsif_data_documents DROP COLUMN diagnostics;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000012
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000014,
				"Name": "schema version index",
				"UpQuery": "CREATE INDEX IF NOT EXISTS lsif_data_documents_schema_versions_dump_id_schema_version_bounds ON lsif_data_documents_schema_versions (dump_id, min_schema_version, max_schema_version);\nCREATE INDEX IF NOT EXISTS lsif_data_definitions_schema_versions_dump_id_schema_version_bounds ON lsif_data_definitions_schema_versions (dump_id, min_schema_version, max_schema_version);\nCREATE INDEX IF NOT EXISTS lsif_data_references_schema_versions_dump_id_schema_version_bounds ON lsif_data_references_schema_versions (dump_id, min_schema_version, max_schema_version);",
				"DownQuery": "DROP INDEX IF EXISTS lsif_data_documents_schema_versions_dump_id_schema_version_bounds;\nDROP INDEX IF EXISTS lsif_data_definitions_schema_versions_dump_id_schema_version_bounds;\nDROP INDEX IF EXISTS lsif_data_references_schema_versions_dump_id_schema_version_bounds;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000013
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000015,
				"Name": "lsif documentation",
				"UpQuery": "CREATE TABLE IF NOT EXISTS lsif_data_documentation_pages (\n    dump_id integer NOT NULL,\n    path_id TEXT,\n    data bytea\n);\n\nALTER TABLE lsif_data_documentation_pages ADD PRIMARY KEY (dump_id, path_id);\n\nCOMMENT ON TABLE lsif_data_documentation_pages IS 'Associates documentation pathIDs to their documentation page hierarchy chunk.';\nCOMMENT ON COLUMN lsif_data_documentation_pages.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\nCOMMENT ON COLUMN lsif_data_documentation_pages.path_id IS 'The documentation page path ID, see see GraphQL codeintel.schema:documentationPage for what this is.';\nCOMMENT ON COLUMN lsif_data_documentation_pages.data IS 'A gob-encoded payload conforming to a `type DocumentationPageData struct` pointer (lib/codeintel/semantic/types.go)';",
				"DownQuery": "DROP TABLE IF EXISTS lsif_data_documentation_pages;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000014
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000016,
				"Name": "apidocs clean",
				"UpQuery": "-- PR #22080 landed a number of backwards-incompatible API docs data changes and given how early\n-- stages API docs is, we don't care to maintain backwards compat with the old data and choose to\n-- instead start from scratch with indexing again (not many repos have been indexed with API docs,\n-- anyway.)\nTRUNCATE lsif_data_documentation_pages;",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000015
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000017,
				"Name": "lsif documentation path info",
				"UpQuery": "CREATE TABLE IF NOT EXISTS lsif_data_documentation_path_info (\n    dump_id integer NOT NULL,\n    path_id TEXT,\n    data bytea\n);\n\nALTER TABLE lsif_data_documentation_path_info ADD PRIMARY KEY (dump_id, path_id);\n\nCOMMENT ON TABLE lsif_data_documentation_path_info IS 'Associates documentation page pathIDs to information about what is at that pathID, its immediate children, etc.';\nCOMMENT ON COLUMN lsif_data_documentation_path_info.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\nCOMMENT ON COLUMN lsif_data_documentation_path_info.path_id IS 'The documentation page path ID, see see GraphQL codeintel.schema:documentationPage for what this is.';\nCOMMENT ON COLUMN lsif_data_documentation_path_info.data IS 'A gob-encoded payload conforming to a `type DocumentationPathInoData struct` pointer (lib/codeintel/semantic/types.go)';",
				"DownQuery": "DROP TABLE IF EXISTS lsif_data_documentation_path_info;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000016
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000018,
				"Name": "lsif documentation mappings",
				"UpQuery": "CREATE TABLE IF NOT EXISTS lsif_data_documentation_mappings (\n    dump_id integer NOT NULL,\n    path_id TEXT NOT NULL,\n    result_id integer NOT NULL\n);\n\nALTER TABLE lsif_data_documentation_mappings ADD PRIMARY KEY (dump_id, path_id);\n\nCREATE UNIQUE INDEX lsif_data_documentation_mappings_inverse_unique_idx ON lsif_data_documentation_mappings(dump_id, result_id);\n\nCOMMENT ON TABLE lsif_data_documentation_mappings IS 'Maps documentation path IDs to their corresponding integral documentationResult vertex IDs, which are unique within a dump.';\nCOMMENT ON COLUMN lsif_data_documentation_mappings.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\nCOMMENT ON COLUMN lsif_data_documentation_mappings.path_id IS 'The documentation page path ID, see see GraphQL codeintel.schema:documentationPage for what this is.';\nCOMMENT ON COLUMN lsif_data_documentation_mappings.result_id IS 'The documentationResult vertex ID.';",
				"DownQuery": "DROP TABLE IF EXISTS lsif_data_documentation_mappings;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000017
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000019,
				"Name": "documentation path mapping",
				"UpQuery": "-- Add nullable file_path column, for mapping documentationResult ID -\u003e file_path\nALTER TABLE lsif_data_documentation_mappings ADD COLUMN file_path text;\nCOMMENT ON COLUMN lsif_data_documentation_mappings.file_path IS 'The document file path for the documentationResult, if any. e.g. the path to the file where the symbol described by this documentationResult is located, if it is a symbol.';",
				"DownQuery": "ALTER TABLE lsif_data_documentation_mappings DROP COLUMN file_path;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000018
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000020,
				"Name": "lsif data documentation search",
				"UpQuery": "CREATE EXTENSION IF NOT EXISTS pg_trgm;\n\nALTER TABLE lsif_data_documentation_pages ADD COLUMN search_indexed boolean DEFAULT 'false';\n\n-- We're going to create the new lsif_data_documentation_search_* tables. These tables will have a\n-- trigram index and will be data decoded from the GOB encoded lsif_data_documentation_pages.data\n-- field, hence an OOB migration is needed as that table is quite large and not decodable in SQL\n-- alone.\nCREATE TABLE IF NOT EXISTS lsif_data_documentation_search_public (\n    -- Metadata fields\n    dump_id integer NOT NULL,\n    repo_id integer NOT NULL,\n    path_id TEXT NOT NULL,\n    detail TEXT NOT NULL,\n\n    -- FTS-enabled fields\n    lang TEXT NOT NULL,\n    repo_name TEXT NOT NULL,\n    search_key TEXT NOT NULL,\n    label TEXT NOT NULL,\n    tags TEXT NOT NULL,\n\n    PRIMARY KEY (dump_id, path_id)\n);\n\nCREATE INDEX IF NOT EXISTS lsif_data_documentation_search_public_repo_id_idx ON lsif_data_documentation_search_public USING BTREE(repo_id);\nCREATE INDEX IF NOT EXISTS lsif_data_documentation_search_public_lang_trgm ON lsif_data_documentation_search_public USING gin(lang gin_trgm_ops);\nCREATE INDEX IF NOT EXISTS lsif_data_documentation_search_public_repo_name_trgm ON lsif_data_documentation_search_public USING gin(repo_name gin_trgm_ops);\nCREATE INDEX IF NOT EXISTS lsif_data_documentation_search_public_search_key_trgm ON lsif_data_documentation_search_public USING gin(search_key gin_trgm_ops);\nCREATE INDEX IF NOT EXISTS lsif_data_documentation_search_public_label_trgm ON lsif_data_documentation_search_public USING gin(label gin_trgm_ops);\nCREATE INDEX IF NOT EXISTS lsif_data_documentation_search_public_tags_trgm ON lsif_data_documentation_search_public USING gin(tags gin_trgm_ops);\n\nCOMMENT ON TABLE lsif_data_documentation_search_public IS 'A trigram index over documentation for search (public repos only)';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.repo_id IS 'The repo ID, from the main app DB repo table. Used to search over a select set of repos by ID.';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.path_id IS 'The fully qualified documentation page path ID, e.g. including \"#section\". See GraphQL codeintel.schema:documentationPage for what this is.';\n\nCOMMENT ON COLUMN lsif_data_documentation_search_public.lang IS 'The lowercase language name (go, java, etc.) OR, if unknown, the LSIF indexer name';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.repo_name IS 'The name of the repository containing this search key.';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.search_key IS 'The search key generated by the indexer, e.g. mux.Router.ServeHTTP. It is language-specific, and likely unique within a repository (but not always.) See protocol/documentation.go:Documentation.SearchKey';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.label IS 'The label string of the result, e.g. a one-line function signature. See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.detail IS 'The detail string (e.g. the full function signature and its docs). See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.tags IS 'A space separated list of tags from the documentation node. See protocol/documentation.go:Documentation';\n\n-- Same exact thing as above, but for \"_private\" repos.\nCREATE TABLE IF NOT EXISTS lsif_data_documentation_search_private (\n    -- Metadata fields\n    dump_id integer NOT NULL,\n    repo_id integer NOT NULL,\n    path_id TEXT NOT NULL,\n    detail TEXT NOT NULL,\n\n    -- FTS-enabled fields\n    lang TEXT NOT NULL,\n    repo_name TEXT NOT NULL,\n    search_key TEXT NOT NULL,\n    label TEXT NOT NULL,\n    tags TEXT NOT NULL,\n\n    PRIMARY KEY (dump_id, path_id)\n);\n\nCREATE INDEX IF NOT EXISTS lsif_data_documentation_search_private_repo_id_idx ON lsif_data_documentation_search_private USING BTREE(repo_id);\nCREATE INDEX IF NOT EXISTS lsif_data_documentation_search_private_lang_trgm ON lsif_data_documentation_search_private USING gin(lang gin_trgm_ops);\nCREATE INDEX IF NOT EXISTS lsif_data_documentation_search_private_repo_name_trgm ON lsif_data_documentation_search_private USING gin(repo_name gin_trgm_ops);\nCREATE INDEX IF NOT EXISTS lsif_data_documentation_search_private_search_key_trgm ON lsif_data_documentation_search_private USING gin(search_key gin_trgm_ops);\nCREATE INDEX IF NOT EXISTS lsif_data_documentation_search_private_label_trgm ON lsif_data_documentation_search_private USING gin(label gin_trgm_ops);\nCREATE INDEX IF NOT EXISTS lsif_data_documentation_search_private_tags_trgm ON lsif_data_documentation_search_private USING gin(tags gin_trgm_ops);\n\nCOMMENT ON TABLE lsif_data_documentation_search_private IS 'A trigram index over documentation for search (private repos only)';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.repo_id IS 'The repo ID, from the main app DB repo table. Used to search over a select set of repos by ID.';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.path_id IS 'The fully qualified documentation page path ID, e.g. including \"#section\". See GraphQL codeintel.schema:documentationPage for what this is.';\n\nCOMMENT ON COLUMN lsif_data_documentation_search_private.lang IS 'The lowercase language name (go, java, etc.) OR, if unknown, the LSIF indexer name';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.repo_name IS 'The name of the repository containing this search key.';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.search_key IS 'The search key generated by the indexer, e.g. mux.Router.ServeHTTP. It is language-specific, and likely unique within a repository (but not always.) See protocol/documentation.go:Documentation.SearchKey';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.label IS 'The label string of the result, e.g. a one-line function signature. See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.detail IS 'The detail string (e.g. the full function signature and its docs). See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.tags IS 'A space separated list of tags from the documentation node. See protocol/documentation.go:Documentation';",
				"DownQuery": "ALTER TABLE lsif_data_documentation_pages DROP COLUMN search_indexed;\nDROP TABLE IF EXISTS lsif_data_documentation_search;",
				"Privileged": true,
				"NonIdempotent": false,
				"Parents": [
					1000000019
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000021,
				"Name": "reverted",
				"UpQuery": "-- Empty migration, this migration was reverted: https://github.com/sourcegraph/sourcegraph/pull/25715",
				"DownQuery": "-- Empty migration, this migration was reverted: https://github.com/sourcegraph/sourcegraph/pull/25715",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000020
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000022,
				"Name": "undo apidocs root column",
				"UpQuery": "-- Undo the changes corresponding to https://github.com/sourcegraph/sourcegraph/pull/25715\nALTER TABLE lsif_data_documentation_search_public DROP COLUMN IF EXISTS dump_root;\nALTER TABLE lsif_data_documentation_search_private DROP COLUMN IF EXISTS dump_root;",
				"DownQuery": "-- Nothing to do, the up migration undid changes previously made.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000021
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000023,
				"Name": "apidocs add dump root column",
				"UpQuery": "ALTER TABLE lsif_data_documentation_search_public ADD COLUMN dump_root TEXT NOT NULL DEFAULT '';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.dump_root IS 'Identical to lsif_dumps.root; The working directory of the indexer image relative to the repository root.';\nCREATE INDEX lsif_data_documentation_search_public_dump_root_idx ON lsif_data_documentation_search_public USING BTREE(dump_root);\n\nALTER TABLE lsif_data_documentation_search_private ADD COLUMN dump_root TEXT NOT NULL DEFAULT '';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.dump_root IS 'Identical to lsif_dumps.root; The working directory of the indexer image relative to the repository root.';\nCREATE INDEX lsif_data_documentation_search_private_dump_root_idx ON lsif_data_documentation_search_public USING BTREE(dump_root);\n\n-- Truncate both tables; we don't care about reindexing given so little has been indexed to date.\nTRUNCATE lsif_data_documentation_search_public;\nTRUNCATE lsif_data_documentation_search_private;",
				"DownQuery": "ALTER TABLE lsif_data_documentation_search_public DROP COLUMN IF EXISTS dump_root;\nALTER TABLE lsif_data_documentation_search_private DROP COLUMN IF EXISTS dump_root;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000022
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000024,
				"Name": "apidocs search to tsvector",
				"UpQuery": "-- We're completely changing the API docs search table schema, so we'll reindex everything\n-- from scratch. Reset our OOB migration's progress entirely.\n--\n-- IMPORTANT: Dropping the column and recreating it is nearly instant, updating the table\n-- to set the column to 'false' again can take several minutes.\nALTER TABLE lsif_data_documentation_pages DROP COLUMN search_indexed;\nALTER TABLE lsif_data_documentation_pages ADD COLUMN search_indexed boolean DEFAULT 'false';\n\n-- We're completely redefining the table.\nDROP TABLE IF EXISTS lsif_data_documentation_search_public;\n\n-- Each unique language name being stored in the search index.\n--\n-- Contains a tsvector index for matching a logical OR of query terms against the language name\n-- (e.g. \"http router go\" to match \"go\" without knowing if \"http\", \"router\", or \"go\" are actually\n-- a language name or not.)\nCREATE TABLE lsif_data_docs_search_lang_names_public (\n    id BIGSERIAL PRIMARY KEY,\n    lang_name TEXT NOT NULL UNIQUE,\n    tsv TSVECTOR NOT NULL\n);\nCREATE INDEX lsif_data_docs_search_lang_names_public_tsv_idx ON lsif_data_docs_search_lang_names_public USING GIN(tsv);\n\nCOMMENT ON TABLE lsif_data_docs_search_lang_names_public IS 'Each unique language name being stored in the API docs search index.';\nCOMMENT ON COLUMN lsif_data_docs_search_lang_names_public.id IS 'The ID of the language name.';\nCOMMENT ON COLUMN lsif_data_docs_search_lang_names_public.lang_name IS 'The lowercase language name (go, java, etc.) OR, if unknown, the LSIF indexer name.';\nCOMMENT ON COLUMN lsif_data_docs_search_lang_names_public.tsv IS 'Indexed tsvector for the lang_name field. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\n\n-- Each unique repository name being stored in the search index.\n--\n-- Contains a tsvector index for matching against repository names, with both prefix and suffix\n-- (reverse prefix) matching within lexemes (words).\nCREATE TABLE lsif_data_docs_search_repo_names_public (\n    id BIGSERIAL PRIMARY KEY,\n    repo_name TEXT NOT NULL UNIQUE,\n    tsv TSVECTOR NOT NULL,\n    reverse_tsv TSVECTOR NOT NULL\n);\nCREATE INDEX lsif_data_docs_search_repo_names_public_tsv_idx ON lsif_data_docs_search_repo_names_public USING GIN(tsv);\nCREATE INDEX lsif_data_docs_search_repo_names_public_reverse_tsv_idx ON lsif_data_docs_search_repo_names_public USING GIN(reverse_tsv);\n\nCOMMENT ON TABLE lsif_data_docs_search_repo_names_public IS 'Each unique repository name being stored in the API docs search index.';\nCOMMENT ON COLUMN lsif_data_docs_search_repo_names_public.id IS 'The ID of the repository name.';\nCOMMENT ON COLUMN lsif_data_docs_search_repo_names_public.repo_name IS 'The fully qualified name of the repository.';\nCOMMENT ON COLUMN lsif_data_docs_search_repo_names_public.tsv IS 'Indexed tsvector for the lang_name field. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\nCOMMENT ON COLUMN lsif_data_docs_search_repo_names_public.reverse_tsv IS 'Indexed tsvector for the reverse of the lang_name field, for suffix lexeme/word matching. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\n\n-- Each unique sequence of space-separated tags being stored in the search index. This could be as\n-- many rows as the search table itself, because in theory each result could have a unique string\n-- of tags. In practice, though, they are frequently similar sequences.\n--\n-- The space separated tags have a tsvector for matching a logcal OR of query terms against, for\n-- the same reason as the lang_names table. e.g. so that we can have a query for \"go private function net router\"\n-- match the tags string \"private function\" without knowing which query terms are tags or not.\n--\n-- The entire sequence of space-separated tags are stored, in part so that lookups in the search table\n-- are faster (single ID lookup rather than array ALL lookup) and partly to allow for more complex\n-- tag matching options in the future.\nCREATE TABLE lsif_data_docs_search_tags_public (\n    id BIGSERIAL PRIMARY KEY,\n    tags TEXT NOT NULL UNIQUE,\n    tsv TSVECTOR NOT NULL\n);\nCREATE INDEX lsif_data_docs_search_tags_public_tsv_idx ON lsif_data_docs_search_tags_public USING GIN(tsv);\n\nCOMMENT ON TABLE lsif_data_docs_search_tags_public IS 'Each uniques sequence of space-separated tags being stored in the API docs search index.';\nCOMMENT ON COLUMN lsif_data_docs_search_tags_public.id IS 'The ID of the tags.';\nCOMMENT ON COLUMN lsif_data_docs_search_tags_public.tags IS 'The full sequence of space-separated tags. See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_docs_search_tags_public.tsv IS 'Indexed tsvector for the tags field. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\n\n-- The actual search index over API docs, one entry per symbol/section of API docs.\nCREATE TABLE lsif_data_docs_search_public (\n    -- Metadata fields\n    id BIGSERIAL PRIMARY KEY,\n    repo_id INTEGER NOT NULL,\n    dump_id INTEGER NOT NULL,\n    dump_root TEXT NOT NULL,\n    path_id TEXT NOT NULL,\n    detail TEXT NOT NULL,\n    lang_name_id INTEGER NOT NULL,\n    repo_name_id INTEGER NOT NULL,\n    tags_id INTEGER NOT NULL,\n\n    -- FTS-enabled fields\n    search_key TEXT NOT NULL,\n    search_key_tsv TSVECTOR NOT NULL,\n    search_key_reverse_tsv TSVECTOR NOT NULL,\n\n    label TEXT NOT NULL,\n    label_tsv TSVECTOR NOT NULL,\n    label_reverse_tsv TSVECTOR NOT NULL,\n\n    CONSTRAINT lsif_data_docs_search_public_lang_name_id_fk FOREIGN KEY(lang_name_id) REFERENCES lsif_data_docs_search_lang_names_public(id),\n    CONSTRAINT lsif_data_docs_search_public_repo_name_id_fk FOREIGN KEY(repo_name_id) REFERENCES lsif_data_docs_search_repo_names_public(id),\n    CONSTRAINT lsif_data_docs_search_public_tags_id_fk FOREIGN KEY(tags_id) REFERENCES lsif_data_docs_search_tags_public(id)\n);\n\n-- This pair of fields is used to purge stale data from the search index, so use a btree index on it.\nCREATE INDEX lsif_data_docs_search_public_repo_id_idx ON lsif_data_docs_search_public USING BTREE(repo_id);\nCREATE INDEX lsif_data_docs_search_public_dump_id_idx ON lsif_data_docs_search_public USING BTREE(dump_id);\nCREATE INDEX lsif_data_docs_search_public_dump_root_idx ON lsif_data_docs_search_public USING BTREE(dump_root);\n\n-- tsvector indexes\nCREATE INDEX lsif_data_docs_search_public_search_key_tsv_idx ON lsif_data_docs_search_public USING BTREE(search_key_tsv);\nCREATE INDEX lsif_data_docs_search_public_search_key_reverse_tsv_idx ON lsif_data_docs_search_public USING BTREE(search_key_reverse_tsv);\nCREATE INDEX lsif_data_docs_search_public_label_tsv_idx ON lsif_data_docs_search_public USING BTREE(label_tsv);\nCREATE INDEX lsif_data_docs_search_public_label_reverse_tsv_idx ON lsif_data_docs_search_public USING BTREE(label_reverse_tsv);\n\nCOMMENT ON TABLE lsif_data_docs_search_public IS 'A tsvector search index over API documentation (public repos only)';\nCOMMENT ON COLUMN lsif_data_docs_search_public.id IS 'The row ID of the search result.';\nCOMMENT ON COLUMN lsif_data_docs_search_public.repo_id IS 'The repo ID, from the main app DB repo table. Used to search over a select set of repos by ID.';\nCOMMENT ON COLUMN lsif_data_docs_search_public.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\nCOMMENT ON COLUMN lsif_data_docs_search_public.dump_root IS 'Identical to lsif_dumps.root; The working directory of the indexer image relative to the repository root.';\nCOMMENT ON COLUMN lsif_data_docs_search_public.path_id IS 'The fully qualified documentation page path ID, e.g. including \"#section\". See GraphQL codeintel.schema:documentationPage for what this is.';\nCOMMENT ON COLUMN lsif_data_docs_search_public.detail IS 'The detail string (e.g. the full function signature and its docs). See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_docs_search_public.lang_name_id IS 'The programming language (or indexer name) that produced the result. Foreign key into lsif_data_docs_search_lang_names_public.';\nCOMMENT ON COLUMN lsif_data_docs_search_public.repo_name_id IS 'The repository name that produced the result. Foreign key into lsif_data_docs_search_repo_names_public.';\nCOMMENT ON COLUMN lsif_data_docs_search_public.tags_id IS 'The tags from the documentation node. Foreign key into lsif_data_docs_search_tags_public.';\n\nCOMMENT ON COLUMN lsif_data_docs_search_public.search_key IS 'The search key generated by the indexer, e.g. mux.Router.ServeHTTP. It is language-specific, and likely unique within a repository (but not always.) See protocol/documentation.go:Documentation.SearchKey';\nCOMMENT ON COLUMN lsif_data_docs_search_public.search_key_tsv IS 'Indexed tsvector for the search_key field. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\nCOMMENT ON COLUMN lsif_data_docs_search_public.search_key_reverse_tsv IS 'Indexed tsvector for the reverse of the search_key field, for suffix lexeme/word matching. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\n\nCOMMENT ON COLUMN lsif_data_docs_search_public.label IS 'The label string of the result, e.g. a one-line function signature. See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_docs_search_public.label_tsv IS 'Indexed tsvector for the label field. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\nCOMMENT ON COLUMN lsif_data_docs_search_public.label_reverse_tsv IS 'Indexed tsvector for the reverse of the label field, for suffix lexeme/word matching. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\n\n-- ************************************************************************************************\n-- Below here is a direct copy of the above, but with \"public\" replaced with \"private\" for the    *\n-- private variant of the table.                                                                  *\n-- ************************************************************************************************\n\n-- We're completely redefining the table.\nDROP TABLE IF EXISTS lsif_data_documentation_search_private;\n\n-- Each unique language name being stored in the search index.\n--\n-- Contains a tsvector index for matching a logical OR of query terms against the language name\n-- (e.g. \"http router go\" to match \"go\" without knowing if \"http\", \"router\", or \"go\" are actually\n-- a language name or not.)\nCREATE TABLE lsif_data_docs_search_lang_names_private (\n    id BIGSERIAL PRIMARY KEY,\n    lang_name TEXT NOT NULL UNIQUE,\n    tsv TSVECTOR NOT NULL\n);\nCREATE INDEX lsif_data_docs_search_lang_names_private_tsv_idx ON lsif_data_docs_search_lang_names_private USING GIN(tsv);\n\nCOMMENT ON TABLE lsif_data_docs_search_lang_names_private IS 'Each unique language name being stored in the API docs search index.';\nCOMMENT ON COLUMN lsif_data_docs_search_lang_names_private.id IS 'The ID of the language name.';\nCOMMENT ON COLUMN lsif_data_docs_search_lang_names_private.lang_name IS 'The lowercase language name (go, java, etc.) OR, if unknown, the LSIF indexer name.';\nCOMMENT ON COLUMN lsif_data_docs_search_lang_names_private.tsv IS 'Indexed tsvector for the lang_name field. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\n\n-- Each unique repository name being stored in the search index.\n--\n-- Contains a tsvector index for matching against repository names, with both prefix and suffix\n-- (reverse prefix) matching within lexemes (words).\nCREATE TABLE lsif_data_docs_search_repo_names_private (\n    id BIGSERIAL PRIMARY KEY,\n    repo_name TEXT NOT NULL UNIQUE,\n    tsv TSVECTOR NOT NULL,\n    reverse_tsv TSVECTOR NOT NULL\n);\nCREATE INDEX lsif_data_docs_search_repo_names_private_tsv_idx ON lsif_data_docs_search_repo_names_private USING GIN(tsv);\nCREATE INDEX lsif_data_docs_search_repo_names_private_reverse_tsv_idx ON lsif_data_docs_search_repo_names_private USING GIN(reverse_tsv);\n\nCOMMENT ON TABLE lsif_data_docs_search_repo_names_private IS 'Each unique repository name being stored in the API docs search index.';\nCOMMENT ON COLUMN lsif_data_docs_search_repo_names_private.id IS 'The ID of the repository name.';\nCOMMENT ON COLUMN lsif_data_docs_search_repo_names_private.repo_name IS 'The fully qualified name of the repository.';\nCOMMENT ON COLUMN lsif_data_docs_search_repo_names_private.tsv IS 'Indexed tsvector for the lang_name field. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\nCOMMENT ON COLUMN lsif_data_docs_search_repo_names_private.reverse_tsv IS 'Indexed tsvector for the reverse of the lang_name field, for suffix lexeme/word matching. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\n\n-- Each unique sequence of space-separated tags being stored in the search index. This could be as\n-- many rows as the search table itself, because in theory each result could have a unique string\n-- of tags. In practice, though, they are frequently similar sequences.\n--\n-- The space separated tags have a tsvector for matching a logcal OR of query terms against, for\n-- the same reason as the lang_names table. e.g. so that we can have a query for \"go private function net router\"\n-- match the tags string \"private function\" without knowing which query terms are tags or not.\n--\n-- The entire sequence of space-separated tags are stored, in part so that lookups in the search table\n-- are faster (single ID lookup rather than array ALL lookup) and partly to allow for more complex\n-- tag matching options in the future.\nCREATE TABLE lsif_data_docs_search_tags_private (\n    id BIGSERIAL PRIMARY KEY,\n    tags TEXT NOT NULL UNIQUE,\n    tsv TSVECTOR NOT NULL\n);\nCREATE INDEX lsif_data_docs_search_tags_private_tsv_idx ON lsif_data_docs_search_tags_private USING GIN(tsv);\n\nCOMMENT ON TABLE lsif_data_docs_search_tags_private IS 'Each uniques sequence of space-separated tags being stored in the API docs search index.';\nCOMMENT ON COLUMN lsif_data_docs_search_tags_private.id IS 'The ID of the tags.';\nCOMMENT ON COLUMN lsif_data_docs_search_tags_private.tags IS 'The full sequence of space-separated tags. See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_docs_search_tags_private.tsv IS 'Indexed tsvector for the tags field. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\n\n-- The actual search index over API docs, one entry per symbol/section of API docs.\nCREATE TABLE lsif_data_docs_search_private (\n    -- Metadata fields\n    id BIGSERIAL PRIMARY KEY,\n    repo_id INTEGER NOT NULL,\n    dump_id INTEGER NOT NULL,\n    dump_root TEXT NOT NULL,\n    path_id TEXT NOT NULL,\n    detail TEXT NOT NULL,\n    lang_name_id INTEGER NOT NULL,\n    repo_name_id INTEGER NOT NULL,\n    tags_id INTEGER NOT NULL,\n\n    -- FTS-enabled fields\n    search_key TEXT NOT NULL,\n    search_key_tsv TSVECTOR NOT NULL,\n    search_key_reverse_tsv TSVECTOR NOT NULL,\n\n    label TEXT NOT NULL,\n    label_tsv TSVECTOR NOT NULL,\n    label_reverse_tsv TSVECTOR NOT NULL,\n\n    CONSTRAINT lsif_data_docs_search_private_lang_name_id_fk FOREIGN KEY(lang_name_id) REFERENCES lsif_data_docs_search_lang_names_private(id),\n    CONSTRAINT lsif_data_docs_search_private_repo_name_id_fk FOREIGN KEY(repo_name_id) REFERENCES lsif_data_docs_search_repo_names_private(id),\n    CONSTRAINT lsif_data_docs_search_private_tags_id_fk FOREIGN KEY(tags_id) REFERENCES lsif_data_docs_search_tags_private(id)\n);\n\n-- This pair of fields is used to purge stale data from the search index, so use a btree index on it.\nCREATE INDEX lsif_data_docs_search_private_repo_id_idx ON lsif_data_docs_search_private USING BTREE(repo_id);\nCREATE INDEX lsif_data_docs_search_private_dump_id_idx ON lsif_data_docs_search_private USING BTREE(dump_id);\nCREATE INDEX lsif_data_docs_search_private_dump_root_idx ON lsif_data_docs_search_private USING BTREE(dump_root);\n\n-- tsvector indexes\nCREATE INDEX lsif_data_docs_search_private_search_key_tsv_idx ON lsif_data_docs_search_private USING BTREE(search_key_tsv);\nCREATE INDEX lsif_data_docs_search_private_search_key_reverse_tsv_idx ON lsif_data_docs_search_private USING BTREE(search_key_reverse_tsv);\nCREATE INDEX lsif_data_docs_search_private_label_tsv_idx ON lsif_data_docs_search_private USING BTREE(label_tsv);\nCREATE INDEX lsif_data_docs_search_private_label_reverse_tsv_idx ON lsif_data_docs_search_private USING BTREE(label_reverse_tsv);\n\nCOMMENT ON TABLE lsif_data_docs_search_private IS 'A tsvector search index over API documentation (private repos only)';\nCOMMENT ON COLUMN lsif_data_docs_search_private.id IS 'The row ID of the search result.';\nCOMMENT ON COLUMN lsif_data_docs_search_private.repo_id IS 'The repo ID, from the main app DB repo table. Used to search over a select set of repos by ID.';\nCOMMENT ON COLUMN lsif_data_docs_search_private.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\nCOMMENT ON COLUMN lsif_data_docs_search_private.dump_root IS 'Identical to lsif_dumps.root; The working directory of the indexer image relative to the repository root.';\nCOMMENT ON COLUMN lsif_data_docs_search_private.path_id IS 'The fully qualified documentation page path ID, e.g. including \"#section\". See GraphQL codeintel.schema:documentationPage for what this is.';\nCOMMENT ON COLUMN lsif_data_docs_search_private.detail IS 'The detail string (e.g. the full function signature and its docs). See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_docs_search_private.lang_name_id IS 'The programming language (or indexer name) that produced the result. Foreign key into lsif_data_docs_search_lang_names_private.';\nCOMMENT ON COLUMN lsif_data_docs_search_private.repo_name_id IS 'The repository name that produced the result. Foreign key into lsif_data_docs_search_repo_names_private.';\nCOMMENT ON COLUMN lsif_data_docs_search_private.tags_id IS 'The tags from the documentation node. Foreign key into lsif_data_docs_search_tags_private.';\n\nCOMMENT ON COLUMN lsif_data_docs_search_private.search_key IS 'The search key generated by the indexer, e.g. mux.Router.ServeHTTP. It is language-specific, and likely unique within a repository (but not always.) See protocol/documentation.go:Documentation.SearchKey';\nCOMMENT ON COLUMN lsif_data_docs_search_private.search_key_tsv IS 'Indexed tsvector for the search_key field. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\nCOMMENT ON COLUMN lsif_data_docs_search_private.search_key_reverse_tsv IS 'Indexed tsvector for the reverse of the search_key field, for suffix lexeme/word matching. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\n\nCOMMENT ON COLUMN lsif_data_docs_search_private.label IS 'The label string of the result, e.g. a one-line function signature. See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_docs_search_private.label_tsv IS 'Indexed tsvector for the label field. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\nCOMMENT ON COLUMN lsif_data_docs_search_private.label_reverse_tsv IS 'Indexed tsvector for the reverse of the label field, for suffix lexeme/word matching. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';",
				"DownQuery": "-- We've alterd tables beyond rollback in our up migration. The best we can do for a down migration\n-- is bring back the old schema so the previous version of Sourcegraph runs properly.\nDROP TABLE IF EXISTS lsif_data_docs_search_public;\nDROP TABLE IF EXISTS lsif_data_docs_search_lang_names_public;\nDROP TABLE IF EXISTS lsif_data_docs_search_repo_names_public;\nDROP TABLE IF EXISTS lsif_data_docs_search_tags_public;\n\nCREATE TABLE IF NOT EXISTS lsif_data_documentation_search_public (\n    -- Metadata fields\n    dump_id integer NOT NULL,\n    repo_id integer NOT NULL,\n    path_id TEXT NOT NULL,\n    detail TEXT NOT NULL,\n\n    -- FTS-enabled fields\n    lang TEXT NOT NULL,\n    repo_name TEXT NOT NULL,\n    search_key TEXT NOT NULL,\n    label TEXT NOT NULL,\n    tags TEXT NOT NULL\n);\n\nALTER TABLE lsif_data_documentation_search_public ADD PRIMARY KEY (dump_id, path_id);\n\nCREATE INDEX lsif_data_documentation_search_public_repo_id_idx ON lsif_data_documentation_search_public USING BTREE(repo_id);\nCREATE INDEX lsif_data_documentation_search_public_lang_trgm ON lsif_data_documentation_search_public USING gin(lang gin_trgm_ops);\nCREATE INDEX lsif_data_documentation_search_public_repo_name_trgm ON lsif_data_documentation_search_public USING gin(repo_name gin_trgm_ops);\nCREATE INDEX lsif_data_documentation_search_public_search_key_trgm ON lsif_data_documentation_search_public USING gin(search_key gin_trgm_ops);\nCREATE INDEX lsif_data_documentation_search_public_label_trgm ON lsif_data_documentation_search_public USING gin(label gin_trgm_ops);\nCREATE INDEX lsif_data_documentation_search_public_tags_trgm ON lsif_data_documentation_search_public USING gin(tags gin_trgm_ops);\n\nCOMMENT ON TABLE lsif_data_documentation_search_public IS 'A trigram index over documentation for search (public repos only)';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.repo_id IS 'The repo ID, from the main app DB repo table. Used to search over a select set of repos by ID.';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.path_id IS 'The fully qualified documentation page path ID, e.g. including \"#section\". See GraphQL codeintel.schema:documentationPage for what this is.';\n\nCOMMENT ON COLUMN lsif_data_documentation_search_public.lang IS 'The lowercase language name (go, java, etc.) OR, if unknown, the LSIF indexer name';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.repo_name IS 'The name of the repository containing this search key.';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.search_key IS 'The search key generated by the indexer, e.g. mux.Router.ServeHTTP. It is language-specific, and likely unique within a repository (but not always.) See protocol/documentation.go:Documentation.SearchKey';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.label IS 'The label string of the result, e.g. a one-line function signature. See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.detail IS 'The detail string (e.g. the full function signature and its docs). See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.tags IS 'A space separated list of tags from the documentation node. See protocol/documentation.go:Documentation';\n\nALTER TABLE lsif_data_documentation_search_public ADD COLUMN dump_root TEXT NOT NULL DEFAULT '';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.dump_root IS 'Identical to lsif_dumps.root; The working directory of the indexer image relative to the repository root.';\nCREATE INDEX lsif_data_documentation_search_public_dump_root_idx ON lsif_data_documentation_search_public USING BTREE(dump_root);\n\n-- ************************************************************************************************\n-- Below here is a direct copy of the above, but with \"public\" replaced with \"private\" for the    *\n-- private variant of the table.                                                                  *\n-- ************************************************************************************************\n\n-- We've alterd tables beyond rollback in our up migration. The best we can do for a down migration\n-- is bring back the old schema so the previous version of Sourcegraph runs properly.\nDROP TABLE IF EXISTS lsif_data_docs_search_private;\nDROP TABLE IF EXISTS lsif_data_docs_search_lang_names_private;\nDROP TABLE IF EXISTS lsif_data_docs_search_repo_names_private;\nDROP TABLE IF EXISTS lsif_data_docs_search_tags_private;\n\nCREATE TABLE IF NOT EXISTS lsif_data_documentation_search_private (\n    -- Metadata fields\n    dump_id integer NOT NULL,\n    repo_id integer NOT NULL,\n    path_id TEXT NOT NULL,\n    detail TEXT NOT NULL,\n\n    -- FTS-enabled fields\n    lang TEXT NOT NULL,\n    repo_name TEXT NOT NULL,\n    search_key TEXT NOT NULL,\n    label TEXT NOT NULL,\n    tags TEXT NOT NULL\n);\n\nALTER TABLE lsif_data_documentation_search_private ADD PRIMARY KEY (dump_id, path_id);\n\nCREATE INDEX lsif_data_documentation_search_private_repo_id_idx ON lsif_data_documentation_search_private USING BTREE(repo_id);\nCREATE INDEX lsif_data_documentation_search_private_lang_trgm ON lsif_data_documentation_search_private USING gin(lang gin_trgm_ops);\nCREATE INDEX lsif_data_documentation_search_private_repo_name_trgm ON lsif_data_documentation_search_private USING gin(repo_name gin_trgm_ops);\nCREATE INDEX lsif_data_documentation_search_private_search_key_trgm ON lsif_data_documentation_search_private USING gin(search_key gin_trgm_ops);\nCREATE INDEX lsif_data_documentation_search_private_label_trgm ON lsif_data_documentation_search_private USING gin(label gin_trgm_ops);\nCREATE INDEX lsif_data_documentation_search_private_tags_trgm ON lsif_data_documentation_search_private USING gin(tags gin_trgm_ops);\n\nCOMMENT ON TABLE lsif_data_documentation_search_private IS 'A trigram index over documentation for search (private repos only)';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.repo_id IS 'The repo ID, from the main app DB repo table. Used to search over a select set of repos by ID.';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.path_id IS 'The fully qualified documentation page path ID, e.g. including \"#section\". See GraphQL codeintel.schema:documentationPage for what this is.';\n\nCOMMENT ON COLUMN lsif_data_documentation_search_private.lang IS 'The lowercase language name (go, java, etc.) OR, if unknown, the LSIF indexer name';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.repo_name IS 'The name of the repository containing this search key.';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.search_key IS 'The search key generated by the indexer, e.g. mux.Router.ServeHTTP. It is language-specific, and likely unique within a repository (but not always.) See protocol/documentation.go:Documentation.SearchKey';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.label IS 'The label string of the result, e.g. a one-line function signature. See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.detail IS 'The detail string (e.g. the full function signature and its docs). See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.tags IS 'A space separated list of tags from the documentation node. See protocol/documentation.go:Documentation';\n\nALTER TABLE lsif_data_documentation_search_private ADD COLUMN dump_root TEXT NOT NULL DEFAULT '';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.dump_root IS 'Identical to lsif_dumps.root; The working directory of the indexer image relative to the repository root.';\nCREATE INDEX lsif_data_documentation_search_private_dump_root_idx ON lsif_data_documentation_search_private USING BTREE(dump_root);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000023
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000025,
				"Name": "apidocs materialized stats",
				"UpQuery": "--------------------------------------------------------\n-- Stats for the lsif_data_documentation_pages table. --\n--------------------------------------------------------\nCREATE TABLE lsif_data_apidocs_num_pages AS SELECT count(*) FROM lsif_data_documentation_pages;\nCREATE TABLE lsif_data_apidocs_num_dumps AS SELECT count(DISTINCT dump_id) FROM lsif_data_documentation_pages;\nCREATE TABLE lsif_data_apidocs_num_dumps_indexed AS SELECT count(DISTINCT dump_id) FROM lsif_data_documentation_pages WHERE search_indexed='true';\n\nCREATE OR REPLACE FUNCTION lsif_data_documentation_pages_delete()\nRETURNS TRIGGER LANGUAGE plpgsql\nAS $$\nBEGIN\nUPDATE lsif_data_apidocs_num_pages SET count = count - (select count(*) from oldtbl);\nUPDATE lsif_data_apidocs_num_dumps SET count = count - (select count(DISTINCT dump_id) from oldtbl);\nUPDATE lsif_data_apidocs_num_dumps_indexed SET count = count - (select count(DISTINCT dump_id) from oldtbl WHERE search_indexed='true');\nRETURN NULL;\nEND $$;\n\nCREATE TRIGGER lsif_data_documentation_pages_delete\nAFTER DELETE ON lsif_data_documentation_pages\nREFERENCING OLD TABLE AS oldtbl\nFOR EACH STATEMENT EXECUTE PROCEDURE lsif_data_documentation_pages_delete();\n\nCREATE OR REPLACE FUNCTION lsif_data_documentation_pages_insert()\nRETURNS TRIGGER LANGUAGE plpgsql\nAS $$\nBEGIN\nUPDATE lsif_data_apidocs_num_pages SET count = count + (select count(*) from newtbl);\nUPDATE lsif_data_apidocs_num_dumps SET count = count + (select count(DISTINCT dump_id) from newtbl);\nUPDATE lsif_data_apidocs_num_dumps_indexed SET count = count + (select count(DISTINCT dump_id) from newtbl WHERE search_indexed='true');\nRETURN NULL;\nEND $$;\n\nCREATE TRIGGER lsif_data_documentation_pages_insert\nAFTER INSERT ON lsif_data_documentation_pages\nREFERENCING NEW TABLE AS newtbl\nFOR EACH STATEMENT EXECUTE PROCEDURE lsif_data_documentation_pages_insert();\n\nCREATE OR REPLACE FUNCTION lsif_data_documentation_pages_update()\nRETURNS TRIGGER LANGUAGE plpgsql\nAS $$\nBEGIN\nWITH\n    beforeIndexed AS (SELECT count(DISTINCT dump_id) FROM oldtbl WHERE search_indexed='true'),\n    afterIndexed AS (SELECT count(DISTINCT dump_id) FROM newtbl WHERE search_indexed='true')\nUPDATE lsif_data_apidocs_num_dumps_indexed SET count=count + ((select * from afterIndexed) - (select * from beforeIndexed));\nRETURN NULL;\nEND $$;\n\nCREATE TRIGGER lsif_data_documentation_pages_update\nAFTER UPDATE ON lsif_data_documentation_pages\nREFERENCING OLD TABLE AS oldtbl NEW TABLE AS newtbl\nFOR EACH STATEMENT EXECUTE PROCEDURE lsif_data_documentation_pages_update();\n\n-------------------------------------------------------\n-- Stats for the lsif_data_docs_search_public table. --\n-------------------------------------------------------\nCREATE TABLE lsif_data_apidocs_num_search_results_public AS SELECT count(*) FROM lsif_data_docs_search_public;\n\nCREATE OR REPLACE FUNCTION lsif_data_docs_search_public_delete()\nRETURNS TRIGGER LANGUAGE plpgsql\nAS $$\nBEGIN\nUPDATE lsif_data_apidocs_num_search_results_public SET count = count - (select count(*) from oldtbl);\nRETURN NULL;\nEND $$;\n\nCREATE TRIGGER lsif_data_docs_search_public_delete\nAFTER DELETE\nON lsif_data_docs_search_public\nREFERENCING OLD TABLE AS oldtbl\nFOR EACH STATEMENT EXECUTE PROCEDURE lsif_data_docs_search_public_delete();\n\nCREATE OR REPLACE FUNCTION lsif_data_docs_search_public_insert()\nRETURNS TRIGGER LANGUAGE plpgsql\nAS $$\nBEGIN\nUPDATE lsif_data_apidocs_num_search_results_public SET count = count + (select count(*) from newtbl);\nRETURN NULL;\nEND $$;\n\nCREATE TRIGGER lsif_data_docs_search_public_insert\nAFTER INSERT\nON lsif_data_docs_search_public\nREFERENCING NEW TABLE AS newtbl\nFOR EACH STATEMENT EXECUTE PROCEDURE lsif_data_docs_search_public_insert();\n\n-------------------------------------------------------\n-- Stats for the lsif_data_docs_search_private table. --\n-------------------------------------------------------\nCREATE TABLE lsif_data_apidocs_num_search_results_private AS SELECT count(*) FROM lsif_data_docs_search_private;\n\nCREATE OR REPLACE FUNCTION lsif_data_docs_search_private_delete()\nRETURNS TRIGGER LANGUAGE plpgsql\nAS $$\nBEGIN\nUPDATE lsif_data_apidocs_num_search_results_private SET count = count - (select count(*) from oldtbl);\nRETURN NULL;\nEND $$;\n\nCREATE TRIGGER lsif_data_docs_search_private_delete\nAFTER DELETE\nON lsif_data_docs_search_private\nREFERENCING OLD TABLE AS oldtbl\nFOR EACH STATEMENT EXECUTE PROCEDURE lsif_data_docs_search_private_delete();\n\nCREATE OR REPLACE FUNCTION lsif_data_docs_search_private_insert()\nRETURNS TRIGGER LANGUAGE plpgsql\nAS $$\nBEGIN\nUPDATE lsif_data_apidocs_num_search_results_private SET count = count + (select count(*) from newtbl);\nRETURN NULL;\nEND $$;\n\nCREATE TRIGGER lsif_data_docs_search_private_insert\nAFTER INSERT\nON lsif_data_docs_search_private\nREFERENCING NEW TABLE AS newtbl\nFOR EACH STATEMENT EXECUTE PROCEDURE lsif_data_docs_search_private_insert();",
				"DownQuery": "DROP TABLE lsif_data_apidocs_num_pages;\nDROP TABLE lsif_data_apidocs_num_dumps;\nDROP TABLE lsif_data_apidocs_num_dumps_indexed;\nDROP TRIGGER lsif_data_documentation_pages_delete ON lsif_data_documentation_pages;\nDROP TRIGGER lsif_data_documentation_pages_insert ON lsif_data_documentation_pages;\nDROP TRIGGER lsif_data_documentation_pages_update ON lsif_data_documentation_pages;\nDROP FUNCTION lsif_data_documentation_pages_delete;\nDROP FUNCTION lsif_data_documentation_pages_insert;\nDROP FUNCTION lsif_data_documentation_pages_update;\n\nDROP TABLE lsif_data_apidocs_num_search_results_public;\nDROP TRIGGER lsif_data_docs_search_public_delete ON lsif_data_docs_search_public;\nDROP TRIGGER lsif_data_docs_search_public_insert ON lsif_data_docs_search_public;\nDROP FUNCTION lsif_data_docs_search_public_delete;\nDROP FUNCTION lsif_data_docs_search_public_insert;\n\nDROP TABLE lsif_data_apidocs_num_search_results_private;\nDROP TRIGGER lsif_data_docs_search_private_delete ON lsif_data_docs_search_private;\nDROP TRIGGER lsif_data_docs_search_private_insert ON lsif_data_docs_search_private;\nDROP FUNCTION lsif_data_docs_search_private_delete;\nDROP FUNCTION lsif_data_docs_search_private_insert;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000024
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000026,
				"Name": "add lsif data docs search current",
				"UpQuery": "CREATE TABLE IF NOT EXISTS lsif_data_docs_search_current_public (\n    repo_id INTEGER NOT NULL,\n    dump_root TEXT NOT NULL,\n    lang_name_id INTEGER NOT NULL,\n    dump_id INTEGER NOT NULL,\n    last_cleanup_scan_at timestamp with time zone NOT NULL,\n\n    PRIMARY KEY (repo_id, dump_root, lang_name_id)\n);\n\nCOMMENT ON TABLE lsif_data_docs_search_current_public IS 'A table indicating the most current search index for a unique repository, root, and language.';\nCOMMENT ON COLUMN lsif_data_docs_search_current_public.repo_id IS 'The repository identifier of the associated dump.';\nCOMMENT ON COLUMN lsif_data_docs_search_current_public.dump_root IS 'The root of the associated dump.';\nCOMMENT ON COLUMN lsif_data_docs_search_current_public.lang_name_id IS 'The interned index name of the associated dump.';\nCOMMENT ON COLUMN lsif_data_docs_search_current_public.dump_id IS 'The most recent dump identifier for this key. See associated content in the lsif_data_docs_search_public table.';\nCOMMENT ON COLUMN lsif_data_docs_search_current_public.last_cleanup_scan_at IS 'The last time outdated records in the lsif_data_docs_search_public table have been cleaned.';\n\nCREATE TABLE IF NOT EXISTS lsif_data_docs_search_current_private (\n    repo_id INTEGER NOT NULL,\n    dump_root TEXT NOT NULL,\n    lang_name_id INTEGER NOT NULL,\n    dump_id INTEGER NOT NULL,\n    last_cleanup_scan_at timestamp with time zone NOT NULL,\n\n    PRIMARY KEY (repo_id, dump_root, lang_name_id)\n);\n\nCOMMENT ON TABLE lsif_data_docs_search_current_private IS 'A table indicating the most current search index for a unique repository, root, and language.';\nCOMMENT ON COLUMN lsif_data_docs_search_current_private.repo_id IS 'The repository identifier of the associated dump.';\nCOMMENT ON COLUMN lsif_data_docs_search_current_private.dump_root IS 'The root of the associated dump.';\nCOMMENT ON COLUMN lsif_data_docs_search_current_private.lang_name_id IS 'The interned index name of the associated dump.';\nCOMMENT ON COLUMN lsif_data_docs_search_current_private.dump_id IS 'The most recent dump identifier for this key. See associated content in the lsif_data_docs_search_private table.';\nCOMMENT ON COLUMN lsif_data_docs_search_current_private.last_cleanup_scan_at IS 'The last time outdated records in the lsif_data_docs_search_private table have been cleaned.';",
				"DownQuery": "DROP TABLE IF EXISTS lsif_data_docs_search_current_public;\nDROP TABLE IF EXISTS lsif_data_docs_search_current_private;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000025
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000027,
				"Name": "add search repo names index",
				"UpQuery": "CREATE INDEX IF NOT EXISTS lsif_data_documentation_pages_dump_id_unindexed ON lsif_data_documentation_pages(dump_id) WHERE NOT search_indexed;",
				"DownQuery": "DROP INDEX lsif_data_documentation_pages_dump_id_unindexed;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000026
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000028,
				"Name": "lsif non unique docs search current tables",
				"UpQuery": "--\n-- Public\n\n-- Change comment\nCOMMENT ON COLUMN lsif_data_docs_search_current_public.dump_id IS 'The associated dump identifier.';\n\n-- Create new created_at column to decide a leader\nALTER TABLE lsif_data_docs_search_current_public ADD COLUMN IF NOT EXISTS created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW();\nCOMMENT ON COLUMN lsif_data_docs_search_current_public.created_at IS 'The time this record was inserted. The records with the latest created_at value for the same repository, root, and language is the only visible one and others will be deleted asynchronously.';\n\n-- Add default to last_cleanup_scan_at column\nALTER TABLE lsif_data_docs_search_current_public ALTER COLUMN last_cleanup_scan_at SET DEFAULT NOW();\nCOMMENT ON COLUMN lsif_data_docs_search_current_public.last_cleanup_scan_at IS 'The last time this record was checked as part of a data retention scan.';\n\n-- Create new indexes\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_current_public_lookup\nON lsif_data_docs_search_current_public(repo_id, dump_root, lang_name_id, created_at)\nINCLUDE (dump_id);\n\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_current_public_last_cleanup_scan_at ON lsif_data_docs_search_current_public(last_cleanup_scan_at);\n\n-- Drop existing primary key\nALTER TABLE lsif_data_docs_search_current_public DROP CONSTRAINT IF EXISTS lsif_data_docs_search_current_public_pkey;\n\n-- Create new serial primary key\nALTER TABLE lsif_data_docs_search_current_public ADD COLUMN IF NOT EXISTS id SERIAL PRIMARY KEY;\n\n--\n-- Private\n\n-- Change comment\nCOMMENT ON COLUMN lsif_data_docs_search_current_private.dump_id IS 'The associated dump identifier.';\n\n-- Create new created_at column to decide a leader\nALTER TABLE lsif_data_docs_search_current_private ADD COLUMN IF NOT EXISTS created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW();\nCOMMENT ON COLUMN lsif_data_docs_search_current_private.created_at IS 'The time this record was inserted. The records with the latest created_at value for the same repository, root, and language is the only visible one and others will be deleted asynchronously.';\n\n-- Add default to last_cleanup_scan_at column\nALTER TABLE lsif_data_docs_search_current_private ALTER COLUMN last_cleanup_scan_at SET DEFAULT NOW();\nCOMMENT ON COLUMN lsif_data_docs_search_current_private.last_cleanup_scan_at IS 'The last time this record was checked as part of a data retention scan.';\n\n-- Add index to last_cleanup_scan_at\n\n\n-- Create new indexes\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_current_private_lookup\nON lsif_data_docs_search_current_private(repo_id, dump_root, lang_name_id, created_at)\nINCLUDE (dump_id);\n\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_current_private_last_cleanup_scan_at ON lsif_data_docs_search_current_private(last_cleanup_scan_at);\n\n-- Drop existing primary key\nALTER TABLE lsif_data_docs_search_current_private DROP CONSTRAINT IF EXISTS lsif_data_docs_search_current_private_pkey;\n\n-- Create new serial primary key\nALTER TABLE lsif_data_docs_search_current_private ADD COLUMN IF NOT EXISTS id SERIAL PRIMARY KEY;",
				"DownQuery": "--\n-- Public\n\n-- De-duplicate records before adding the unique index\nDELETE FROM lsif_data_docs_search_current_public WHERE id NOT IN (\n    SELECT MAX(id) as max_id\n    FROM lsif_data_docs_search_current_public\n    GROUP BY repo_id, dump_root, lang_name_id\n);\n\n-- Drop new columns\nALTER TABLE lsif_data_docs_search_current_public DROP COLUMN IF EXISTS id;\nALTER TABLE lsif_data_docs_search_current_public DROP COLUMN IF EXISTS created_at;\n\n-- Drop new index\nDROP INDEX IF EXISTS lsif_data_docs_search_current_public_last_cleanup_scan_at;\n\n-- Re-create old primary key\nALTER TABLE lsif_data_docs_search_current_public ADD PRIMARY KEY (repo_id, dump_root, lang_name_id);\n\n-- Restore old comment\nCOMMENT ON COLUMN lsif_data_docs_search_current_public.dump_id IS 'The most recent dump identifier for this key. See associated content in the lsif_data_docs_search_public table.';\n\n-- Restore old last_cleanup_scan_at column\nCOMMENT ON COLUMN lsif_data_docs_search_current_public.last_cleanup_scan_at IS 'The last time outdated records in the lsif_data_docs_search_public table have been cleaned.';\nALTER TABLE lsif_data_docs_search_current_public ALTER COLUMN last_cleanup_scan_at DROP DEFAULT;\n\n--\n-- Private\n\n-- De-duplicate records before adding the unique index\nDELETE FROM lsif_data_docs_search_current_private WHERE id NOT IN (\n    SELECT MAX(id) as max_id\n    FROM lsif_data_docs_search_current_private\n    GROUP BY repo_id, dump_root, lang_name_id\n);\n\n-- Drop new columns\nALTER TABLE lsif_data_docs_search_current_private DROP COLUMN IF EXISTS id;\nALTER TABLE lsif_data_docs_search_current_private DROP COLUMN IF EXISTS created_at;\n\n-- Drop new index\nDROP INDEX IF EXISTS lsif_data_docs_search_current_private_last_cleanup_scan_at;\n\n-- Re-create old primary key\nALTER TABLE lsif_data_docs_search_current_private ADD PRIMARY KEY (repo_id, dump_root, lang_name_id);\n\n-- Restore old comment\nCOMMENT ON COLUMN lsif_data_docs_search_current_private.dump_id IS 'The most recent dump identifier for this key. See associated content in the lsif_data_docs_search_public table.';\n\n-- Restore old last_cleanup_scan_at column\nCOMMENT ON COLUMN lsif_data_docs_search_current_private.last_cleanup_scan_at IS 'The last time outdated records in the lsif_data_docs_search_public table have been cleaned.';\nALTER TABLE lsif_data_docs_search_current_private ALTER COLUMN last_cleanup_scan_at DROP DEFAULT;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000027
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000029,
				"Name": "apidocs missing fts indexes",
				"UpQuery": "-- Drop the btree indexes that we intended to be GIN indexes.\n-- btree indexes are no where near as performant for tsvector indexing.\nDROP INDEX IF EXISTS lsif_data_docs_search_public_search_key_tsv_idx;\nDROP INDEX IF EXISTS lsif_data_docs_search_public_search_key_reverse_tsv_idx;\nDROP INDEX IF EXISTS lsif_data_docs_search_public_label_tsv_idx;\nDROP INDEX IF EXISTS lsif_data_docs_search_public_label_reverse_tsv_idx;\n\nDROP INDEX IF EXISTS lsif_data_docs_search_private_search_key_tsv_idx;\nDROP INDEX IF EXISTS lsif_data_docs_search_private_search_key_reverse_tsv_idx;\nDROP INDEX IF EXISTS lsif_data_docs_search_private_label_tsv_idx;\nDROP INDEX IF EXISTS lsif_data_docs_search_private_label_reverse_tsv_idx;\n\n-- Recreate indexes with GIN instead.\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_public_search_key_tsv_idx ON lsif_data_docs_search_public USING GIN (search_key_tsv);\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_public_search_key_reverse_tsv_idx ON lsif_data_docs_search_public USING GIN (search_key_reverse_tsv);\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_public_label_tsv_idx ON lsif_data_docs_search_public USING GIN (label_tsv);\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_public_label_reverse_tsv_idx ON lsif_data_docs_search_public USING GIN (label_reverse_tsv);\n\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_private_search_key_tsv_idx ON lsif_data_docs_search_private USING GIN (search_key_tsv);\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_private_search_key_reverse_tsv_idx ON lsif_data_docs_search_private USING GIN (search_key_reverse_tsv);\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_private_label_tsv_idx ON lsif_data_docs_search_private USING GIN (label_tsv);\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_private_label_reverse_tsv_idx ON lsif_data_docs_search_private USING GIN (label_reverse_tsv);",
				"DownQuery": "DROP INDEX IF EXISTS lsif_data_docs_search_public_search_key_tsv_idx;\nDROP INDEX IF EXISTS lsif_data_docs_search_public_search_key_reverse_tsv_idx;\nDROP INDEX IF EXISTS lsif_data_docs_search_public_label_tsv_idx;\nDROP INDEX IF EXISTS lsif_data_docs_search_public_label_reverse_tsv_idx;\n\nDROP INDEX IF EXISTS lsif_data_docs_search_private_search_key_tsv_idx;\nDROP INDEX IF EXISTS lsif_data_docs_search_private_search_key_reverse_tsv_idx;\nDROP INDEX IF EXISTS lsif_data_docs_search_private_label_tsv_idx;\nDROP INDEX IF EXISTS lsif_data_docs_search_private_label_reverse_tsv_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000028
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000030,
				"Name": "lsif data implementations",
				"UpQuery": "CREATE TABLE lsif_data_implementations (\n    dump_id        INTEGER NOT NULL,\n    scheme         TEXT    NOT NULL,\n    identifier     TEXT    NOT NULL,\n    data           BYTEA           ,\n    schema_version INTEGER NOT NULL,\n    num_locations  INTEGER NOT NULL\n);\n\nCOMMENT ON TABLE  lsif_data_implementations                IS 'Associates (document, range) pairs with the implementation monikers attached to the range.';\nCOMMENT ON COLUMN lsif_data_implementations.dump_id        IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\nCOMMENT ON COLUMN lsif_data_implementations.scheme         IS 'The moniker scheme.';\nCOMMENT ON COLUMN lsif_data_implementations.identifier     IS 'The moniker identifier.';\nCOMMENT ON COLUMN lsif_data_implementations.data           IS 'A gob-encoded payload conforming to an array of [LocationData](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.26/-/blob/enterprise/lib/codeintel/semantic/types.go#L106:6) types.';\nCOMMENT ON COLUMN lsif_data_implementations.schema_version IS 'The schema version of this row - used to determine presence and encoding of data.';\nCOMMENT ON COLUMN lsif_data_implementations.num_locations  IS 'The number of locations stored in the data field.';\n\nALTER TABLE ONLY lsif_data_implementations ADD CONSTRAINT lsif_data_implementations_pkey PRIMARY KEY (dump_id, scheme, identifier);\n\nCREATE INDEX lsif_data_implementations_dump_id_schema_version ON lsif_data_implementations (dump_id, schema_version);\n\nCREATE TABLE lsif_data_implementations_schema_versions (\n    dump_id            INTEGER NOT NULL,\n    min_schema_version INTEGER         ,\n    max_schema_version INTEGER\n);\n\nCOMMENT ON TABLE lsif_data_implementations_schema_versions                     IS 'Tracks the range of schema_versions for each upload in the lsif_data_implementations table.';\nCOMMENT ON COLUMN lsif_data_implementations_schema_versions.dump_id            IS 'The identifier of the associated dump in the lsif_uploads table.';\nCOMMENT ON COLUMN lsif_data_implementations_schema_versions.min_schema_version IS 'A lower-bound on the `lsif_data_implementations.schema_version` where `lsif_data_implementations.dump_id = dump_id`.';\nCOMMENT ON COLUMN lsif_data_implementations_schema_versions.max_schema_version IS 'An upper-bound on the `lsif_data_implementations.schema_version` where `lsif_data_implementations.dump_id = dump_id`.';\n\nALTER TABLE ONLY lsif_data_implementations_schema_versions ADD CONSTRAINT lsif_data_implementations_schema_versions_pkey PRIMARY KEY (dump_id);\n\nCREATE INDEX lsif_data_implementations_schema_versions_dump_id_schema_version_bounds ON lsif_data_implementations_schema_versions (dump_id, min_schema_version, max_schema_version);\n\n-- On every insert into lsif_data_implementations, we need to make sure we have an associated row in the\n-- lsif_data_implementations_schema_versions table. We do not currently care about cleaning the table up\n-- (we will do this asynchronously).\n--\n-- We use FOR EACH STATEMENT here because we batch insert into this table. Running the trigger per\n-- statement rather than per row will save a ton of extra work. Running over batch inserts lets us\n-- do a GROUP BY on the new table and effectively upsert our new ranges.\n--\n-- Note that the only places where data is _modified_ in this database is during migrations, which\n-- will necessarily update this table's bounds for any migrated index records.\n\nCREATE OR REPLACE FUNCTION update_lsif_data_implementations_schema_versions_insert() RETURNS trigger AS $$ BEGIN\n    INSERT INTO\n        lsif_data_implementations_schema_versions\n    SELECT\n        dump_id,\n        MIN(schema_version) as min_schema_version,\n        MAX(schema_version) as max_schema_version\n    FROM\n        newtab\n    GROUP BY\n        dump_id\n    ON CONFLICT (dump_id) DO UPDATE SET\n        -- Update with min(old_min, new_min) and max(old_max, new_max)\n        min_schema_version = LEAST   (lsif_data_implementations_schema_versions.min_schema_version, EXCLUDED.min_schema_version),\n        max_schema_version = GREATEST(lsif_data_implementations_schema_versions.max_schema_version, EXCLUDED.max_schema_version);\n\n    RETURN NULL;\nEND $$ LANGUAGE plpgsql;\n\nCREATE TRIGGER lsif_data_implementations_schema_versions_insert\n    AFTER INSERT ON lsif_data_implementations REFERENCING NEW TABLE AS newtab\n    FOR EACH STATEMENT EXECUTE PROCEDURE update_lsif_data_implementations_schema_versions_insert();",
				"DownQuery": "DROP TABLE lsif_data_implementations_schema_versions;\nDROP TRIGGER lsif_data_implementations_schema_versions_insert ON lsif_data_implementations;\nDROP FUNCTION update_lsif_data_implementations_schema_versions_insert;\n\nDROP TABLE lsif_data_implementations;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000029
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000031,
				"Name": "intarray extension",
				"UpQuery": "CREATE EXTENSION IF NOT EXISTS intarray;\n\nCOMMENT ON EXTENSION intarray IS 'functions, operators, and index support for 1-D arrays of integers';",
				"DownQuery": "DROP EXTENSION IF EXISTS intarray;",
				"Privileged": true,
				"NonIdempotent": false,
				"Parents": [
					1000000030
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000032,
				"Name": "rockskip",
				"UpQuery": "CREATE TABLE IF NOT EXISTS rockskip_repos (\n    id               SERIAL    PRIMARY KEY,\n    repo             TEXT      NOT NULL,\n    last_accessed_at TIMESTAMP WITH TIME ZONE NOT NULL,\n    UNIQUE (repo)\n);\n\nCREATE TABLE IF NOT EXISTS rockskip_ancestry (\n    id          SERIAL      PRIMARY KEY,\n    repo_id     INTEGER     NOT NULL,\n    commit_id   VARCHAR(40) NOT NULL,\n    height      INTEGER     NOT NULL,\n    ancestor    INTEGER     NOT NULL,\n    UNIQUE (repo_id, commit_id)\n);\n\n-- Insert the null commit. repo_id 0 will not conflict with other repos because SERIAL's MINVALUE\n-- defaults to 1.\nINSERT INTO rockskip_ancestry\n       (id, commit_id                                 , repo_id    , height, ancestor)\nVALUES (0 , '0000000000000000000000000000000000000000', 0          , 0     , 0       )\nON CONFLICT DO NOTHING;\n\nCREATE TABLE IF NOT EXISTS rockskip_symbols (\n    -- Globally unique ID of this instance of the symbol.\n    id           SERIAL        PRIMARY KEY,\n    added        INTEGER[]     NOT NULL,\n    deleted      INTEGER[]     NOT NULL,\n\n    -- Since we only support searching by symbol name and we re-parse the file at query time, symbols\n    -- with the same name in the same file only need to be stored once. Upon re-parsing the file at query\n    -- time we will discover all symbols that match.\n    repo_id      INTEGER       NOT NULL,\n    path         TEXT          NOT NULL,\n    name         TEXT          NOT NULL\n);\n\nCREATE OR REPLACE FUNCTION singleton(value TEXT) RETURNS TEXT[] AS $$ BEGIN\n    RETURN ARRAY[value];\nEND; $$ IMMUTABLE language plpgsql;\n\nCREATE OR REPLACE FUNCTION singleton_integer(value INTEGER) RETURNS INTEGER[] AS $$ BEGIN\n    RETURN ARRAY[value];\nEND; $$ IMMUTABLE language plpgsql;\n\nCREATE OR REPLACE FUNCTION path_prefixes(path TEXT) RETURNS TEXT[] AS $$ BEGIN\n    RETURN (\n        SELECT array_agg(array_to_string(components[:len], '/')) prefixes\n        FROM\n            (SELECT regexp_split_to_array(path, E'/') components) t,\n            generate_series(1, array_length(components, 1)) AS len\n    );\nEND; $$ IMMUTABLE language plpgsql;\n\nCREATE INDEX IF NOT EXISTS rockskip_repos_repo ON rockskip_repos(repo);\n\nCREATE INDEX IF NOT EXISTS rockskip_repos_last_accessed_at ON rockskip_repos(last_accessed_at);\n\nCREATE INDEX IF NOT EXISTS rockskip_ancestry_repo_commit_id ON rockskip_ancestry(repo_id, commit_id);\n\nCREATE INDEX IF NOT EXISTS rockskip_symbols_repo_id_path_name ON rockskip_symbols(repo_id, path, name);\n\nCREATE INDEX IF NOT EXISTS rockskip_symbols_gin ON rockskip_symbols USING GIN (\n    singleton_integer(repo_id) gin__int_ops,\n    added gin__int_ops,\n    deleted gin__int_ops,\n    singleton(path),\n    path_prefixes(path),\n    singleton(name),\n    name gin_trgm_ops\n);",
				"DownQuery": "DROP TABLE IF EXISTS rockskip_ancestry;\nDROP TABLE IF EXISTS rockskip_symbols;\nDROP TABLE IF EXISTS rockskip_repos;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000031
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000033,
				"Name": "rockskip file extension",
				"UpQuery": "DROP INDEX IF EXISTS rockskip_symbols_gin;\n\nCREATE OR REPLACE FUNCTION get_file_extension(path TEXT) RETURNS TEXT AS $$ BEGIN\n    RETURN substring(path FROM '\\.([^\\.]*)$');\nEND; $$ IMMUTABLE language plpgsql;\n\nCREATE INDEX IF NOT EXISTS rockskip_symbols_gin ON rockskip_symbols USING GIN (\n    singleton_integer(repo_id) gin__int_ops,\n    added gin__int_ops,\n    deleted gin__int_ops,\n    singleton(path),\n    path_prefixes(path),\n    singleton(name),\n    name gin_trgm_ops,\n    singleton(get_file_extension(path))\n);",
				"DownQuery": "DROP INDEX IF EXISTS rockskip_symbols_gin;\n\nDROP FUNCTION IF EXISTS get_file_extension;\n\nCREATE INDEX IF NOT EXISTS rockskip_symbols_gin ON rockskip_symbols USING GIN (\n    singleton_integer(repo_id) gin__int_ops,\n    added gin__int_ops,\n    deleted gin__int_ops,\n    singleton(path),\n    path_prefixes(path),\n    singleton(name),\n    name gin_trgm_ops\n);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000032
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000034,
				"Name": "rockskip lowercase",
				"UpQuery": "DROP INDEX IF EXISTS rockskip_symbols_gin;\n\nCREATE OR REPLACE FUNCTION get_file_extension(path TEXT) RETURNS TEXT AS $$ BEGIN\n    RETURN substring(path FROM '\\.([^\\.]*)$');\nEND; $$ IMMUTABLE language plpgsql;\n\nCREATE INDEX IF NOT EXISTS rockskip_symbols_gin ON rockskip_symbols USING GIN (\n    -- repo_id\n    singleton_integer(repo_id) gin__int_ops,\n\n    -- added,deleted\n    added gin__int_ops,\n    deleted gin__int_ops,\n\n    -- name\n    name gin_trgm_ops,\n    singleton(name),\n    singleton(lower(name)),\n\n    -- path\n    path gin_trgm_ops,\n    singleton(path),\n    path_prefixes(path),\n    singleton(lower(path)),\n    path_prefixes(lower(path)),\n\n    -- file extension\n    singleton(get_file_extension(path)),\n    singleton(get_file_extension(lower(path)))\n);",
				"DownQuery": "DROP INDEX IF EXISTS rockskip_symbols_gin;\n\nCREATE INDEX IF NOT EXISTS rockskip_symbols_gin ON rockskip_symbols USING GIN (\n    singleton_integer(repo_id) gin__int_ops,\n    added gin__int_ops,\n    deleted gin__int_ops,\n    singleton(path),\n    path_prefixes(path),\n    singleton(name),\n    name gin_trgm_ops,\n    singleton(get_file_extension(path))\n);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000033
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1665531314,
				"Name": "Remove API docs tables",
				"UpQuery": "DROP TRIGGER IF EXISTS lsif_data_docs_search_private_delete ON lsif_data_docs_search_private;\n\nDROP TRIGGER IF EXISTS lsif_data_docs_search_private_insert ON lsif_data_docs_search_private;\n\nDROP TRIGGER IF EXISTS lsif_data_docs_search_public_delete ON lsif_data_docs_search_public;\n\nDROP TRIGGER IF EXISTS lsif_data_docs_search_public_insert ON lsif_data_docs_search_public;\n\nDROP TRIGGER IF EXISTS lsif_data_documentation_pages_delete ON lsif_data_documentation_pages;\n\nDROP TRIGGER IF EXISTS lsif_data_documentation_pages_insert ON lsif_data_documentation_pages;\n\nDROP TRIGGER IF EXISTS lsif_data_documentation_pages_update ON lsif_data_documentation_pages;\n\nDROP FUNCTION IF EXISTS lsif_data_docs_search_private_delete();\n\nDROP FUNCTION IF EXISTS lsif_data_docs_search_private_insert();\n\nDROP FUNCTION IF EXISTS lsif_data_docs_search_public_delete();\n\nDROP FUNCTION IF EXISTS lsif_data_docs_search_public_insert();\n\nDROP FUNCTION IF EXISTS lsif_data_documentation_pages_delete();\n\nDROP FUNCTION IF EXISTS lsif_data_documentation_pages_insert();\n\nDROP FUNCTION IF EXISTS lsif_data_documentation_pages_update();\n\nDROP TABLE IF EXISTS lsif_data_apidocs_num_dumps CASCADE;\n\nDROP TABLE IF EXISTS lsif_data_apidocs_num_dumps_indexed CASCADE;\n\nDROP TABLE IF EXISTS lsif_data_apidocs_num_pages CASCADE;\n\nDROP TABLE IF EXISTS lsif_data_apidocs_num_search_results_private CASCADE;\n\nDROP TABLE IF EXISTS lsif_data_apidocs_num_search_results_public CASCADE;\n\nDROP TABLE IF EXISTS lsif_data_docs_search_current_private CASCADE;\n\nDROP TABLE IF EXISTS lsif_data_docs_search_current_public CASCADE;\n\nDROP TABLE IF EXISTS lsif_data_docs_search_lang_names_private CASCADE;\n\nDROP TABLE IF EXISTS lsif_data_docs_search_lang_names_public CASCADE;\n\nDROP TABLE IF EXISTS lsif_data_docs_search_private CASCADE;\n\nDROP TABLE IF EXISTS lsif_data_docs_search_public CASCADE;\n\nDROP TABLE IF EXISTS lsif_data_docs_search_repo_names_private CASCADE;\n\nDROP TABLE IF EXISTS lsif_data_docs_search_repo_names_public CASCADE;\n\nDROP TABLE IF EXISTS lsif_data_docs_search_tags_private CASCADE;\n\nDROP TABLE IF EXISTS lsif_data_docs_search_tags_public CASCADE;\n\nDROP TABLE IF EXISTS lsif_data_documentation_mappings CASCADE;\n\nDROP TABLE IF EXISTS lsif_data_documentation_pages CASCADE;\n\nDROP TABLE IF EXISTS lsif_data_documentation_path_info CASCADE;",
				"DownQuery": "CREATE OR REPLACE FUNCTION lsif_data_docs_search_private_delete() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$\nBEGIN\nUPDATE lsif_data_apidocs_num_search_results_private SET count = count - (select count(*) from oldtbl);\nRETURN NULL;\nEND $$;\n\nCREATE OR REPLACE FUNCTION lsif_data_docs_search_private_insert() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$\nBEGIN\nUPDATE lsif_data_apidocs_num_search_results_private SET count = count + (select count(*) from newtbl);\nRETURN NULL;\nEND $$;\n\nCREATE OR REPLACE FUNCTION lsif_data_docs_search_public_delete() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$\nBEGIN\nUPDATE lsif_data_apidocs_num_search_results_public SET count = count - (select count(*) from oldtbl);\nRETURN NULL;\nEND $$;\n\nCREATE OR REPLACE FUNCTION lsif_data_docs_search_public_insert() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$\nBEGIN\nUPDATE lsif_data_apidocs_num_search_results_public SET count = count + (select count(*) from newtbl);\nRETURN NULL;\nEND $$;\n\nCREATE OR REPLACE FUNCTION lsif_data_documentation_pages_delete() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$\nBEGIN\nUPDATE lsif_data_apidocs_num_pages SET count = count - (select count(*) from oldtbl);\nUPDATE lsif_data_apidocs_num_dumps SET count = count - (select count(DISTINCT dump_id) from oldtbl);\nUPDATE lsif_data_apidocs_num_dumps_indexed SET count = count - (select count(DISTINCT dump_id) from oldtbl WHERE search_indexed='true');\nRETURN NULL;\nEND $$;\n\nCREATE OR REPLACE FUNCTION lsif_data_documentation_pages_insert() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$\nBEGIN\nUPDATE lsif_data_apidocs_num_pages SET count = count + (select count(*) from newtbl);\nUPDATE lsif_data_apidocs_num_dumps SET count = count + (select count(DISTINCT dump_id) from newtbl);\nUPDATE lsif_data_apidocs_num_dumps_indexed SET count = count + (select count(DISTINCT dump_id) from newtbl WHERE search_indexed='true');\nRETURN NULL;\nEND $$;\n\nCREATE OR REPLACE FUNCTION lsif_data_documentation_pages_update() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$\nBEGIN\nWITH\n    beforeIndexed AS (SELECT count(DISTINCT dump_id) FROM oldtbl WHERE search_indexed='true'),\n    afterIndexed AS (SELECT count(DISTINCT dump_id) FROM newtbl WHERE search_indexed='true')\nUPDATE lsif_data_apidocs_num_dumps_indexed SET count=count + ((select * from afterIndexed) - (select * from beforeIndexed));\nRETURN NULL;\nEND $$;\n\nCREATE TABLE IF NOT EXISTS lsif_data_apidocs_num_dumps (count bigint);\nCREATE TABLE IF NOT EXISTS lsif_data_apidocs_num_dumps_indexed (count bigint);\nCREATE TABLE IF NOT EXISTS lsif_data_apidocs_num_pages (count bigint);\nCREATE TABLE IF NOT EXISTS lsif_data_apidocs_num_search_results_private (count bigint);\nCREATE TABLE IF NOT EXISTS lsif_data_apidocs_num_search_results_public (count bigint);\n\nINSERT INTO lsif_data_apidocs_num_dumps VALUES (0);\nINSERT INTO lsif_data_apidocs_num_dumps_indexed VALUES (0);\nINSERT INTO lsif_data_apidocs_num_pages VALUES (0);\nINSERT INTO lsif_data_apidocs_num_search_results_private VALUES (0);\nINSERT INTO lsif_data_apidocs_num_search_results_public VALUES (0);\n\nCREATE TABLE IF NOT EXISTS lsif_data_docs_search_current_private (\n    repo_id integer NOT NULL,\n    dump_root text NOT NULL,\n    lang_name_id integer NOT NULL,\n    dump_id integer NOT NULL,\n    last_cleanup_scan_at timestamp with time zone DEFAULT now() NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    id BIGSERIAL,\n    PRIMARY KEY(id)\n);\n\nCREATE TABLE IF NOT EXISTS lsif_data_docs_search_current_public (\n    repo_id integer NOT NULL,\n    dump_root text NOT NULL,\n    lang_name_id integer NOT NULL,\n    dump_id integer NOT NULL,\n    last_cleanup_scan_at timestamp with time zone DEFAULT now() NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    id BIGSERIAL,\n    PRIMARY KEY(id)\n);\n\nCREATE TABLE IF NOT EXISTS lsif_data_docs_search_lang_names_private (\n    id BIGSERIAL,\n    lang_name text NOT NULL,\n    tsv tsvector NOT NULL,\n    PRIMARY KEY(id),\n    UNIQUE(lang_name)\n);\n\nCREATE TABLE IF NOT EXISTS lsif_data_docs_search_lang_names_public (\n    id BIGSERIAL,\n    lang_name text NOT NULL,\n    tsv tsvector NOT NULL,\n    PRIMARY KEY(id),\n    UNIQUE(lang_name)\n);\n\nCREATE TABLE IF NOT EXISTS lsif_data_docs_search_private (\n    id BIGSERIAL,\n    repo_id integer NOT NULL,\n    dump_id integer NOT NULL,\n    dump_root text NOT NULL,\n    path_id text NOT NULL,\n    detail text NOT NULL,\n    lang_name_id integer NOT NULL,\n    repo_name_id integer NOT NULL,\n    tags_id integer NOT NULL,\n    search_key text NOT NULL,\n    search_key_tsv tsvector NOT NULL,\n    search_key_reverse_tsv tsvector NOT NULL,\n    label text NOT NULL,\n    label_tsv tsvector NOT NULL,\n    label_reverse_tsv tsvector NOT NULL,\n    PRIMARY KEY(id)\n);\n\nCREATE TABLE IF NOT EXISTS lsif_data_docs_search_public (\n    id BIGSERIAL,\n    repo_id integer NOT NULL,\n    dump_id integer NOT NULL,\n    dump_root text NOT NULL,\n    path_id text NOT NULL,\n    detail text NOT NULL,\n    lang_name_id integer NOT NULL,\n    repo_name_id integer NOT NULL,\n    tags_id integer NOT NULL,\n    search_key text NOT NULL,\n    search_key_tsv tsvector NOT NULL,\n    search_key_reverse_tsv tsvector NOT NULL,\n    label text NOT NULL,\n    label_tsv tsvector NOT NULL,\n    label_reverse_tsv tsvector NOT NULL,\n    PRIMARY KEY(id)\n);\n\nCREATE TABLE IF NOT EXISTS lsif_data_docs_search_repo_names_private (\n    id BIGSERIAL,\n    repo_name text NOT NULL,\n    tsv tsvector NOT NULL,\n    reverse_tsv tsvector NOT NULL,\n    PRIMARY KEY(id),\n    UNIQUE(repo_name)\n);\n\nCREATE TABLE IF NOT EXISTS lsif_data_docs_search_repo_names_public (\n    id BIGSERIAL,\n    repo_name text NOT NULL,\n    tsv tsvector NOT NULL,\n    reverse_tsv tsvector NOT NULL,\n    PRIMARY KEY(id),\n    UNIQUE(repo_name)\n);\n\nCREATE TABLE IF NOT EXISTS lsif_data_docs_search_tags_private (\n    id BIGSERIAL,\n    tags text NOT NULL UNIQUE,\n    tsv tsvector NOT NULL,\n    PRIMARY KEY(id)\n);\n\nCREATE TABLE IF NOT EXISTS lsif_data_docs_search_tags_public (\n    id BIGSERIAL,\n    tags text NOT NULL UNIQUE,\n    tsv tsvector NOT NULL,\n    PRIMARY KEY(id),\n    UNIQUE(tags)\n);\n\nCREATE TABLE IF NOT EXISTS lsif_data_documentation_mappings (\n    dump_id integer NOT NULL,\n    path_id text NOT NULL,\n    result_id integer NOT NULL,\n    file_path text,\n    PRIMARY KEY(dump_id, path_id)\n);\n\nCREATE TABLE IF NOT EXISTS lsif_data_documentation_pages (\n    dump_id integer NOT NULL,\n    path_id text NOT NULL,\n    data bytea,\n    search_indexed boolean DEFAULT false,\n    PRIMARY KEY(dump_id, path_id)\n);\n\nCREATE TABLE IF NOT EXISTS lsif_data_documentation_path_info (\n    dump_id integer NOT NULL,\n    path_id text NOT NULL,\n    data bytea,\n    PRIMARY KEY(dump_id, path_id)\n);\n\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_current_private_last_cleanup_scan_at ON lsif_data_docs_search_current_private USING btree (last_cleanup_scan_at);\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_current_private_lookup ON lsif_data_docs_search_current_private USING btree (repo_id, dump_root, lang_name_id, created_at) INCLUDE (dump_id);\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_current_public_last_cleanup_scan_at ON lsif_data_docs_search_current_public USING btree (last_cleanup_scan_at);\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_current_public_lookup ON lsif_data_docs_search_current_public USING btree (repo_id, dump_root, lang_name_id, created_at) INCLUDE (dump_id);\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_lang_names_private_tsv_idx ON lsif_data_docs_search_lang_names_private USING gin (tsv);\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_lang_names_public_tsv_idx ON lsif_data_docs_search_lang_names_public USING gin (tsv);\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_private_dump_id_idx ON lsif_data_docs_search_private USING btree (dump_id);\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_private_dump_root_idx ON lsif_data_docs_search_private USING btree (dump_root);\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_private_label_reverse_tsv_idx ON lsif_data_docs_search_private USING gin (label_reverse_tsv);\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_private_label_tsv_idx ON lsif_data_docs_search_private USING gin (label_tsv);\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_private_repo_id_idx ON lsif_data_docs_search_private USING btree (repo_id);\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_private_search_key_reverse_tsv_idx ON lsif_data_docs_search_private USING gin (search_key_reverse_tsv);\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_private_search_key_tsv_idx ON lsif_data_docs_search_private USING gin (search_key_tsv);\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_public_dump_id_idx ON lsif_data_docs_search_public USING btree (dump_id);\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_public_dump_root_idx ON lsif_data_docs_search_public USING btree (dump_root);\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_public_label_reverse_tsv_idx ON lsif_data_docs_search_public USING gin (label_reverse_tsv);\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_public_label_tsv_idx ON lsif_data_docs_search_public USING gin (label_tsv);\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_public_repo_id_idx ON lsif_data_docs_search_public USING btree (repo_id);\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_public_search_key_reverse_tsv_idx ON lsif_data_docs_search_public USING gin (search_key_reverse_tsv);\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_public_search_key_tsv_idx ON lsif_data_docs_search_public USING gin (search_key_tsv);\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_repo_names_private_reverse_tsv_idx ON lsif_data_docs_search_repo_names_private USING gin (reverse_tsv);\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_repo_names_private_tsv_idx ON lsif_data_docs_search_repo_names_private USING gin (tsv);\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_repo_names_public_reverse_tsv_idx ON lsif_data_docs_search_repo_names_public USING gin (reverse_tsv);\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_repo_names_public_tsv_idx ON lsif_data_docs_search_repo_names_public USING gin (tsv);\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_tags_private_tsv_idx ON lsif_data_docs_search_tags_private USING gin (tsv);\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_tags_public_tsv_idx ON lsif_data_docs_search_tags_public USING gin (tsv);\nCREATE UNIQUE INDEX IF NOT EXISTS lsif_data_documentation_mappings_inverse_unique_idx ON lsif_data_documentation_mappings USING btree (dump_id, result_id);\nCREATE INDEX IF NOT EXISTS lsif_data_documentation_pages_dump_id_unindexed ON lsif_data_documentation_pages USING btree (dump_id) WHERE (NOT search_indexed);\n\nDROP TRIGGER IF EXISTS lsif_data_docs_search_private_delete ON lsif_data_docs_search_private;\nCREATE TRIGGER lsif_data_docs_search_private_delete AFTER DELETE ON lsif_data_docs_search_private REFERENCING OLD TABLE AS oldtbl FOR EACH STATEMENT EXECUTE FUNCTION lsif_data_docs_search_private_delete();\nDROP TRIGGER IF EXISTS lsif_data_docs_search_private_insert ON lsif_data_docs_search_private;\nCREATE TRIGGER lsif_data_docs_search_private_insert AFTER INSERT ON lsif_data_docs_search_private REFERENCING NEW TABLE AS newtbl FOR EACH STATEMENT EXECUTE FUNCTION lsif_data_docs_search_private_insert();\nDROP TRIGGER IF EXISTS lsif_data_docs_search_public_delete ON lsif_data_docs_search_public;\nCREATE TRIGGER lsif_data_docs_search_public_delete AFTER DELETE ON lsif_data_docs_search_public REFERENCING OLD TABLE AS oldtbl FOR EACH STATEMENT EXECUTE FUNCTION lsif_data_docs_search_public_delete();\nDROP TRIGGER IF EXISTS lsif_data_docs_search_public_insert ON lsif_data_docs_search_public;\nCREATE TRIGGER lsif_data_docs_search_public_insert AFTER INSERT ON lsif_data_docs_search_public REFERENCING NEW TABLE AS newtbl FOR EACH STATEMENT EXECUTE FUNCTION lsif_data_docs_search_public_insert();\nDROP TRIGGER IF EXISTS lsif_data_documentation_pages_delete ON lsif_data_documentation_pages;\nCREATE TRIGGER lsif_data_documentation_pages_delete AFTER DELETE ON lsif_data_documentation_pages REFERENCING OLD TABLE AS oldtbl FOR EACH STATEMENT EXECUTE FUNCTION lsif_data_documentation_pages_delete();\nDROP TRIGGER IF EXISTS lsif_data_documentation_pages_insert ON lsif_data_documentation_pages;\nCREATE TRIGGER lsif_data_documentation_pages_insert AFTER INSERT ON lsif_data_documentation_pages REFERENCING NEW TABLE AS newtbl FOR EACH STATEMENT EXECUTE FUNCTION lsif_data_documentation_pages_insert();\nDROP TRIGGER IF EXISTS lsif_data_documentation_pages_update ON lsif_data_documentation_pages;\nCREATE TRIGGER lsif_data_documentation_pages_update AFTER UPDATE ON lsif_data_documentation_pages REFERENCING OLD TABLE AS oldtbl NEW TABLE AS newtbl FOR EACH STATEMENT EXECUTE FUNCTION lsif_data_documentation_pages_update();\n\nCOMMENT ON TABLE lsif_data_docs_search_current_private IS 'A table indicating the most current search index for a unique repository, root, and language.';\nCOMMENT ON COLUMN lsif_data_docs_search_current_private.repo_id IS 'The repository identifier of the associated dump.';\nCOMMENT ON COLUMN lsif_data_docs_search_current_private.dump_root IS 'The root of the associated dump.';\nCOMMENT ON COLUMN lsif_data_docs_search_current_private.lang_name_id IS 'The interned index name of the associated dump.';\nCOMMENT ON COLUMN lsif_data_docs_search_current_private.dump_id IS 'The associated dump identifier.';\nCOMMENT ON COLUMN lsif_data_docs_search_current_private.last_cleanup_scan_at IS 'The last time this record was checked as part of a data retention scan.';\nCOMMENT ON COLUMN lsif_data_docs_search_current_private.created_at IS 'The time this record was inserted. The records with the latest created_at value for the same repository, root, and language is the only visible one and others will be deleted asynchronously.';\n\nCOMMENT ON TABLE lsif_data_docs_search_current_public IS 'A table indicating the most current search index for a unique repository, root, and language.';\nCOMMENT ON COLUMN lsif_data_docs_search_current_public.repo_id IS 'The repository identifier of the associated dump.';\nCOMMENT ON COLUMN lsif_data_docs_search_current_public.dump_root IS 'The root of the associated dump.';\nCOMMENT ON COLUMN lsif_data_docs_search_current_public.lang_name_id IS 'The interned index name of the associated dump.';\nCOMMENT ON COLUMN lsif_data_docs_search_current_public.dump_id IS 'The associated dump identifier.';\nCOMMENT ON COLUMN lsif_data_docs_search_current_public.last_cleanup_scan_at IS 'The last time this record was checked as part of a data retention scan.';\nCOMMENT ON COLUMN lsif_data_docs_search_current_public.created_at IS 'The time this record was inserted. The records with the latest created_at value for the same repository, root, and language is the only visible one and others will be deleted asynchronously.';\n\nCOMMENT ON TABLE lsif_data_docs_search_lang_names_private IS 'Each unique language name being stored in the API docs search index.';\nCOMMENT ON COLUMN lsif_data_docs_search_lang_names_private.id IS 'The ID of the language name.';\nCOMMENT ON COLUMN lsif_data_docs_search_lang_names_private.lang_name IS 'The lowercase language name (go, java, etc.) OR, if unknown, the LSIF indexer name.';\nCOMMENT ON COLUMN lsif_data_docs_search_lang_names_private.tsv IS 'Indexed tsvector for the lang_name field. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\n\nCOMMENT ON TABLE lsif_data_docs_search_lang_names_public IS 'Each unique language name being stored in the API docs search index.';\nCOMMENT ON COLUMN lsif_data_docs_search_lang_names_public.id IS 'The ID of the language name.';\nCOMMENT ON COLUMN lsif_data_docs_search_lang_names_public.lang_name IS 'The lowercase language name (go, java, etc.) OR, if unknown, the LSIF indexer name.';\nCOMMENT ON COLUMN lsif_data_docs_search_lang_names_public.tsv IS 'Indexed tsvector for the lang_name field. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\n\nCOMMENT ON TABLE lsif_data_docs_search_private IS 'A tsvector search index over API documentation (private repos only)';\nCOMMENT ON COLUMN lsif_data_docs_search_private.id IS 'The row ID of the search result.';\nCOMMENT ON COLUMN lsif_data_docs_search_private.repo_id IS 'The repo ID, from the main app DB repo table. Used to search over a select set of repos by ID.';\nCOMMENT ON COLUMN lsif_data_docs_search_private.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\nCOMMENT ON COLUMN lsif_data_docs_search_private.dump_root IS 'Identical to lsif_dumps.root; The working directory of the indexer image relative to the repository root.';\nCOMMENT ON COLUMN lsif_data_docs_search_private.path_id IS 'The fully qualified documentation page path ID, e.g. including \"#section\". See GraphQL codeintel.schema:documentationPage for what this is.';\nCOMMENT ON COLUMN lsif_data_docs_search_private.detail IS 'The detail string (e.g. the full function signature and its docs). See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_docs_search_private.lang_name_id IS 'The programming language (or indexer name) that produced the result. Foreign key into lsif_data_docs_search_lang_names_private.';\nCOMMENT ON COLUMN lsif_data_docs_search_private.repo_name_id IS 'The repository name that produced the result. Foreign key into lsif_data_docs_search_repo_names_private.';\nCOMMENT ON COLUMN lsif_data_docs_search_private.tags_id IS 'The tags from the documentation node. Foreign key into lsif_data_docs_search_tags_private.';\nCOMMENT ON COLUMN lsif_data_docs_search_private.search_key IS 'The search key generated by the indexer, e.g. mux.Router.ServeHTTP. It is language-specific, and likely unique within a repository (but not always.) See protocol/documentation.go:Documentation.SearchKey';\nCOMMENT ON COLUMN lsif_data_docs_search_private.search_key_tsv IS 'Indexed tsvector for the search_key field. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\nCOMMENT ON COLUMN lsif_data_docs_search_private.search_key_reverse_tsv IS 'Indexed tsvector for the reverse of the search_key field, for suffix lexeme/word matching. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\nCOMMENT ON COLUMN lsif_data_docs_search_private.label IS 'The label string of the result, e.g. a one-line function signature. See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_docs_search_private.label_tsv IS 'Indexed tsvector for the label field. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\nCOMMENT ON COLUMN lsif_data_docs_search_private.label_reverse_tsv IS 'Indexed tsvector for the reverse of the label field, for suffix lexeme/word matching. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\n\nCOMMENT ON TABLE lsif_data_docs_search_public IS 'A tsvector search index over API documentation (public repos only)';\nCOMMENT ON COLUMN lsif_data_docs_search_public.id IS 'The row ID of the search result.';\nCOMMENT ON COLUMN lsif_data_docs_search_public.repo_id IS 'The repo ID, from the main app DB repo table. Used to search over a select set of repos by ID.';\nCOMMENT ON COLUMN lsif_data_docs_search_public.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\nCOMMENT ON COLUMN lsif_data_docs_search_public.dump_root IS 'Identical to lsif_dumps.root; The working directory of the indexer image relative to the repository root.';\nCOMMENT ON COLUMN lsif_data_docs_search_public.path_id IS 'The fully qualified documentation page path ID, e.g. including \"#section\". See GraphQL codeintel.schema:documentationPage for what this is.';\nCOMMENT ON COLUMN lsif_data_docs_search_public.detail IS 'The detail string (e.g. the full function signature and its docs). See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_docs_search_public.lang_name_id IS 'The programming language (or indexer name) that produced the result. Foreign key into lsif_data_docs_search_lang_names_public.';\nCOMMENT ON COLUMN lsif_data_docs_search_public.repo_name_id IS 'The repository name that produced the result. Foreign key into lsif_data_docs_search_repo_names_public.';\nCOMMENT ON COLUMN lsif_data_docs_search_public.tags_id IS 'The tags from the documentation node. Foreign key into lsif_data_docs_search_tags_public.';\nCOMMENT ON COLUMN lsif_data_docs_search_public.search_key IS 'The search key generated by the indexer, e.g. mux.Router.ServeHTTP. It is language-specific, and likely unique within a repository (but not always.) See protocol/documentation.go:Documentation.SearchKey';\nCOMMENT ON COLUMN lsif_data_docs_search_public.search_key_tsv IS 'Indexed tsvector for the search_key field. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\nCOMMENT ON COLUMN lsif_data_docs_search_public.search_key_reverse_tsv IS 'Indexed tsvector for the reverse of the search_key field, for suffix lexeme/word matching. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\nCOMMENT ON COLUMN lsif_data_docs_search_public.label IS 'The label string of the result, e.g. a one-line function signature. See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_docs_search_public.label_tsv IS 'Indexed tsvector for the label field. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\nCOMMENT ON COLUMN lsif_data_docs_search_public.label_reverse_tsv IS 'Indexed tsvector for the reverse of the label field, for suffix lexeme/word matching. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\n\nCOMMENT ON TABLE lsif_data_docs_search_repo_names_private IS 'Each unique repository name being stored in the API docs search index.';\nCOMMENT ON COLUMN lsif_data_docs_search_repo_names_private.id IS 'The ID of the repository name.';\nCOMMENT ON COLUMN lsif_data_docs_search_repo_names_private.repo_name IS 'The fully qualified name of the repository.';\nCOMMENT ON COLUMN lsif_data_docs_search_repo_names_private.tsv IS 'Indexed tsvector for the lang_name field. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\nCOMMENT ON COLUMN lsif_data_docs_search_repo_names_private.reverse_tsv IS 'Indexed tsvector for the reverse of the lang_name field, for suffix lexeme/word matching. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\n\nCOMMENT ON TABLE lsif_data_docs_search_repo_names_public IS 'Each unique repository name being stored in the API docs search index.';\nCOMMENT ON COLUMN lsif_data_docs_search_repo_names_public.id IS 'The ID of the repository name.';\nCOMMENT ON COLUMN lsif_data_docs_search_repo_names_public.repo_name IS 'The fully qualified name of the repository.';\nCOMMENT ON COLUMN lsif_data_docs_search_repo_names_public.tsv IS 'Indexed tsvector for the lang_name field. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\nCOMMENT ON COLUMN lsif_data_docs_search_repo_names_public.reverse_tsv IS 'Indexed tsvector for the reverse of the lang_name field, for suffix lexeme/word matching. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\n\nCOMMENT ON TABLE lsif_data_docs_search_tags_private IS 'Each uniques sequence of space-separated tags being stored in the API docs search index.';\nCOMMENT ON COLUMN lsif_data_docs_search_tags_private.id IS 'The ID of the tags.';\nCOMMENT ON COLUMN lsif_data_docs_search_tags_private.tags IS 'The full sequence of space-separated tags. See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_docs_search_tags_private.tsv IS 'Indexed tsvector for the tags field. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\n\nCOMMENT ON TABLE lsif_data_docs_search_tags_public IS 'Each uniques sequence of space-separated tags being stored in the API docs search index.';\nCOMMENT ON COLUMN lsif_data_docs_search_tags_public.id IS 'The ID of the tags.';\nCOMMENT ON COLUMN lsif_data_docs_search_tags_public.tags IS 'The full sequence of space-separated tags. See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_docs_search_tags_public.tsv IS 'Indexed tsvector for the tags field. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\n\nCOMMENT ON TABLE lsif_data_documentation_mappings IS 'Maps documentation path IDs to their corresponding integral documentationResult vertex IDs, which are unique within a dump.';\nCOMMENT ON COLUMN lsif_data_documentation_mappings.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\nCOMMENT ON COLUMN lsif_data_documentation_mappings.path_id IS 'The documentation page path ID, see see GraphQL codeintel.schema:documentationPage for what this is.';\nCOMMENT ON COLUMN lsif_data_documentation_mappings.result_id IS 'The documentationResult vertex ID.';\nCOMMENT ON COLUMN lsif_data_documentation_mappings.file_path IS 'The document file path for the documentationResult, if any. e.g. the path to the file where the symbol described by this documentationResult is located, if it is a symbol.';\n\nCOMMENT ON TABLE lsif_data_documentation_pages IS 'Associates documentation pathIDs to their documentation page hierarchy chunk.';\nCOMMENT ON COLUMN lsif_data_documentation_pages.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\nCOMMENT ON COLUMN lsif_data_documentation_pages.path_id IS 'The documentation page path ID, see see GraphQL codeintel.schema:documentationPage for what this is.';\nCOMMENT ON COLUMN lsif_data_documentation_pages.data IS 'A gob-encoded payload conforming to a `type DocumentationPageData struct` pointer (lib/codeintel/semantic/types.go)';\n\nCOMMENT ON TABLE lsif_data_documentation_path_info IS 'Associates documentation page pathIDs to information about what is at that pathID, its immediate children, etc.';\nCOMMENT ON COLUMN lsif_data_documentation_path_info.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\nCOMMENT ON COLUMN lsif_data_documentation_path_info.path_id IS 'The documentation page path ID, see see GraphQL codeintel.schema:documentationPage for what this is.';\nCOMMENT ON COLUMN lsif_data_documentation_path_info.data IS 'A gob-encoded payload conforming to a `type DocumentationPathInoData struct` pointer (lib/codeintel/semantic/types.go)';",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000034
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1666727108,
				"Name": "Add codeintel_last_reconcile table",
				"UpQuery": "CREATE TABLE IF NOT EXISTS codeintel_last_reconcile (\n    dump_id integer NOT NULL UNIQUE,\n    last_reconcile_at timestamp with time zone NOT NULL\n);\n\nCOMMENT ON TABLE codeintel_last_reconcile IS 'Stores the last time processed LSIF data was reconciled with the other database.';\n\nCREATE INDEX IF NOT EXISTS codeintel_last_reconcile_last_reconcile_at_dump_id ON codeintel_last_reconcile(last_reconcile_at, dump_id);",
				"DownQuery": "DROP TABLE IF EXISTS codeintel_last_reconcile;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1665531314
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1669075922,
				"Name": "Add SCIP tables",
				"UpQuery": "CREATE TABLE IF NOT EXISTS codeintel_scip_metadata (\n    id bigserial,\n    upload_id integer NOT NULL,\n    tool_name text NOT NULL,\n    tool_version text NOT NULL,\n    tool_arguments text[] NOT NULL,\n    PRIMARY KEY(id)\n);\n\nCOMMENT ON TABLE codeintel_scip_metadata IS 'Global metadatadata about a single processed upload.';\nCOMMENT ON COLUMN codeintel_scip_metadata.id IS 'An auto-generated identifier.';\nCOMMENT ON COLUMN codeintel_scip_metadata.upload_id IS 'The identifier of the upload that provided this SCIP index.';\nCOMMENT ON COLUMN codeintel_scip_metadata.tool_name IS 'Name of the indexer that produced this index.';\nCOMMENT ON COLUMN codeintel_scip_metadata.tool_version IS 'Version of the indexer that produced this index.';\nCOMMENT ON COLUMN codeintel_scip_metadata.tool_arguments IS 'Command-line arguments that were used to invoke this indexer.';\n\nCREATE TABLE IF NOT EXISTS codeintel_scip_documents(\n    id bigserial,\n    payload_hash bytea NOT NULL UNIQUE,\n    schema_version integer NOT NULL,\n    raw_scip_payload bytea NOT NULL,\n    PRIMARY KEY(id)\n);\n\nCOMMENT ON TABLE codeintel_scip_documents IS 'A lookup of SCIP [Document](https://sourcegraph.com/search?q=context:%40sourcegraph/all+repo:%5Egithub%5C.com/sourcegraph/scip%24+file:%5Escip%5C.proto+message+Document\u0026patternType=standard) payloads by their hash.';\nCOMMENT ON COLUMN codeintel_scip_documents.id IS 'An auto-generated identifier. This column is used as a foreign key target to reduce occurrences of the full payload hash value.';\nCOMMENT ON COLUMN codeintel_scip_documents.payload_hash IS 'A deterministic hash of the raw SCIP payload. We use this as a unique value to enforce deduplication between indexes with the same document data.';\nCOMMENT ON COLUMN codeintel_scip_documents.schema_version IS 'The schema version of this row - used to determine presence and encoding of (future) denormalized data.';\nCOMMENT ON COLUMN codeintel_scip_documents.raw_scip_payload IS 'The raw, canonicalized SCIP [Document](https://sourcegraph.com/search?q=context:%40sourcegraph/all+repo:%5Egithub%5C.com/sourcegraph/scip%24+file:%5Escip%5C.proto+message+Document\u0026patternType=standard) payload.';\n\nCREATE TABLE IF NOT EXISTS codeintel_scip_document_lookup(\n    id bigserial,\n    upload_id integer NOT NULL,\n    document_path text NOT NULL,\n    document_id bigint NOT NULL,\n    PRIMARY KEY (id),\n    UNIQUE (upload_id, document_path),\n    CONSTRAINT codeintel_scip_document_lookup_document_id_fk FOREIGN KEY(document_id) REFERENCES codeintel_scip_documents(id)\n);\n\nCREATE INDEX IF NOT EXISTS codeintel_scip_document_lookup_document_id ON codeintel_scip_document_lookup USING hash(document_id);\n\nCOMMENT ON TABLE codeintel_scip_document_lookup IS 'A mapping from file paths to document references within a particular SCIP index.';\nCOMMENT ON COLUMN codeintel_scip_document_lookup.id IS 'An auto-generated identifier. This column is used as a foreign key target to reduce occurrences of the full document path value.';\nCOMMENT ON COLUMN codeintel_scip_document_lookup.upload_id IS 'The identifier of the upload that provided this SCIP index.';\nCOMMENT ON COLUMN codeintel_scip_document_lookup.document_path IS 'The file path to the document relative to the root of the index.';\nCOMMENT ON COLUMN codeintel_scip_document_lookup.document_id IS 'The foreign key to the shared document payload (see the table [`codeintel_scip_document_lookup`](#table-publiccodeintel_scip_document_lookup)).';\n\nCREATE TABLE IF NOT EXISTS codeintel_scip_document_lookup_schema_versions (\n    upload_id integer NOT NULL,\n    min_schema_version integer,\n    max_schema_version integer,\n    PRIMARY KEY(upload_id)\n);\n\nCOMMENT ON TABLE codeintel_scip_document_lookup_schema_versions IS 'Tracks the range of `schema_versions` values associated with each SCIP index in the [`codeintel_scip_document_lookup`](#table-publiccodeintel_scip_document_lookup) table.';\nCOMMENT ON COLUMN codeintel_scip_document_lookup_schema_versions.upload_id IS 'The identifier of the associated SCIP index.';\nCOMMENT ON COLUMN codeintel_scip_document_lookup_schema_versions.min_schema_version IS 'A lower-bound on the `schema_version` values of the records in the table [`codeintel_scip_document_lookup`](#table-publiccodeintel_scip_document_lookup) where the `upload_id` column matches the associated SCIP index.';\nCOMMENT ON COLUMN codeintel_scip_document_lookup_schema_versions.max_schema_version IS 'An upper-bound on the `schema_version` values of the records in the table [`codeintel_scip_document_lookup`](#table-publiccodeintel_scip_document_lookup) where the `upload_id` column matches the associated SCIP index.';\n\nCREATE OR REPLACE FUNCTION update_codeintel_scip_document_lookup_schema_versions_insert() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$ BEGIN\n    INSERT INTO codeintel_scip_document_lookup_schema_versions\n    SELECT\n        upload_id,\n        MIN(documents.schema_version) as min_schema_version,\n        MAX(documents.schema_version) as max_schema_version\n    FROM newtab\n    JOIN codeintel_scip_documents ON codeintel_scip_documents.id = newtab.document_id\n    GROUP BY newtab.upload_id\n    ON CONFLICT (upload_id) DO UPDATE SET\n        -- Update with min(old_min, new_min) and max(old_max, new_max)\n        min_schema_version = LEAST(codeintel_scip_document_lookup_schema_versions.min_schema_version, EXCLUDED.min_schema_version),\n        max_schema_version = GREATEST(codeintel_scip_document_lookup_schema_versions.max_schema_version, EXCLUDED.max_schema_version);\n    RETURN NULL;\nEND $$;\n\nDROP TRIGGER IF EXISTS codeintel_scip_document_lookup_schema_versions_insert ON codeintel_scip_document_lookup_schema_versions;\nCREATE TRIGGER codeintel_scip_document_lookup_schema_versions_insert AFTER INSERT ON codeintel_scip_document_lookup_schema_versions\nREFERENCING NEW TABLE AS newtab FOR EACH STATEMENT EXECUTE FUNCTION update_codeintel_scip_document_lookup_schema_versions_insert();\n\nCREATE TABLE IF NOT EXISTS codeintel_scip_symbols(\n    upload_id integer NOT NULL,\n    symbol_name text NOT NULL,\n    document_lookup_id bigint NOT NULL,\n    schema_version integer NOT NULL,\n    definition_ranges bytea,\n    reference_ranges bytea,\n    implementation_ranges bytea,\n    type_definition_ranges bytea,\n    PRIMARY KEY (upload_id, symbol_name, document_lookup_id),\n    CONSTRAINT codeintel_scip_symbols_document_lookup_id_fk FOREIGN KEY(document_lookup_id) REFERENCES codeintel_scip_document_lookup(id) ON DELETE CASCADE\n);\n\nCOMMENT ON TABLE codeintel_scip_symbols IS 'A mapping from SCIP [Symbol names](https://sourcegraph.com/search?q=context:%40sourcegraph/all+repo:%5Egithub%5C.com/sourcegraph/scip%24+file:%5Escip%5C.proto+message+Symbol\u0026patternType=standard) to path and ranges where that symbol occurs within a particular SCIP index.';\nCOMMENT ON COLUMN codeintel_scip_symbols.upload_id IS 'The identifier of the upload that provided this SCIP index.';\nCOMMENT ON COLUMN codeintel_scip_symbols.symbol_name IS 'The SCIP [Symbol names](https://sourcegraph.com/search?q=context:%40sourcegraph/all+repo:%5Egithub%5C.com/sourcegraph/scip%24+file:%5Escip%5C.proto+message+Symbol\u0026patternType=standard).';\nCOMMENT ON COLUMN codeintel_scip_symbols.document_lookup_id IS 'A reference to the `id` column of [`codeintel_scip_document_lookup`](#table-publiccodeintel_scip_document_lookup). Joining on this table yields the document path relative to the index root.';\nCOMMENT ON COLUMN codeintel_scip_symbols.schema_version IS 'The schema version of this row - used to determine presence and encoding of denormalized data.';\nCOMMENT ON COLUMN codeintel_scip_symbols.definition_ranges IS 'An encoded set of ranges within the associated document that have a **definition** relationship to the associated symbol.';\nCOMMENT ON COLUMN codeintel_scip_symbols.reference_ranges IS 'An encoded set of ranges within the associated document that have a **reference** relationship to the associated symbol.';\nCOMMENT ON COLUMN codeintel_scip_symbols.implementation_ranges IS 'An encoded set of ranges within the associated document that have a **implementation** relationship to the associated symbol.';\nCOMMENT ON COLUMN codeintel_scip_symbols.type_definition_ranges IS 'An encoded set of ranges within the associated document that have a **type definition** relationship to the associated symbol.';\n\nCREATE TABLE IF NOT EXISTS codeintel_scip_symbols_schema_versions (\n    upload_id integer NOT NULL,\n    min_schema_version integer,\n    max_schema_version integer,\n    PRIMARY KEY(upload_id)\n);\n\nCOMMENT ON TABLE codeintel_scip_symbols_schema_versions IS 'Tracks the range of `schema_versions` for each index in the [`codeintel_scip_symbols`](#table-publiccodeintel_scip_symbols) table.';\nCOMMENT ON COLUMN codeintel_scip_symbols_schema_versions.upload_id IS 'The identifier of the associated SCIP index.';\nCOMMENT ON COLUMN codeintel_scip_symbols_schema_versions.min_schema_version IS 'A lower-bound on the `schema_version` values of the records in the table [`codeintel_scip_symbols`](#table-publiccodeintel_scip_symbols) where the `upload_id` column matches the associated SCIP index.';\nCOMMENT ON COLUMN codeintel_scip_symbols_schema_versions.max_schema_version IS 'An upper-bound on the `schema_version` values of the records in the table [`codeintel_scip_symbols`](#table-publiccodeintel_scip_symbols) where the `upload_id` column matches the associated SCIP index.';\n\nCREATE OR REPLACE FUNCTION update_codeintel_scip_symbols_schema_versions_insert() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$ BEGIN\n    INSERT INTO codeintel_scip_symbols_schema_versions\n    SELECT\n        upload_id,\n        MIN(schema_version) as min_schema_version,\n        MAX(schema_version) as max_schema_version\n    FROM newtab\n    GROUP BY upload_id\n    ON CONFLICT (upload_id) DO UPDATE SET\n        -- Update with min(old_min, new_min) and max(old_max, new_max)\n        min_schema_version = LEAST(codeintel_scip_symbols_schema_versions.min_schema_version, EXCLUDED.min_schema_version),\n        max_schema_version = GREATEST(codeintel_scip_symbols_schema_versions.max_schema_version, EXCLUDED.max_schema_version);\n    RETURN NULL;\nEND $$;\n\nDROP TRIGGER IF EXISTS codeintel_scip_symbols_schema_versions_insert ON codeintel_scip_symbols_schema_versions;\nCREATE TRIGGER codeintel_scip_symbols_schema_versions_insert AFTER INSERT ON codeintel_scip_symbols_schema_versions\nREFERENCING NEW TABLE AS newtab FOR EACH STATEMENT EXECUTE FUNCTION update_codeintel_scip_symbols_schema_versions_insert();",
				"DownQuery": "DROP TRIGGER IF EXISTS codeintel_scip_symbols_schema_versions_insert ON codeintel_scip_symbols_schema_versions;\nDROP FUNCTION IF EXISTS update_codeintel_scip_symbols_schema_versions_insert();\nDROP TABLE IF EXISTS codeintel_scip_symbols_schema_versions;\n\nDROP TRIGGER IF EXISTS codeintel_scip_document_lookup_schema_versions_insert ON codeintel_scip_document_lookup_schema_versions;\nDROP FUNCTION IF EXISTS update_codeintel_scip_document_lookup_schema_versions_insert();\nDROP TABLE IF EXISTS codeintel_scip_document_lookup_schema_versions;\n\nDROP TABLE IF EXISTS codeintel_scip_symbols;\nDROP TABLE IF EXISTS codeintel_scip_document_lookup;\nDROP TABLE IF EXISTS codeintel_scip_documents;\nDROP TABLE IF EXISTS codeintel_scip_metadata;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1666727108
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1669842405,
				"Name": "Add additional metadata fields",
				"UpQuery": "ALTER TABLE codeintel_scip_metadata ADD COLUMN IF NOT EXISTS text_document_encoding text NOT NULL;\nALTER TABLE codeintel_scip_metadata ADD COLUMN IF NOT EXISTS protocol_version integer NOT NULL;\n\nCOMMENT ON COLUMN codeintel_scip_metadata.text_document_encoding IS 'The encoding of the text documents within this index. May affect range boundaries.';\nCOMMENT ON COLUMN codeintel_scip_metadata.protocol_version IS 'The version of the SCIP protocol used to encode this index.';",
				"DownQuery": "ALTER TABLE codeintel_scip_metadata DROP COLUMN IF EXISTS text_document_encoding;\nALTER TABLE codeintel_scip_metadata DROP COLUMN IF EXISTS protocol_version;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1669075922
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1669934289,
				"Name": "Add scip document schema versions table",
				"UpQuery": "CREATE TABLE IF NOT EXISTS codeintel_scip_documents_schema_versions (\n    upload_id integer NOT NULL,\n    min_schema_version integer,\n    max_schema_version integer,\n    PRIMARY KEY(upload_id)\n);\n\nCOMMENT ON TABLE codeintel_scip_documents_schema_versions IS 'Tracks the range of `schema_versions` values associated with each SCIP index in the [`codeintel_scip_documents`](#table-publiccodeintel_scip_documents) table.';\nCOMMENT ON COLUMN codeintel_scip_documents_schema_versions.upload_id IS 'The identifier of the associated SCIP index.';\nCOMMENT ON COLUMN codeintel_scip_documents_schema_versions.min_schema_version IS 'A lower-bound on the `schema_version` values of the records in the table [`codeintel_scip_documents`](#table-publiccodeintel_scip_documents) where the `upload_id` column matches the associated SCIP index.';\nCOMMENT ON COLUMN codeintel_scip_documents_schema_versions.max_schema_version IS 'An upper-bound on the `schema_version` values of the records in the table [`codeintel_scip_documents`](#table-publiccodeintel_scip_documents) where the `upload_id` column matches the associated SCIP index.';\n\nCREATE OR REPLACE FUNCTION update_codeintel_scip_documents_schema_versions_insert() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$ BEGIN\n    INSERT INTO codeintel_scip_documents_schema_versions\n    SELECT\n        upload_id,\n        MIN(documents.schema_version) as min_schema_version,\n        MAX(documents.schema_version) as max_schema_version\n    FROM newtab\n    JOIN codeintel_scip_documents ON codeintel_scip_documents.id = newtab.document_id\n    GROUP BY newtab.upload_id\n    ON CONFLICT (upload_id) DO UPDATE SET\n        -- Update with min(old_min, new_min) and max(old_max, new_max)\n        min_schema_version = LEAST(codeintel_scip_documents_schema_versions.min_schema_version, EXCLUDED.min_schema_version),\n        max_schema_version = GREATEST(codeintel_scip_documents_schema_versions.max_schema_version, EXCLUDED.max_schema_version);\n    RETURN NULL;\nEND $$;\n\nDROP TRIGGER IF EXISTS codeintel_scip_documents_schema_versions_insert ON codeintel_scip_documents_schema_versions;\nCREATE TRIGGER codeintel_scip_documents_schema_versions_insert AFTER INSERT ON codeintel_scip_documents_schema_versions\nREFERENCING NEW TABLE AS newtab FOR EACH STATEMENT EXECUTE FUNCTION update_codeintel_scip_documents_schema_versions_insert();",
				"DownQuery": "DROP TRIGGER IF EXISTS codeintel_scip_documents_schema_versions_insert ON codeintel_scip_documents_schema_versions;\nDROP FUNCTION IF EXISTS update_codeintel_scip_documents_schema_versions_insert();\nDROP TABLE IF EXISTS codeintel_scip_documents_schema_versions;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1669842405
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1670001463,
				"Name": "Add missing index for cascading deletes",
				"UpQuery": "CREATE INDEX IF NOT EXISTS codeintel_scip_symbols_document_lookup_id ON codeintel_scip_symbols(document_lookup_id);",
				"DownQuery": "DROP INDEX IF EXISTS codeintel_scip_symbols_document_lookup_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1669934289
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1670363942,
				"Name": "Fix SCIP schema version triggers",
				"UpQuery": "DROP TRIGGER IF EXISTS codeintel_scip_documents_schema_versions_insert ON codeintel_scip_documents;\nDROP TRIGGER IF EXISTS codeintel_scip_documents_schema_versions_insert ON codeintel_scip_documents_schema_versions;\nDROP FUNCTION IF EXISTS update_codeintel_scip_documents_schema_versions_insert();\n\nDROP TRIGGER IF EXISTS codeintel_scip_document_lookup_schema_versions_insert ON codeintel_scip_document_lookup;\nDROP TRIGGER IF EXISTS codeintel_scip_document_lookup_schema_versions_insert ON codeintel_scip_document_lookup_schema_versions;\nCREATE TRIGGER codeintel_scip_document_lookup_schema_versions_insert AFTER INSERT ON codeintel_scip_document_lookup\nREFERENCING NEW TABLE AS newtab FOR EACH STATEMENT EXECUTE FUNCTION update_codeintel_scip_document_lookup_schema_versions_insert();\n\nDROP TRIGGER IF EXISTS codeintel_scip_symbols_schema_versions_insert ON codeintel_scip_symbols;\nDROP TRIGGER IF EXISTS codeintel_scip_symbols_schema_versions_insert ON codeintel_scip_symbols_schema_versions;\nCREATE TRIGGER codeintel_scip_symbols_schema_versions_insert AFTER INSERT ON codeintel_scip_symbols\nREFERENCING NEW TABLE AS newtab FOR EACH STATEMENT EXECUTE FUNCTION update_codeintel_scip_symbols_schema_versions_insert();\n\nCREATE OR REPLACE FUNCTION update_codeintel_scip_document_lookup_schema_versions_insert() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$ BEGIN\n    INSERT INTO codeintel_scip_document_lookup_schema_versions\n    SELECT\n        upload_id,\n        MIN(schema_version) as min_schema_version,\n        MAX(schema_version) as max_schema_version\n    FROM newtab\n    JOIN codeintel_scip_documents ON codeintel_scip_documents.id = newtab.document_id\n    GROUP BY newtab.upload_id\n    ON CONFLICT (upload_id) DO UPDATE SET\n        -- Update with min(old_min, new_min) and max(old_max, new_max)\n        min_schema_version = LEAST(codeintel_scip_document_lookup_schema_versions.min_schema_version, EXCLUDED.min_schema_version),\n        max_schema_version = GREATEST(codeintel_scip_document_lookup_schema_versions.max_schema_version, EXCLUDED.max_schema_version);\n    RETURN NULL;\nEND $$;\n\nCREATE OR REPLACE FUNCTION update_codeintel_scip_symbols_schema_versions_insert() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$ BEGIN\n    INSERT INTO codeintel_scip_symbols_schema_versions\n    SELECT\n        upload_id,\n        MIN(schema_version) as min_schema_version,\n        MAX(schema_version) as max_schema_version\n    FROM newtab\n    GROUP BY upload_id\n    ON CONFLICT (upload_id) DO UPDATE SET\n        -- Update with min(old_min, new_min) and max(old_max, new_max)\n        min_schema_version = LEAST(codeintel_scip_symbols_schema_versions.min_schema_version, EXCLUDED.min_schema_version),\n        max_schema_version = GREATEST(codeintel_scip_symbols_schema_versions.max_schema_version, EXCLUDED.max_schema_version);\n    RETURN NULL;\nEND $$;",
				"DownQuery": "--\n-- Restore some gibberish I guess?\n--\n\nCREATE OR REPLACE FUNCTION update_codeintel_scip_documents_schema_versions_insert() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$ BEGIN\n    INSERT INTO codeintel_scip_documents_schema_versions\n    SELECT\n        upload_id,\n        MIN(documents.schema_version) as min_schema_version,\n        MAX(documents.schema_version) as max_schema_version\n    FROM newtab\n    JOIN codeintel_scip_documents ON codeintel_scip_documents.id = newtab.document_id\n    GROUP BY newtab.upload_id\n    ON CONFLICT (upload_id) DO UPDATE SET\n        -- Update with min(old_min, new_min) and max(old_max, new_max)\n        min_schema_version = LEAST(codeintel_scip_documents_schema_versions.min_schema_version, EXCLUDED.min_schema_version),\n        max_schema_version = GREATEST(codeintel_scip_documents_schema_versions.max_schema_version, EXCLUDED.max_schema_version);\n    RETURN NULL;\nEND $$;\n\nCREATE OR REPLACE FUNCTION update_codeintel_scip_document_lookup_schema_versions_insert() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$ BEGIN\n    INSERT INTO codeintel_scip_document_lookup_schema_versions\n    SELECT\n        upload_id,\n        MIN(documents.schema_version) as min_schema_version,\n        MAX(documents.schema_version) as max_schema_version\n    FROM newtab\n    JOIN codeintel_scip_documents ON codeintel_scip_documents.id = newtab.document_id\n    GROUP BY newtab.upload_id\n    ON CONFLICT (upload_id) DO UPDATE SET\n        -- Update with min(old_min, new_min) and max(old_max, new_max)\n        min_schema_version = LEAST(codeintel_scip_document_lookup_schema_versions.min_schema_version, EXCLUDED.min_schema_version),\n        max_schema_version = GREATEST(codeintel_scip_document_lookup_schema_versions.max_schema_version, EXCLUDED.max_schema_version);\n    RETURN NULL;\nEND $$;\n\nCREATE OR REPLACE FUNCTION update_codeintel_scip_symbols_schema_versions_insert() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$ BEGIN\n    INSERT INTO codeintel_scip_symbols_schema_versions\n    SELECT\n        upload_id,\n        MIN(schema_version) as min_schema_version,\n        MAX(schema_version) as max_schema_version\n    FROM newtab\n    GROUP BY upload_id\n    ON CONFLICT (upload_id) DO UPDATE SET\n        -- Update with min(old_min, new_min) and max(old_max, new_max)\n        min_schema_version = LEAST(codeintel_scip_symbols_schema_versions.min_schema_version, EXCLUDED.min_schema_version),\n        max_schema_version = GREATEST(codeintel_scip_symbols_schema_versions.max_schema_version, EXCLUDED.max_schema_version);\n    RETURN NULL;\nEND $$;\n\n--\n-- Actual triggers\n--\n\nDROP TRIGGER IF EXISTS codeintel_scip_documents_schema_versions_insert ON codeintel_scip_documents;\nDROP TRIGGER IF EXISTS codeintel_scip_documents_schema_versions_insert ON codeintel_scip_documents_schema_versions;\nCREATE TRIGGER codeintel_scip_documents_schema_versions_insert AFTER INSERT ON codeintel_scip_documents_schema_versions\nREFERENCING NEW TABLE AS newtab FOR EACH STATEMENT EXECUTE FUNCTION update_codeintel_scip_documents_schema_versions_insert();\n\nDROP TRIGGER IF EXISTS codeintel_scip_document_lookup_schema_versions_insert ON codeintel_scip_document_lookup;\nDROP TRIGGER IF EXISTS codeintel_scip_document_lookup_schema_versions_insert ON codeintel_scip_document_lookup_schema_versions;\nCREATE TRIGGER codeintel_scip_document_lookup_schema_versions_insert AFTER INSERT ON codeintel_scip_document_lookup_schema_versions\nREFERENCING NEW TABLE AS newtab FOR EACH STATEMENT EXECUTE FUNCTION update_codeintel_scip_document_lookup_schema_versions_insert();\n\nDROP TRIGGER IF EXISTS codeintel_scip_symbols_schema_versions_insert ON codeintel_scip_symbols;\nDROP TRIGGER IF EXISTS codeintel_scip_symbols_schema_versions_insert ON codeintel_scip_symbols_schema_versions;\nCREATE TRIGGER codeintel_scip_symbols_schema_versions_insert AFTER INSERT ON codeintel_scip_symbols_schema_versions\nREFERENCING NEW TABLE AS newtab FOR EACH STATEMENT EXECUTE FUNCTION update_codeintel_scip_symbols_schema_versions_insert();",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1670001463
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1670365552,
				"Name": "Fix SCIP document schema counting",
				"UpQuery": "-- Add shard id to documents\nALTER TABLE codeintel_scip_documents ADD COLUMN IF NOT EXISTS metadata_shard_id integer NOT NULL DEFAULT floor(random() * 128 + 1)::integer;\nCOMMENT ON COLUMN codeintel_scip_documents.metadata_shard_id IS 'A randomly generated integer used to arbitrarily bucket groups of documents for things like expiration checks and data migrations.';\n\n-- Replace table and triggers\nDROP TABLE IF EXISTS codeintel_scip_documents_schema_versions;\nCREATE TABLE codeintel_scip_documents_schema_versions (\n    metadata_shard_id integer NOT NULL,\n    min_schema_version integer,\n    max_schema_version integer,\n    PRIMARY KEY(metadata_shard_id)\n);\n\nCOMMENT ON TABLE codeintel_scip_documents_schema_versions IS 'Tracks the range of `schema_versions` values associated with each document metadata shard in the [`codeintel_scip_documents`](#table-publiccodeintel_scip_documents) table.';\nCOMMENT ON COLUMN codeintel_scip_documents_schema_versions.metadata_shard_id IS 'The identifier of the associated document metadata shard.';\nCOMMENT ON COLUMN codeintel_scip_documents_schema_versions.min_schema_version IS 'A lower-bound on the `schema_version` values of the records in the table [`codeintel_scip_documents`](#table-publiccodeintel_scip_documents) where the `metadata_shard_id` column matches the associated document metadata shard.';\nCOMMENT ON COLUMN codeintel_scip_documents_schema_versions.max_schema_version IS 'An upper-bound on the `schema_version` values of the records in the table [`codeintel_scip_documents`](#table-publiccodeintel_scip_documents) where the `metadata_shard_id` column matches the associated document metadata shard.';\n\nCREATE OR REPLACE FUNCTION update_codeintel_scip_documents_schema_versions_insert() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$ BEGIN\n    INSERT INTO codeintel_scip_documents_schema_versions\n    SELECT\n        newtab.metadata_shard_id,\n        MIN(codeintel_scip_documents.schema_version) as min_schema_version,\n        MAX(codeintel_scip_documents.schema_version) as max_schema_version\n    FROM newtab\n    JOIN codeintel_scip_documents ON codeintel_scip_documents.metadata_shard_id = newtab.metadata_shard_id\n    GROUP BY newtab.metadata_shard_id\n    ON CONFLICT (metadata_shard_id) DO UPDATE SET\n        -- Update with min(old_min, new_min) and max(old_max, new_max)\n        min_schema_version = LEAST(codeintel_scip_documents_schema_versions.min_schema_version, EXCLUDED.min_schema_version),\n        max_schema_version = GREATEST(codeintel_scip_documents_schema_versions.max_schema_version, EXCLUDED.max_schema_version);\n    RETURN NULL;\nEND $$;\n\nDROP TRIGGER IF EXISTS codeintel_scip_documents_schema_versions_insert ON codeintel_scip_documents;\nDROP TRIGGER IF EXISTS codeintel_scip_documents_schema_versions_insert ON codeintel_scip_documents_schema_versions;\nCREATE TRIGGER codeintel_scip_documents_schema_versions_insert AFTER INSERT ON codeintel_scip_documents\nREFERENCING NEW TABLE AS newtab FOR EACH STATEMENT EXECUTE FUNCTION update_codeintel_scip_documents_schema_versions_insert();",
				"DownQuery": "-- Restore table and triggers\nDROP TABLE codeintel_scip_documents_schema_versions;\nCREATE TABLE IF NOT EXISTS codeintel_scip_documents_schema_versions (\n    upload_id integer NOT NULL,\n    min_schema_version integer,\n    max_schema_version integer,\n    PRIMARY KEY(upload_id)\n);\n\nCOMMENT ON TABLE codeintel_scip_documents_schema_versions IS 'Tracks the range of `schema_versions` values associated with each SCIP index in the [`codeintel_scip_documents`](#table-publiccodeintel_scip_documents) table.';\nCOMMENT ON COLUMN codeintel_scip_documents_schema_versions.upload_id IS 'The identifier of the associated SCIP index.';\nCOMMENT ON COLUMN codeintel_scip_documents_schema_versions.min_schema_version IS 'A lower-bound on the `schema_version` values of the records in the table [`codeintel_scip_documents`](#table-publiccodeintel_scip_documents) where the `upload_id` column matches the associated SCIP index.';\nCOMMENT ON COLUMN codeintel_scip_documents_schema_versions.max_schema_version IS 'An upper-bound on the `schema_version` values of the records in the table [`codeintel_scip_documents`](#table-publiccodeintel_scip_documents) where the `upload_id` column matches the associated SCIP index.';\n\nCREATE OR REPLACE FUNCTION update_codeintel_scip_documents_schema_versions_insert() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$ BEGIN\n    INSERT INTO codeintel_scip_documents_schema_versions\n    SELECT\n        upload_id,\n        MIN(documents.schema_version) as min_schema_version,\n        MAX(documents.schema_version) as max_schema_version\n    FROM newtab\n    JOIN codeintel_scip_documents ON codeintel_scip_documents.id = newtab.document_id\n    GROUP BY newtab.upload_id\n    ON CONFLICT (upload_id) DO UPDATE SET\n        -- Update with min(old_min, new_min) and max(old_max, new_max)\n        min_schema_version = LEAST(codeintel_scip_documents_schema_versions.min_schema_version, EXCLUDED.min_schema_version),\n        max_schema_version = GREATEST(codeintel_scip_documents_schema_versions.max_schema_version, EXCLUDED.max_schema_version);\n    RETURN NULL;\nEND $$;\n\nDROP TRIGGER IF EXISTS codeintel_scip_documents_schema_versions_insert ON codeintel_scip_documents;\nDROP TRIGGER IF EXISTS codeintel_scip_documents_schema_versions_insert ON codeintel_scip_documents_schema_versions;\nCREATE TRIGGER codeintel_scip_documents_schema_versions_insert AFTER INSERT ON codeintel_scip_documents_schema_versions\nREFERENCING NEW TABLE AS newtab FOR EACH STATEMENT EXECUTE FUNCTION update_codeintel_scip_documents_schema_versions_insert();\n\n-- Restore documents table\nALTER TABLE codeintel_scip_documents DROP COLUMN IF EXISTS metadata_shard_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1670363942
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1670370058,
				"Name": "Process unreferenced documents",
				"UpQuery": "CREATE TABLE IF NOT EXISTS codeintel_scip_documents_dereference_logs (\n    id bigserial,\n    document_id bigint NOT NULL,\n    last_removal_time timestamp with time zone NOT NULL DEFAULT NOW(),\n    PRIMARY KEY(id)\n);\n\nCOMMENT ON TABLE codeintel_scip_documents_dereference_logs IS 'A list of document rows that were recently dereferenced by the deletion of an index.';\nCOMMENT ON COLUMN codeintel_scip_documents_dereference_logs.document_id IS 'The identifier of the document that was dereferenced.';\nCOMMENT ON COLUMN codeintel_scip_documents_dereference_logs.last_removal_time IS 'The time that the log entry was inserted.';\n\nCREATE INDEX IF NOT EXISTS codeintel_scip_documents_dereference_logs_last_removal_time_document_id ON codeintel_scip_documents_dereference_logs(last_removal_time, document_id);\n\nCREATE OR REPLACE FUNCTION update_codeintel_scip_documents_dereference_logs_delete() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$ BEGIN\n    INSERT INTO codeintel_scip_documents_dereference_logs (document_id)\n    SELECT document_id FROM oldtab;\n    RETURN NULL;\nEND $$;\n\nDROP TRIGGER IF EXISTS codeintel_scip_documents_dereference_logs_insert ON codeintel_scip_document_lookup;\nCREATE TRIGGER codeintel_scip_documents_dereference_logs_insert AFTER DELETE ON codeintel_scip_document_lookup\nREFERENCING OLD TABLE AS oldtab FOR EACH STATEMENT EXECUTE FUNCTION update_codeintel_scip_documents_dereference_logs_delete();",
				"DownQuery": "DROP TRIGGER IF EXISTS codeintel_scip_documents_dereference_logs_insert ON codeintel_scip_document_lookup;\nDROP FUNCTION IF EXISTS update_codeintel_scip_documents_dereference_logs_delete;\nDROP TABlE IF EXISTS codeintel_scip_documents_dereference_logs;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1670365552
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1670881409,
				"Name": "Fix SCIP document schema counting (again)",
				"UpQuery": "DROP TRIGGER IF EXISTS codeintel_scip_documents_schema_versions_insert ON codeintel_scip_documents;\nDROP TRIGGER IF EXISTS codeintel_scip_documents_schema_versions_insert ON codeintel_scip_document_lookup;\nDROP TRIGGER IF EXISTS codeintel_scip_documents_schema_versions_insert ON codeintel_scip_documents_schema_versions;\nDROP FUNCTION update_codeintel_scip_documents_schema_versions_insert;\n\nDROP TABLE IF EXISTS codeintel_scip_documents_schema_versions;\nALTER TABLE codeintel_scip_documents DROP COLUMN IF EXISTS metadata_shard_id;\n\nCREATE TABLE codeintel_scip_documents_schema_versions (\n    upload_id integer NOT NULL,\n    min_schema_version integer,\n    max_schema_version integer,\n    PRIMARY KEY(upload_id)\n);\n\nCOMMENT ON TABLE codeintel_scip_documents_schema_versions IS 'Tracks the range of `schema_versions` values associated with each document referenced from the [`codeintel_scip_document_lookup`](#table-publiccodeintel_scip_document_lookup) table.';\nCOMMENT ON COLUMN codeintel_scip_documents_schema_versions.upload_id IS 'The identifier of the associated SCIP index.';\nCOMMENT ON COLUMN codeintel_scip_documents_schema_versions.min_schema_version IS 'A lower-bound on the `schema_version` values of the document records referenced from the table [`codeintel_scip_document_lookup`](#table-publiccodeintel_scip_document_lookup) where the `upload_id` column matches the associated SCIP index.';\nCOMMENT ON COLUMN codeintel_scip_documents_schema_versions.max_schema_version IS 'An upper-bound on the `schema_version` values of the document records referenced from the table [`codeintel_scip_document_lookup`](#table-publiccodeintel_scip_document_lookup) where the `upload_id` column matches the associated SCIP index.';\n\nCREATE OR REPLACE FUNCTION update_codeintel_scip_documents_schema_versions_insert() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$ BEGIN\n    INSERT INTO codeintel_scip_documents_schema_versions\n    SELECT\n        newtab.upload_id,\n        MIN(codeintel_scip_documents.schema_version) as min_schema_version,\n        MAX(codeintel_scip_documents.schema_version) as max_schema_version\n    FROM newtab\n    JOIN codeintel_scip_documents ON codeintel_scip_documents.id = newtab.document_id\n    GROUP BY newtab.upload_id\n    ON CONFLICT (upload_id) DO UPDATE SET\n        -- Update with min(old_min, new_min) and max(old_max, new_max)\n        min_schema_version = LEAST(codeintel_scip_documents_schema_versions.min_schema_version, EXCLUDED.min_schema_version),\n        max_schema_version = GREATEST(codeintel_scip_documents_schema_versions.max_schema_version, EXCLUDED.max_schema_version);\n    RETURN NULL;\nEND $$;\n\nCREATE TRIGGER codeintel_scip_documents_schema_versions_insert AFTER INSERT ON codeintel_scip_document_lookup\nREFERENCING NEW TABLE AS newtab FOR EACH STATEMENT EXECUTE FUNCTION update_codeintel_scip_documents_schema_versions_insert();",
				"DownQuery": "-- Add shard id to documents\nALTER TABLE codeintel_scip_documents ADD COLUMN IF NOT EXISTS metadata_shard_id integer NOT NULL DEFAULT floor(random() * 128 + 1)::integer;\nCOMMENT ON COLUMN codeintel_scip_documents.metadata_shard_id IS 'A randomly generated integer used to arbitrarily bucket groups of documents for things like expiration checks and data migrations.';\n\n-- Replace table and triggers\nDROP TABLE IF EXISTS codeintel_scip_documents_schema_versions;\nCREATE TABLE codeintel_scip_documents_schema_versions (\n    metadata_shard_id integer NOT NULL,\n    min_schema_version integer,\n    max_schema_version integer,\n    PRIMARY KEY(metadata_shard_id)\n);\n\nCOMMENT ON TABLE codeintel_scip_documents_schema_versions IS 'Tracks the range of `schema_versions` values associated with each document metadata shard in the [`codeintel_scip_documents`](#table-publiccodeintel_scip_documents) table.';\nCOMMENT ON COLUMN codeintel_scip_documents_schema_versions.metadata_shard_id IS 'The identifier of the associated document metadata shard.';\nCOMMENT ON COLUMN codeintel_scip_documents_schema_versions.min_schema_version IS 'A lower-bound on the `schema_version` values of the records in the table [`codeintel_scip_documents`](#table-publiccodeintel_scip_documents) where the `metadata_shard_id` column matches the associated document metadata shard.';\nCOMMENT ON COLUMN codeintel_scip_documents_schema_versions.max_schema_version IS 'An upper-bound on the `schema_version` values of the records in the table [`codeintel_scip_documents`](#table-publiccodeintel_scip_documents) where the `metadata_shard_id` column matches the associated document metadata shard.';\n\nCREATE OR REPLACE FUNCTION update_codeintel_scip_documents_schema_versions_insert() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$ BEGIN\n    INSERT INTO codeintel_scip_documents_schema_versions\n    SELECT\n        newtab.metadata_shard_id,\n        MIN(codeintel_scip_documents.schema_version) as min_schema_version,\n        MAX(codeintel_scip_documents.schema_version) as max_schema_version\n    FROM newtab\n    JOIN codeintel_scip_documents ON codeintel_scip_documents.metadata_shard_id = newtab.metadata_shard_id\n    GROUP BY newtab.metadata_shard_id\n    ON CONFLICT (metadata_shard_id) DO UPDATE SET\n        -- Update with min(old_min, new_min) and max(old_max, new_max)\n        min_schema_version = LEAST(codeintel_scip_documents_schema_versions.min_schema_version, EXCLUDED.min_schema_version),\n        max_schema_version = GREATEST(codeintel_scip_documents_schema_versions.max_schema_version, EXCLUDED.max_schema_version);\n    RETURN NULL;\nEND $$;\n\nDROP TRIGGER IF EXISTS codeintel_scip_documents_schema_versions_insert ON codeintel_scip_documents;\nDROP TRIGGER IF EXISTS codeintel_scip_documents_schema_versions_insert ON codeintel_scip_document_lookup;\nDROP TRIGGER IF EXISTS codeintel_scip_documents_schema_versions_insert ON codeintel_scip_documents_schema_versions;\nCREATE TRIGGER codeintel_scip_documents_schema_versions_insert AFTER INSERT ON codeintel_scip_documents\nREFERENCING NEW TABLE AS newtab FOR EACH STATEMENT EXECUTE FUNCTION update_codeintel_scip_documents_schema_versions_insert();",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1670370058
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1670940342,
				"Name": "Add codeintel_scip_symbol_names table",
				"UpQuery": "CREATE TABLE IF NOT EXISTS codeintel_scip_symbol_names (\n    id integer NOT NULL,\n    upload_id integer NOT NULL,\n    name_segment text NOT NULL,\n    prefix_id integer,\n    PRIMARY KEY (upload_id, id)\n);\n\nCOMMENT ON TABLE codeintel_scip_symbol_names IS 'Stores a prefix tree of symbol names within a particular upload.';\nCOMMENT ON COLUMN codeintel_scip_symbol_names.id IS 'An identifier unique within the index for this symbol name segment.';\nCOMMENT ON COLUMN codeintel_scip_symbol_names.upload_id IS 'The identifier of the upload that provided this SCIP index.';\nCOMMENT ON COLUMN codeintel_scip_symbol_names.name_segment IS 'The portion of the symbol name that is unique to this symbol and its children.';\nCOMMENT ON COLUMN codeintel_scip_symbol_names.prefix_id IS 'The identifier of the segment that forms the prefix of this symbol, if any.';\n\nALTER TABLE codeintel_scip_symbols ADD COLUMN IF NOT EXISTS symbol_id integer NOT NULL;\nCOMMENT ON COLUMN codeintel_scip_symbols.symbol_id IS 'The identifier of the segment that terminates the name of this symbol. See the table [`codeintel_scip_symbol_names`](#table-publiccodeintel_scip_symbol_names) on how to reconstruct the full symbol name.';\nALTER TABLE codeintel_scip_symbols DROP CONSTRAINT IF EXISTS codeintel_scip_symbols_pkey;\nALTER TABLE codeintel_scip_symbols ADD PRIMARY KEY (upload_id, symbol_id, document_lookup_id);\nALTER TABLE codeintel_scip_symbols DROP COLUMN IF EXISTS symbol_name;",
				"DownQuery": "ALTER TABLE codeintel_scip_symbols ADD COLUMN IF NOT EXISTS symbol_name text NOT NULL;\nALTER TABLE codeintel_scip_symbols DROP CONSTRAINT IF EXISTS codeintel_scip_symbols_pkey;\nALTER TABLE codeintel_scip_symbols ADD PRIMARY KEY (upload_id, symbol_name, document_lookup_id);\nALTER TABLE codeintel_scip_symbols DROP COLUMN IF EXISTS symbol_id;\n\nDROP TABLE IF EXISTS codeintel_scip_symbol_names;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1670370058
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1670967960,
				"Name": "Add codeintel_scip_symbol_names indexes",
				"UpQuery": "CREATE INDEX IF NOT EXISTS codeintel_scip_symbol_names_upload_id_roots ON codeintel_scip_symbol_names(upload_id) WHERE prefix_id IS NULL;\nCREATE INDEX IF NOT EXISTS codeisdntel_scip_symbol_names_upload_id_children ON codeintel_scip_symbol_names(upload_id, prefix_id) WHERE prefix_id IS NOT NULL;",
				"DownQuery": "DROP INDEX IF EXISTS codeintel_scip_symbol_names_upload_id_roots;\nDROP INDEX IF EXISTS codeisdntel_scip_symbol_names_upload_id_children;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1670881409,
					1670940342
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1671059396,
				"Name": "Remove duplicate trigger",
				"UpQuery": "DROP TRIGGER IF EXISTS codeintel_scip_documents_schema_versions_insert ON codeintel_scip_document_lookup;\nDROP FUNCTION IF EXISTS update_codeintel_scip_documents_schema_versions_insert;",
				"DownQuery": "CREATE OR REPLACE FUNCTION update_codeintel_scip_documents_schema_versions_insert() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$ BEGIN\n    INSERT INTO codeintel_scip_documents_schema_versions\n    SELECT\n        newtab.upload_id,\n        MIN(codeintel_scip_documents.schema_version) as min_schema_version,\n        MAX(codeintel_scip_documents.schema_version) as max_schema_version\n    FROM newtab\n    JOIN codeintel_scip_documents ON codeintel_scip_documents.id = newtab.document_id\n    GROUP BY newtab.upload_id\n    ON CONFLICT (upload_id) DO UPDATE SET\n        -- Update with min(old_min, new_min) and max(old_max, new_max)\n        min_schema_version = LEAST(codeintel_scip_documents_schema_versions.min_schema_version, EXCLUDED.min_schema_version),\n        max_schema_version = GREATEST(codeintel_scip_documents_schema_versions.max_schema_version, EXCLUDED.max_schema_version);\n    RETURN NULL;\nEND $$;\n\nDROP TRIGGER IF EXISTS codeintel_scip_documents_schema_versions_insert ON codeintel_scip_document_lookup;\nCREATE TRIGGER codeintel_scip_documents_schema_versions_insert AFTER INSERT ON codeintel_scip_document_lookup \nREFERENCING NEW TABLE AS newtab FOR EACH STATEMENT EXECUTE FUNCTION update_codeintel_scip_documents_schema_versions_insert();",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1670967960
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			}
		],
		"BoundsByRev": {
			"v3.20.0": {
				"RootID": 0,
				"LeafIDs": null,
				"PreCreation": true
			},
			"v3.21.0": {
				"RootID": 0,
				"LeafIDs": null,
				"PreCreation": true
			},
			"v3.22.0": {
				"RootID": -1000000000,
				"LeafIDs": [
					1000000002
				],
				"PreCreation": false
			},
			"v3.23.0": {
				"RootID": -1000000000,
				"LeafIDs": [
					1000000003
				],
				"PreCreation": false
			},
			"v3.24.0": {
				"RootID": -1000000000,
				"LeafIDs": [
					1000000004
				],
				"PreCreation": false
			},
			"v3.25.0": {
				"RootID": -1000000000,
				"LeafIDs": [
					1000000005
				],
				"PreCreation": false
			},
			"v3.26.0": {
				"RootID": -1000000000,
				"LeafIDs": [
					1000000005
				],
				"PreCreation": false
			},
			"v3.27.0": {
				"RootID": -1000000000,
				"LeafIDs": [
					1000000014
				],
				"PreCreation": false
			},
			"v3.28.0": {
				"RootID": -1000000000,
				"LeafIDs": [
					1000000015
				],
				"PreCreation": false
			},
			"v3.29.0": {
				"RootID": -1000000005,
				"LeafIDs": [
					1000000015
				],
				"PreCreation": false
			},
			"v3.30.0": {
				"RootID": -1000000005,
				"LeafIDs": [
					1000000018
				],
				"PreCreation": false
			},
			"v3.31.0": {
				"RootID": -1000000005,
				"LeafIDs": [
					1000000019
				],
				"PreCreation": false
			},
			"v3.32.0": {
				"RootID": -1000000005,
				"LeafIDs": [
					1000000019
				],
				"PreCreation": false
			},
			"v3.33.0": {
				"RootID": -1000000015,
				"LeafIDs": [
					1000000025
				],
				"PreCreation": false
			},
			"v3.34.0": {
				"RootID": -1000000015,
				"LeafIDs": [
					1000000030
				],
				"PreCreation": false
			},
			"v3.35.0": {
				"RootID": -1000000015,
				"LeafIDs": [
					1000000030
				],
				"PreCreation": false
			},
			"v3.36.0": {
				"RootID": -1000000015,
				"LeafIDs": [
					1000000030
				],
				"PreCreation": false
			},
			"v3.37.0": {
				"RootID": -1000000015,
				"LeafIDs": [
					1000000030
				],
				"PreCreation": false
			},
			"v3.38.0": {
				"RootID": 1000000029,
				"LeafIDs": [
					1000000034
				],
				"PreCreation": false
			},
			"v3.39.0": {
				"RootID": 1000000029,
				"LeafIDs": [
					1000000034
				],
				"PreCreation": false
			},
			"v3.40.0": {
				"RootID": 1000000029,
				"LeafIDs": [
					1000000034
				],
				"PreCreation": false
			},
			"v3.41.0": {
				"RootID": 1000000029,
				"LeafIDs": [
					1000000034
				],
				"PreCreation": false
			},
			"v3.42.0": {
				"RootID": 1000000033,
				"LeafIDs": [
					1000000034
				],
				"PreCreation": false
			},
			"v3.43.0": {
				"RootID": 1000000033,
				"LeafIDs": [
					1000000034
				],
				"PreCreation": false
			},
			"v4.0.0": {
				"RootID": 1000000033,
				"LeafIDs": [
					1000000034
				],
				"PreCreation": false
			},
			"v4.1.0": {
				"RootID": 1000000033,
				"LeafIDs": [
					1665531314
				],
				"PreCreation": false
			},
			"v4.2.0": {
				"RootID": 1000000033,
				"LeafIDs": [
					1666727108
				],
				"PreCreation": false
			},
			"v4.3.0": {
				"RootID": 1000000033,
				"LeafIDs": [
					1670370058
				],
				"PreCreation": false
			},
			"v4.4.0": {
				"RootID": 1000000033,
				"LeafIDs": [
					1671059396
				],
				"PreCreation": false
			},
			"v4.5.0": {
				"RootID": 1000000033,
				"LeafIDs": [
					1671059396
				],
				"PreCreation": false
			}
		}
	},
	"frontend": {
		"Definitions": [
			{
				"ID": -1528395684,
				"Name": "squashed migrations (privileged)",
				"UpQuery": "CREATE EXTENSION IF NOT EXISTS citext;\n\nCREATE EXTENSION IF NOT EXISTS hstore;\n\nCREATE EXTENSION IF NOT EXISTS pg_trgm;",
				"DownQuery": "",
				"Privileged": true,
				"NonIdempotent": false,
				"Parents": null,
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395684,
				"Name": "squashed migrations",
				"UpQuery": "ALTER TABLE IF EXISTS ONLY user_external_accounts DROP CONSTRAINT IF EXISTS user_external_accounts_user_id_fkey;\nALTER TABLE IF EXISTS ONLY user_emails DROP CONSTRAINT IF EXISTS user_emails_user_id_fkey;\nALTER TABLE IF EXISTS ONLY survey_responses DROP CONSTRAINT IF EXISTS survey_responses_user_id_fkey;\nALTER TABLE IF EXISTS ONLY settings DROP CONSTRAINT IF EXISTS settings_user_id_fkey;\nALTER TABLE IF EXISTS ONLY settings DROP CONSTRAINT IF EXISTS settings_references_orgs;\nALTER TABLE IF EXISTS ONLY settings DROP CONSTRAINT IF EXISTS settings_author_user_id_fkey;\nALTER TABLE IF EXISTS ONLY saved_searches DROP CONSTRAINT IF EXISTS saved_searches_user_id_fkey;\nALTER TABLE IF EXISTS ONLY saved_searches DROP CONSTRAINT IF EXISTS saved_searches_org_id_fkey;\nALTER TABLE IF EXISTS ONLY registry_extensions DROP CONSTRAINT IF EXISTS registry_extensions_publisher_user_id_fkey;\nALTER TABLE IF EXISTS ONLY registry_extensions DROP CONSTRAINT IF EXISTS registry_extensions_publisher_org_id_fkey;\nALTER TABLE IF EXISTS ONLY registry_extension_releases DROP CONSTRAINT IF EXISTS registry_extension_releases_registry_extension_id_fkey;\nALTER TABLE IF EXISTS ONLY registry_extension_releases DROP CONSTRAINT IF EXISTS registry_extension_releases_creator_user_id_fkey;\nALTER TABLE IF EXISTS ONLY product_subscriptions DROP CONSTRAINT IF EXISTS product_subscriptions_user_id_fkey;\nALTER TABLE IF EXISTS ONLY product_licenses DROP CONSTRAINT IF EXISTS product_licenses_product_subscription_id_fkey;\nALTER TABLE IF EXISTS ONLY org_members DROP CONSTRAINT IF EXISTS org_members_user_id_fkey;\nALTER TABLE IF EXISTS ONLY org_members DROP CONSTRAINT IF EXISTS org_members_references_orgs;\nALTER TABLE IF EXISTS ONLY org_invitations DROP CONSTRAINT IF EXISTS org_invitations_sender_user_id_fkey;\nALTER TABLE IF EXISTS ONLY org_invitations DROP CONSTRAINT IF EXISTS org_invitations_recipient_user_id_fkey;\nALTER TABLE IF EXISTS ONLY org_invitations DROP CONSTRAINT IF EXISTS org_invitations_org_id_fkey;\nALTER TABLE IF EXISTS ONLY names DROP CONSTRAINT IF EXISTS names_user_id_fkey;\nALTER TABLE IF EXISTS ONLY names DROP CONSTRAINT IF EXISTS names_org_id_fkey;\nALTER TABLE IF EXISTS ONLY lsif_references DROP CONSTRAINT IF EXISTS lsif_references_dump_id_fkey;\nALTER TABLE IF EXISTS ONLY lsif_packages DROP CONSTRAINT IF EXISTS lsif_packages_dump_id_fkey;\nALTER TABLE IF EXISTS ONLY discussion_threads_target_repo DROP CONSTRAINT IF EXISTS discussion_threads_target_repo_thread_id_fkey;\nALTER TABLE IF EXISTS ONLY discussion_threads_target_repo DROP CONSTRAINT IF EXISTS discussion_threads_target_repo_repo_id_fkey;\nALTER TABLE IF EXISTS ONLY discussion_threads DROP CONSTRAINT IF EXISTS discussion_threads_target_repo_id_fk;\nALTER TABLE IF EXISTS ONLY discussion_threads DROP CONSTRAINT IF EXISTS discussion_threads_author_user_id_fkey;\nALTER TABLE IF EXISTS ONLY discussion_mail_reply_tokens DROP CONSTRAINT IF EXISTS discussion_mail_reply_tokens_user_id_fkey;\nALTER TABLE IF EXISTS ONLY discussion_mail_reply_tokens DROP CONSTRAINT IF EXISTS discussion_mail_reply_tokens_thread_id_fkey;\nALTER TABLE IF EXISTS ONLY discussion_comments DROP CONSTRAINT IF EXISTS discussion_comments_thread_id_fkey;\nALTER TABLE IF EXISTS ONLY discussion_comments DROP CONSTRAINT IF EXISTS discussion_comments_author_user_id_fkey;\nALTER TABLE IF EXISTS ONLY default_repos DROP CONSTRAINT IF EXISTS default_repos_repo_id_fkey;\nALTER TABLE IF EXISTS ONLY changesets DROP CONSTRAINT IF EXISTS changesets_repo_id_fkey;\nALTER TABLE IF EXISTS ONLY changeset_jobs DROP CONSTRAINT IF EXISTS changeset_jobs_changeset_id_fkey;\nALTER TABLE IF EXISTS ONLY changeset_jobs DROP CONSTRAINT IF EXISTS changeset_jobs_campaign_job_id_fkey;\nALTER TABLE IF EXISTS ONLY changeset_jobs DROP CONSTRAINT IF EXISTS changeset_jobs_campaign_id_fkey;\nALTER TABLE IF EXISTS ONLY changeset_events DROP CONSTRAINT IF EXISTS changeset_events_changeset_id_fkey;\nALTER TABLE IF EXISTS ONLY campaigns DROP CONSTRAINT IF EXISTS campaigns_namespace_user_id_fkey;\nALTER TABLE IF EXISTS ONLY campaigns DROP CONSTRAINT IF EXISTS campaigns_namespace_org_id_fkey;\nALTER TABLE IF EXISTS ONLY campaigns DROP CONSTRAINT IF EXISTS campaigns_campaign_plan_id_fkey;\nALTER TABLE IF EXISTS ONLY campaigns DROP CONSTRAINT IF EXISTS campaigns_author_id_fkey;\nALTER TABLE IF EXISTS ONLY patch_sets DROP CONSTRAINT IF EXISTS campaign_plans_user_id_fkey;\nALTER TABLE IF EXISTS ONLY patches DROP CONSTRAINT IF EXISTS campaign_jobs_repo_id_fkey;\nALTER TABLE IF EXISTS ONLY patches DROP CONSTRAINT IF EXISTS campaign_jobs_campaign_plan_id_fkey;\nALTER TABLE IF EXISTS ONLY access_tokens DROP CONSTRAINT IF EXISTS access_tokens_subject_user_id_fkey;\nALTER TABLE IF EXISTS ONLY access_tokens DROP CONSTRAINT IF EXISTS access_tokens_creator_user_id_fkey;\nDROP TRIGGER IF EXISTS trig_delete_changeset_reference_on_campaigns ON changesets;\nDROP TRIGGER IF EXISTS trig_delete_campaign_reference_on_changesets ON campaigns;\nDROP INDEX IF EXISTS users_username;\nDROP INDEX IF EXISTS users_billing_customer_id;\nDROP INDEX IF EXISTS user_external_accounts_user_id;\nDROP INDEX IF EXISTS user_external_accounts_account;\nDROP INDEX IF EXISTS saved_queries_query_unique;\nDROP INDEX IF EXISTS repo_uri_idx;\nDROP INDEX IF EXISTS repo_sources_gin_idx;\nDROP INDEX IF EXISTS repo_private;\nDROP INDEX IF EXISTS repo_name_trgm;\nDROP INDEX IF EXISTS repo_metadata_gin_idx;\nDROP INDEX IF EXISTS repo_fork;\nDROP INDEX IF EXISTS repo_external_unique_idx;\nDROP INDEX IF EXISTS repo_archived;\nDROP INDEX IF EXISTS registry_extensions_uuid;\nDROP INDEX IF EXISTS registry_extensions_publisher_name;\nDROP INDEX IF EXISTS registry_extension_releases_version;\nDROP INDEX IF EXISTS registry_extension_releases_registry_extension_id;\nDROP INDEX IF EXISTS orgs_name;\nDROP INDEX IF EXISTS org_invitations_singleflight;\nDROP INDEX IF EXISTS org_invitations_recipient_user_id;\nDROP INDEX IF EXISTS org_invitations_org_id;\nDROP INDEX IF EXISTS lsif_uploads_visible_repository_id_commit;\nDROP INDEX IF EXISTS lsif_uploads_uploaded_at;\nDROP INDEX IF EXISTS lsif_uploads_state;\nDROP INDEX IF EXISTS lsif_uploads_repository_id_commit_root_indexer;\nDROP INDEX IF EXISTS lsif_references_package;\nDROP INDEX IF EXISTS lsif_packages_scheme_name_version;\nDROP INDEX IF EXISTS lsif_commits_repository_id_parent_commit;\nDROP INDEX IF EXISTS lsif_commits_repository_id_commit_parent_commit_unique;\nDROP INDEX IF EXISTS event_logs_user_id;\nDROP INDEX IF EXISTS event_logs_timestamp_at_utc;\nDROP INDEX IF EXISTS event_logs_timestamp;\nDROP INDEX IF EXISTS event_logs_source;\nDROP INDEX IF EXISTS event_logs_name;\nDROP INDEX IF EXISTS event_logs_anonymous_user_id;\nDROP INDEX IF EXISTS discussion_threads_target_repo_repo_id_path_idx;\nDROP INDEX IF EXISTS discussion_threads_author_user_id_idx;\nDROP INDEX IF EXISTS discussion_mail_reply_tokens_user_id_thread_id_idx;\nDROP INDEX IF EXISTS discussion_comments_thread_id_idx;\nDROP INDEX IF EXISTS discussion_comments_reports_array_length_idx;\nDROP INDEX IF EXISTS discussion_comments_author_user_id_idx;\nDROP INDEX IF EXISTS critical_and_site_config_unique;\nDROP INDEX IF EXISTS changeset_jobs_started_at;\nDROP INDEX IF EXISTS changeset_jobs_finished_at;\nDROP INDEX IF EXISTS changeset_jobs_error_not_null;\nDROP INDEX IF EXISTS changeset_jobs_campaign_job_id;\nDROP INDEX IF EXISTS campaigns_namespace_user_id;\nDROP INDEX IF EXISTS campaigns_namespace_org_id;\nDROP INDEX IF EXISTS campaigns_changeset_ids_gin_idx;\nDROP INDEX IF EXISTS access_tokens_lookup;\nALTER TABLE IF EXISTS ONLY versions DROP CONSTRAINT IF EXISTS versions_pkey;\nALTER TABLE IF EXISTS ONLY users DROP CONSTRAINT IF EXISTS users_pkey;\nALTER TABLE IF EXISTS ONLY user_permissions DROP CONSTRAINT IF EXISTS user_permissions_perm_object_unique;\nALTER TABLE IF EXISTS ONLY user_pending_permissions DROP CONSTRAINT IF EXISTS user_pending_permissions_service_perm_object_unique;\nALTER TABLE IF EXISTS ONLY user_external_accounts DROP CONSTRAINT IF EXISTS user_external_accounts_pkey;\nALTER TABLE IF EXISTS ONLY user_emails DROP CONSTRAINT IF EXISTS user_emails_unique_verified_email;\nALTER TABLE IF EXISTS ONLY user_emails DROP CONSTRAINT IF EXISTS user_emails_no_duplicates_per_user;\nALTER TABLE IF EXISTS ONLY survey_responses DROP CONSTRAINT IF EXISTS survey_responses_pkey;\nALTER TABLE IF EXISTS ONLY settings DROP CONSTRAINT IF EXISTS settings_pkey;\nALTER TABLE IF EXISTS ONLY schema_migrations DROP CONSTRAINT IF EXISTS schema_migrations_pkey;\nALTER TABLE IF EXISTS ONLY saved_searches DROP CONSTRAINT IF EXISTS saved_searches_pkey;\nALTER TABLE IF EXISTS ONLY repo DROP CONSTRAINT IF EXISTS repo_pkey;\nALTER TABLE IF EXISTS ONLY repo_permissions DROP CONSTRAINT IF EXISTS repo_permissions_perm_unique;\nALTER TABLE IF EXISTS ONLY repo_pending_permissions DROP CONSTRAINT IF EXISTS repo_pending_permissions_perm_unique;\nALTER TABLE IF EXISTS ONLY repo DROP CONSTRAINT IF EXISTS repo_name_unique;\nALTER TABLE IF EXISTS ONLY registry_extensions DROP CONSTRAINT IF EXISTS registry_extensions_pkey;\nALTER TABLE IF EXISTS ONLY registry_extension_releases DROP CONSTRAINT IF EXISTS registry_extension_releases_pkey;\nALTER TABLE IF EXISTS ONLY product_subscriptions DROP CONSTRAINT IF EXISTS product_subscriptions_pkey;\nALTER TABLE IF EXISTS ONLY product_licenses DROP CONSTRAINT IF EXISTS product_licenses_pkey;\nALTER TABLE IF EXISTS ONLY phabricator_repos DROP CONSTRAINT IF EXISTS phabricator_repos_repo_name_key;\nALTER TABLE IF EXISTS ONLY phabricator_repos DROP CONSTRAINT IF EXISTS phabricator_repos_pkey;\nALTER TABLE IF EXISTS ONLY orgs DROP CONSTRAINT IF EXISTS orgs_pkey;\nALTER TABLE IF EXISTS ONLY org_members DROP CONSTRAINT IF EXISTS org_members_pkey;\nALTER TABLE IF EXISTS ONLY org_members DROP CONSTRAINT IF EXISTS org_members_org_id_user_id_key;\nALTER TABLE IF EXISTS ONLY org_invitations DROP CONSTRAINT IF EXISTS org_invitations_pkey;\nALTER TABLE IF EXISTS ONLY names DROP CONSTRAINT IF EXISTS names_pkey;\nALTER TABLE IF EXISTS ONLY lsif_uploads DROP CONSTRAINT IF EXISTS lsif_uploads_pkey;\nALTER TABLE IF EXISTS ONLY lsif_references DROP CONSTRAINT IF EXISTS lsif_references_pkey;\nALTER TABLE IF EXISTS ONLY lsif_packages DROP CONSTRAINT IF EXISTS lsif_packages_pkey;\nALTER TABLE IF EXISTS ONLY lsif_indexes DROP CONSTRAINT IF EXISTS lsif_indexes_pkey;\nALTER TABLE IF EXISTS ONLY lsif_indexable_repositories DROP CONSTRAINT IF EXISTS lsif_indexable_repositories_repository_id_key;\nALTER TABLE IF EXISTS ONLY lsif_indexable_repositories DROP CONSTRAINT IF EXISTS lsif_indexable_repositories_pkey;\nALTER TABLE IF EXISTS ONLY lsif_commits DROP CONSTRAINT IF EXISTS lsif_commits_pkey;\nALTER TABLE IF EXISTS ONLY global_state DROP CONSTRAINT IF EXISTS global_state_pkey;\nALTER TABLE IF EXISTS ONLY external_services DROP CONSTRAINT IF EXISTS external_services_pkey;\nALTER TABLE IF EXISTS ONLY event_logs DROP CONSTRAINT IF EXISTS event_logs_pkey;\nALTER TABLE IF EXISTS ONLY discussion_threads_target_repo DROP CONSTRAINT IF EXISTS discussion_threads_target_repo_pkey;\nALTER TABLE IF EXISTS ONLY discussion_threads DROP CONSTRAINT IF EXISTS discussion_threads_pkey;\nALTER TABLE IF EXISTS ONLY discussion_mail_reply_tokens DROP CONSTRAINT IF EXISTS discussion_mail_reply_tokens_pkey;\nALTER TABLE IF EXISTS ONLY discussion_comments DROP CONSTRAINT IF EXISTS discussion_comments_pkey;\nALTER TABLE IF EXISTS ONLY default_repos DROP CONSTRAINT IF EXISTS default_repos_pkey;\nALTER TABLE IF EXISTS ONLY critical_and_site_config DROP CONSTRAINT IF EXISTS critical_and_site_config_pkey;\nALTER TABLE IF EXISTS ONLY changesets DROP CONSTRAINT IF EXISTS changesets_repo_external_id_unique;\nALTER TABLE IF EXISTS ONLY changesets DROP CONSTRAINT IF EXISTS changesets_pkey;\nALTER TABLE IF EXISTS ONLY changeset_jobs DROP CONSTRAINT IF EXISTS changeset_jobs_unique;\nALTER TABLE IF EXISTS ONLY changeset_jobs DROP CONSTRAINT IF EXISTS changeset_jobs_pkey;\nALTER TABLE IF EXISTS ONLY changeset_events DROP CONSTRAINT IF EXISTS changeset_events_pkey;\nALTER TABLE IF EXISTS ONLY changeset_events DROP CONSTRAINT IF EXISTS changeset_events_changeset_id_kind_key_unique;\nALTER TABLE IF EXISTS ONLY campaigns DROP CONSTRAINT IF EXISTS campaigns_pkey;\nALTER TABLE IF EXISTS ONLY patch_sets DROP CONSTRAINT IF EXISTS campaign_plans_pkey;\nALTER TABLE IF EXISTS ONLY patches DROP CONSTRAINT IF EXISTS campaign_jobs_pkey;\nALTER TABLE IF EXISTS ONLY patches DROP CONSTRAINT IF EXISTS campaign_jobs_campaign_plan_repo_rev_unique;\nALTER TABLE IF EXISTS ONLY access_tokens DROP CONSTRAINT IF EXISTS access_tokens_value_sha256_key;\nALTER TABLE IF EXISTS ONLY access_tokens DROP CONSTRAINT IF EXISTS access_tokens_pkey;\nALTER TABLE IF EXISTS users ALTER COLUMN id DROP DEFAULT;\nALTER TABLE IF EXISTS user_pending_permissions ALTER COLUMN id DROP DEFAULT;\nALTER TABLE IF EXISTS user_external_accounts ALTER COLUMN id DROP DEFAULT;\nALTER TABLE IF EXISTS survey_responses ALTER COLUMN id DROP DEFAULT;\nALTER TABLE IF EXISTS settings ALTER COLUMN id DROP DEFAULT;\nALTER TABLE IF EXISTS saved_searches ALTER COLUMN id DROP DEFAULT;\nALTER TABLE IF EXISTS repo ALTER COLUMN id DROP DEFAULT;\nALTER TABLE IF EXISTS registry_extensions ALTER COLUMN id DROP DEFAULT;\nALTER TABLE IF EXISTS registry_extension_releases ALTER COLUMN id DROP DEFAULT;\nALTER TABLE IF EXISTS phabricator_repos ALTER COLUMN id DROP DEFAULT;\nALTER TABLE IF EXISTS patches ALTER COLUMN id DROP DEFAULT;\nALTER TABLE IF EXISTS patch_sets ALTER COLUMN id DROP DEFAULT;\nALTER TABLE IF EXISTS orgs ALTER COLUMN id DROP DEFAULT;\nALTER TABLE IF EXISTS org_members ALTER COLUMN id DROP DEFAULT;\nALTER TABLE IF EXISTS org_invitations ALTER COLUMN id DROP DEFAULT;\nALTER TABLE IF EXISTS lsif_uploads ALTER COLUMN id DROP DEFAULT;\nALTER TABLE IF EXISTS lsif_references ALTER COLUMN id DROP DEFAULT;\nALTER TABLE IF EXISTS lsif_packages ALTER COLUMN id DROP DEFAULT;\nALTER TABLE IF EXISTS lsif_indexes ALTER COLUMN id DROP DEFAULT;\nALTER TABLE IF EXISTS lsif_indexable_repositories ALTER COLUMN id DROP DEFAULT;\nALTER TABLE IF EXISTS lsif_commits ALTER COLUMN id DROP DEFAULT;\nALTER TABLE IF EXISTS external_services ALTER COLUMN id DROP DEFAULT;\nALTER TABLE IF EXISTS event_logs ALTER COLUMN id DROP DEFAULT;\nALTER TABLE IF EXISTS discussion_threads_target_repo ALTER COLUMN id DROP DEFAULT;\nALTER TABLE IF EXISTS discussion_threads ALTER COLUMN id DROP DEFAULT;\nALTER TABLE IF EXISTS discussion_comments ALTER COLUMN id DROP DEFAULT;\nALTER TABLE IF EXISTS critical_and_site_config ALTER COLUMN id DROP DEFAULT;\nALTER TABLE IF EXISTS changesets ALTER COLUMN id DROP DEFAULT;\nALTER TABLE IF EXISTS changeset_jobs ALTER COLUMN id DROP DEFAULT;\nALTER TABLE IF EXISTS changeset_events ALTER COLUMN id DROP DEFAULT;\nALTER TABLE IF EXISTS campaigns ALTER COLUMN id DROP DEFAULT;\nALTER TABLE IF EXISTS access_tokens ALTER COLUMN id DROP DEFAULT;\nDROP TABLE IF EXISTS versions;\nDROP SEQUENCE IF EXISTS users_id_seq;\nDROP TABLE IF EXISTS users;\nDROP TABLE IF EXISTS user_permissions;\nDROP SEQUENCE IF EXISTS user_pending_permissions_id_seq;\nDROP TABLE IF EXISTS user_pending_permissions;\nDROP SEQUENCE IF EXISTS user_external_accounts_id_seq;\nDROP TABLE IF EXISTS user_external_accounts;\nDROP TABLE IF EXISTS user_emails;\nDROP SEQUENCE IF EXISTS survey_responses_id_seq;\nDROP TABLE IF EXISTS survey_responses;\nDROP VIEW IF EXISTS site_config;\nDROP SEQUENCE IF EXISTS settings_id_seq;\nDROP TABLE IF EXISTS settings_bkup_1514702776;\nDROP TABLE IF EXISTS settings;\nDROP TABLE IF EXISTS schema_migrations;\nDROP SEQUENCE IF EXISTS saved_searches_id_seq;\nDROP TABLE IF EXISTS saved_searches;\nDROP TABLE IF EXISTS saved_queries;\nDROP TABLE IF EXISTS repo_permissions;\nDROP TABLE IF EXISTS repo_pending_permissions;\nDROP SEQUENCE IF EXISTS repo_id_seq;\nDROP TABLE IF EXISTS repo;\nDROP SEQUENCE IF EXISTS registry_extensions_id_seq;\nDROP TABLE IF EXISTS registry_extensions;\nDROP SEQUENCE IF EXISTS registry_extension_releases_id_seq;\nDROP TABLE IF EXISTS registry_extension_releases;\nDROP TABLE IF EXISTS query_runner_state;\nDROP TABLE IF EXISTS product_subscriptions;\nDROP TABLE IF EXISTS product_licenses;\nDROP SEQUENCE IF EXISTS phabricator_repos_id_seq;\nDROP TABLE IF EXISTS phabricator_repos;\nDROP SEQUENCE IF EXISTS orgs_id_seq;\nDROP TABLE IF EXISTS orgs;\nDROP SEQUENCE IF EXISTS org_members_id_seq;\nDROP TABLE IF EXISTS org_members_bkup_1514536731;\nDROP TABLE IF EXISTS org_members;\nDROP SEQUENCE IF EXISTS org_invitations_id_seq;\nDROP TABLE IF EXISTS org_invitations;\nDROP TABLE IF EXISTS names;\nDROP SEQUENCE IF EXISTS lsif_references_id_seq;\nDROP TABLE IF EXISTS lsif_references;\nDROP SEQUENCE IF EXISTS lsif_packages_id_seq;\nDROP TABLE IF EXISTS lsif_packages;\nDROP SEQUENCE IF EXISTS lsif_indexes_id_seq;\nDROP TABLE IF EXISTS lsif_indexes;\nDROP SEQUENCE IF EXISTS lsif_indexable_repositories_id_seq;\nDROP TABLE IF EXISTS lsif_indexable_repositories;\nDROP SEQUENCE IF EXISTS lsif_dumps_id_seq;\nDROP VIEW IF EXISTS lsif_dumps;\nDROP TABLE IF EXISTS lsif_uploads;\nDROP SEQUENCE IF EXISTS lsif_commits_id_seq;\nDROP TABLE IF EXISTS lsif_commits;\nDROP TABLE IF EXISTS global_state;\nDROP SEQUENCE IF EXISTS external_services_id_seq;\nDROP TABLE IF EXISTS external_services;\nDROP SEQUENCE IF EXISTS event_logs_id_seq;\nDROP TABLE IF EXISTS event_logs;\nDROP SEQUENCE IF EXISTS discussion_threads_target_repo_id_seq;\nDROP TABLE IF EXISTS discussion_threads_target_repo;\nDROP SEQUENCE IF EXISTS discussion_threads_id_seq;\nDROP TABLE IF EXISTS discussion_threads;\nDROP TABLE IF EXISTS discussion_mail_reply_tokens;\nDROP SEQUENCE IF EXISTS discussion_comments_id_seq;\nDROP TABLE IF EXISTS discussion_comments;\nDROP TABLE IF EXISTS default_repos;\nDROP SEQUENCE IF EXISTS critical_and_site_config_id_seq;\nDROP TABLE IF EXISTS critical_and_site_config;\nDROP SEQUENCE IF EXISTS changesets_id_seq;\nDROP TABLE IF EXISTS changesets;\nDROP SEQUENCE IF EXISTS changeset_jobs_id_seq;\nDROP TABLE IF EXISTS changeset_jobs;\nDROP SEQUENCE IF EXISTS changeset_events_id_seq;\nDROP TABLE IF EXISTS changeset_events;\nDROP SEQUENCE IF EXISTS campaigns_id_seq;\nDROP TABLE IF EXISTS campaigns;\nDROP SEQUENCE IF EXISTS campaign_plans_id_seq;\nDROP TABLE IF EXISTS patch_sets;\nDROP SEQUENCE IF EXISTS campaign_jobs_id_seq;\nDROP TABLE IF EXISTS patches;\nDROP SEQUENCE IF EXISTS access_tokens_id_seq;\nDROP TABLE IF EXISTS access_tokens;\nDROP FUNCTION IF EXISTS delete_changeset_reference_on_campaigns();\nDROP FUNCTION IF EXISTS delete_campaign_reference_on_changesets();\nDROP TYPE IF EXISTS lsif_upload_state;\nDROP TYPE IF EXISTS lsif_index_state;\nDROP TYPE IF EXISTS critical_or_site;\n\n\n\n\n\n\n\nCREATE TYPE critical_or_site AS ENUM (\n    'critical',\n    'site'\n);\n\nCREATE TYPE lsif_index_state AS ENUM (\n    'queued',\n    'processing',\n    'completed',\n    'errored'\n);\n\nCREATE TYPE lsif_upload_state AS ENUM (\n    'uploading',\n    'queued',\n    'processing',\n    'completed',\n    'errored'\n);\n\nCREATE FUNCTION delete_campaign_reference_on_changesets() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$\n    BEGIN\n        UPDATE\n          changesets\n        SET\n          campaign_ids = changesets.campaign_ids - OLD.id::text\n        WHERE\n          changesets.campaign_ids ? OLD.id::text;\n\n        RETURN OLD;\n    END;\n$$;\n\nCREATE FUNCTION delete_changeset_reference_on_campaigns() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$\n    BEGIN\n        UPDATE\n          campaigns\n        SET\n          changeset_ids = campaigns.changeset_ids - OLD.id::text\n        WHERE\n          campaigns.changeset_ids ? OLD.id::text;\n\n        RETURN OLD;\n    END;\n$$;\n\nCREATE TABLE access_tokens (\n    id bigint NOT NULL,\n    subject_user_id integer NOT NULL,\n    value_sha256 bytea NOT NULL,\n    note text NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    last_used_at timestamp with time zone,\n    deleted_at timestamp with time zone,\n    creator_user_id integer NOT NULL,\n    scopes text[] NOT NULL\n);\n\nCREATE SEQUENCE access_tokens_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE access_tokens_id_seq OWNED BY access_tokens.id;\n\nCREATE TABLE patches (\n    id bigint NOT NULL,\n    patch_set_id bigint NOT NULL,\n    repo_id bigint NOT NULL,\n    rev text NOT NULL,\n    diff text NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    base_ref text NOT NULL,\n    diff_stat_added integer,\n    diff_stat_changed integer,\n    diff_stat_deleted integer,\n    CONSTRAINT campaign_jobs_base_ref_check CHECK ((base_ref \u003c\u003e ''::text))\n);\n\nCREATE SEQUENCE campaign_jobs_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE campaign_jobs_id_seq OWNED BY patches.id;\n\nCREATE TABLE patch_sets (\n    id bigint NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    user_id integer NOT NULL\n);\n\nCREATE SEQUENCE campaign_plans_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE campaign_plans_id_seq OWNED BY patch_sets.id;\n\nCREATE TABLE campaigns (\n    id bigint NOT NULL,\n    name text NOT NULL,\n    description text,\n    author_id integer NOT NULL,\n    namespace_user_id integer,\n    namespace_org_id integer,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    changeset_ids jsonb DEFAULT '{}'::jsonb NOT NULL,\n    patch_set_id integer,\n    closed_at timestamp with time zone,\n    branch text,\n    CONSTRAINT campaigns_changeset_ids_check CHECK ((jsonb_typeof(changeset_ids) = 'object'::text)),\n    CONSTRAINT campaigns_has_1_namespace CHECK (((namespace_user_id IS NULL) \u003c\u003e (namespace_org_id IS NULL))),\n    CONSTRAINT campaigns_name_not_blank CHECK ((name \u003c\u003e ''::text))\n);\n\nCREATE SEQUENCE campaigns_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE campaigns_id_seq OWNED BY campaigns.id;\n\nCREATE TABLE changeset_events (\n    id bigint NOT NULL,\n    changeset_id bigint NOT NULL,\n    kind text NOT NULL,\n    key text NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    metadata jsonb DEFAULT '{}'::jsonb NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    CONSTRAINT changeset_events_key_check CHECK ((key \u003c\u003e ''::text)),\n    CONSTRAINT changeset_events_kind_check CHECK ((kind \u003c\u003e ''::text)),\n    CONSTRAINT changeset_events_metadata_check CHECK ((jsonb_typeof(metadata) = 'object'::text))\n);\n\nCREATE SEQUENCE changeset_events_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE changeset_events_id_seq OWNED BY changeset_events.id;\n\nCREATE TABLE changeset_jobs (\n    id bigint NOT NULL,\n    campaign_id bigint NOT NULL,\n    patch_id bigint NOT NULL,\n    changeset_id bigint,\n    error text,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    started_at timestamp with time zone,\n    finished_at timestamp with time zone,\n    branch text\n);\n\nCREATE SEQUENCE changeset_jobs_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE changeset_jobs_id_seq OWNED BY changeset_jobs.id;\n\nCREATE TABLE changesets (\n    id bigint NOT NULL,\n    campaign_ids jsonb DEFAULT '{}'::jsonb NOT NULL,\n    repo_id integer NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    metadata jsonb DEFAULT '{}'::jsonb NOT NULL,\n    external_id text NOT NULL,\n    external_service_type text NOT NULL,\n    external_deleted_at timestamp with time zone,\n    external_branch text,\n    external_updated_at timestamp with time zone,\n    external_state text,\n    external_review_state text,\n    external_check_state text,\n    created_by_campaign boolean DEFAULT false NOT NULL,\n    added_to_campaign boolean DEFAULT false NOT NULL,\n    CONSTRAINT changesets_campaign_ids_check CHECK ((jsonb_typeof(campaign_ids) = 'object'::text)),\n    CONSTRAINT changesets_external_id_check CHECK ((external_id \u003c\u003e ''::text)),\n    CONSTRAINT changesets_external_service_type_not_blank CHECK ((external_service_type \u003c\u003e ''::text)),\n    CONSTRAINT changesets_metadata_check CHECK ((jsonb_typeof(metadata) = 'object'::text))\n);\n\nCREATE SEQUENCE changesets_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE changesets_id_seq OWNED BY changesets.id;\n\nCREATE TABLE critical_and_site_config (\n    id integer NOT NULL,\n    type critical_or_site NOT NULL,\n    contents text NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL\n);\n\nCREATE SEQUENCE critical_and_site_config_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE critical_and_site_config_id_seq OWNED BY critical_and_site_config.id;\n\nCREATE TABLE default_repos (\n    repo_id integer NOT NULL\n);\n\nCREATE TABLE discussion_comments (\n    id bigint NOT NULL,\n    thread_id bigint NOT NULL,\n    author_user_id integer NOT NULL,\n    contents text NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    deleted_at timestamp with time zone,\n    reports text[] DEFAULT '{}'::text[] NOT NULL\n);\n\nCREATE SEQUENCE discussion_comments_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE discussion_comments_id_seq OWNED BY discussion_comments.id;\n\nCREATE TABLE discussion_mail_reply_tokens (\n    token text NOT NULL,\n    user_id integer NOT NULL,\n    thread_id bigint NOT NULL,\n    deleted_at timestamp with time zone\n);\n\nCREATE TABLE discussion_threads (\n    id bigint NOT NULL,\n    author_user_id integer NOT NULL,\n    title text,\n    target_repo_id bigint,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    archived_at timestamp with time zone,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    deleted_at timestamp with time zone\n);\n\nCREATE SEQUENCE discussion_threads_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE discussion_threads_id_seq OWNED BY discussion_threads.id;\n\nCREATE TABLE discussion_threads_target_repo (\n    id bigint NOT NULL,\n    thread_id bigint NOT NULL,\n    repo_id integer NOT NULL,\n    path text,\n    branch text,\n    revision text,\n    start_line integer,\n    end_line integer,\n    start_character integer,\n    end_character integer,\n    lines_before text,\n    lines text,\n    lines_after text\n);\n\nCREATE SEQUENCE discussion_threads_target_repo_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE discussion_threads_target_repo_id_seq OWNED BY discussion_threads_target_repo.id;\n\nCREATE TABLE event_logs (\n    id bigint NOT NULL,\n    name text NOT NULL,\n    url text NOT NULL,\n    user_id integer NOT NULL,\n    anonymous_user_id text NOT NULL,\n    source text NOT NULL,\n    argument jsonb NOT NULL,\n    version text NOT NULL,\n    \"timestamp\" timestamp with time zone NOT NULL,\n    CONSTRAINT event_logs_check_has_user CHECK ((((user_id = 0) AND (anonymous_user_id \u003c\u003e ''::text)) OR ((user_id \u003c\u003e 0) AND (anonymous_user_id = ''::text)) OR ((user_id \u003c\u003e 0) AND (anonymous_user_id \u003c\u003e ''::text)))),\n    CONSTRAINT event_logs_check_name_not_empty CHECK ((name \u003c\u003e ''::text)),\n    CONSTRAINT event_logs_check_source_not_empty CHECK ((source \u003c\u003e ''::text)),\n    CONSTRAINT event_logs_check_version_not_empty CHECK ((version \u003c\u003e ''::text))\n);\n\nCREATE SEQUENCE event_logs_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE event_logs_id_seq OWNED BY event_logs.id;\n\nCREATE TABLE external_services (\n    id bigint NOT NULL,\n    kind text NOT NULL,\n    display_name text NOT NULL,\n    config text NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    deleted_at timestamp with time zone,\n    CONSTRAINT check_non_empty_config CHECK ((btrim(config) \u003c\u003e ''::text))\n);\n\nCREATE SEQUENCE external_services_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE external_services_id_seq OWNED BY external_services.id;\n\nCREATE TABLE global_state (\n    site_id uuid NOT NULL,\n    initialized boolean DEFAULT false NOT NULL,\n    mgmt_password_plaintext text DEFAULT ''::text NOT NULL,\n    mgmt_password_bcrypt text DEFAULT ''::text NOT NULL\n);\n\nCREATE TABLE lsif_commits (\n    id integer NOT NULL,\n    commit text NOT NULL,\n    parent_commit text,\n    repository_id integer NOT NULL,\n    CONSTRAINT lsif_commits_commit_valid_chars CHECK ((commit ~ '^[a-z0-9]{40}$'::text)),\n    CONSTRAINT lsif_commits_parent_commit_valid_chars CHECK ((parent_commit ~ '^[a-z0-9]{40}$'::text))\n);\n\nCREATE SEQUENCE lsif_commits_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE lsif_commits_id_seq OWNED BY lsif_commits.id;\n\nCREATE TABLE lsif_uploads (\n    id integer NOT NULL,\n    commit text NOT NULL,\n    root text DEFAULT ''::text NOT NULL,\n    visible_at_tip boolean DEFAULT false NOT NULL,\n    uploaded_at timestamp with time zone DEFAULT now() NOT NULL,\n    state lsif_upload_state DEFAULT 'queued'::lsif_upload_state NOT NULL,\n    failure_message text,\n    started_at timestamp with time zone,\n    finished_at timestamp with time zone,\n    repository_id integer NOT NULL,\n    indexer text NOT NULL,\n    num_parts integer NOT NULL,\n    uploaded_parts integer[] NOT NULL,\n    process_after timestamp with time zone,\n    num_resets integer DEFAULT 0 NOT NULL,\n    CONSTRAINT lsif_uploads_commit_valid_chars CHECK ((commit ~ '^[a-z0-9]{40}$'::text))\n);\n\nCREATE VIEW lsif_dumps AS\n SELECT u.id,\n    u.commit,\n    u.root,\n    u.visible_at_tip,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.finished_at AS processed_at\n   FROM lsif_uploads u\n  WHERE (u.state = 'completed'::lsif_upload_state);\n\nCREATE SEQUENCE lsif_dumps_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE lsif_dumps_id_seq OWNED BY lsif_uploads.id;\n\nCREATE TABLE lsif_indexable_repositories (\n    id integer NOT NULL,\n    repository_id integer NOT NULL,\n    search_count integer DEFAULT 0 NOT NULL,\n    precise_count integer DEFAULT 0 NOT NULL,\n    last_index_enqueued_at timestamp with time zone\n);\n\nCREATE SEQUENCE lsif_indexable_repositories_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE lsif_indexable_repositories_id_seq OWNED BY lsif_indexable_repositories.id;\n\nCREATE TABLE lsif_indexes (\n    id bigint NOT NULL,\n    commit text NOT NULL,\n    queued_at timestamp with time zone DEFAULT now() NOT NULL,\n    state lsif_index_state DEFAULT 'queued'::lsif_index_state NOT NULL,\n    failure_message text,\n    started_at timestamp with time zone,\n    finished_at timestamp with time zone,\n    repository_id integer NOT NULL,\n    process_after timestamp with time zone,\n    num_resets integer DEFAULT 0 NOT NULL,\n    CONSTRAINT lsif_uploads_commit_valid_chars CHECK ((commit ~ '^[a-z0-9]{40}$'::text))\n);\n\nCREATE SEQUENCE lsif_indexes_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE lsif_indexes_id_seq OWNED BY lsif_indexes.id;\n\nCREATE TABLE lsif_packages (\n    id integer NOT NULL,\n    scheme text NOT NULL,\n    name text NOT NULL,\n    version text,\n    dump_id integer NOT NULL\n);\n\nCREATE SEQUENCE lsif_packages_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE lsif_packages_id_seq OWNED BY lsif_packages.id;\n\nCREATE TABLE lsif_references (\n    id integer NOT NULL,\n    scheme text NOT NULL,\n    name text NOT NULL,\n    version text,\n    filter bytea NOT NULL,\n    dump_id integer NOT NULL\n);\n\nCREATE SEQUENCE lsif_references_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE lsif_references_id_seq OWNED BY lsif_references.id;\n\nCREATE TABLE names (\n    name citext NOT NULL,\n    user_id integer,\n    org_id integer,\n    CONSTRAINT names_check CHECK (((user_id IS NOT NULL) OR (org_id IS NOT NULL)))\n);\n\nCREATE TABLE org_invitations (\n    id bigint NOT NULL,\n    org_id integer NOT NULL,\n    sender_user_id integer NOT NULL,\n    recipient_user_id integer NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    notified_at timestamp with time zone,\n    responded_at timestamp with time zone,\n    response_type boolean,\n    revoked_at timestamp with time zone,\n    deleted_at timestamp with time zone,\n    CONSTRAINT check_atomic_response CHECK (((responded_at IS NULL) = (response_type IS NULL))),\n    CONSTRAINT check_single_use CHECK ((((responded_at IS NULL) AND (response_type IS NULL)) OR (revoked_at IS NULL)))\n);\n\nCREATE SEQUENCE org_invitations_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE org_invitations_id_seq OWNED BY org_invitations.id;\n\nCREATE TABLE org_members (\n    id integer NOT NULL,\n    org_id integer NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    user_id integer NOT NULL\n);\n\nCREATE TABLE org_members_bkup_1514536731 (\n    id integer,\n    org_id integer,\n    user_id_old text,\n    created_at timestamp with time zone,\n    updated_at timestamp with time zone,\n    user_id integer\n);\n\nCREATE SEQUENCE org_members_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE org_members_id_seq OWNED BY org_members.id;\n\nCREATE TABLE orgs (\n    id integer NOT NULL,\n    name citext NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    display_name text,\n    slack_webhook_url text,\n    deleted_at timestamp with time zone,\n    CONSTRAINT orgs_display_name_max_length CHECK ((char_length(display_name) \u003c= 255)),\n    CONSTRAINT orgs_name_max_length CHECK ((char_length((name)::text) \u003c= 255)),\n    CONSTRAINT orgs_name_valid_chars CHECK ((name OPERATOR(~) '^[a-zA-Z0-9](?:[a-zA-Z0-9]|[-.](?=[a-zA-Z0-9]))*-?$'::citext))\n);\n\nCREATE SEQUENCE orgs_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE orgs_id_seq OWNED BY orgs.id;\n\nCREATE TABLE phabricator_repos (\n    id integer NOT NULL,\n    callsign citext NOT NULL,\n    repo_name citext NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    deleted_at timestamp with time zone,\n    url text DEFAULT ''::text NOT NULL\n);\n\nCREATE SEQUENCE phabricator_repos_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE phabricator_repos_id_seq OWNED BY phabricator_repos.id;\n\nCREATE TABLE product_licenses (\n    id uuid NOT NULL,\n    product_subscription_id uuid NOT NULL,\n    license_key text NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL\n);\n\nCREATE TABLE product_subscriptions (\n    id uuid NOT NULL,\n    user_id integer NOT NULL,\n    billing_subscription_id text,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    archived_at timestamp with time zone\n);\n\nCREATE TABLE query_runner_state (\n    query text,\n    last_executed timestamp with time zone,\n    latest_result timestamp with time zone,\n    exec_duration_ns bigint\n);\n\nCREATE TABLE registry_extension_releases (\n    id bigint NOT NULL,\n    registry_extension_id integer NOT NULL,\n    creator_user_id integer NOT NULL,\n    release_version citext,\n    release_tag citext NOT NULL,\n    manifest jsonb NOT NULL,\n    bundle text,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    deleted_at timestamp with time zone,\n    source_map text\n);\n\nCREATE SEQUENCE registry_extension_releases_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE registry_extension_releases_id_seq OWNED BY registry_extension_releases.id;\n\nCREATE TABLE registry_extensions (\n    id integer NOT NULL,\n    uuid uuid NOT NULL,\n    publisher_user_id integer,\n    publisher_org_id integer,\n    name citext NOT NULL,\n    manifest text,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    deleted_at timestamp with time zone,\n    CONSTRAINT registry_extensions_name_length CHECK (((char_length((name)::text) \u003e 0) AND (char_length((name)::text) \u003c= 128))),\n    CONSTRAINT registry_extensions_name_valid_chars CHECK ((name OPERATOR(~) '^[a-zA-Z0-9](?:[a-zA-Z0-9]|[_.-](?=[a-zA-Z0-9]))*$'::citext)),\n    CONSTRAINT registry_extensions_single_publisher CHECK (((publisher_user_id IS NULL) \u003c\u003e (publisher_org_id IS NULL)))\n);\n\nCREATE SEQUENCE registry_extensions_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE registry_extensions_id_seq OWNED BY registry_extensions.id;\n\nCREATE TABLE repo (\n    id integer NOT NULL,\n    name citext NOT NULL,\n    description text,\n    language text,\n    fork boolean,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone,\n    external_id text,\n    external_service_type text,\n    external_service_id text,\n    archived boolean DEFAULT false NOT NULL,\n    uri citext,\n    deleted_at timestamp with time zone,\n    sources jsonb DEFAULT '{}'::jsonb NOT NULL,\n    metadata jsonb DEFAULT '{}'::jsonb NOT NULL,\n    private boolean DEFAULT false NOT NULL,\n    CONSTRAINT check_name_nonempty CHECK ((name OPERATOR(\u003c\u003e) ''::citext)),\n    CONSTRAINT repo_metadata_check CHECK ((jsonb_typeof(metadata) = 'object'::text)),\n    CONSTRAINT repo_sources_check CHECK ((jsonb_typeof(sources) = 'object'::text))\n);\n\nCREATE SEQUENCE repo_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE repo_id_seq OWNED BY repo.id;\n\nCREATE TABLE repo_pending_permissions (\n    repo_id integer NOT NULL,\n    permission text NOT NULL,\n    user_ids bytea NOT NULL,\n    updated_at timestamp with time zone NOT NULL\n);\n\nCREATE TABLE repo_permissions (\n    repo_id integer NOT NULL,\n    permission text NOT NULL,\n    user_ids bytea NOT NULL,\n    updated_at timestamp with time zone NOT NULL,\n    synced_at timestamp with time zone\n);\n\nCREATE TABLE saved_queries (\n    query text NOT NULL,\n    last_executed timestamp with time zone NOT NULL,\n    latest_result timestamp with time zone NOT NULL,\n    exec_duration_ns bigint NOT NULL\n);\n\nCREATE TABLE saved_searches (\n    id integer NOT NULL,\n    description text NOT NULL,\n    query text NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    notify_owner boolean NOT NULL,\n    notify_slack boolean NOT NULL,\n    user_id integer,\n    org_id integer,\n    slack_webhook_url text,\n    CONSTRAINT user_or_org_id_not_null CHECK ((((user_id IS NOT NULL) AND (org_id IS NULL)) OR ((org_id IS NOT NULL) AND (user_id IS NULL))))\n);\n\nCREATE SEQUENCE saved_searches_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE saved_searches_id_seq OWNED BY saved_searches.id;\n\nCREATE TABLE schema_migrations (\n    version bigint NOT NULL,\n    dirty boolean NOT NULL\n);\n\nCREATE TABLE settings (\n    id integer NOT NULL,\n    org_id integer,\n    contents text,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    user_id integer,\n    author_user_id integer\n);\n\nCREATE TABLE settings_bkup_1514702776 (\n    id integer,\n    org_id integer,\n    author_user_id_old text,\n    contents text,\n    created_at timestamp with time zone,\n    user_id integer,\n    author_user_id integer\n);\n\nCREATE SEQUENCE settings_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE settings_id_seq OWNED BY settings.id;\n\nCREATE VIEW site_config AS\n SELECT global_state.site_id,\n    global_state.initialized\n   FROM global_state;\n\nCREATE TABLE survey_responses (\n    id bigint NOT NULL,\n    user_id integer,\n    email text,\n    score integer NOT NULL,\n    reason text,\n    better text,\n    created_at timestamp with time zone DEFAULT now() NOT NULL\n);\n\nCREATE SEQUENCE survey_responses_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE survey_responses_id_seq OWNED BY survey_responses.id;\n\nCREATE TABLE user_emails (\n    user_id integer NOT NULL,\n    email citext NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    verification_code text,\n    verified_at timestamp with time zone,\n    last_verification_sent_at timestamp with time zone\n);\n\nCREATE TABLE user_external_accounts (\n    id integer NOT NULL,\n    user_id integer NOT NULL,\n    service_type text NOT NULL,\n    service_id text NOT NULL,\n    account_id text NOT NULL,\n    auth_data jsonb,\n    account_data jsonb,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    deleted_at timestamp with time zone,\n    client_id text NOT NULL\n);\n\nCREATE SEQUENCE user_external_accounts_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE user_external_accounts_id_seq OWNED BY user_external_accounts.id;\n\nCREATE TABLE user_pending_permissions (\n    id integer NOT NULL,\n    bind_id text NOT NULL,\n    permission text NOT NULL,\n    object_type text NOT NULL,\n    object_ids bytea NOT NULL,\n    updated_at timestamp with time zone NOT NULL,\n    service_type text NOT NULL,\n    service_id text NOT NULL\n);\n\nCREATE SEQUENCE user_pending_permissions_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE user_pending_permissions_id_seq OWNED BY user_pending_permissions.id;\n\nCREATE TABLE user_permissions (\n    user_id integer NOT NULL,\n    permission text NOT NULL,\n    object_type text NOT NULL,\n    object_ids bytea NOT NULL,\n    updated_at timestamp with time zone NOT NULL,\n    synced_at timestamp with time zone\n);\n\nCREATE TABLE users (\n    id integer NOT NULL,\n    username citext NOT NULL,\n    display_name text,\n    avatar_url text,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    deleted_at timestamp with time zone,\n    invite_quota integer DEFAULT 15 NOT NULL,\n    passwd text,\n    passwd_reset_code text,\n    passwd_reset_time timestamp with time zone,\n    site_admin boolean DEFAULT false NOT NULL,\n    page_views integer DEFAULT 0 NOT NULL,\n    search_queries integer DEFAULT 0 NOT NULL,\n    tags text[] DEFAULT '{}'::text[],\n    billing_customer_id text,\n    CONSTRAINT users_display_name_max_length CHECK ((char_length(display_name) \u003c= 255)),\n    CONSTRAINT users_username_max_length CHECK ((char_length((username)::text) \u003c= 255)),\n    CONSTRAINT users_username_valid_chars CHECK ((username OPERATOR(~) '^[a-zA-Z0-9](?:[a-zA-Z0-9]|[-.](?=[a-zA-Z0-9]))*-?$'::citext))\n);\n\nCREATE SEQUENCE users_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE users_id_seq OWNED BY users.id;\n\nCREATE TABLE versions (\n    service text NOT NULL,\n    version text NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL\n);\n\nALTER TABLE ONLY access_tokens ALTER COLUMN id SET DEFAULT nextval('access_tokens_id_seq'::regclass);\n\nALTER TABLE ONLY campaigns ALTER COLUMN id SET DEFAULT nextval('campaigns_id_seq'::regclass);\n\nALTER TABLE ONLY changeset_events ALTER COLUMN id SET DEFAULT nextval('changeset_events_id_seq'::regclass);\n\nALTER TABLE ONLY changeset_jobs ALTER COLUMN id SET DEFAULT nextval('changeset_jobs_id_seq'::regclass);\n\nALTER TABLE ONLY changesets ALTER COLUMN id SET DEFAULT nextval('changesets_id_seq'::regclass);\n\nALTER TABLE ONLY critical_and_site_config ALTER COLUMN id SET DEFAULT nextval('critical_and_site_config_id_seq'::regclass);\n\nALTER TABLE ONLY discussion_comments ALTER COLUMN id SET DEFAULT nextval('discussion_comments_id_seq'::regclass);\n\nALTER TABLE ONLY discussion_threads ALTER COLUMN id SET DEFAULT nextval('discussion_threads_id_seq'::regclass);\n\nALTER TABLE ONLY discussion_threads_target_repo ALTER COLUMN id SET DEFAULT nextval('discussion_threads_target_repo_id_seq'::regclass);\n\nALTER TABLE ONLY event_logs ALTER COLUMN id SET DEFAULT nextval('event_logs_id_seq'::regclass);\n\nALTER TABLE ONLY external_services ALTER COLUMN id SET DEFAULT nextval('external_services_id_seq'::regclass);\n\nALTER TABLE ONLY lsif_commits ALTER COLUMN id SET DEFAULT nextval('lsif_commits_id_seq'::regclass);\n\nALTER TABLE ONLY lsif_indexable_repositories ALTER COLUMN id SET DEFAULT nextval('lsif_indexable_repositories_id_seq'::regclass);\n\nALTER TABLE ONLY lsif_indexes ALTER COLUMN id SET DEFAULT nextval('lsif_indexes_id_seq'::regclass);\n\nALTER TABLE ONLY lsif_packages ALTER COLUMN id SET DEFAULT nextval('lsif_packages_id_seq'::regclass);\n\nALTER TABLE ONLY lsif_references ALTER COLUMN id SET DEFAULT nextval('lsif_references_id_seq'::regclass);\n\nALTER TABLE ONLY lsif_uploads ALTER COLUMN id SET DEFAULT nextval('lsif_dumps_id_seq'::regclass);\n\nALTER TABLE ONLY org_invitations ALTER COLUMN id SET DEFAULT nextval('org_invitations_id_seq'::regclass);\n\nALTER TABLE ONLY org_members ALTER COLUMN id SET DEFAULT nextval('org_members_id_seq'::regclass);\n\nALTER TABLE ONLY orgs ALTER COLUMN id SET DEFAULT nextval('orgs_id_seq'::regclass);\n\nALTER TABLE ONLY patch_sets ALTER COLUMN id SET DEFAULT nextval('campaign_plans_id_seq'::regclass);\n\nALTER TABLE ONLY patches ALTER COLUMN id SET DEFAULT nextval('campaign_jobs_id_seq'::regclass);\n\nALTER TABLE ONLY phabricator_repos ALTER COLUMN id SET DEFAULT nextval('phabricator_repos_id_seq'::regclass);\n\nALTER TABLE ONLY registry_extension_releases ALTER COLUMN id SET DEFAULT nextval('registry_extension_releases_id_seq'::regclass);\n\nALTER TABLE ONLY registry_extensions ALTER COLUMN id SET DEFAULT nextval('registry_extensions_id_seq'::regclass);\n\nALTER TABLE ONLY repo ALTER COLUMN id SET DEFAULT nextval('repo_id_seq'::regclass);\n\nALTER TABLE ONLY saved_searches ALTER COLUMN id SET DEFAULT nextval('saved_searches_id_seq'::regclass);\n\nALTER TABLE ONLY settings ALTER COLUMN id SET DEFAULT nextval('settings_id_seq'::regclass);\n\nALTER TABLE ONLY survey_responses ALTER COLUMN id SET DEFAULT nextval('survey_responses_id_seq'::regclass);\n\nALTER TABLE ONLY user_external_accounts ALTER COLUMN id SET DEFAULT nextval('user_external_accounts_id_seq'::regclass);\n\nALTER TABLE ONLY user_pending_permissions ALTER COLUMN id SET DEFAULT nextval('user_pending_permissions_id_seq'::regclass);\n\nALTER TABLE ONLY users ALTER COLUMN id SET DEFAULT nextval('users_id_seq'::regclass);\n\nALTER TABLE ONLY access_tokens\n    ADD CONSTRAINT access_tokens_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY access_tokens\n    ADD CONSTRAINT access_tokens_value_sha256_key UNIQUE (value_sha256);\n\nALTER TABLE ONLY patches\n    ADD CONSTRAINT campaign_jobs_campaign_plan_repo_rev_unique UNIQUE (patch_set_id, repo_id, rev) DEFERRABLE;\n\nALTER TABLE ONLY patches\n    ADD CONSTRAINT campaign_jobs_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY patch_sets\n    ADD CONSTRAINT campaign_plans_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY campaigns\n    ADD CONSTRAINT campaigns_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY changeset_events\n    ADD CONSTRAINT changeset_events_changeset_id_kind_key_unique UNIQUE (changeset_id, kind, key);\n\nALTER TABLE ONLY changeset_events\n    ADD CONSTRAINT changeset_events_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY changeset_jobs\n    ADD CONSTRAINT changeset_jobs_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY changeset_jobs\n    ADD CONSTRAINT changeset_jobs_unique UNIQUE (campaign_id, patch_id);\n\nALTER TABLE ONLY changesets\n    ADD CONSTRAINT changesets_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY changesets\n    ADD CONSTRAINT changesets_repo_external_id_unique UNIQUE (repo_id, external_id);\n\nALTER TABLE ONLY critical_and_site_config\n    ADD CONSTRAINT critical_and_site_config_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY default_repos\n    ADD CONSTRAINT default_repos_pkey PRIMARY KEY (repo_id);\n\nALTER TABLE ONLY discussion_comments\n    ADD CONSTRAINT discussion_comments_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY discussion_mail_reply_tokens\n    ADD CONSTRAINT discussion_mail_reply_tokens_pkey PRIMARY KEY (token);\n\nALTER TABLE ONLY discussion_threads\n    ADD CONSTRAINT discussion_threads_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY discussion_threads_target_repo\n    ADD CONSTRAINT discussion_threads_target_repo_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY event_logs\n    ADD CONSTRAINT event_logs_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY external_services\n    ADD CONSTRAINT external_services_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY global_state\n    ADD CONSTRAINT global_state_pkey PRIMARY KEY (site_id);\n\nALTER TABLE ONLY lsif_commits\n    ADD CONSTRAINT lsif_commits_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY lsif_indexable_repositories\n    ADD CONSTRAINT lsif_indexable_repositories_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY lsif_indexable_repositories\n    ADD CONSTRAINT lsif_indexable_repositories_repository_id_key UNIQUE (repository_id);\n\nALTER TABLE ONLY lsif_indexes\n    ADD CONSTRAINT lsif_indexes_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY lsif_packages\n    ADD CONSTRAINT lsif_packages_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY lsif_references\n    ADD CONSTRAINT lsif_references_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY lsif_uploads\n    ADD CONSTRAINT lsif_uploads_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY names\n    ADD CONSTRAINT names_pkey PRIMARY KEY (name);\n\nALTER TABLE ONLY org_invitations\n    ADD CONSTRAINT org_invitations_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY org_members\n    ADD CONSTRAINT org_members_org_id_user_id_key UNIQUE (org_id, user_id);\n\nALTER TABLE ONLY org_members\n    ADD CONSTRAINT org_members_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY orgs\n    ADD CONSTRAINT orgs_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY phabricator_repos\n    ADD CONSTRAINT phabricator_repos_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY phabricator_repos\n    ADD CONSTRAINT phabricator_repos_repo_name_key UNIQUE (repo_name);\n\nALTER TABLE ONLY product_licenses\n    ADD CONSTRAINT product_licenses_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY product_subscriptions\n    ADD CONSTRAINT product_subscriptions_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY registry_extension_releases\n    ADD CONSTRAINT registry_extension_releases_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY registry_extensions\n    ADD CONSTRAINT registry_extensions_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY repo\n    ADD CONSTRAINT repo_name_unique UNIQUE (name) DEFERRABLE;\n\nALTER TABLE ONLY repo_pending_permissions\n    ADD CONSTRAINT repo_pending_permissions_perm_unique UNIQUE (repo_id, permission);\n\nALTER TABLE ONLY repo_permissions\n    ADD CONSTRAINT repo_permissions_perm_unique UNIQUE (repo_id, permission);\n\nALTER TABLE ONLY repo\n    ADD CONSTRAINT repo_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY saved_searches\n    ADD CONSTRAINT saved_searches_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY schema_migrations\n    ADD CONSTRAINT schema_migrations_pkey PRIMARY KEY (version);\n\nALTER TABLE ONLY settings\n    ADD CONSTRAINT settings_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY survey_responses\n    ADD CONSTRAINT survey_responses_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY user_emails\n    ADD CONSTRAINT user_emails_no_duplicates_per_user UNIQUE (user_id, email);\n\nALTER TABLE ONLY user_emails\n    ADD CONSTRAINT user_emails_unique_verified_email EXCLUDE USING btree (email WITH OPERATOR(=)) WHERE ((verified_at IS NOT NULL));\n\nALTER TABLE ONLY user_external_accounts\n    ADD CONSTRAINT user_external_accounts_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY user_pending_permissions\n    ADD CONSTRAINT user_pending_permissions_service_perm_object_unique UNIQUE (service_type, service_id, permission, object_type, bind_id);\n\nALTER TABLE ONLY user_permissions\n    ADD CONSTRAINT user_permissions_perm_object_unique UNIQUE (user_id, permission, object_type);\n\nALTER TABLE ONLY users\n    ADD CONSTRAINT users_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY versions\n    ADD CONSTRAINT versions_pkey PRIMARY KEY (service);\n\nCREATE INDEX access_tokens_lookup ON access_tokens USING hash (value_sha256) WHERE (deleted_at IS NULL);\n\nCREATE INDEX campaigns_changeset_ids_gin_idx ON campaigns USING gin (changeset_ids);\n\nCREATE INDEX campaigns_namespace_org_id ON campaigns USING btree (namespace_org_id);\n\nCREATE INDEX campaigns_namespace_user_id ON campaigns USING btree (namespace_user_id);\n\nCREATE INDEX changeset_jobs_campaign_job_id ON changeset_jobs USING btree (patch_id);\n\nCREATE INDEX changeset_jobs_error_not_null ON changeset_jobs USING btree (((error IS NOT NULL)));\n\nCREATE INDEX changeset_jobs_finished_at ON changeset_jobs USING btree (finished_at);\n\nCREATE INDEX changeset_jobs_started_at ON changeset_jobs USING btree (started_at);\n\nCREATE UNIQUE INDEX critical_and_site_config_unique ON critical_and_site_config USING btree (id, type);\n\nCREATE INDEX discussion_comments_author_user_id_idx ON discussion_comments USING btree (author_user_id);\n\nCREATE INDEX discussion_comments_reports_array_length_idx ON discussion_comments USING btree (array_length(reports, 1));\n\nCREATE INDEX discussion_comments_thread_id_idx ON discussion_comments USING btree (thread_id);\n\nCREATE INDEX discussion_mail_reply_tokens_user_id_thread_id_idx ON discussion_mail_reply_tokens USING btree (user_id, thread_id);\n\nCREATE INDEX discussion_threads_author_user_id_idx ON discussion_threads USING btree (author_user_id);\n\nCREATE INDEX discussion_threads_target_repo_repo_id_path_idx ON discussion_threads_target_repo USING btree (repo_id, path);\n\nCREATE INDEX event_logs_anonymous_user_id ON event_logs USING btree (anonymous_user_id);\n\nCREATE INDEX event_logs_name ON event_logs USING btree (name);\n\nCREATE INDEX event_logs_source ON event_logs USING btree (source);\n\nCREATE INDEX event_logs_timestamp ON event_logs USING btree (\"timestamp\");\n\nCREATE INDEX event_logs_timestamp_at_utc ON event_logs USING btree (date(timezone('UTC'::text, \"timestamp\")));\n\nCREATE INDEX event_logs_user_id ON event_logs USING btree (user_id);\n\nCREATE UNIQUE INDEX lsif_commits_repository_id_commit_parent_commit_unique ON lsif_commits USING btree (repository_id, commit, parent_commit);\n\nCREATE INDEX lsif_commits_repository_id_parent_commit ON lsif_commits USING btree (repository_id, parent_commit);\n\nCREATE INDEX lsif_packages_scheme_name_version ON lsif_packages USING btree (scheme, name, version);\n\nCREATE INDEX lsif_references_package ON lsif_references USING btree (scheme, name, version);\n\nCREATE UNIQUE INDEX lsif_uploads_repository_id_commit_root_indexer ON lsif_uploads USING btree (repository_id, commit, root, indexer) WHERE (state = 'completed'::lsif_upload_state);\n\nCREATE INDEX lsif_uploads_state ON lsif_uploads USING btree (state);\n\nCREATE INDEX lsif_uploads_uploaded_at ON lsif_uploads USING btree (uploaded_at);\n\nCREATE INDEX lsif_uploads_visible_repository_id_commit ON lsif_uploads USING btree (repository_id, commit) WHERE visible_at_tip;\n\nCREATE INDEX org_invitations_org_id ON org_invitations USING btree (org_id) WHERE (deleted_at IS NULL);\n\nCREATE INDEX org_invitations_recipient_user_id ON org_invitations USING btree (recipient_user_id) WHERE (deleted_at IS NULL);\n\nCREATE UNIQUE INDEX org_invitations_singleflight ON org_invitations USING btree (org_id, recipient_user_id) WHERE ((responded_at IS NULL) AND (revoked_at IS NULL) AND (deleted_at IS NULL));\n\nCREATE UNIQUE INDEX orgs_name ON orgs USING btree (name) WHERE (deleted_at IS NULL);\n\nCREATE INDEX registry_extension_releases_registry_extension_id ON registry_extension_releases USING btree (registry_extension_id, release_tag, created_at DESC) WHERE (deleted_at IS NULL);\n\nCREATE UNIQUE INDEX registry_extension_releases_version ON registry_extension_releases USING btree (registry_extension_id, release_version) WHERE (release_version IS NOT NULL);\n\nCREATE UNIQUE INDEX registry_extensions_publisher_name ON registry_extensions USING btree ((COALESCE(publisher_user_id, 0)), (COALESCE(publisher_org_id, 0)), name) WHERE (deleted_at IS NULL);\n\nCREATE UNIQUE INDEX registry_extensions_uuid ON registry_extensions USING btree (uuid);\n\nCREATE INDEX repo_archived ON repo USING btree (archived);\n\nCREATE UNIQUE INDEX repo_external_unique_idx ON repo USING btree (external_service_type, external_service_id, external_id);\n\nCREATE INDEX repo_fork ON repo USING btree (fork);\n\nCREATE INDEX repo_metadata_gin_idx ON repo USING gin (metadata);\n\nCREATE INDEX repo_name_trgm ON repo USING gin (lower((name)::text) gin_trgm_ops);\n\nCREATE INDEX repo_private ON repo USING btree (private);\n\nCREATE INDEX repo_sources_gin_idx ON repo USING gin (sources);\n\nCREATE INDEX repo_uri_idx ON repo USING btree (uri);\n\nCREATE UNIQUE INDEX saved_queries_query_unique ON saved_queries USING btree (query);\n\nCREATE UNIQUE INDEX user_external_accounts_account ON user_external_accounts USING btree (service_type, service_id, client_id, account_id) WHERE (deleted_at IS NULL);\n\nCREATE INDEX user_external_accounts_user_id ON user_external_accounts USING btree (user_id) WHERE (deleted_at IS NULL);\n\nCREATE UNIQUE INDEX users_billing_customer_id ON users USING btree (billing_customer_id) WHERE (deleted_at IS NULL);\n\nCREATE UNIQUE INDEX users_username ON users USING btree (username) WHERE (deleted_at IS NULL);\n\nCREATE TRIGGER trig_delete_campaign_reference_on_changesets AFTER DELETE ON campaigns FOR EACH ROW EXECUTE PROCEDURE delete_campaign_reference_on_changesets();\n\nCREATE TRIGGER trig_delete_changeset_reference_on_campaigns AFTER DELETE ON changesets FOR EACH ROW EXECUTE PROCEDURE delete_changeset_reference_on_campaigns();\n\nALTER TABLE ONLY access_tokens\n    ADD CONSTRAINT access_tokens_creator_user_id_fkey FOREIGN KEY (creator_user_id) REFERENCES users(id);\n\nALTER TABLE ONLY access_tokens\n    ADD CONSTRAINT access_tokens_subject_user_id_fkey FOREIGN KEY (subject_user_id) REFERENCES users(id);\n\nALTER TABLE ONLY patches\n    ADD CONSTRAINT campaign_jobs_campaign_plan_id_fkey FOREIGN KEY (patch_set_id) REFERENCES patch_sets(id) ON DELETE CASCADE DEFERRABLE;\n\nALTER TABLE ONLY patches\n    ADD CONSTRAINT campaign_jobs_repo_id_fkey FOREIGN KEY (repo_id) REFERENCES repo(id) ON DELETE CASCADE DEFERRABLE;\n\nALTER TABLE ONLY patch_sets\n    ADD CONSTRAINT campaign_plans_user_id_fkey FOREIGN KEY (user_id) REFERENCES users(id) DEFERRABLE;\n\nALTER TABLE ONLY campaigns\n    ADD CONSTRAINT campaigns_author_id_fkey FOREIGN KEY (author_id) REFERENCES users(id) ON DELETE CASCADE DEFERRABLE;\n\nALTER TABLE ONLY campaigns\n    ADD CONSTRAINT campaigns_campaign_plan_id_fkey FOREIGN KEY (patch_set_id) REFERENCES patch_sets(id) DEFERRABLE;\n\nALTER TABLE ONLY campaigns\n    ADD CONSTRAINT campaigns_namespace_org_id_fkey FOREIGN KEY (namespace_org_id) REFERENCES orgs(id) ON DELETE CASCADE DEFERRABLE;\n\nALTER TABLE ONLY campaigns\n    ADD CONSTRAINT campaigns_namespace_user_id_fkey FOREIGN KEY (namespace_user_id) REFERENCES users(id) ON DELETE CASCADE DEFERRABLE;\n\nALTER TABLE ONLY changeset_events\n    ADD CONSTRAINT changeset_events_changeset_id_fkey FOREIGN KEY (changeset_id) REFERENCES changesets(id) ON DELETE CASCADE DEFERRABLE;\n\nALTER TABLE ONLY changeset_jobs\n    ADD CONSTRAINT changeset_jobs_campaign_id_fkey FOREIGN KEY (campaign_id) REFERENCES campaigns(id) ON DELETE CASCADE DEFERRABLE;\n\nALTER TABLE ONLY changeset_jobs\n    ADD CONSTRAINT changeset_jobs_campaign_job_id_fkey FOREIGN KEY (patch_id) REFERENCES patches(id) ON DELETE CASCADE DEFERRABLE;\n\nALTER TABLE ONLY changeset_jobs\n    ADD CONSTRAINT changeset_jobs_changeset_id_fkey FOREIGN KEY (changeset_id) REFERENCES changesets(id) ON DELETE CASCADE DEFERRABLE;\n\nALTER TABLE ONLY changesets\n    ADD CONSTRAINT changesets_repo_id_fkey FOREIGN KEY (repo_id) REFERENCES repo(id) ON DELETE CASCADE DEFERRABLE;\n\nALTER TABLE ONLY default_repos\n    ADD CONSTRAINT default_repos_repo_id_fkey FOREIGN KEY (repo_id) REFERENCES repo(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY discussion_comments\n    ADD CONSTRAINT discussion_comments_author_user_id_fkey FOREIGN KEY (author_user_id) REFERENCES users(id) ON DELETE RESTRICT;\n\nALTER TABLE ONLY discussion_comments\n    ADD CONSTRAINT discussion_comments_thread_id_fkey FOREIGN KEY (thread_id) REFERENCES discussion_threads(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY discussion_mail_reply_tokens\n    ADD CONSTRAINT discussion_mail_reply_tokens_thread_id_fkey FOREIGN KEY (thread_id) REFERENCES discussion_threads(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY discussion_mail_reply_tokens\n    ADD CONSTRAINT discussion_mail_reply_tokens_user_id_fkey FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE RESTRICT;\n\nALTER TABLE ONLY discussion_threads\n    ADD CONSTRAINT discussion_threads_author_user_id_fkey FOREIGN KEY (author_user_id) REFERENCES users(id) ON DELETE RESTRICT;\n\nALTER TABLE ONLY discussion_threads\n    ADD CONSTRAINT discussion_threads_target_repo_id_fk FOREIGN KEY (target_repo_id) REFERENCES discussion_threads_target_repo(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY discussion_threads_target_repo\n    ADD CONSTRAINT discussion_threads_target_repo_repo_id_fkey FOREIGN KEY (repo_id) REFERENCES repo(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY discussion_threads_target_repo\n    ADD CONSTRAINT discussion_threads_target_repo_thread_id_fkey FOREIGN KEY (thread_id) REFERENCES discussion_threads(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY lsif_packages\n    ADD CONSTRAINT lsif_packages_dump_id_fkey FOREIGN KEY (dump_id) REFERENCES lsif_uploads(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY lsif_references\n    ADD CONSTRAINT lsif_references_dump_id_fkey FOREIGN KEY (dump_id) REFERENCES lsif_uploads(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY names\n    ADD CONSTRAINT names_org_id_fkey FOREIGN KEY (org_id) REFERENCES orgs(id) ON UPDATE CASCADE ON DELETE CASCADE;\n\nALTER TABLE ONLY names\n    ADD CONSTRAINT names_user_id_fkey FOREIGN KEY (user_id) REFERENCES users(id) ON UPDATE CASCADE ON DELETE CASCADE;\n\nALTER TABLE ONLY org_invitations\n    ADD CONSTRAINT org_invitations_org_id_fkey FOREIGN KEY (org_id) REFERENCES orgs(id);\n\nALTER TABLE ONLY org_invitations\n    ADD CONSTRAINT org_invitations_recipient_user_id_fkey FOREIGN KEY (recipient_user_id) REFERENCES users(id);\n\nALTER TABLE ONLY org_invitations\n    ADD CONSTRAINT org_invitations_sender_user_id_fkey FOREIGN KEY (sender_user_id) REFERENCES users(id);\n\nALTER TABLE ONLY org_members\n    ADD CONSTRAINT org_members_references_orgs FOREIGN KEY (org_id) REFERENCES orgs(id) ON DELETE RESTRICT;\n\nALTER TABLE ONLY org_members\n    ADD CONSTRAINT org_members_user_id_fkey FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE RESTRICT;\n\nALTER TABLE ONLY product_licenses\n    ADD CONSTRAINT product_licenses_product_subscription_id_fkey FOREIGN KEY (product_subscription_id) REFERENCES product_subscriptions(id);\n\nALTER TABLE ONLY product_subscriptions\n    ADD CONSTRAINT product_subscriptions_user_id_fkey FOREIGN KEY (user_id) REFERENCES users(id);\n\nALTER TABLE ONLY registry_extension_releases\n    ADD CONSTRAINT registry_extension_releases_creator_user_id_fkey FOREIGN KEY (creator_user_id) REFERENCES users(id);\n\nALTER TABLE ONLY registry_extension_releases\n    ADD CONSTRAINT registry_extension_releases_registry_extension_id_fkey FOREIGN KEY (registry_extension_id) REFERENCES registry_extensions(id) ON UPDATE CASCADE ON DELETE CASCADE;\n\nALTER TABLE ONLY registry_extensions\n    ADD CONSTRAINT registry_extensions_publisher_org_id_fkey FOREIGN KEY (publisher_org_id) REFERENCES orgs(id);\n\nALTER TABLE ONLY registry_extensions\n    ADD CONSTRAINT registry_extensions_publisher_user_id_fkey FOREIGN KEY (publisher_user_id) REFERENCES users(id);\n\nALTER TABLE ONLY saved_searches\n    ADD CONSTRAINT saved_searches_org_id_fkey FOREIGN KEY (org_id) REFERENCES orgs(id);\n\nALTER TABLE ONLY saved_searches\n    ADD CONSTRAINT saved_searches_user_id_fkey FOREIGN KEY (user_id) REFERENCES users(id);\n\nALTER TABLE ONLY settings\n    ADD CONSTRAINT settings_author_user_id_fkey FOREIGN KEY (author_user_id) REFERENCES users(id) ON DELETE RESTRICT;\n\nALTER TABLE ONLY settings\n    ADD CONSTRAINT settings_references_orgs FOREIGN KEY (org_id) REFERENCES orgs(id) ON DELETE RESTRICT;\n\nALTER TABLE ONLY settings\n    ADD CONSTRAINT settings_user_id_fkey FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE RESTRICT;\n\nALTER TABLE ONLY survey_responses\n    ADD CONSTRAINT survey_responses_user_id_fkey FOREIGN KEY (user_id) REFERENCES users(id);\n\nALTER TABLE ONLY user_emails\n    ADD CONSTRAINT user_emails_user_id_fkey FOREIGN KEY (user_id) REFERENCES users(id);\n\nALTER TABLE ONLY user_external_accounts\n    ADD CONSTRAINT user_external_accounts_user_id_fkey FOREIGN KEY (user_id) REFERENCES users(id);",
				"DownQuery": "DROP SCHEMA IF EXISTS public CASCADE;\nCREATE SCHEMA public;\n\nCREATE TABLE IF NOT EXISTS schema_migrations (\n    version bigint NOT NULL PRIMARY KEY,\n    dirty boolean NOT NULL\n);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					-1528395684
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395685,
				"Name": "add diffstat fields to changesets",
				"UpQuery": "ALTER TABLE changesets ADD COLUMN IF NOT EXISTS diff_stat_added integer;\nALTER TABLE changesets ADD COLUMN IF NOT EXISTS diff_stat_changed integer;\nALTER TABLE changesets ADD COLUMN IF NOT EXISTS diff_stat_deleted integer;\nALTER TABLE changesets ADD COLUMN IF NOT EXISTS sync_state jsonb DEFAULT '{}'::jsonb NOT NULL;",
				"DownQuery": "ALTER TABLE changesets DROP COLUMN IF EXISTS diff_stat_added;\nALTER TABLE changesets DROP COLUMN IF EXISTS diff_stat_changed;\nALTER TABLE changesets DROP COLUMN IF EXISTS diff_stat_deleted;\nALTER TABLE changesets DROP COLUMN IF EXISTS sync_state;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395684
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395686,
				"Name": "lsif repository",
				"UpQuery": "CREATE VIEW lsif_dumps_with_repository_name AS\n    SELECT u.*, r.name as repository_name FROM lsif_dumps u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_uploads_with_repository_name AS\n    SELECT u.*, r.name as repository_name FROM lsif_uploads u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_indexes_with_repository_name AS\n    SELECT u.*, r.name as repository_name FROM lsif_indexes u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;",
				"DownQuery": "DROP VIEW lsif_dumps_with_repository_name;\nDROP VIEW lsif_uploads_with_repository_name;\nDROP VIEW lsif_indexes_with_repository_name;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395685
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395687,
				"Name": "lsif indexable repositories last updated",
				"UpQuery": "ALTER TABLE lsif_indexable_repositories ADD COLUMN last_updated_at timestamp with time zone DEFAULT now() NOT NULL;\nUPDATE lsif_indexable_repositories SET last_updated_at = NOW();\nALTER TABLE lsif_indexable_repositories ALTER COLUMN last_updated_at SET NOT NULL;",
				"DownQuery": "ALTER TABLE lsif_indexable_repositories DROP COLUMN last_updated_at;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395686
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395688,
				"Name": "add cloned column to repo",
				"UpQuery": "ALTER TABLE repo ADD COLUMN IF NOT EXISTS cloned BOOLEAN NOT NULL DEFAULT FALSE;\nCREATE INDEX IF NOT EXISTS repo_cloned ON repo(cloned);",
				"DownQuery": "DROP INDEX IF EXISTS repo_cloned;\nALTER TABLE repo DROP COLUMN cloned;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395687
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395689,
				"Name": "lsif indexable repositories enable",
				"UpQuery": "ALTER TABLE lsif_indexable_repositories ADD COLUMN enabled boolean;",
				"DownQuery": "ALTER TABLE lsif_indexable_repositories DROP COLUMN enabled;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395688
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395690,
				"Name": "lsif upload size",
				"UpQuery": "DROP VIEW lsif_dumps_with_repository_name;\nDROP VIEW lsif_uploads_with_repository_name;\nDROP VIEW lsif_dumps;\n\nALTER TABLE lsif_uploads ADD COLUMN upload_size bigint;\n\n-- Recreate views with new columns\nCREATE VIEW lsif_dumps AS SELECT u.*, u.finished_at as processed_at FROM lsif_uploads u WHERE state = 'completed';\n\nCREATE VIEW lsif_dumps_with_repository_name AS\n    SELECT u.*, r.name as repository_name FROM lsif_dumps u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_uploads_with_repository_name AS\n    SELECT u.*, r.name as repository_name FROM lsif_uploads u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;",
				"DownQuery": "DROP VIEW lsif_dumps_with_repository_name;\nDROP VIEW lsif_uploads_with_repository_name;\nDROP VIEW lsif_dumps;\n\nALTER TABLE lsif_uploads DROP COLUMN upload_size;\n\n-- Recreate views with new columns\nCREATE VIEW lsif_dumps AS SELECT u.*, u.finished_at as processed_at FROM lsif_uploads u WHERE state = 'completed';\n\nCREATE VIEW lsif_dumps_with_repository_name AS\n    SELECT u.*, r.name as repository_name FROM lsif_dumps u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_uploads_with_repository_name AS\n    SELECT u.*, r.name as repository_name FROM lsif_uploads u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395689
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395691,
				"Name": "encrypt tokens",
				"UpQuery": "CREATE TABLE secrets (\n    id BIGSERIAL PRIMARY KEY,\n    source_type varchar(50),\n    source_id bigint,\n    key_name varchar(100),\n    value text NOT NULL\n);\n\n-- A source_type/source_id combination should always be unique, otherwise we\n-- can have duplicate token entries\nCREATE UNIQUE INDEX secret_sourcetype_idx ON secrets USING btree (source_type, source_id);\n\n-- PostgreSQL treats NULL as distinct values\nCREATE UNIQUE INDEX secret_key_idx ON secrets USING btree (key_name);",
				"DownQuery": "DROP INDEX if exists secret_sourcetype_idx;\nDROP INDEX if exists secret_key_idx;\nDROP table if exists secrets;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395690
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395692,
				"Name": "add campaign specs and changeset specs",
				"UpQuery": "CREATE TABLE campaign_specs (\n    id bigserial NOT NULL PRIMARY KEY,\n    rand_id text NOT NULL,\n\n    raw_spec text NOT NULL,\n    spec jsonb DEFAULT '{}'::jsonb NOT NULL,\n\n    namespace_user_id integer,\n    namespace_org_id integer,\n\n    user_id integer NOT NULL,\n\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n\n    CONSTRAINT campaign_specs_has_1_namespace CHECK (((namespace_user_id IS NULL) \u003c\u003e (namespace_org_id IS NULL))),\n\n    FOREIGN KEY (user_id) REFERENCES users(id) DEFERRABLE\n);\n\nCREATE INDEX IF NOT EXISTS campaign_specs_rand_id ON campaign_specs(rand_id);\n\nALTER TABLE campaigns\n  ADD COLUMN IF NOT EXISTS campaign_spec_id bigint REFERENCES campaign_specs(id) DEFERRABLE;\n\nCREATE TABLE changeset_specs (\n  id bigserial NOT NULL PRIMARY KEY,\n  rand_id text NOT NULL,\n\n  raw_spec text NOT NULL,\n  spec jsonb DEFAULT '{}'::jsonb NOT NULL,\n\n  campaign_spec_id bigint,\n  repo_id integer NOT NULL,\n\n  user_id integer NOT NULL,\n\n  diff_stat_added integer,\n  diff_stat_changed integer,\n  diff_stat_deleted integer,\n\n  created_at timestamp with time zone DEFAULT now() NOT NULL,\n  updated_at timestamp with time zone DEFAULT now() NOT NULL,\n\n  FOREIGN KEY (campaign_spec_id) REFERENCES campaign_specs(id) DEFERRABLE,\n  FOREIGN KEY (repo_id)          REFERENCES repo(id)           DEFERRABLE,\n  FOREIGN KEY (user_id)          REFERENCES users(id)          DEFERRABLE\n);\n\nCREATE INDEX IF NOT EXISTS changeset_specs_rand_id ON changeset_specs(rand_id);\n\nALTER TABLE changesets\n  ADD COLUMN IF NOT EXISTS changeset_spec_id bigint REFERENCES changeset_specs(id) DEFERRABLE;",
				"DownQuery": "ALTER TABLE IF EXISTS changesets DROP COLUMN IF EXISTS changeset_spec_id;\nDROP TABLE IF EXISTS changeset_specs;\n\nALTER TABLE IF EXISTS campaigns DROP COLUMN IF EXISTS campaign_spec_id;\nDROP TABLE IF EXISTS campaign_specs;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395691
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395693,
				"Name": "remove old campaigns workflow tables",
				"UpQuery": "-- Drop references to old tables.\nALTER TABLE campaigns DROP COLUMN IF EXISTS patch_set_id;\n\n-- Now drop all old tables.\nDROP TABLE changeset_jobs;\nDROP TABLE patches;\nDROP TABLE patch_sets;",
				"DownQuery": "CREATE TABLE patch_sets (\n    id bigserial NOT NULL PRIMARY KEY,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    user_id integer NOT NULL\n);\nALTER TABLE patch_sets ADD CONSTRAINT patch_sets_user_id_fkey FOREIGN KEY (user_id) REFERENCES users(id) DEFERRABLE;\n\nALTER TABLE campaigns\n  ADD COLUMN IF NOT EXISTS patch_set_id bigint REFERENCES patch_sets(id) DEFERRABLE;\n\nCREATE TABLE patches (\n    id bigserial NOT NULL PRIMARY KEY,\n    patch_set_id bigint NOT NULL,\n    repo_id bigint NOT NULL,\n    rev text NOT NULL,\n    diff text NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    base_ref text NOT NULL,\n    diff_stat_added integer,\n    diff_stat_changed integer,\n    diff_stat_deleted integer,\n    CONSTRAINT patches_base_ref_check CHECK ((base_ref \u003c\u003e ''::text)),\n\n    FOREIGN KEY (patch_set_id) REFERENCES patch_sets(id) ON DELETE CASCADE DEFERRABLE,\n    FOREIGN KEY (repo_id) REFERENCES repo(id) ON DELETE CASCADE DEFERRABLE\n);\n\nALTER TABLE patches ADD CONSTRAINT patches_patch_set_repo_rev_unique UNIQUE (patch_set_id, repo_id, rev) DEFERRABLE;\n\nCREATE TABLE changeset_jobs (\n    id bigserial NOT NULL PRIMARY KEY,\n    campaign_id bigint NOT NULL,\n    patch_id bigint NOT NULL,\n    changeset_id bigint,\n    error text,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    started_at timestamp with time zone,\n    finished_at timestamp with time zone,\n    branch text,\n\n    FOREIGN KEY (campaign_id) REFERENCES campaigns(id) DEFERRABLE,\n    FOREIGN KEY (patch_id) REFERENCES patches(id) DEFERRABLE,\n    FOREIGN KEY (changeset_id) REFERENCES changesets(id) DEFERRABLE\n);\nALTER TABLE changeset_jobs ADD CONSTRAINT changeset_jobs_unique UNIQUE (campaign_id, patch_id);\n\nCREATE INDEX changeset_jobs_campaign_job_id ON changeset_jobs USING btree (patch_id);\nCREATE INDEX changeset_jobs_error_not_null ON changeset_jobs USING btree (((error IS NOT NULL)));\nCREATE INDEX changeset_jobs_finished_at ON changeset_jobs USING btree (finished_at);\nCREATE INDEX changeset_jobs_started_at ON changeset_jobs USING btree (started_at);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395692
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395694,
				"Name": "lsif nearest uploads",
				"UpQuery": "CREATE TABLE lsif_nearest_uploads (\n    repository_id integer NOT NULL,\n    \"commit\" text NOT NULL,\n    upload_id integer NOT NULL,\n    distance integer NOT NULL\n);\n\nCREATE TABLE lsif_uploads_visible_at_tip (\n    repository_id integer NOT NULL,\n    upload_id integer NOT NULL\n);\n\nCREATE TABLE lsif_dirty_repositories (\n    repository_id integer PRIMARY KEY,\n    dirty_token int NOT NULL,\n    update_token int NOT NULL\n);\n\nCREATE INDEX lsif_nearest_uploads_repository_id_commit ON lsif_nearest_uploads(repository_id, \"commit\");\nCREATE INDEX lsif_uploads_visible_at_tip_repository_id ON lsif_uploads_visible_at_tip(repository_id);",
				"DownQuery": "DROP TABLE lsif_nearest_uploads;\nDROP TABLE lsif_uploads_visible_at_tip;\nDROP TABLE lsif_dirty_repositories;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395693
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395695,
				"Name": "lsif remove commits",
				"UpQuery": "DROP TABLE lsif_commits;\n\n-- Drop dependent views\nDROP VIEW lsif_dumps_with_repository_name;\nDROP VIEW lsif_uploads_with_repository_name;\nDROP VIEW lsif_dumps;\n\nALTER TABLE lsif_uploads DROP COLUMN visible_at_tip;\n\n-- Recreate views\nCREATE VIEW lsif_dumps AS SELECT u.*, u.finished_at as processed_at FROM lsif_uploads u WHERE state = 'completed';\n\nCREATE VIEW lsif_dumps_with_repository_name AS\n    SELECT u.*, r.name as repository_name FROM lsif_dumps u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_uploads_with_repository_name AS\n    SELECT u.*, r.name as repository_name FROM lsif_uploads u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;",
				"DownQuery": "CREATE TABLE lsif_commits (\n    id SERIAL PRIMARY KEY,\n    commit text NOT NULL,\n    parent_commit text,\n    repository_id integer NOT NULL,\n    CONSTRAINT lsif_commits_commit_valid_chars CHECK ((commit ~ '^[a-z0-9]{40}$'::text)),\n    CONSTRAINT lsif_commits_parent_commit_valid_chars CHECK ((parent_commit ~ '^[a-z0-9]{40}$'::text))\n);\n\n-- Drop dependent views\nDROP VIEW lsif_dumps_with_repository_name;\nDROP VIEW lsif_uploads_with_repository_name;\nDROP VIEW lsif_dumps;\n\nALTER TABLE lsif_uploads ADD COLUMN visible_at_tip boolean NOT NULL DEFAULT false;\n\n-- Recreate views\nCREATE VIEW lsif_dumps AS SELECT u.*, u.finished_at as processed_at FROM lsif_uploads u WHERE state = 'completed';\n\nCREATE VIEW lsif_dumps_with_repository_name AS\n    SELECT u.*, r.name as repository_name FROM lsif_dumps u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_uploads_with_repository_name AS\n    SELECT u.*, r.name as repository_name FROM lsif_uploads u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395694
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395696,
				"Name": "repo name index",
				"UpQuery": "-- Note: CREATE INDEX CONCURRENTLY cannot run inside a transaction block\n\n--- Aug 20, 2020: This migration was redacted as it caused upgrade deadlocks in v3.19.0. See also 1528395705_remove_bad_migration.up.sql\n--- CREATE INDEX CONCURRENTLY IF NOT EXISTS repo_name_idx ON public.repo USING btree (lower(name::text) COLLATE pg_catalog.\"C\");",
				"DownQuery": "DROP INDEX IF EXISTS repo_name_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395695
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "public",
					"IndexName": "repo_name_idx"
				}
			},
			{
				"ID": 1528395697,
				"Name": "add changeset state machine",
				"UpQuery": "-- We need two references to changeset_specs: one current spec and the previous one.\n-- We use the already-existing column, changeset_spec_id, and rename it to current_spec_id.\nALTER TABLE changesets RENAME COLUMN changeset_spec_id TO current_spec_id;\nALTER TABLE changesets ADD COLUMN IF NOT EXISTS previous_spec_id bigint REFERENCES changeset_specs(id) DEFERRABLE;\n\n-- Now we add the 'publication_state' field to changesets.\n-- See ./internal/campaigns/types.go for the possible values here:\n--   - UNPUBLISHED\n--   - PUBLISHING\n-- We use UNPUBLISHED was the default value\nALTER TABLE changesets ADD COLUMN IF NOT EXISTS publication_state text DEFAULT 'UNPUBLISHED';\n\n-- Before switching to the new flow every changeset we had has been created\n-- on the code host.\nUPDATE changesets SET publication_state = 'PUBLISHED';\n\n-- Since changesets can now be created in an \"unpublished\" state, we need to\n-- make the following columns nullable:\nALTER TABLE changesets ALTER COLUMN external_id DROP NOT NULL;\nALTER TABLE changesets ALTER COLUMN metadata DROP NOT NULL;\n\n-- We also need this field to make it easier to keep track of which campaign\n-- \"owns\" which changeset: a campaign that owns a changeset can create and\n-- close it on the code host.\n-- Other campaigns that don't own a changeset can merely import/track it.\nALTER TABLE changesets ADD COLUMN IF NOT EXISTS owned_by_campaign_id bigint REFERENCES campaigns(id) DEFERRABLE;\n\n-- These columns are necessary to make the reconciler work using the workerutils package.\nALTER TABLE changesets ADD COLUMN IF NOT EXISTS reconciler_state text DEFAULT 'queued';\nALTER TABLE changesets ADD COLUMN IF NOT EXISTS failure_message text;\nALTER TABLE changesets ADD COLUMN IF NOT EXISTS started_at timestamp with time zone;\nALTER TABLE changesets ADD COLUMN IF NOT EXISTS finished_at timestamp with time zone;\nALTER TABLE changesets ADD COLUMN IF NOT EXISTS process_after timestamp with time zone;\nALTER TABLE changesets ADD COLUMN IF NOT EXISTS num_resets integer NOT NULL DEFAULT 0;\n\n-- Every changeset we have so far has been completed.\nUPDATE changesets\nSET reconciler_state = 'completed',\n    started_at = created_at,\n    finished_at = created_at;",
				"DownQuery": "ALTER TABLE changesets RENAME COLUMN current_spec_id TO changeset_spec_id;\nALTER TABLE changesets DROP COLUMN IF EXISTS previous_spec_id;\n\nALTER TABLE changesets DROP COLUMN IF EXISTS publication_state;\nALTER TABLE changesets ALTER COLUMN external_id SET NOT NULL;\nALTER TABLE changesets ALTER COLUMN metadata SET NOT NULL;\n\nALTER TABLE changesets DROP COLUMN IF EXISTS owned_by_campaign_id;\n\nALTER TABLE changesets DROP COLUMN IF EXISTS reconciler_state;\nALTER TABLE changesets DROP COLUMN IF EXISTS failure_message;\nALTER TABLE changesets DROP COLUMN IF EXISTS started_at;\nALTER TABLE changesets DROP COLUMN IF EXISTS finished_at;\nALTER TABLE changesets DROP COLUMN IF EXISTS process_after;\nALTER TABLE changesets DROP COLUMN IF EXISTS num_resets;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395696
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395698,
				"Name": "add sync time and user id to external services",
				"UpQuery": "ALTER TABLE external_services ADD COLUMN last_sync_at timestamp with time zone;\nALTER TABLE external_services ADD COLUMN next_sync_at timestamp with time zone;\nALTER TABLE external_services ADD COLUMN namespace_user_id integer;\n\nALTER TABLE ONLY external_services\n    ADD CONSTRAINT external_services_namepspace_user_id_fkey FOREIGN KEY (namespace_user_id) REFERENCES users(id) ON DELETE CASCADE DEFERRABLE;",
				"DownQuery": "ALTER TABLE external_services DROP COLUMN IF EXISTS last_sync_at;\nALTER TABLE external_services DROP COLUMN IF EXISTS next_sync_at;\nALTER TABLE external_services DROP COLUMN IF EXISTS namespace_user_id;\n\nALTER TABLE IF EXISTS ONLY external_services DROP CONSTRAINT IF EXISTS external_services_namepspace_user_id_fkey;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395697
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395699,
				"Name": "campaign remove branch",
				"UpQuery": "ALTER TABLE campaigns DROP COLUMN IF EXISTS branch;",
				"DownQuery": "ALTER TABLE campaigns ADD COLUMN branch text;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395698
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395700,
				"Name": "add apply data to campaign",
				"UpQuery": "ALTER TABLE campaigns RENAME COLUMN author_id TO initial_applier_id;\n\nALTER TABLE campaigns ADD COLUMN IF NOT EXISTS last_applier_id bigint REFERENCES users(id) DEFERRABLE;\nALTER TABLE campaigns ADD COLUMN IF NOT EXISTS last_applied_at timestamp with time zone;",
				"DownQuery": "ALTER TABLE campaigns RENAME COLUMN initial_applier_id TO author_id;\n\nALTER TABLE campaigns DROP COLUMN IF EXISTS last_applier_id;\nALTER TABLE campaigns DROP COLUMN IF EXISTS last_applied_at;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395699
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395701,
				"Name": "burn the campaigns boats",
				"UpQuery": "-- We're pruning pre-spec campaigns and changesets so that we can tighten up\n-- the schema to match the new spec-based way campaigns are represented.\n-- However, we need to keep the data so that we can provide a somewhat graceful\n-- migration, so the first thing we'll do is to create tables to retain old\n-- campaigns and changesets.\n\nCREATE TABLE IF NOT EXISTS\n    campaigns_old\nAS\n    SELECT\n        id,\n        name,\n        description,\n        initial_applier_id,\n        namespace_user_id,\n        namespace_org_id,\n        created_at,\n        updated_at,\n        changeset_ids,\n        closed_at,\n        campaign_spec_id,\n        last_applier_id,\n        last_applied_at\n    FROM\n        campaigns\n    WHERE\n        campaign_spec_id IS NULL;\n\n-- This query's a bit tricky: what we want is changesets that are _only_\n-- attached to campaigns without specs. Changesets that are (somehow) attached\n-- to both a spec and non-spec campaign should be left untouched.\n\nCREATE TABLE IF NOT EXISTS\n    changesets_old\nAS\n    SELECT\n        *\n    FROM\n        changesets\n    WHERE\n        campaign_ids ?| array(\n            SELECT\n                id::VARCHAR\n            FROM\n                campaigns\n            WHERE campaign_spec_id IS NULL\n        )\n        AND NOT campaign_ids ?| array(\n            SELECT\n                id::VARCHAR\n            FROM\n                campaigns\n            WHERE campaign_spec_id IS NOT NULL\n        );\n\n-- Now we've set up the tables, we can take the next step, which is to delete\n-- the old campaigns and changesets.\n\nDELETE FROM\n    changesets\nWHERE\n    campaign_ids ?| array(\n        SELECT\n            id::VARCHAR\n        FROM\n            campaigns\n        WHERE campaign_spec_id IS NULL\n    )\n    AND NOT campaign_ids ?| array(\n        SELECT\n            id::VARCHAR\n        FROM\n            campaigns\n        WHERE campaign_spec_id IS NOT NULL\n    );\n\nDELETE FROM\n    campaigns\nWHERE\n    campaign_spec_id IS NULL;\n\n-- It was theoretically possible to end up with a NULL last_applied_at while\n-- having a NOT NULL campaign_spec_id, as the migrations were not done at the\n-- same time. While the likelihood of this happening for anyone other than\n-- developers actively working on campaigns during the 3.19 cycle is\n-- essentially zero, let's take care of it just in case.\nUPDATE campaigns\n    SET last_applied_at = created_at\n    WHERE last_applied_at IS NULL;\n\n-- Now we can alter our fields.\n\n-- Set up the new NOT NULL constraints on the last applied at and campaign spec\n-- ID fields.\n\nALTER TABLE campaigns\n    ALTER COLUMN last_applied_at SET NOT NULL,\n    ALTER COLUMN campaign_spec_id SET NOT NULL,\n    ALTER COLUMN initial_applier_id DROP NOT NULL;\n\n-- When a user is hard deleted, we don't want campaigns and specs to be deleted\n-- just because their metadata is affected. We need to tweak their constraints\n-- accordingly.\n\nALTER TABLE campaign_specs\n    ALTER COLUMN user_id DROP NOT NULL,\n    DROP CONSTRAINT IF EXISTS campaign_specs_user_id_fkey,\n    ADD CONSTRAINT campaign_specs_user_id_fkey\n        FOREIGN KEY (user_id)\n        REFERENCES users (id)\n        ON DELETE SET NULL\n        DEFERRABLE;\n\nALTER TABLE campaigns\n    DROP CONSTRAINT IF EXISTS campaigns_author_id_fkey,\n    DROP CONSTRAINT IF EXISTS campaigns_last_applier_id_fkey,\n    ADD CONSTRAINT campaigns_initial_applier_id_fkey\n        FOREIGN KEY (initial_applier_id)\n        REFERENCES users (id)\n        ON DELETE SET NULL\n        DEFERRABLE,\n    ADD CONSTRAINT campaigns_last_applier_id_fkey\n        FOREIGN KEY (last_applier_id)\n        REFERENCES users (id)\n        ON DELETE SET NULL\n        DEFERRABLE;",
				"DownQuery": "-- Refer to the up migration for full details on what we're doing: we're just\n-- doing all of that in reverse.\n\nALTER TABLE campaign_specs\n    DROP CONSTRAINT IF EXISTS campaign_specs_user_id_fkey,\n    ADD CONSTRAINT campaign_specs_user_id_fkey\n        FOREIGN KEY (user_id)\n        REFERENCES users (id)\n        DEFERRABLE,\n    ALTER COLUMN user_id SET NOT NULL;\n\nALTER TABLE campaigns\n    DROP CONSTRAINT IF EXISTS campaigns_initial_applier_id_fkey,\n    DROP CONSTRAINT IF EXISTS campaigns_last_applier_id_fkey,\n    ADD CONSTRAINT campaigns_author_id_fkey\n        FOREIGN KEY (initial_applier_id)\n        REFERENCES users (id)\n        ON DELETE CASCADE\n        DEFERRABLE,\n    ADD CONSTRAINT campaigns_last_applier_id_fkey\n        FOREIGN KEY (last_applier_id)\n        REFERENCES users (id)\n        DEFERRABLE;\n\nALTER TABLE campaigns\n    ALTER COLUMN last_applied_at DROP NOT NULL,\n    ALTER COLUMN campaign_spec_id DROP NOT NULL,\n    ALTER COLUMN initial_applier_id SET NOT NULL;\n\n-- The ON CONFLICT clause here is because changesets can be partially migrated:\n-- if a changeset is attached to multiple campaigns and the repo-updater\n-- migrator has already run, we may have a matching external changeset in the\n-- changesets table that would violate the unique key on (repo_id,\n-- external_id). Since we have a changeset, that's OK, and we can just ignore\n-- those records.\nINSERT INTO\n    changesets\n    (\n        id,\n        campaign_ids,\n        repo_id,\n        created_at,\n        updated_at,\n        metadata,\n        external_id,\n        external_service_type,\n        external_deleted_at,\n        external_branch,\n        external_updated_at,\n        external_state,\n        external_review_state,\n        external_check_state,\n        created_by_campaign,\n        added_to_campaign,\n        diff_stat_added,\n        diff_stat_changed,\n        diff_stat_deleted,\n        sync_state,\n        current_spec_id,\n        previous_spec_id,\n        publication_state,\n        owned_by_campaign_id,\n        reconciler_state,\n        failure_message,\n        started_at,\n        finished_at,\n        process_after,\n        num_resets\n    )\nSELECT\n    id,\n    campaign_ids,\n    repo_id,\n    created_at,\n    updated_at,\n    metadata,\n    external_id,\n    external_service_type,\n    external_deleted_at,\n    external_branch,\n    external_updated_at,\n    external_state,\n    external_review_state,\n    external_check_state,\n    created_by_campaign,\n    added_to_campaign,\n    diff_stat_added,\n    diff_stat_changed,\n    diff_stat_deleted,\n    sync_state,\n    current_spec_id,\n    previous_spec_id,\n    publication_state,\n    owned_by_campaign_id,\n    reconciler_state,\n    failure_message,\n    started_at,\n    finished_at,\n    process_after,\n    num_resets\nFROM\n    changesets_old\nON CONFLICT\n    DO NOTHING;\n\nINSERT INTO\n    campaigns\nSELECT\n    id,\n    name,\n    description,\n    initial_applier_id,\n    namespace_user_id,\n    namespace_org_id,\n    created_at,\n    updated_at,\n    closed_at,\n    campaign_spec_id,\n    last_applier_id,\n    last_applied_at,\n    changeset_ids\nFROM\n    campaigns_old;\n\nDROP TABLE IF EXISTS changesets_old;\nDROP TABLE IF EXISTS campaigns_old;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395700
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395702,
				"Name": "changeset user fk",
				"UpQuery": "ALTER TABLE changeset_specs\n    ALTER COLUMN user_id DROP NOT NULL,\n    DROP CONSTRAINT IF EXISTS changeset_specs_user_id_fkey,\n    ADD CONSTRAINT changeset_specs_user_id_fkey\n        FOREIGN KEY (user_id)\n        REFERENCES users (id)\n        ON DELETE SET NULL\n        DEFERRABLE;",
				"DownQuery": "ALTER TABLE changeset_specs\n    DROP CONSTRAINT IF EXISTS changeset_specs_user_id_fkey,\n    ADD CONSTRAINT changeset_specs_user_id_fkey\n        FOREIGN KEY (user_id)\n        REFERENCES users (id)\n        DEFERRABLE,\n    ALTER COLUMN user_id SET NOT NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395701
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395703,
				"Name": "soft delete external service upon user deletion",
				"UpQuery": "DROP FUNCTION IF EXISTS soft_delete_user_reference_on_external_service();\n\nCREATE FUNCTION soft_delete_user_reference_on_external_service() RETURNS trigger\n    LANGUAGE plpgsql\nAS $$\nBEGIN\n    -- If a user is soft-deleted, delete every row that references that user\n    IF (OLD.deleted_at IS NULL AND NEW.deleted_at IS NOT NULL) THEN\n        UPDATE external_services\n        SET deleted_at = NOW()\n        WHERE namespace_user_id = OLD.id;\n    END IF;\n\n    RETURN OLD;\nEND;\n$$;\n\nCREATE TRIGGER trig_soft_delete_user_reference_on_external_service\n    AFTER UPDATE OF deleted_at ON users\n    FOR EACH ROW EXECUTE PROCEDURE soft_delete_user_reference_on_external_service();",
				"DownQuery": "DROP TRIGGER IF EXISTS trig_soft_delete_user_reference_on_external_service ON users;\nDROP FUNCTION IF EXISTS soft_delete_user_reference_on_external_service();",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395702
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395704,
				"Name": "remove owner on campaign delete",
				"UpQuery": "ALTER TABLE changesets\n    DROP CONSTRAINT IF EXISTS changesets_owned_by_campaign_id_fkey,\n    ADD CONSTRAINT changesets_owned_by_campaign_id_fkey\n        FOREIGN KEY (owned_by_campaign_id)\n        REFERENCES campaigns (id)\n        ON DELETE SET NULL\n        DEFERRABLE;",
				"DownQuery": "ALTER TABLE changesets\n    DROP CONSTRAINT IF EXISTS changesets_owned_by_campaign_id_fkey,\n    ADD CONSTRAINT changesets_owned_by_campaign_id_fkey\n        FOREIGN KEY (owned_by_campaign_id)\n        REFERENCES campaigns (id)\n        DEFERRABLE;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395703
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395705,
				"Name": "remove bad migration",
				"UpQuery": "-- Undoes the bad migration 1528395696_repo_name_index.up.sql in deployments that had it rolled out before\n-- v3.19.1 was released (primarily sourcegraph.com, k8s.sgdev.org, and other internal deployments - but\n-- also to keep consistency in other deployments that may have ran v3.19.0 which had this bug like server\n-- deployments.)\nDROP INDEX IF EXISTS repo_name_idx;",
				"DownQuery": "",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395704
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395706,
				"Name": "add table external services repos",
				"UpQuery": "CREATE TABLE IF NOT EXISTS external_service_repos (\n    external_service_id bigint NOT NULL,\n    repo_id integer NOT NULL,\n    clone_url text NOT NULL\n);\n\n-- Lock the repo table before running the migration.\nLOCK TABLE ONLY repo IN EXCLUSIVE MODE;\n\n\n-- Mark the sources columns as read-only using a trigger.\nCREATE FUNCTION make_repo_sources_column_read_only() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$\n    BEGIN\n        IF (OLD.sources != NEW.sources) THEN\n            RAISE EXCEPTION 'sources is read-only';\n        END IF;\n\n        RETURN OLD;\n    END;\n$$;\nCREATE TRIGGER trig_read_only_repo_sources_column BEFORE UPDATE OF sources ON repo FOR EACH ROW EXECUTE PROCEDURE make_repo_sources_column_read_only();\n\n-- Migrate repo.sources column content to the external_service_repos table.\n-- Each repo.sources value is a jsonb containing one or more source.\n-- Each source must be extracted as a single row in the external_service_repos table.\n\nDO $$\nDECLARE\n   _key   text;\n   _value text;\n   _repo_id integer;\n   _sources jsonb;\nBEGIN\n    FOR _repo_id, _sources IN\n        SELECT id, sources FROM repo WHERE deleted_at IS NULL\n    LOOP\n        FOR _key, _value IN\n            SELECT * FROM jsonb_each_text(_sources)\n        LOOP\n            INSERT INTO external_service_repos (external_service_id, repo_id, clone_url)\n            VALUES (\n                split_part((_value::jsonb-\u003e'ID'#\u003e\u003e'{}')::text, ':', 3)::bigint,\n                _repo_id,\n                _value::jsonb-\u003e'CloneURL'#\u003e\u003e'{}'\n            );\n        END LOOP;\n    END LOOP;\nEND$$;\n\nALTER TABLE ONLY external_service_repos\n    ADD CONSTRAINT external_service_repos_external_service_id_fkey FOREIGN KEY (external_service_id) REFERENCES external_services(id) ON DELETE CASCADE DEFERRABLE;\n\nALTER TABLE ONLY external_service_repos\n    ADD CONSTRAINT external_service_repos_repo_id_fkey FOREIGN KEY (repo_id) REFERENCES repo(id) ON DELETE CASCADE DEFERRABLE;\n\nCREATE FUNCTION delete_repo_ref_on_external_service_repos() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$\n    BEGIN\n        -- if a repo is soft-deleted, delete every row that references that repo\n        IF (OLD.deleted_at IS NULL AND NEW.deleted_at IS NOT NULL) THEN\n        DELETE FROM\n            external_service_repos\n        WHERE\n            repo_id = OLD.id;\n        END IF;\n\n        RETURN OLD;\n    END;\n$$;\n\nCREATE FUNCTION delete_external_service_ref_on_external_service_repos() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$\n    BEGIN\n        -- if an external service is soft-deleted, delete every row that references it\n        IF (OLD.deleted_at IS NULL AND NEW.deleted_at IS NOT NULL) THEN\n          DELETE FROM\n            external_service_repos\n          WHERE\n            external_service_id = OLD.id;\n        END IF;\n\n        RETURN OLD;\n    END;\n$$;\n\nCREATE TRIGGER trig_delete_repo_ref_on_external_service_repos AFTER UPDATE OF deleted_at ON repo FOR EACH ROW EXECUTE PROCEDURE delete_repo_ref_on_external_service_repos();\nCREATE TRIGGER trig_delete_external_service_ref_on_external_service_repos AFTER UPDATE OF deleted_at ON external_services FOR EACH ROW EXECUTE PROCEDURE delete_external_service_ref_on_external_service_repos();",
				"DownQuery": "DROP TRIGGER IF EXISTS trig_delete_repo_ref_on_external_service_repos ON repo;\nDROP TRIGGER IF EXISTS trig_delete_external_service_ref_on_external_service_repos ON external_services;\nDROP TRIGGER IF EXISTS trig_read_only_repo_sources_column ON repo;\n\nDROP FUNCTION IF EXISTS delete_repo_ref_on_external_service_repos();\nDROP FUNCTION IF EXISTS delete_external_service_ref_on_external_service_repos();\nDROP FUNCTION IF EXISTS make_repo_sources_column_read_only();\n\nDROP TABLE IF EXISTS external_service_repos;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395705
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395707,
				"Name": "add index to external services repos repo id",
				"UpQuery": "-- Note: CREATE INDEX CONCURRENTLY cannot run inside a transaction block\n\nCREATE INDEX CONCURRENTLY IF NOT EXISTS external_service_repos_repo_id ON external_service_repos(repo_id);",
				"DownQuery": "-- Note: DROP INDEX CONCURRENTLY cannot run inside a transaction block\n\nDROP INDEX CONCURRENTLY IF EXISTS external_service_repos_repo_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395706
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "external_service_repos",
					"IndexName": "external_service_repos_repo_id"
				}
			},
			{
				"ID": 1528395708,
				"Name": "add index to external services repos external service id",
				"UpQuery": "-- Note: CREATE INDEX CONCURRENTLY cannot run inside a transaction block\n\nCREATE INDEX CONCURRENTLY IF NOT EXISTS external_service_repos_external_service_id ON external_service_repos(external_service_id);",
				"DownQuery": "-- Note: DROP INDEX CONCURRENTLY cannot run inside a transaction block\n\nDROP INDEX CONCURRENTLY IF EXISTS external_service_repos_external_service_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395707
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "external_service_repos",
					"IndexName": "external_service_repos_external_service_id"
				}
			},
			{
				"ID": 1528395709,
				"Name": "create external service sync jobs table",
				"UpQuery": "CREATE SEQUENCE IF NOT EXISTS external_service_sync_jobs_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nCREATE TABLE IF NOT EXISTS external_service_sync_jobs (\n    -- Columns required by workerutil.Store\n    id integer NOT NULL DEFAULT nextval('external_service_sync_jobs_id_seq'::regclass),\n    state text NOT NULL DEFAULT 'queued'::text,\n    failure_message text,\n    started_at timestamp with time zone,\n    finished_at timestamp with time zone,\n    process_after timestamp with time zone,\n    num_resets integer not null DEFAULT 0,\n    -- Extra columns\n    external_service_id bigint,\n    -- Constraints\n    CONSTRAINT external_services_id_fk\n    FOREIGN KEY(external_service_id)\n    REFERENCES external_services(id)\n);\n\nCREATE OR REPLACE VIEW external_service_sync_jobs_with_next_sync_at AS\n    SELECT j.id,\n            j.state,\n            j.failure_message,\n            j.started_at,\n            j.finished_at,\n            j.process_after,\n            j.num_resets,\n            j.external_service_id,\n            e.next_sync_at\n    FROM\n    external_services e join external_service_sync_jobs j on e.id = j.external_service_id;\n\n-- NOTE: No index on the state column was added as we expect the size of this table to stay fairly small",
				"DownQuery": "DROP VIEW IF EXISTS external_service_sync_jobs_with_next_sync_at;\nDROP TABLE IF EXISTS external_service_sync_jobs;\nDROP SEQUENCE IF EXISTS external_service_sync_jobs_id_seq;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395708
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395710,
				"Name": "add unsynced flag to changesets",
				"UpQuery": "ALTER TABLE changesets ADD COLUMN IF NOT EXISTS unsynced BOOLEAN NOT NULL DEFAULT FALSE;",
				"DownQuery": "ALTER TABLE changesets DROP COLUMN IF EXISTS unsynced;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395709
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395711,
				"Name": "add soft deleted repository name func",
				"UpQuery": "DROP FUNCTION IF EXISTS soft_deleted_repository_name(text);\n\nCREATE FUNCTION soft_deleted_repository_name(name TEXT) RETURNS TEXT AS $$\nBEGIN\n    RETURN 'DELETED-' || extract(epoch from transaction_timestamp()) || '-' || name;\nEND;\n$$ LANGUAGE plpgsql VOLATILE STRICT;",
				"DownQuery": "DROP FUNCTION IF EXISTS soft_deleted_repository_name(text);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395710
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395712,
				"Name": "add closing flag to changesets",
				"UpQuery": "ALTER TABLE changesets ADD COLUMN IF NOT EXISTS closing BOOLEAN NOT NULL DEFAULT FALSE;",
				"DownQuery": "ALTER TABLE changesets DROP COLUMN IF EXISTS closing;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395711
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395713,
				"Name": "add trigger to delete orphan repos",
				"UpQuery": "DROP FUNCTION IF EXISTS soft_delete_orphan_repo_by_external_service_repos() CASCADE;\n\nCREATE FUNCTION soft_delete_orphan_repo_by_external_service_repos() RETURNS trigger\n    LANGUAGE plpgsql\nAS $$\nBEGIN\n    -- When an external service is soft or hard-deleted,\n    -- performs a clean up to soft-delete orphan repositories.\n    UPDATE\n        repo\n    SET\n        name = soft_deleted_repository_name(name),\n        deleted_at = transaction_timestamp()\n    WHERE\n        deleted_at IS NULL\n        AND id = OLD.repo_id\n        AND id NOT IN (\n            SELECT DISTINCT(repo_id) FROM external_service_repos\n        );\n\n    RETURN OLD;\nEND;\n$$;\n\nCREATE TRIGGER trig_soft_delete_orphan_repo_by_external_service_repo\n    AFTER DELETE ON external_service_repos\n    FOR EACH ROW EXECUTE PROCEDURE soft_delete_orphan_repo_by_external_service_repos();",
				"DownQuery": "DROP FUNCTION IF EXISTS soft_delete_orphan_repo_by_external_service_repos() CASCADE;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395712
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395714,
				"Name": "worker num failures",
				"UpQuery": "-- Drop dependent views\nDROP VIEW lsif_dumps_with_repository_name;\nDROP VIEW lsif_indexes_with_repository_name;\nDROP VIEW lsif_uploads_with_repository_name;\nDROP VIEW lsif_dumps;\nDROP VIEW external_service_sync_jobs_with_next_sync_at;\n\n-- Add columns\nALTER TABLE lsif_uploads ADD COLUMN num_failures INTEGER NOT NULL DEFAULT 0;\nALTER TABLE lsif_indexes ADD COLUMN num_failures INTEGER NOT NULL DEFAULT 0;\nALTER TABLE changesets ADD COLUMN num_failures INTEGER NOT NULL DEFAULT 0;\nALTER TABLE external_service_sync_jobs ADD COLUMN num_failures INTEGER NOT NULL DEFAULT 0;\n\n-- Recreate views\nCREATE VIEW lsif_dumps AS SELECT u.*, u.finished_at as processed_at FROM lsif_uploads u WHERE state = 'completed';\n\nCREATE VIEW lsif_dumps_with_repository_name AS\n    SELECT u.*, r.name as repository_name FROM lsif_dumps u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_uploads_with_repository_name AS\n    SELECT u.*, r.name as repository_name FROM lsif_uploads u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_indexes_with_repository_name AS\n    SELECT u.*, r.name as repository_name FROM lsif_indexes u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;\n\nCREATE VIEW external_service_sync_jobs_with_next_sync_at AS\n    SELECT j.id,\n            j.state,\n            j.failure_message,\n            j.started_at,\n            j.finished_at,\n            j.process_after,\n            j.num_resets,\n            j.num_failures,\n            j.external_service_id,\n            e.next_sync_at\n    FROM\n    external_services e join external_service_sync_jobs j on e.id = j.external_service_id;",
				"DownQuery": "-- Drop dependent views\nDROP VIEW lsif_dumps_with_repository_name;\nDROP VIEW lsif_indexes_with_repository_name;\nDROP VIEW lsif_uploads_with_repository_name;\nDROP VIEW lsif_dumps;\nDROP VIEW external_service_sync_jobs_with_next_sync_at;\n\n-- Drop columns\nALTER TABLE lsif_uploads DROP COLUMN num_failures;\nALTER TABLE lsif_indexes DROP COLUMN num_failures;\nALTER TABLE changesets DROP COLUMN num_failures;\nALTER TABLE external_service_sync_jobs DROP COLUMN num_failures;\n\n-- Recreate views\nCREATE VIEW lsif_dumps AS SELECT u.*, u.finished_at as processed_at FROM lsif_uploads u WHERE state = 'completed';\n\nCREATE VIEW lsif_dumps_with_repository_name AS\n    SELECT u.*, r.name as repository_name FROM lsif_dumps u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_uploads_with_repository_name AS\n    SELECT u.*, r.name as repository_name FROM lsif_uploads u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_indexes_with_repository_name AS\n    SELECT u.*, r.name as repository_name FROM lsif_indexes u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;\n\nCREATE VIEW external_service_sync_jobs_with_next_sync_at AS\n    SELECT j.id,\n            j.state,\n            j.failure_message,\n            j.started_at,\n            j.finished_at,\n            j.process_after,\n            j.num_resets,\n            j.external_service_id,\n            e.next_sync_at\n    FROM\n    external_services e join external_service_sync_jobs j on e.id = j.external_service_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395713
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395715,
				"Name": "repo name index take 2",
				"UpQuery": "CREATE INDEX IF NOT EXISTS repo_name_idx ON public.repo USING btree (lower(name::text) COLLATE pg_catalog.\"C\");",
				"DownQuery": "DROP INDEX IF EXISTS repo_name_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395714
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395716,
				"Name": "add git commit author",
				"UpQuery": "-- Add default values for git commit author (name and email)\nUPDATE changeset_specs\nSET spec = spec || json_build_object(\n        'commits',\n        json_build_array(\n            spec-\u003e'commits'-\u003e0 || '{\"authorName\": \"Sourcegraph\", \"authorEmail\": \"campaigns@sourcegraph.com\"}'\n        )\n    )::jsonb\nWHERE jsonb_array_length(spec-\u003e'commits') \u003e 0;",
				"DownQuery": "-- Nothing needed, non-destructive operation",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395715
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395717,
				"Name": "replicate permissions object ids to intarray",
				"UpQuery": "CREATE EXTENSION IF NOT EXISTS intarray;\n\nALTER TABLE repo_permissions ADD COLUMN user_ids_ints INT[] NOT NULL DEFAULT '{}';\nALTER TABLE user_permissions ADD COLUMN object_ids_ints INT[] NOT NULL DEFAULT '{}';\nALTER TABLE repo_pending_permissions ADD COLUMN user_ids_ints INT[] NOT NULL DEFAULT '{}';\nALTER TABLE user_pending_permissions ADD COLUMN object_ids_ints INT[] NOT NULL DEFAULT '{}';",
				"DownQuery": "ALTER TABLE repo_permissions DROP COLUMN IF EXISTS user_ids_ints;\nALTER TABLE user_permissions DROP COLUMN IF EXISTS object_ids_ints;\nALTER TABLE repo_pending_permissions DROP COLUMN IF EXISTS user_ids_ints;\nALTER TABLE user_pending_permissions DROP COLUMN IF EXISTS object_ids_ints;\n\nDROP EXTENSION IF EXISTS intarray;",
				"Privileged": true,
				"NonIdempotent": false,
				"Parents": [
					1528395716
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395718,
				"Name": "user invalidate session",
				"UpQuery": "-- Default to now, since we can't have null times\nALTER TABLE IF EXISTS users ADD COLUMN IF NOT EXISTS invalidated_sessions_at timestamp with time zone DEFAULT now() NOT NULL;\n-- Update the invalidated sessions at to be when the user was created\nUPDATE users SET invalidated_sessions_at = created_at;\n\n-- Create a procedure that invalidates sessions for the user that can be used for our trigger\n-- Invalidates if the password is updated\n-- For the reasoning behind adding one second, see security issue #93\nCREATE OR REPLACE FUNCTION invalidate_session_for_userid_on_password_change() RETURNS trigger\nLANGUAGE plpgsql\n    AS $$\n    BEGIN\n        IF OLD.passwd != NEW.passwd THEN\n            NEW.invalidated_sessions_at = now() + (1 * interval '1 second');\n            RETURN NEW;\n        END IF;\n    RETURN NEW;\n    END;\n$$;\n\n-- Need to drop and create, since we can't create if not exstis\nDROP TRIGGER IF EXISTS trig_invalidate_session_on_password_change ON users;\n-- Create a trigger to to invalidate sessions if the user's password is ever changed\nCREATE TRIGGER trig_invalidate_session_on_password_change\n    BEFORE UPDATE OF passwd ON users \n    FOR EACH ROW EXECUTE PROCEDURE invalidate_session_for_userid_on_password_change();",
				"DownQuery": "DROP FUNCTION IF EXISTS invalidate_session_for_userid_on_password_change() CASCADE;\nALTER TABLE IF EXISTS users DROP COLUMN IF EXISTS invalidated_sessions_at;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395717
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395719,
				"Name": "migration sql",
				"UpQuery": "DROP TABLE IF EXISTS saved_queries;",
				"DownQuery": "CREATE TABLE IF NOT EXISTS saved_queries\n(\n    query TEXT NOT NULL,\n    last_executed TIMESTAMP WITH TIME ZONE NOT NULL,\n    latest_result TIMESTAMP WITH TIME ZONE NOT NULL,\n    exec_duration_ns BIGINT NOT NULL\n);\n\nCREATE UNIQUE INDEX saved_queries_query_unique\n    ON saved_queries (query);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395718
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395720,
				"Name": "drop repo sources column",
				"UpQuery": "DROP TRIGGER IF EXISTS trig_read_only_repo_sources_column ON repo;\n\nDROP FUNCTION IF EXISTS make_repo_sources_column_read_only();\n\nALTER TABLE repo DROP COLUMN IF EXISTS sources;",
				"DownQuery": "ALTER TABLE repo\n  ADD COLUMN IF NOT EXISTS sources jsonb DEFAULT '{}'::jsonb NOT NULL;\n\n-- Mark the sources columns as read-only using a trigger.\nCREATE FUNCTION make_repo_sources_column_read_only() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$\n    BEGIN\n        IF (OLD.sources != NEW.sources) THEN\n            RAISE EXCEPTION 'sources is read-only';\n        END IF;\n\n        RETURN OLD;\n    END;\n$$;\n\nCREATE TRIGGER trig_read_only_repo_sources_column BEFORE UPDATE OF sources ON repo FOR EACH ROW EXECUTE PROCEDURE make_repo_sources_column_read_only();",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395719
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395721,
				"Name": "lsif deleted",
				"UpQuery": "-- Unfortunatley we can't add a value to a enum within a transaction, so we have to make\n-- an entirely new enum and transfer all refrences to the old enum to the new one. Hence\n-- the verbosity here.\n\n-- Drop objects that depends on this type\nDROP VIEW lsif_dumps_with_repository_name;\nDROP VIEW lsif_uploads_with_repository_name;\nDROP VIEW lsif_dumps;\nDROP INDEX lsif_uploads_repository_id_commit_root_indexer;\n\n-- Create new enum\nCREATE TYPE lsif_upload_state_temp AS ENUM(\n    'uploading',\n    'queued',\n    'processing',\n    'completed',\n    'errored',\n    'deleted'\n);\n\n-- Update type of state column\nALTER TABLE lsif_uploads\n    ALTER COLUMN state DROP DEFAULT,\n    ALTER COLUMN state TYPE lsif_upload_state_temp USING state::text::lsif_upload_state_temp,\n    ALTER COLUMN state SET DEFAULT 'queued';\n\n-- Switch enum names\nDROP TYPE lsif_upload_state;\nALTER TYPE lsif_upload_state_temp RENAME TO lsif_upload_state;\n\n-- Restore index and views\nCREATE UNIQUE INDEX lsif_uploads_repository_id_commit_root_indexer ON lsif_uploads(repository_id, \"commit\", root, indexer) WHERE state = 'completed'::lsif_upload_state;\nCREATE VIEW lsif_dumps AS SELECT u.*, u.finished_at as processed_at FROM lsif_uploads u WHERE state = 'completed';\n\nCREATE VIEW lsif_dumps_with_repository_name AS\n    SELECT u.*, r.name as repository_name FROM lsif_dumps u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_uploads_with_repository_name AS\n    SELECT u.*, r.name as repository_name FROM lsif_uploads u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;",
				"DownQuery": "-- Drop objects that depends on this type\nDROP VIEW lsif_dumps_with_repository_name;\nDROP VIEW lsif_uploads_with_repository_name;\nDROP VIEW lsif_dumps;\nDROP INDEX lsif_uploads_repository_id_commit_root_indexer;\n\n-- Create old enum\nCREATE TYPE lsif_upload_state_temp AS ENUM(\n    'uploading',\n    'queued',\n    'processing',\n    'completed',\n    'errored'\n);\n\n-- Update type of state column\nALTER TABLE lsif_uploads\n    ALTER COLUMN state DROP DEFAULT,\n    ALTER COLUMN state TYPE lsif_upload_state_temp USING (CASE state WHEN 'deleted' THEN 'errored' ELSE state::text END)::lsif_upload_state_temp,\n    ALTER COLUMN state SET DEFAULT 'queued';\n\n-- Switch enum names\nDROP TYPE lsif_upload_state;\nALTER TYPE lsif_upload_state_temp RENAME TO lsif_upload_state;\n\n-- Restore index and views\nCREATE UNIQUE INDEX lsif_uploads_repository_id_commit_root_indexer ON lsif_uploads(repository_id, \"commit\", root, indexer) WHERE state = 'completed'::lsif_upload_state;\nCREATE VIEW lsif_dumps AS SELECT u.*, u.finished_at as processed_at FROM lsif_uploads u WHERE state = 'completed';\n\nCREATE VIEW lsif_dumps_with_repository_name AS\n    SELECT u.*, r.name as repository_name FROM lsif_dumps u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_uploads_with_repository_name AS\n    SELECT u.*, r.name as repository_name FROM lsif_uploads u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395720
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395722,
				"Name": "drop created by campaign",
				"UpQuery": "ALTER TABLE changesets DROP COLUMN IF EXISTS created_by_campaign;",
				"DownQuery": "ALTER TABLE changesets ADD COLUMN IF NOT EXISTS created_by_campaign boolean DEFAULT false NOT NULL;\n\nUPDATE changesets SET created_by_campaign = true WHERE owned_by_campaign_id IS NOT NULL AND publication_state = 'PUBLISHED';",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395721
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395723,
				"Name": "convert secret jsonb to text",
				"UpQuery": "ALTER TABLE IF EXISTS user_external_accounts ALTER COLUMN auth_data TYPE TEXT;\nALTER TABLE IF EXISTS user_external_accounts ALTER COLUMN account_data TYPE TEXT;",
				"DownQuery": "--- Note: This rollback will fail if encryption has been enabled since the base64 value will not be valid jsonb\nALTER TABLE user_external_accounts ALTER COLUMN auth_data TYPE JSONB USING auth_data::JSON;\nALTER TABLE user_external_accounts ALTER COLUMN account_data TYPE JSONB USING account_data::JSON;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395722
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395724,
				"Name": "settings org id idx",
				"UpQuery": "CREATE INDEX IF NOT EXISTS settings_org_id_idx ON settings(org_id);",
				"DownQuery": "DROP INDEX IF EXISTS settings_org_id_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395723
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395725,
				"Name": "indexer configuration fields",
				"UpQuery": "DROP VIEW lsif_indexes_with_repository_name;\n\nALTER TABLE lsif_indexes\n    ADD COLUMN docker_steps jsonb[],  -- root, image, commands\n    ADD COLUMN root text,\n    ADD COLUMN indexer text,\n    ADD COLUMN indexer_args text[],\n    ADD COLUMN outfile text;\n\nUPDATE lsif_indexes SET\n    docker_steps = '{}',\n    root = '',\n    indexer = 'sourcegraph/lsif-go:latest',\n    indexer_args = '{}'::text[],\n    outfile = '';\n\nALTER TABLE lsif_indexes\n    ALTER COLUMN root SET NOT NULL,\n    ALTER COLUMN indexer SET NOT NULL,\n    ALTER COLUMN indexer_args SET NOT NULL,\n    ALTER COLUMN outfile SET NOT NULL,\n    ALTER COLUMN docker_steps SET NOT NULL;\n\nCREATE VIEW lsif_indexes_with_repository_name AS\n    SELECT u.*, r.name as repository_name FROM lsif_indexes u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;",
				"DownQuery": "DROP VIEW lsif_indexes_with_repository_name;\n\nALTER TABLE lsif_indexes\n    DROP COLUMN docker_steps,\n    DROP COLUMN root,\n    DROP COLUMN indexer,\n    DROP COLUMN indexer_args,\n    DROP COLUMN outfile;\n\nCREATE VIEW lsif_indexes_with_repository_name AS\n    SELECT u.*, r.name as repository_name FROM lsif_indexes u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395724
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395726,
				"Name": "lsif index defaults",
				"UpQuery": "UPDATE lsif_indexes\nSET\n    indexer_args = '{lsif-go,--no-progress}'\nWHERE\n    indexer = 'sourcegraph/lsif-go:latest' AND\n    indexer_args = '{}';",
				"DownQuery": "UPDATE lsif_indexes\nSET\n    indexer_args = '{}'\nWHERE\n    indexer = 'sourcegraph/lsif-go:latest' AND\n    indexer_args = '{lsif-go,--no-progress}';",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395725
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395727,
				"Name": "frontend",
				"UpQuery": "UPDATE lsif_indexes\nSET\n    indexer_args = '{lsif-go,--no-animation}'\nWHERE\n    indexer_args = '{lsif-go,--no-progress}';",
				"DownQuery": "UPDATE lsif_indexes\nSET\n    indexer_args = '{lsif-go,--no-progress}'\nWHERE\n    indexer_args = '{lsif-go,--no-animation}';",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395726
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395728,
				"Name": "lsif index configuration",
				"UpQuery": "CREATE TABLE lsif_index_configuration (\n    id bigserial NOT NULL PRIMARY KEY,\n    repository_id integer UNIQUE NOT NULL REFERENCES repo(id) ON DELETE CASCADE,\n    data bytea NOT NULL\n);",
				"DownQuery": "DROP TABLE lsif_index_configuration;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395727
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395729,
				"Name": "add external services namespace user id index",
				"UpQuery": "CREATE INDEX external_services_namespace_user_id_idx ON external_services (namespace_user_id);",
				"DownQuery": "DROP INDEX external_services_namespace_user_id_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395728
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395730,
				"Name": "lsif index log contents",
				"UpQuery": "DROP VIEW lsif_indexes_with_repository_name;\n\nALTER TABLE lsif_indexes ADD COLUMN log_contents TEXT;\n\nCREATE VIEW lsif_indexes_with_repository_name AS\n    SELECT u.*, r.name as repository_name FROM lsif_indexes u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;",
				"DownQuery": "DROP VIEW lsif_indexes_with_repository_name;\n\nALTER TABLE lsif_indexes DROP COLUMN log_contents;\n\nCREATE VIEW lsif_indexes_with_repository_name AS\n    SELECT u.*, r.name as repository_name FROM lsif_indexes u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395729
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395731,
				"Name": "add nearest upload direction",
				"UpQuery": "ALTER TABLE lsif_nearest_uploads ADD COLUMN ancestor_visible boolean;\nALTER TABLE lsif_nearest_uploads ADD COLUMN overwritten boolean;\nUPDATE lsif_nearest_uploads SET ancestor_visible = false, overwritten = false;\nALTER TABLE lsif_nearest_uploads ALTER COLUMN ancestor_visible SET NOT NULL;\nALTER TABLE lsif_nearest_uploads ALTER COLUMN overwritten SET NOT NULL;\n\n-- Mark all repositories as dirty so that we will refresh them\nUPDATE lsif_dirty_repositories SET dirty_token = dirty_token + 1;",
				"DownQuery": "ALTER TABLE lsif_nearest_uploads DROP COLUMN ancestor_visible;\nALTER TABLE lsif_nearest_uploads DROP COLUMN overwritten;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395730
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395732,
				"Name": "add external services sync jobs state index",
				"UpQuery": "CREATE INDEX IF NOT EXISTS external_service_sync_jobs_state_idx ON external_service_sync_jobs (state);",
				"DownQuery": "DROP INDEX IF EXISTS external_service_sync_jobs_state_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395731
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395733,
				"Name": "add permissions object ids default",
				"UpQuery": "ALTER TABLE repo_permissions ALTER COLUMN user_ids SET DEFAULT '\\x';\nALTER TABLE user_permissions ALTER COLUMN object_ids SET DEFAULT '\\x';\nALTER TABLE repo_pending_permissions ALTER COLUMN user_ids SET DEFAULT '\\x';\nALTER TABLE user_pending_permissions ALTER COLUMN object_ids SET DEFAULT '\\x';",
				"DownQuery": "ALTER TABLE repo_permissions ALTER COLUMN user_ids DROP DEFAULT;\nALTER TABLE user_permissions ALTER COLUMN object_ids DROP DEFAULT;\nALTER TABLE repo_pending_permissions ALTER COLUMN user_ids DROP DEFAULT;\nALTER TABLE user_pending_permissions ALTER COLUMN object_ids DROP DEFAULT;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395732
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395734,
				"Name": "repo updater log contents",
				"UpQuery": "DROP VIEW external_service_sync_jobs_with_next_sync_at;\n\nALTER TABLE external_service_sync_jobs ADD COLUMN log_contents text;\n\nCREATE VIEW external_service_sync_jobs_with_next_sync_at AS SELECT\n    j.id,\n    j.state,\n    j.failure_message,\n    j.started_at,\n    j.finished_at,\n    j.process_after,\n    j.num_resets,\n    j.num_failures,\n    j.log_contents,\n    j.external_service_id,\n    e.next_sync_at\nFROM external_services e JOIN external_service_sync_jobs j ON e.id = j.external_service_id;\n\nALTER TABLE changesets ADD COLUMN log_contents text;",
				"DownQuery": "DROP VIEW external_service_sync_jobs_with_next_sync_at;\n\nALTER TABLE external_service_sync_jobs DROP COLUMN log_contents;\n\nCREATE OR REPLACE VIEW external_service_sync_jobs_with_next_sync_at AS SELECT j.id,\n    j.state,\n    j.failure_message,\n    j.started_at,\n    j.finished_at,\n    j.process_after,\n    j.num_resets,\n    j.num_failures,\n    j.external_service_id,\n    e.next_sync_at\nFROM external_services e JOIN external_service_sync_jobs j ON e.id = j.external_service_id;\n\nALTER TABLE changesets DROP COLUMN log_contents;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395733
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395735,
				"Name": "drop language from repo",
				"UpQuery": "ALTER TABLE repo DROP COLUMN IF EXISTS language;",
				"DownQuery": "ALTER TABLE repo ADD COLUMN IF NOT EXISTS language TEXT;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395734
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395736,
				"Name": "add index to repo created at",
				"UpQuery": "-- Note: CREATE INDEX CONCURRENTLY cannot run inside a transaction block\n\nCREATE INDEX CONCURRENTLY IF NOT EXISTS repo_created_at ON repo(created_at);",
				"DownQuery": "-- Note: DROP INDEX CONCURRENTLY cannot run inside a transaction block\n\nDROP INDEX CONCURRENTLY IF EXISTS repo_created_at;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395735
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "repo",
					"IndexName": "repo_created_at"
				}
			},
			{
				"ID": 1528395737,
				"Name": "compressed commits",
				"UpQuery": "ALTER TABLE lsif_nearest_uploads ADD COLUMN commit_bytea bytea;\nCREATE INDEX lsif_nearest_uploads_repository_id_commit_bytea ON lsif_nearest_uploads USING btree (repository_id, commit_bytea);\n\n-- Mark all repositories as dirty so that we will refresh them\nUPDATE lsif_dirty_repositories SET dirty_token = dirty_token + 1;",
				"DownQuery": "ALTER TABLE lsif_nearest_uploads DROP COLUMN commit_bytea;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395736
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395738,
				"Name": "nullable commit",
				"UpQuery": "UPDATE lsif_nearest_uploads SET commit_bytea = decode(\"commit\", 'hex') WHERE commit_bytea IS NULL;\nALTER TABLE lsif_nearest_uploads ALTER COLUMN \"commit\" DROP NOT NULL;\nALTER TABLE lsif_nearest_uploads ALTER COLUMN commit_bytea SET NOT NULL;",
				"DownQuery": "UPDATE lsif_nearest_uploads SET \"commit\" = encode(commit_bytea, 'hex') WHERE \"commit\" IS NULL;\nALTER TABLE lsif_nearest_uploads ALTER COLUMN \"commit\" SET NOT NULL;\nALTER TABLE lsif_nearest_uploads ALTER COLUMN commit_bytea DROP NOT NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395737
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395739,
				"Name": "user credentials",
				"UpQuery": "CREATE TABLE IF NOT EXISTS user_credentials (\n    id BIGSERIAL PRIMARY KEY,\n    domain TEXT NOT NULL,\n    user_id INTEGER NOT NULL,\n    external_service_type TEXT NOT NULL,\n    external_service_id TEXT NOT NULL,\n    credential TEXT NOT NULL,\n    created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n    updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n\n    -- deleted_at is intentionally left out: given the secret nature of tokens,\n    -- users will likely want to be certain that tokens are deleted when\n    -- removed, even with encryption in place.\n\n    -- Set up the foreign key.\n    FOREIGN KEY (user_id) REFERENCES users (id) ON DELETE CASCADE DEFERRABLE,\n\n    -- Set up a unique constraint across the fields that are, in fact, unique.\n    UNIQUE (domain, user_id, external_service_type, external_service_id)\n);",
				"DownQuery": "DROP TABLE IF EXISTS user_credentials;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395738
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395740,
				"Name": "add table cm monitors",
				"UpQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nCREATE TABLE IF NOT EXISTS cm_monitors\n(\n    id                BIGSERIAL PRIMARY KEY,\n    created_by        int4        NOT NULL,\n    created_at        timestamptz NOT NULL DEFAULT now(),\n    description       text        NOT NULL,\n    changed_at        timestamptz NOT NULL DEFAULT now(),\n    changed_by        int4        NOT NULL,\n    enabled           boolean     NOT NULL DEFAULT TRUE,\n    namespace_user_id int4,\n    namespace_org_id  int4,\n    constraint cm_monitors_user_id_fk\n        foreign key (namespace_user_id)\n            REFERENCES users (id)\n            ON DELETE CASCADE,\n    constraint cm_monitors_org_id_fk\n        foreign key (namespace_org_id)\n            REFERENCES orgs (id)\n            ON DELETE CASCADE,\n    constraint cm_monitors_created_by_fk\n        foreign key (created_by)\n            REFERENCES users (id)\n            ON DELETE CASCADE,\n    constraint cm_monitors_changed_by_fk\n        foreign key (changed_by)\n            REFERENCES users (id)\n            ON DELETE cascade\n);",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nDROP TABLE IF EXISTS cm_monitors;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395739
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395741,
				"Name": "create external service unrestricted column",
				"UpQuery": "ALTER TABLE external_services ADD COLUMN IF NOT EXISTS unrestricted BOOLEAN NOT NULL DEFAULT FALSE;",
				"DownQuery": "ALTER TABLE external_services DROP COLUMN IF EXISTS unrestricted;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395740
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395742,
				"Name": "add table cm queries",
				"UpQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nCREATE TABLE IF NOT EXISTS cm_queries\n(\n    id         BIGSERIAL PRIMARY KEY,\n    monitor    int8        NOT NULL,\n    query      text        NOT NULL,\n    created_by int4        NOT NULL,\n    created_at timestamptz NOT NULL DEFAULT now(),\n    changed_by int4        NOT NULL,\n    changed_at timestamptz NOT NULL DEFAULT now(),\n    constraint cm_triggers_monitor\n        foreign key (monitor)\n            REFERENCES cm_monitors (id)\n            ON DELETE CASCADE,\n    constraint cm_triggers_created_by_fk\n        foreign key (created_by)\n            REFERENCES users (id)\n            ON DELETE CASCADE,\n    constraint cm_triggers_changed_by_fk\n        foreign key (changed_by)\n            REFERENCES users (id)\n            ON DELETE cascade\n);",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nDROP TABLE IF EXISTS cm_queries;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395741
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395743,
				"Name": "add table cm emails",
				"UpQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nCREATE TYPE cm_email_priority AS ENUM ('NORMAL', 'CRITICAL');\n\nCREATE TABLE IF NOT EXISTS cm_emails\n(\n    id                BIGSERIAL PRIMARY KEY,\n    monitor           int8              NOT NULL,\n    enabled           boolean           NOT NULL,\n    priority          cm_email_priority NOT NULL,\n    header            text              NOT NULL,\n    created_by        int4              NOT NULL,\n    created_at        timestamptz       NOT NULL DEFAULT now(),\n    changed_by        int4              NOT NULL,\n    changed_at        timestamptz       NOT NULL DEFAULT now(),\n    constraint cm_emails_monitor\n        foreign key (monitor)\n            REFERENCES cm_monitors (id)\n            ON DELETE CASCADE,\n    constraint cm_emails_created_by_fk\n        foreign key (created_by)\n            REFERENCES users (id)\n            ON DELETE CASCADE,\n    constraint cm_emails_changed_by_fk\n        foreign key (changed_by)\n            REFERENCES users (id)\n            ON DELETE cascade\n);",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nDROP TABLE IF EXISTS cm_emails;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395742
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395744,
				"Name": "add table cm recipients",
				"UpQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nCREATE TABLE IF NOT EXISTS cm_recipients\n(\n    id                BIGSERIAL PRIMARY KEY,\n    email             int8 NOT NULL,\n    namespace_user_id int4,\n    namespace_org_id  int4,\n    constraint cm_recipients_emails\n        foreign key (email)\n            REFERENCES cm_emails (id)\n            ON DELETE CASCADE,\n    constraint cm_recipients_user_id_fk\n        foreign key (namespace_user_id)\n            REFERENCES users (id)\n            ON DELETE CASCADE,\n    constraint cm_recipients_org_id_fk\n        foreign key (namespace_org_id)\n            REFERENCES orgs (id)\n            ON DELETE CASCADE\n);",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nDROP TABLE IF EXISTS cm_recipients;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395743
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395745,
				"Name": "ref prefix external branch",
				"UpQuery": "UPDATE changesets SET external_branch = CONCAT('refs/heads/', external_branch) WHERE external_branch IS NOT NULL AND external_branch NOT LIKE 'refs/heads/%';\n\nUPDATE changeset_specs SET spec = jsonb_set(spec, '{headRef}', to_jsonb(CONCAT('refs/heads/', spec-\u003e\u003e'headRef'))) WHERE spec-\u003e\u003e'headRef' IS NOT NULL AND spec-\u003e\u003e'headRef' != '' AND spec-\u003e\u003e'headRef' NOT LIKE 'refs/heads/%';\nUPDATE changeset_specs SET spec = jsonb_set(spec, '{baseRef}', to_jsonb(CONCAT('refs/heads/', spec-\u003e\u003e'baseRef'))) WHERE spec-\u003e\u003e'baseRef' IS NOT NULL AND spec-\u003e\u003e'baseRef' != '' AND spec-\u003e\u003e'baseRef' NOT LIKE 'refs/heads/%';\n\nALTER TABLE changesets ADD CONSTRAINT external_branch_ref_prefix CHECK (external_branch LIKE 'refs/heads/%');",
				"DownQuery": "ALTER TABLE changesets DROP CONSTRAINT IF EXISTS external_branch_ref_prefix;\n\nUPDATE changesets SET external_branch = LTRIM(external_branch, 'refs/heads/') WHERE external_branch IS NOT NULL;\n\nUPDATE changeset_specs SET spec = jsonb_set(spec, '{headRef}', to_jsonb(LTRIM(spec-\u003e\u003e'headRef', 'refs/heads/'))) WHERE spec-\u003e\u003e'headRef' IS NOT NULL AND spec-\u003e\u003e'headRef' != '' AND spec-\u003e\u003e'headRef' LIKE 'refs/heads/%';\nUPDATE changeset_specs SET spec = jsonb_set(spec, '{baseRef}', to_jsonb(LTRIM(spec-\u003e\u003e'baseRef', 'refs/heads/'))) WHERE spec-\u003e\u003e'baseRef' IS NOT NULL AND spec-\u003e\u003e'baseRef' != '' AND spec-\u003e\u003e'baseRef' LIKE 'refs/heads/%';",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395744
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395746,
				"Name": "add is primary to user emails",
				"UpQuery": "ALTER TABLE user_emails ADD COLUMN is_primary bool DEFAULT false NOT NULL;\n\n-- Use our old logic to set the initial primary address.\n-- From this point we expect it to be set from the UI.\nUPDATE user_emails ue SET is_primary = true\nFROM (\n         SELECT DISTINCT ON (user_id) user_id, email\n         FROM user_emails\n         ORDER BY user_id ASC, (verified_at IS NOT NULL), created_at ASC, email ASC\n     ) s\nWHERE ue.user_id = s.user_id AND ue.email = s.email;\n\n-- A user can only have one primary address\nCREATE UNIQUE INDEX user_emails_user_id_is_primary_idx ON user_emails (user_id, is_primary)\nWHERE is_primary = true;",
				"DownQuery": "DROP INDEX IF EXISTS user_emails_user_id_is_primary_idx;\nALTER TABLE user_emails DROP COLUMN IF EXISTS is_primary;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395745
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395747,
				"Name": "add users created at index",
				"UpQuery": "CREATE INDEX IF NOT EXISTS users_created_at_idx ON users(created_at);",
				"DownQuery": "DROP INDEX IF EXISTS users_created_at_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395746
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395748,
				"Name": "drop commit",
				"UpQuery": "ALTER TABLE lsif_nearest_uploads DROP COLUMN \"commit\";",
				"DownQuery": "ALTER TABLE lsif_nearest_uploads ADD COLUMN \"commit\" TEXT;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395747
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395749,
				"Name": "add expired at and last valid at columns to user external accounts",
				"UpQuery": "ALTER TABLE user_external_accounts ADD COLUMN IF NOT EXISTS expired_at TIMESTAMPTZ;\nALTER TABLE user_external_accounts ADD COLUMN IF NOT EXISTS last_valid_at TIMESTAMPTZ;",
				"DownQuery": "ALTER TABLE user_external_accounts DROP COLUMN IF EXISTS expired_at;\nALTER TABLE user_external_accounts DROP COLUMN IF EXISTS last_valid_at;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395748
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395750,
				"Name": "repair view",
				"UpQuery": "-- Recreate lsif_indexes view with columns introduced in 1528395730_lsif_index_log_contents.up.sql.\nDROP VIEW lsif_indexes_with_repository_name;\n\nCREATE VIEW lsif_indexes_with_repository_name AS\n    SELECT u.*, r.name as repository_name FROM lsif_indexes u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;",
				"DownQuery": "DROP VIEW lsif_indexes_with_repository_name;\n\n-- Put it back how it was :(\nCREATE VIEW lsif_indexes_with_repository_name AS SELECT u.id,\n    u.commit,\n    u.queued_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.process_after,\n    u.num_resets,\n    u.num_failures,\n    u.docker_steps,\n    u.root,\n    u.indexer,\n    u.indexer_args,\n    u.outfile,\n    r.name AS repository_name\nFROM lsif_indexes u\nJOIN repo r ON r.id = u.repository_id\nWHERE r.deleted_at IS NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395749
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395751,
				"Name": "add unique constraint to external service repos",
				"UpQuery": "LOCK TABLE external_service_repos;\n\n-- Drop trigger as we don't want it to fire\nDROP TRIGGER IF EXISTS trig_soft_delete_orphan_repo_by_external_service_repo\nON external_service_repos;\n\nWITH dups AS (SELECT external_service_id, repo_id, min(ctid)\n              FROM external_service_repos\n              GROUP BY external_service_id, repo_id\n              HAVING count(*) \u003e 1\n)\nDELETE FROM external_service_repos\nUSING dups\nWHERE (external_service_repos.external_service_id, external_service_repos.repo_id) = (dups.external_service_id, dups.repo_id)\nAND external_service_repos.ctid \u003c\u003e dups.min;\n\n-- Add unique constraint\nALTER TABLE external_service_repos\nADD CONSTRAINT external_service_repos_repo_id_external_service_id_unique\nUNIQUE (repo_id, external_service_id);\n\n-- Recreate trigger\nCREATE TRIGGER trig_soft_delete_orphan_repo_by_external_service_repo\nAFTER DELETE ON external_service_repos\nFOR EACH ROW EXECUTE PROCEDURE soft_delete_orphan_repo_by_external_service_repos();",
				"DownQuery": "ALTER TABLE external_service_repos\nDROP CONSTRAINT IF EXISTS external_service_repos_repo_id_external_service_id_unique;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395750
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395752,
				"Name": "extend worker state enums with failed",
				"UpQuery": "-- This migration is an extension of the combination of\n-- migrations/frontend/1528395714_worker_num_failures.up.sql\n-- and\n-- migrations/frontend/1528395721_lsif_deleted.up.sql\n\n-- We're introducing a new \"state\" to the workers, so we need to extend the two database enums that include the states:\n\n--   lsif_index_state\n--   lsif_upload_state\n\n-- Unfortunately we can't add a value to a enum within a transaction, so we\n-- have to make an entirely new enum and transfer all refrences to the old enum\n-- to the new one. Hence the verbosity here.\n\n-- Drop dependent views/indexes\nDROP VIEW lsif_dumps_with_repository_name;\nDROP VIEW lsif_indexes_with_repository_name;\nDROP VIEW lsif_uploads_with_repository_name;\nDROP VIEW lsif_dumps;\nDROP INDEX lsif_uploads_repository_id_commit_root_indexer;\n\n-- Create new temp enums\n\nCREATE TYPE lsif_upload_state_temp AS ENUM(\n    'uploading',\n    'queued',\n    'processing',\n    'completed',\n    'errored',\n    'deleted',\n    'failed' -- This is the new field\n);\n\nCREATE TYPE lsif_index_state_temp AS ENUM(\n    'queued',\n    'processing',\n    'completed',\n    'errored',\n    'failed' -- This is the new field\n);\n--\n-- Update type of state column that use the enums\nALTER TABLE lsif_uploads\n    ALTER COLUMN state DROP DEFAULT,\n    ALTER COLUMN state TYPE lsif_upload_state_temp USING state::text::lsif_upload_state_temp,\n    ALTER COLUMN state SET DEFAULT 'queued';\n\nALTER TABLE lsif_indexes\n    ALTER COLUMN state DROP DEFAULT,\n    ALTER COLUMN state TYPE lsif_index_state_temp USING state::text::lsif_index_state_temp,\n    ALTER COLUMN state SET DEFAULT 'queued';\n\n-- Switch enum names\nDROP TYPE lsif_upload_state;\nALTER TYPE lsif_upload_state_temp RENAME TO lsif_upload_state;\n\nDROP TYPE lsif_index_state;\nALTER TYPE lsif_index_state_temp RENAME TO lsif_index_state;\n\n-- Recreate views/indexes\nCREATE UNIQUE INDEX lsif_uploads_repository_id_commit_root_indexer ON lsif_uploads(repository_id, \"commit\", root, indexer) WHERE state = 'completed'::lsif_upload_state;\nCREATE VIEW lsif_dumps AS SELECT u.*, u.finished_at as processed_at FROM lsif_uploads u WHERE state = 'completed';\n\nCREATE VIEW lsif_dumps_with_repository_name AS\n    SELECT u.*, r.name as repository_name FROM lsif_dumps u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_uploads_with_repository_name AS\n    SELECT u.*, r.name as repository_name FROM lsif_uploads u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_indexes_with_repository_name AS\n    SELECT u.*, r.name as repository_name FROM lsif_indexes u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;",
				"DownQuery": "-- Drop dependent views\nDROP VIEW lsif_dumps_with_repository_name;\nDROP VIEW lsif_indexes_with_repository_name;\nDROP VIEW lsif_uploads_with_repository_name;\nDROP VIEW lsif_dumps;\nDROP INDEX lsif_uploads_repository_id_commit_root_indexer;\n\n-- Create new temp enums\nCREATE TYPE lsif_upload_state_temp AS ENUM(\n    'uploading',\n    'queued',\n    'processing',\n    'completed',\n    'errored',\n    'deleted'\n    -- no 'failed' in down-migration\n);\n\nCREATE TYPE lsif_index_state_temp AS ENUM(\n    'queued',\n    'processing',\n    'completed',\n    'errored'\n    -- no 'failed' in down-migration\n);\n\n-- Update type of state column that use the enums\nALTER TABLE lsif_uploads\n    ALTER COLUMN state DROP DEFAULT,\n    ALTER COLUMN state TYPE lsif_upload_state_temp USING state::text::lsif_upload_state_temp,\n    ALTER COLUMN state SET DEFAULT 'queued';\n\nALTER TABLE lsif_indexes\n    ALTER COLUMN state DROP DEFAULT,\n    ALTER COLUMN state TYPE lsif_index_state_temp USING state::text::lsif_index_state_temp,\n    ALTER COLUMN state SET DEFAULT 'queued';\n\n-- Switch enum names\nDROP TYPE lsif_upload_state;\nALTER TYPE lsif_upload_state_temp RENAME TO lsif_upload_state;\n\nDROP TYPE lsif_index_state;\nALTER TYPE lsif_index_state_temp RENAME TO lsif_index_state;\n\n-- Recreate views/indexes\nCREATE UNIQUE INDEX lsif_uploads_repository_id_commit_root_indexer ON lsif_uploads(repository_id, \"commit\", root, indexer) WHERE state = 'completed'::lsif_upload_state;\nCREATE VIEW lsif_dumps AS SELECT u.*, u.finished_at as processed_at FROM lsif_uploads u WHERE state = 'completed';\n\nCREATE VIEW lsif_dumps_with_repository_name AS\n    SELECT u.*, r.name as repository_name FROM lsif_dumps u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_uploads_with_repository_name AS\n    SELECT u.*, r.name as repository_name FROM lsif_uploads u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_indexes_with_repository_name AS\n    SELECT u.*, r.name as repository_name FROM lsif_indexes u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395751
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395753,
				"Name": "add enqueue table for trigger queries",
				"UpQuery": "CREATE TABLE IF NOT EXISTS cm_trigger_jobs\n(\n    id              SERIAL PRIMARY KEY,\n    query           int8 NOT NULL,\n    state           text default 'queued',\n    failure_message text,\n    started_at      timestamptz,\n    finished_at     timestamptz,\n    process_after   timestamptz,\n    num_resets      int4 NOT NULL default 0,\n    num_failures    int4 NOT NULL default 0,\n    log_contents    text,\n    CONSTRAINT cm_trigger_jobs_query_fk\n        FOREIGN KEY (query)\n            REFERENCES cm_queries (id)\n            ON DELETE CASCADE\n);",
				"DownQuery": "DROP TABLE IF EXISTS cm_trigger_jobs;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395752
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395754,
				"Name": "add cols next run latest result to cm queries",
				"UpQuery": "ALTER TABLE cm_queries\n    ADD COLUMN IF NOT EXISTS next_run timestamptz default now(),\n    ADD COLUMN IF NOT EXISTS latest_result timestamptz;",
				"DownQuery": "ALTER TABLE cm_queries\n    DROP COLUMN IF EXISTS next_run,\n    DROP COLUMN IF EXISTS latest_result;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395753
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395755,
				"Name": "cm trigger jobs add colums",
				"UpQuery": "ALTER TABLE cm_trigger_jobs\n    ADD COLUMN IF NOT EXISTS query_string text,\n    ADD COLUMN IF NOT EXISTS results boolean;",
				"DownQuery": "ALTER TABLE cm_trigger_jobs\n    DROP COLUMN IF EXISTS query_string,\n    DROP COLUMN IF EXISTS results;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395754
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395756,
				"Name": "alter orphaned repo trigger",
				"UpQuery": "DROP FUNCTION IF EXISTS soft_delete_orphan_repo_by_external_service_repos() CASCADE;\nDROP TRIGGER IF EXISTS trig_soft_delete_orphan_repo_by_external_service_repo ON external_service_repos;\n\nCREATE FUNCTION soft_delete_orphan_repo_by_external_service_repos() RETURNS trigger\n    LANGUAGE plpgsql\nAS $$\nBEGIN\n    -- When an external service is soft or hard-deleted,\n    -- performs a clean up to soft-delete orphan repositories.\n    UPDATE\n        repo\n    SET\n        name = soft_deleted_repository_name(name),\n        deleted_at = transaction_timestamp()\n    WHERE\n      deleted_at IS NULL\n      AND NOT EXISTS (\n        SELECT FROM external_service_repos WHERE repo_id = repo.id\n    );\n\n    RETURN NULL;\nEND;\n$$;\n\nCREATE TRIGGER trig_soft_delete_orphan_repo_by_external_service_repo\n    AFTER DELETE ON external_service_repos\n    FOR EACH STATEMENT EXECUTE PROCEDURE soft_delete_orphan_repo_by_external_service_repos();",
				"DownQuery": "DROP FUNCTION IF EXISTS soft_delete_orphan_repo_by_external_service_repos() CASCADE;\nDROP TRIGGER IF EXISTS trig_soft_delete_orphan_repo_by_external_service_repo ON external_service_repos;\n\nCREATE FUNCTION soft_delete_orphan_repo_by_external_service_repos() RETURNS trigger\n    LANGUAGE plpgsql\nAS $$\nBEGIN\n    -- When an external service is soft or hard-deleted,\n    -- performs a clean up to soft-delete orphan repositories.\n    UPDATE\n        repo\n    SET\n        name = soft_deleted_repository_name(name),\n        deleted_at = transaction_timestamp()\n    WHERE\n        deleted_at IS NULL\n      AND id = OLD.repo_id\n      AND id NOT IN (\n        SELECT DISTINCT(repo_id) FROM external_service_repos\n    );\n\n    RETURN OLD;\nEND;\n$$;\n\nCREATE TRIGGER trig_soft_delete_orphan_repo_by_external_service_repo\n    AFTER DELETE ON external_service_repos\n    FOR EACH ROW EXECUTE PROCEDURE soft_delete_orphan_repo_by_external_service_repos();",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395755
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395757,
				"Name": "drop campaigns changeset ids",
				"UpQuery": "DROP TRIGGER IF EXISTS trig_delete_changeset_reference_on_campaigns ON changesets;\nDROP FUNCTION IF EXISTS delete_changeset_reference_on_campaigns();\n\nALTER TABLE campaigns DROP COLUMN IF EXISTS changeset_ids;",
				"DownQuery": "ALTER TABLE campaigns ADD COLUMN IF NOT EXISTS changeset_ids jsonb NOT NULL DEFAULT '{}'::jsonb CHECK (jsonb_typeof(changeset_ids) = 'object'::text);\nCREATE INDEX IF NOT EXISTS campaigns_changeset_ids_gin_idx ON campaigns USING GIN (changeset_ids jsonb_ops);\n\nWITH changesets AS (\n    SELECT id, campaign_ids FROM changesets\n)\nUPDATE campaigns SET changeset_ids = changeset_ids || jsonb_build_object(changesets.id::TEXT, NULL) FROM changesets WHERE changesets.campaign_ids ? campaigns.id::TEXT;\n\nCREATE FUNCTION delete_changeset_reference_on_campaigns() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$\n    BEGIN\n        UPDATE\n          campaigns\n        SET\n          changeset_ids = campaigns.changeset_ids - OLD.id::text\n        WHERE\n          campaigns.changeset_ids ? OLD.id::text;\n\n        RETURN OLD;\n    END;\n$$;\n\nCREATE TRIGGER trig_delete_changeset_reference_on_campaigns AFTER DELETE ON changesets FOR EACH ROW EXECUTE PROCEDURE delete_changeset_reference_on_campaigns();",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395756
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395758,
				"Name": "cm actions jobs add table",
				"UpQuery": "CREATE TABLE IF NOT EXISTS cm_action_jobs\n(\n    id              SERIAL PRIMARY KEY,\n    email           int8 NOT NULL,\n    state           text default 'queued',\n    failure_message text,\n    started_at      timestamptz,\n    finished_at     timestamptz,\n    process_after   timestamptz,\n    num_resets      int4 NOT NULL default 0,\n    num_failures    int4 NOT NULL default 0,\n    log_contents    text,\n    CONSTRAINT cm_action_jobs_email_fk\n        FOREIGN KEY (email)\n            REFERENCES cm_emails (id)\n            ON DELETE CASCADE\n);",
				"DownQuery": "DROP TABLE IF EXISTS cm_action_jobs;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395757
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395759,
				"Name": "drop repo id index on external service repos",
				"UpQuery": "DROP INDEX IF EXISTS external_service_repos_repo_id;",
				"DownQuery": "CREATE INDEX IF NOT EXISTS external_service_repos_repo_id ON external_service_repos(repo_id);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395758
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395760,
				"Name": "log contents array",
				"UpQuery": "-- Drop dependent views\nDROP VIEW lsif_indexes_with_repository_name;\nDROP VIEW external_service_sync_jobs_with_next_sync_at;\n\n-- Create new columns\nALTER TABLE lsif_indexes ADD COLUMN execution_logs json[];\nALTER TABLE changesets ADD COLUMN execution_logs json[];\nALTER TABLE external_service_sync_jobs ADD execution_logs json[];\n\n-- Back-fill log data into new column\nUPDATE lsif_indexes SET execution_logs = (execution_logs || json_build_object('command', '{}'::text[], 'out', log_contents)) WHERE log_contents IS NOT NULL;\n\n--\n-- Recreate views with new columns\n\nCREATE VIEW lsif_indexes_with_repository_name AS\n    SELECT u.*, r.name as repository_name FROM lsif_indexes u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;\n\nCREATE VIEW external_service_sync_jobs_with_next_sync_at AS SELECT\n    j.id,\n    j.state,\n    j.failure_message,\n    j.started_at,\n    j.finished_at,\n    j.process_after,\n    j.num_resets,\n    j.num_failures,\n    j.execution_logs,\n    j.external_service_id,\n    e.next_sync_at\nFROM external_services e JOIN external_service_sync_jobs j ON e.id = j.external_service_id;",
				"DownQuery": "-- Drop dependent views\nDROP VIEW lsif_indexes_with_repository_name;\nDROP VIEW external_service_sync_jobs_with_next_sync_at;\n\n-- Drop new columns\nALTER TABLE lsif_indexes DROP COLUMN execution_logs;\nALTER TABLE changesets DROP COLUMN execution_logs;\nALTER TABLE external_service_sync_jobs DROP execution_logs;\n\n--\n-- Recreate views with previous columns\n\nCREATE VIEW lsif_indexes_with_repository_name AS\n    SELECT u.*, r.name as repository_name FROM lsif_indexes u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;\n\nCREATE VIEW external_service_sync_jobs_with_next_sync_at AS SELECT\n    j.id,\n    j.state,\n    j.failure_message,\n    j.started_at,\n    j.finished_at,\n    j.process_after,\n    j.num_resets,\n    j.num_failures,\n    j.log_contents,\n    j.external_service_id,\n    e.next_sync_at\nFROM external_services e JOIN external_service_sync_jobs j ON e.id = j.external_service_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395759
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395761,
				"Name": "remove enums",
				"UpQuery": "-- Drop dependent views/indexes\nDROP VIEW lsif_dumps_with_repository_name;\nDROP VIEW lsif_indexes_with_repository_name;\nDROP VIEW lsif_uploads_with_repository_name;\nDROP VIEW lsif_dumps;\nDROP INDEX lsif_uploads_repository_id_commit_root_indexer;\n\n-- Update type of state\nALTER TABLE lsif_uploads\n    ALTER COLUMN state DROP DEFAULT,\n    ALTER COLUMN state TYPE text USING state::text,\n    ALTER COLUMN state SET DEFAULT 'queued';\n\nALTER TABLE lsif_indexes\n    ALTER COLUMN state DROP DEFAULT,\n    ALTER COLUMN state TYPE text USING state::text,\n    ALTER COLUMN state SET DEFAULT 'queued';\n\n-- Recreate views/indexes\nCREATE UNIQUE INDEX lsif_uploads_repository_id_commit_root_indexer ON lsif_uploads(repository_id, \"commit\", root, indexer) WHERE state = 'completed';\nCREATE VIEW lsif_dumps AS SELECT u.*, u.finished_at as processed_at FROM lsif_uploads u WHERE state = 'completed';\n\nCREATE VIEW lsif_dumps_with_repository_name AS\n    SELECT u.*, r.name as repository_name FROM lsif_dumps u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_uploads_with_repository_name AS\n    SELECT u.*, r.name as repository_name FROM lsif_uploads u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_indexes_with_repository_name AS\n    SELECT u.*, r.name as repository_name FROM lsif_indexes u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;",
				"DownQuery": "-- Drop dependent views\nDROP VIEW lsif_dumps_with_repository_name;\nDROP VIEW lsif_indexes_with_repository_name;\nDROP VIEW lsif_uploads_with_repository_name;\nDROP VIEW lsif_dumps;\nDROP INDEX lsif_uploads_repository_id_commit_root_indexer;\n\n-- Update type of state\nALTER TABLE lsif_uploads\n    ALTER COLUMN state DROP DEFAULT,\n    ALTER COLUMN state TYPE lsif_upload_state USING state::text::lsif_upload_state,\n    ALTER COLUMN state SET DEFAULT 'queued';\n\nALTER TABLE lsif_indexes\n    ALTER COLUMN state DROP DEFAULT,\n    ALTER COLUMN state TYPE lsif_index_state USING state::text::lsif_index_state,\n    ALTER COLUMN state SET DEFAULT 'queued';\n\n-- Recreate views/indexes\nCREATE UNIQUE INDEX lsif_uploads_repository_id_commit_root_indexer ON lsif_uploads(repository_id, \"commit\", root, indexer) WHERE state = 'completed'::lsif_upload_state;\nCREATE VIEW lsif_dumps AS SELECT u.*, u.finished_at as processed_at FROM lsif_uploads u WHERE state = 'completed';\n\nCREATE VIEW lsif_dumps_with_repository_name AS\n    SELECT u.*, r.name as repository_name FROM lsif_dumps u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_uploads_with_repository_name AS\n    SELECT u.*, r.name as repository_name FROM lsif_uploads u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_indexes_with_repository_name AS\n    SELECT u.*, r.name as repository_name FROM lsif_indexes u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395760
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395762,
				"Name": "add col num results trigger event",
				"UpQuery": "ALTER TABLE cm_action_jobs\n    ADD COLUMN IF NOT EXISTS trigger_event int,\n    ADD CONSTRAINT cm_action_jobs_trigger_event_fk\n        FOREIGN KEY (trigger_event)\n            REFERENCES cm_trigger_jobs (id)\n            ON DELETE CASCADE;\n\nALTER TABLE cm_trigger_jobs\n    ADD COLUMN IF NOT EXISTS num_results int;",
				"DownQuery": "ALTER TABLE cm_action_jobs\n    DROP COLUMN IF EXISTS trigger_event;\nALTER TABLE cm_trigger_jobs\n    DROP COLUMN IF EXISTS num_results;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395761
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395763,
				"Name": "remove old campaign tables",
				"UpQuery": "DROP TABLE IF EXISTS campaigns_old;\nDROP TABLE IF EXISTS changesets_old;",
				"DownQuery": "CREATE TABLE IF NOT EXISTS campaigns_old (\n    id BIGINT,\n    name TEXT,\n    description TEXT,\n    initial_applier_id INTEGER,\n    namespace_user_id INTEGER,\n    namespace_org_id INTEGER,\n    created_at TIMESTAMP WITH TIME ZONE,\n    updated_at TIMESTAMP WITH TIME ZONE,\n    changeset_ids JSONB,\n    closed_at TIMESTAMP WITH TIME ZONE,\n    campaign_spec_id BIGINT,\n    last_applier_id BIGINT,\n    last_applied_at TIMESTAMP WITH TIME ZONE\n);\n\nCREATE TABLE IF NOT EXISTS changesets_old (\n    id BIGINT,\n    campaign_ids JSONB,\n    repo_id INTEGER,\n    created_at TIMESTAMP WITH TIME ZONE,\n    updated_at TIMESTAMP WITH TIME ZONE,\n    metadata JSONB,\n    external_id TEXT,\n    external_service_type TEXT,\n    external_deleted_at TIMESTAMP WITH TIME ZONE,\n    external_branch TEXT,\n    external_updated_at TIMESTAMP WITH TIME ZONE,\n    external_state TEXT,\n    external_review_state TEXT,\n    external_check_state TEXT,\n    created_by_campaign BOOLEAN,\n    added_to_campaign BOOLEAN,\n    diff_stat_added INTEGER,\n    diff_stat_changed INTEGER,\n    diff_stat_deleted INTEGER,\n    sync_state JSONB,\n    current_spec_id BIGINT,\n    previous_spec_id BIGINT,\n    publication_state TEXT,\n    owned_by_campaign_id BIGINT,\n    reconciler_state TEXT,\n    failure_message TEXT,\n    started_at TIMESTAMP WITH TIME ZONE,\n    finished_at TIMESTAMP WITH TIME ZONE,\n    process_after TIMESTAMP WITH TIME ZONE,\n    num_resets INTEGER\n);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395762
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395764,
				"Name": "pg stat statement ext",
				"UpQuery": "CREATE EXTENSION IF NOT EXISTS pg_stat_statements;",
				"DownQuery": "DROP EXTENSION IF EXISTS pg_stat_statements;",
				"Privileged": true,
				"NonIdempotent": false,
				"Parents": [
					1528395763
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395765,
				"Name": "changeset rewirer views",
				"UpQuery": "CREATE VIEW tracking_changeset_specs_and_changesets AS (\n    SELECT\n        changeset_specs.id AS changeset_spec_id,\n        COALESCE(changesets.id, 0) AS changeset_id,\n        changeset_specs.repo_id AS repo_id,\n        changeset_specs.campaign_spec_id AS campaign_spec_id\n    FROM changeset_specs\n    LEFT JOIN changesets ON\n        changesets.repo_id = changeset_specs.repo_id AND\n        changesets.external_id = changeset_specs.spec-\u003e\u003e'externalID'\n    INNER JOIN repo ON changeset_specs.repo_id = repo.id\n    WHERE\n        changeset_specs.spec-\u003e\u003e'externalID' IS NOT NULL AND\n        repo.deleted_at IS NULL\n);\n\nCREATE VIEW branch_changeset_specs_and_changesets AS (\n    SELECT\n        changeset_specs.id AS changeset_spec_id,\n        COALESCE(changesets.id, 0) AS changeset_id,\n        changeset_specs.repo_id AS repo_id,\n        changeset_specs.campaign_spec_id AS campaign_spec_id,\n        changesets.owned_by_campaign_id AS owner_campaign_id\n    FROM changeset_specs\n    LEFT JOIN changesets ON\n        changesets.repo_id = changeset_specs.repo_id AND\n        changesets.current_spec_id IS NOT NULL AND\n        (SELECT spec FROM changeset_specs WHERE changeset_specs.id = changesets.current_spec_id)-\u003e\u003e'headRef' = changeset_specs.spec-\u003e\u003e'headRef'\n    INNER JOIN repo ON changeset_specs.repo_id = repo.id\n    WHERE\n        changeset_specs.spec-\u003e\u003e'externalID' IS NULL AND\n        repo.deleted_at IS NULL\n);",
				"DownQuery": "DROP VIEW IF EXISTS tracking_changeset_specs_and_changesets;\n\nDROP VIEW IF EXISTS branch_changeset_specs_and_changesets;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395764
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395766,
				"Name": "drop old gitlab events",
				"UpQuery": "DELETE FROM changeset_events WHERE kind LIKE 'gitlab:%';\n\n-- Update all gitlab changesets to appear as being synced at least 8 hours ago.\n-- That will increase their priority in the syncer and make sure those are updated more quickly,\n-- so the state lost before is restored rather fast.\nUPDATE changesets SET updated_at = updated_at - '8 hours'::interval WHERE external_service_type = 'gitlab';",
				"DownQuery": "-- Nothing to do here.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395765
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395767,
				"Name": "split nearest uploads",
				"UpQuery": "TRUNCATE lsif_nearest_uploads;\n\nALTER TABLE lsif_nearest_uploads DROP COLUMN ancestor_visible;\nALTER TABLE lsif_nearest_uploads DROP COLUMN overwritten;\n\nCREATE TABLE IF NOT EXISTS lsif_nearest_uploads_links (\n    repository_id int NOT NULL,\n    commit_bytea bytea NOT NULL,\n    ancestor_commit_bytea bytea NOT NULL,\n    distance int NOT NULL\n);\nCREATE INDEX lsif_nearest_uploads_links_repository_id_commit_bytea ON lsif_nearest_uploads_links USING btree (repository_id, commit_bytea);\n\nDROP INDEX lsif_uploads_visible_at_tip_repository_id;\nCREATE INDEX lsif_uploads_visible_at_tip_repository_id_upload_id ON lsif_uploads_visible_at_tip(repository_id, upload_id);",
				"DownQuery": "TRUNCATE lsif_nearest_uploads;\n\nALTER TABLE lsif_nearest_uploads ADD COLUMN ancestor_visible boolean NOT NULL;\nALTER TABLE lsif_nearest_uploads ADD COLUMN overwritten boolean NOT NULL;\n\nDROP TABLE IF EXISTS lsif_nearest_uploads_links;\n\nDROP INDEX lsif_uploads_visible_at_tip_repository_id_upload_id;\nCREATE INDEX lsif_uploads_visible_at_tip_repository_id ON lsif_uploads_visible_at_tip(repository_id);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395766
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395768,
				"Name": "compress nearest uploads",
				"UpQuery": "TRUNCATE lsif_nearest_uploads;\n\nALTER TABLE lsif_nearest_uploads ADD COLUMN uploads jsonb NOT NULL;\nALTER TABLE lsif_nearest_uploads DROP COLUMN upload_id;\nALTER TABLE lsif_nearest_uploads DROP COLUMN distance;",
				"DownQuery": "TRUNCATE lsif_nearest_uploads;\n\nALTER TABLE lsif_nearest_uploads DROP COLUMN uploads;\nALTER TABLE lsif_nearest_uploads ADD COLUMN upload_id integer NOT NULL;\nALTER TABLE lsif_nearest_uploads ADD COLUMN distance integer NOT NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395767
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395769,
				"Name": "drop added to campaign",
				"UpQuery": "ALTER TABLE changesets DROP COLUMN IF EXISTS added_to_campaign;",
				"DownQuery": "ALTER TABLE changesets ADD COLUMN IF NOT EXISTS added_to_campaign boolean NOT NULL DEFAULT false;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395768
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395770,
				"Name": "drop unsynced",
				"UpQuery": "UPDATE changesets SET publication_state = 'UNPUBLISHED' WHERE unsynced = true;\nALTER TABLE changesets DROP COLUMN IF EXISTS unsynced;",
				"DownQuery": "ALTER TABLE changesets ADD COLUMN IF NOT EXISTS unsynced boolean NOT NULL DEFAULT false;\nUPDATE changesets SET unsynced = true, publication_state = 'PUBLISHED' WHERE publication_state = 'UNPUBLISHED' AND current_spec_id IS NULL AND owned_by_campaign_id IS NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395769
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395771,
				"Name": "auto index add local steps",
				"UpQuery": "ALTER TABLE lsif_indexes ADD COLUMN local_steps text[];\n\nUPDATE lsif_indexes SET local_steps = '{}';\n\nALTER TABLE lsif_indexes ALTER COLUMN local_steps SET NOT NULL;\n\nDROP VIEW lsif_indexes_with_repository_name;\n\nCREATE VIEW lsif_indexes_with_repository_name AS\n    SELECT u.*, r.name as repository_name FROM lsif_indexes u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;",
				"DownQuery": "DROP VIEW lsif_indexes_with_repository_name;\n\nALTER TABLE lsif_indexes DROP COLUMN \"local_steps\";\n\nCREATE VIEW lsif_indexes_with_repository_name AS\n    SELECT u.*, r.name as repository_name FROM lsif_indexes u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395770
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395772,
				"Name": "codeintel comments",
				"UpQuery": "COMMENT ON TABLE lsif_uploads IS 'Stores metadata about an LSIF index uploaded by a user.';\nCOMMENT ON COLUMN lsif_uploads.id IS 'Used as a logical foreign key with the (disjoint) codeintel database.';\nCOMMENT ON COLUMN lsif_uploads.commit IS 'A 40-char revhash. Note that this commit may not be resolvable in the future.';\nCOMMENT ON COLUMN lsif_uploads.root IS 'The path for which the index can resolve code intelligence relative to the repository root.';\nCOMMENT ON COLUMN lsif_uploads.indexer IS 'The name of the indexer that produced the index file. If not supplied by the user it will be pulled from the index metadata.';\nCOMMENT ON COLUMN lsif_uploads.num_parts IS 'The number of parts src-cli split the upload file into.';\nCOMMENT ON COLUMN lsif_uploads.uploaded_parts IS 'The index of parts that have been successfully uploaded.';\nCOMMENT ON COLUMN lsif_uploads.upload_size IS 'The size of the index file (in bytes).';\n-- Omitting repository_id\n-- Commenting on these in another PR: state, uploaded_at, started_at, finished_at, process_after, num_resets, num_failures, failure_message\n\nCOMMENT ON TABLE lsif_packages IS 'Associates an upload with the set of packages they provide within a given packages management scheme.';\nCOMMENT ON COLUMN lsif_packages.scheme IS 'The (export) moniker scheme.';\nCOMMENT ON COLUMN lsif_packages.name IS 'The package name.';\nCOMMENT ON COLUMN lsif_packages.version IS 'The package version.';\nCOMMENT ON COLUMN lsif_packages.dump_id IS 'The identifier of the upload that provides the package.';\n-- Omitting id\n\nCOMMENT ON TABLE lsif_references IS 'Associates an upload with the set of packages they require within a given packages management scheme.';\nCOMMENT ON COLUMN lsif_references.scheme IS 'The (import) moniker scheme.';\nCOMMENT ON COLUMN lsif_references.name IS 'The package name.';\nCOMMENT ON COLUMN lsif_references.version IS 'The package version.';\nCOMMENT ON COLUMN lsif_references.filter IS 'A [bloom filter](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.23/-/blob/enterprise/internal/codeintel/bloomfilter/bloom_filter.go#L27:6) encoded as gzipped JSON. This bloom filter stores the set of identifiers imported from the package.';\nCOMMENT ON COLUMN lsif_references.dump_id IS 'The identifier of the upload that references the package.';\n-- Omitting id\n\nCOMMENT ON TABLE lsif_nearest_uploads IS 'Associates commits with the complete set of uploads visible from that commit. Every commit with upload data is present in this table.';\nCOMMENT ON COLUMN lsif_nearest_uploads.commit_bytea IS 'A 40-char revhash. Note that this commit may not be resolvable in the future.';\nCOMMENT ON COLUMN lsif_nearest_uploads.uploads IS 'Encodes an {upload_id =\u003e distance} map that includes an entry for every upload visible from the commit. There is always at least one entry with a distance of zero.';\n-- Omitting repository_id\n\nCOMMENT ON TABLE lsif_nearest_uploads_links IS 'Associates commits with the closest ancestor commit with usable upload data. Together, this table and lsif_nearest_uploads cover all commits with resolvable code intelligence.';\nCOMMENT ON COLUMN lsif_nearest_uploads_links.commit_bytea IS 'A 40-char revhash. Note that this commit may not be resolvable in the future.';\nCOMMENT ON COLUMN lsif_nearest_uploads_links.ancestor_commit_bytea IS 'The 40-char revhash of the ancestor. Note that this commit may not be resolvable in the future.';\nCOMMENT ON COLUMN lsif_nearest_uploads_links.distance IS 'The distance bewteen the commits. Parent = 1, Grandparent = 2, etc.';\n-- Omitting repository_id\n\nCOMMENT ON TABLE lsif_uploads_visible_at_tip IS 'Associates a repository with the set of LSIF upload identifiers that can serve intelligence for the tip of the default branch.';\nCOMMENT ON COLUMN lsif_uploads_visible_at_tip.upload_id IS 'The identifier of an upload visible at the tip of the default branch.';\n-- Omitting repository_id\n\nCOMMENT ON TABLE lsif_dirty_repositories IS 'Stores whether or not the nearest upload data for a repository is out of date (when update_token \u003e dirty_token).';\nCOMMENT ON COLUMN lsif_dirty_repositories.update_token IS 'This value is incremented on each request to update the commit graph for the repository.';\nCOMMENT ON COLUMN lsif_dirty_repositories.dirty_token IS 'Set to the value of update_token visible to the transaction that updates the commit graph. Updates of dirty_token during this time will cause a second update.';\n-- Omitting repository_id\n\nCOMMENT ON TABLE lsif_indexes IS 'Stores metadata about a code intel index job.';\nCOMMENT ON COLUMN lsif_indexes.commit IS 'A 40-char revhash. Note that this commit may not be resolvable in the future.';\nCOMMENT ON COLUMN lsif_indexes.docker_steps IS 'An array of pre-index [steps](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.23/-/blob/enterprise/internal/codeintel/stores/dbstore/docker_step.go#L9:6) to run.';\nCOMMENT ON COLUMN lsif_indexes.indexer IS 'The docker image used to run the index command (e.g. sourcegraph/lsif-go).';\nCOMMENT ON COLUMN lsif_indexes.root IS 'The working directory of the indexer image relative to the repository root.';\nCOMMENT ON COLUMN lsif_indexes.local_steps IS 'A list of commands to run inside the indexer image prior to running the indexer command.';\nCOMMENT ON COLUMN lsif_indexes.indexer_args IS 'The command run inside the indexer image to produce the index file (e.g. [''lsif-node'', ''-p'', ''.''])';\nCOMMENT ON COLUMN lsif_indexes.outfile IS 'The path to the index file produced by the index command relative to the working directory.';\n\nCOMMENT ON COLUMN lsif_indexes.execution_logs IS 'An array of [log entries](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.23/-/blob/internal/workerutil/store.go#L48:6) (encoded as JSON) from the most recent execution.';\nCOMMENT ON COLUMN lsif_indexes.log_contents IS '**Column deprecated in favor of execution_logs.**';\n-- Omitting id, repository_id\n-- Commenting on these in another PR: state, queued_at, started_at, finished_at, process_after, num_resets, num_failures, failure_message\n\nCOMMENT ON TABLE lsif_indexable_repositories IS 'Stores the number of code intel events for repositories. Used for auto-index scheduling heursitics Sourcegraph Cloud.';\nCOMMENT ON COLUMN lsif_indexable_repositories.search_count IS 'The number of search-based code intel events for the repository in the past week.';\nCOMMENT ON COLUMN lsif_indexable_repositories.precise_count IS 'The number of precise code intel events for the repository in the past week.';\nCOMMENT ON COLUMN lsif_indexable_repositories.last_index_enqueued_at IS 'The last time an index for the repository was enqueued (for basic rate limiting).';\nCOMMENT ON COLUMN lsif_indexable_repositories.last_updated_at IS 'The last time the event counts were updated for this repository.';\nCOMMENT ON COLUMN lsif_indexable_repositories.enabled IS '**Column unused.**';\n-- Omitting id, repository_id\n\nCOMMENT ON TABLE lsif_index_configuration IS 'Stores the configuration used for code intel index jobs for a repository.';\nCOMMENT ON COLUMN lsif_index_configuration.data IS 'The raw user-supplied [configuration](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.23/-/blob/enterprise/internal/codeintel/autoindex/config/types.go#L3:6) (encoded in JSONC).';\n-- Omitting id, repository_id",
				"DownQuery": "",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395771
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395773,
				"Name": "add search fields to campaign views",
				"UpQuery": "DROP VIEW IF EXISTS branch_changeset_specs_and_changesets;\nDROP VIEW IF EXISTS tracking_changeset_specs_and_changesets;\n\nCREATE VIEW tracking_changeset_specs_and_changesets AS (\n    SELECT\n        changeset_specs.id AS changeset_spec_id,\n        COALESCE(changesets.id, 0) AS changeset_id,\n        changeset_specs.repo_id AS repo_id,\n        changeset_specs.campaign_spec_id AS campaign_spec_id,\n        repo.name AS repo_name,\n        COALESCE(changesets.metadata-\u003e\u003e'Title', changesets.metadata-\u003e\u003e'title') AS changeset_name\n    FROM changeset_specs\n    LEFT JOIN changesets ON\n        changesets.repo_id = changeset_specs.repo_id AND\n        changesets.external_id = changeset_specs.spec-\u003e\u003e'externalID'\n    INNER JOIN repo ON changeset_specs.repo_id = repo.id\n    WHERE\n        changeset_specs.spec-\u003e\u003e'externalID' IS NOT NULL AND\n        repo.deleted_at IS NULL\n);\n\nCREATE VIEW branch_changeset_specs_and_changesets AS (\n    SELECT\n        changeset_specs.id AS changeset_spec_id,\n        COALESCE(changesets.id, 0) AS changeset_id,\n        changeset_specs.repo_id AS repo_id,\n        changeset_specs.campaign_spec_id AS campaign_spec_id,\n        changesets.owned_by_campaign_id AS owner_campaign_id,\n        repo.name AS repo_name,\n        changeset_specs.spec-\u003e\u003e'title' AS changeset_name\n    FROM changeset_specs\n    LEFT JOIN changesets ON\n        changesets.repo_id = changeset_specs.repo_id AND\n        changesets.current_spec_id IS NOT NULL AND\n        (SELECT spec FROM changeset_specs WHERE changeset_specs.id = changesets.current_spec_id)-\u003e\u003e'headRef' = changeset_specs.spec-\u003e\u003e'headRef'\n    INNER JOIN repo ON changeset_specs.repo_id = repo.id\n    WHERE\n        changeset_specs.spec-\u003e\u003e'externalID' IS NULL AND\n        repo.deleted_at IS NULL\n);",
				"DownQuery": "DROP VIEW IF EXISTS branch_changeset_specs_and_changesets;\nDROP VIEW IF EXISTS tracking_changeset_specs_and_changesets;\n\nCREATE VIEW tracking_changeset_specs_and_changesets AS (\n    SELECT\n        changeset_specs.id AS changeset_spec_id,\n        COALESCE(changesets.id, 0) AS changeset_id,\n        changeset_specs.repo_id AS repo_id,\n        changeset_specs.campaign_spec_id AS campaign_spec_id\n    FROM changeset_specs\n    LEFT JOIN changesets ON\n        changesets.repo_id = changeset_specs.repo_id AND\n        changesets.external_id = changeset_specs.spec-\u003e\u003e'externalID'\n    INNER JOIN repo ON changeset_specs.repo_id = repo.id\n    WHERE\n        changeset_specs.spec-\u003e\u003e'externalID' IS NOT NULL AND\n        repo.deleted_at IS NULL\n);\n\nCREATE VIEW branch_changeset_specs_and_changesets AS (\n    SELECT\n        changeset_specs.id AS changeset_spec_id,\n        COALESCE(changesets.id, 0) AS changeset_id,\n        changeset_specs.repo_id AS repo_id,\n        changeset_specs.campaign_spec_id AS campaign_spec_id,\n        changesets.owned_by_campaign_id AS owner_campaign_id\n    FROM changeset_specs\n    LEFT JOIN changesets ON\n        changesets.repo_id = changeset_specs.repo_id AND\n        changesets.current_spec_id IS NOT NULL AND\n        (SELECT spec FROM changeset_specs WHERE changeset_specs.id = changesets.current_spec_id)-\u003e\u003e'headRef' = changeset_specs.spec-\u003e\u003e'headRef'\n    INNER JOIN repo ON changeset_specs.repo_id = repo.id\n    WHERE\n        changeset_specs.spec-\u003e\u003e'externalID' IS NULL AND\n        repo.deleted_at IS NULL\n);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395772
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395774,
				"Name": "add user public repo",
				"UpQuery": "CREATE TABLE IF NOT EXISTS user_public_repos (\n    user_id integer,\n    repo_id integer,\n    UNIQUE (user_id, repo_id),\n    CONSTRAINT user_fk\n        FOREIGN KEY (user_id)\n        REFERENCES users (id)\n        ON DELETE CASCADE,\n    CONSTRAINT repo_fk\n        FOREIGN KEY (repo_id)\n        REFERENCES repo (id)\n        ON DELETE CASCADE\n);",
				"DownQuery": "DROP TABLE IF EXISTS user_public_repos;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395773
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395775,
				"Name": "add cloud default to external services",
				"UpQuery": "ALTER TABLE external_services\nADD COLUMN IF NOT EXISTS\n    cloud_default BOOLEAN DEFAULT false;\n\n-- Only only service per kind can have cloud_default set\nCREATE UNIQUE INDEX IF NOT EXISTS kind_cloud_default ON external_services (kind, cloud_default) WHERE cloud_default = true;",
				"DownQuery": "ALTER TABLE external_services DROP COLUMN IF EXISTS cloud_default;\nDROP INDEX IF EXISTS kind_cloud_default;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395774
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395776,
				"Name": "cloud default not null",
				"UpQuery": "ALTER TABLE IF EXISTS external_services ALTER COLUMN cloud_default SET NOT NULL;",
				"DownQuery": "ALTER TABLE IF EXISTS external_services ALTER COLUMN cloud_default DROP NOT NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395775
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395777,
				"Name": "lsif uploads associated index",
				"UpQuery": "DROP VIEW lsif_dumps_with_repository_name;\nDROP VIEW lsif_uploads_with_repository_name;\nDROP VIEW lsif_dumps;\n\nALTER TABLE lsif_uploads ADD COLUMN associated_index_id bigint;\n\n-- Recreate views with new columns\nCREATE VIEW lsif_dumps AS SELECT u.*, u.finished_at as processed_at FROM lsif_uploads u WHERE state = 'completed';\n\nCREATE VIEW lsif_dumps_with_repository_name AS\n  SELECT u.*, r.name as repository_name FROM lsif_dumps u\n                                               JOIN repo r ON r.id = u.repository_id\n   WHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_uploads_with_repository_name AS\n  SELECT u.*, r.name as repository_name FROM lsif_uploads u\n                                               JOIN repo r ON r.id = u.repository_id\n   WHERE r.deleted_at IS NULL;",
				"DownQuery": "DROP VIEW lsif_dumps_with_repository_name;\nDROP VIEW lsif_uploads_with_repository_name;\nDROP VIEW lsif_dumps;\n\nALTER TABLE IF EXISTS lsif_uploads DROP COLUMN IF EXISTS associated_index_id;\n\n-- Recreate views with new columns\nCREATE VIEW lsif_dumps AS SELECT u.*, u.finished_at as processed_at FROM lsif_uploads u WHERE state = 'completed';\n\nCREATE VIEW lsif_dumps_with_repository_name AS\n  SELECT u.*, r.name as repository_name FROM lsif_dumps u\n                                               JOIN repo r ON r.id = u.repository_id\n   WHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_uploads_with_repository_name AS\n  SELECT u.*, r.name as repository_name FROM lsif_uploads u\n                                               JOIN repo r ON r.id = u.repository_id\n   WHERE r.deleted_at IS NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395776
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395778,
				"Name": "add syncer error",
				"UpQuery": "ALTER TABLE changesets ADD COLUMN IF NOT EXISTS syncer_error TEXT;",
				"DownQuery": "ALTER TABLE changesets DROP COLUMN IF EXISTS syncer_error;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395777
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395779,
				"Name": "dirty repositories updated at",
				"UpQuery": "ALTER TABLE lsif_dirty_repositories ADD COLUMN updated_at TIMESTAMP WITH TIME ZONE;\nCOMMENT ON COLUMN lsif_dirty_repositories.updated_at IS 'The time the update_token value was last updated.';",
				"DownQuery": "ALTER TABLE lsif_dirty_repositories DROP COLUMN updated_at;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395778
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395780,
				"Name": "drop secrets sql",
				"UpQuery": "-- The `secrets` table is not used and has no records.\nDROP TABLE IF EXISTS secrets;",
				"DownQuery": "-- Copied (with minor safety modifications) from the squashed migration file.\nCREATE TABLE IF NOT EXISTS secrets (\n    id bigint NOT NULL,\n    source_type character varying(50),\n    source_id bigint,\n    key_name character varying(100),\n    value text NOT NULL\n);\n\nCREATE SEQUENCE IF NOT EXISTS secrets_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE IF EXISTS secrets_id_seq OWNED BY secrets.id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395779
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395781,
				"Name": "remove user repos table",
				"UpQuery": "DROP TABLE IF EXISTS user_public_repos;",
				"DownQuery": "CREATE TABLE IF NOT EXISTS user_public_repos (\n     user_id integer,\n     repo_id integer,\n     UNIQUE (user_id, repo_id),\n     CONSTRAINT user_fk\n         FOREIGN KEY (user_id)\n             REFERENCES users (id)\n             ON DELETE CASCADE,\n     CONSTRAINT repo_fk\n         FOREIGN KEY (repo_id)\n             REFERENCES repo (id)\n             ON DELETE CASCADE\n);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395780
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395782,
				"Name": "normalize spec fields on changeset specs",
				"UpQuery": "ALTER TABLE changeset_specs ADD COLUMN head_ref text DEFAULT NULL;\nALTER TABLE changeset_specs ADD COLUMN title text DEFAULT NULL;\nALTER TABLE changeset_specs ADD COLUMN external_id text DEFAULT NULL;\n\nCREATE INDEX changeset_specs_external_id ON changeset_specs (external_id);\nCREATE INDEX changeset_specs_head_ref ON changeset_specs (head_ref);\nCREATE INDEX changeset_specs_title ON changeset_specs (title);\n\nUPDATE changeset_specs SET head_ref = changeset_specs.spec-\u003e\u003e'headRef'::text WHERE changeset_specs.spec-\u003e\u003e'externalID'::text IS NULL;\nUPDATE changeset_specs SET title = changeset_specs.spec-\u003e\u003e'title'::text;\nUPDATE changeset_specs SET external_id = changeset_specs.spec-\u003e\u003e'externalID'::text;\n\n-- These are the same views as before, except that they now use the new\n-- columns, which is why we need to re-create them.\nDROP VIEW IF EXISTS branch_changeset_specs_and_changesets;\nCREATE VIEW branch_changeset_specs_and_changesets AS (\n    SELECT\n        changeset_specs.id AS changeset_spec_id,\n        COALESCE(changesets.id, 0::bigint) AS changeset_id,\n        changeset_specs.repo_id,\n        changeset_specs.campaign_spec_id,\n        changesets.owned_by_campaign_id AS owner_campaign_id,\n        repo.name AS repo_name,\n        changeset_specs.title AS changeset_name\n    FROM changeset_specs\n    LEFT JOIN\n        changesets\n    ON\n        changesets.repo_id = changeset_specs.repo_id\n        AND\n        changesets.current_spec_id IS NOT NULL\n        AND\n        EXISTS (\n            SELECT 1\n            FROM changeset_specs changeset_specs_1\n            WHERE\n                changeset_specs_1.id = changesets.current_spec_id\n                AND\n                changeset_specs_1.head_ref = changeset_specs.head_ref\n        )\n    JOIN\n        repo\n    ON\n        changeset_specs.repo_id = repo.id\n    WHERE\n        changeset_specs.external_id IS NULL\n        AND\n        repo.deleted_at IS NULL\n);\n\nDROP VIEW IF EXISTS tracking_changeset_specs_and_changesets;\nCREATE VIEW tracking_changeset_specs_and_changesets AS (  \n    SELECT\n        changeset_specs.id AS changeset_spec_id,\n        COALESCE(changesets.id, 0::bigint) AS changeset_id,\n        changeset_specs.repo_id,\n        changeset_specs.campaign_spec_id,\n        repo.name AS repo_name,\n        COALESCE(changesets.metadata -\u003e\u003e 'Title'::text, changesets.metadata -\u003e\u003e 'title'::text) AS changeset_name\n    FROM\n        changeset_specs\n    LEFT JOIN\n        changesets\n    ON\n        changesets.repo_id = changeset_specs.repo_id\n        AND\n        changesets.external_id = changeset_specs.external_id\n    JOIN\n        repo\n    ON\n        changeset_specs.repo_id = repo.id\n    WHERE\n        changeset_specs.external_id IS NOT NULL\n        AND\n        repo.deleted_at IS NULL\n);",
				"DownQuery": "DROP VIEW IF EXISTS branch_changeset_specs_and_changesets;\nDROP VIEW IF EXISTS tracking_changeset_specs_and_changesets;\n\nCREATE VIEW tracking_changeset_specs_and_changesets AS (\n    SELECT\n        changeset_specs.id AS changeset_spec_id,\n        COALESCE(changesets.id, 0) AS changeset_id,\n        changeset_specs.repo_id AS repo_id,\n        changeset_specs.campaign_spec_id AS campaign_spec_id,\n        repo.name AS repo_name,\n        COALESCE(changesets.metadata-\u003e\u003e'Title', changesets.metadata-\u003e\u003e'title') AS changeset_name\n    FROM changeset_specs\n    LEFT JOIN changesets ON\n        changesets.repo_id = changeset_specs.repo_id AND\n        changesets.external_id = changeset_specs.spec-\u003e\u003e'externalID'\n    INNER JOIN repo ON changeset_specs.repo_id = repo.id\n    WHERE\n        changeset_specs.spec-\u003e\u003e'externalID' IS NOT NULL AND\n        repo.deleted_at IS NULL\n);\n\nCREATE VIEW branch_changeset_specs_and_changesets AS (\n    SELECT\n        changeset_specs.id AS changeset_spec_id,\n        COALESCE(changesets.id, 0) AS changeset_id,\n        changeset_specs.repo_id AS repo_id,\n        changeset_specs.campaign_spec_id AS campaign_spec_id,\n        changesets.owned_by_campaign_id AS owner_campaign_id,\n        repo.name AS repo_name,\n        changeset_specs.spec-\u003e\u003e'title' AS changeset_name\n    FROM changeset_specs\n    LEFT JOIN changesets ON\n        changesets.repo_id = changeset_specs.repo_id AND\n        changesets.current_spec_id IS NOT NULL AND\n        (SELECT spec FROM changeset_specs WHERE changeset_specs.id = changesets.current_spec_id)-\u003e\u003e'headRef' = changeset_specs.spec-\u003e\u003e'headRef'\n    INNER JOIN repo ON changeset_specs.repo_id = repo.id\n    WHERE\n        changeset_specs.spec-\u003e\u003e'externalID' IS NULL AND\n        repo.deleted_at IS NULL\n);\n\nALTER TABLE changeset_specs DROP COLUMN head_ref;\nALTER TABLE changeset_specs DROP COLUMN title;\nALTER TABLE changeset_specs DROP COLUMN external_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395781
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395783,
				"Name": "insights query runner jobs",
				"UpQuery": "CREATE TABLE IF NOT EXISTS insights_query_runner_jobs(\n    id SERIAL PRIMARY KEY,\n    series_id text NOT NULL,\n    search_query text NOT NULL,\n    state           text default 'queued',\n    failure_message text,\n    started_at      timestamptz,\n    finished_at     timestamptz,\n    process_after   timestamptz,\n    num_resets      int4 NOT NULL default 0,\n    num_failures    int4 NOT NULL default 0,\n    execution_logs json[]\n);\nCREATE INDEX insights_query_runner_jobs_state_btree ON insights_query_runner_jobs USING btree (state);\n\nCOMMENT ON TABLE insights_query_runner_jobs IS 'See [enterprise/internal/insights/background/queryrunner/worker.go:Job](https://sourcegraph.com/search?q=repo:%5Egithub%5C.com/sourcegraph/sourcegraph%24+file:enterprise/internal/insights/background/queryrunner/worker.go+type+Job\u0026patternType=literal)';",
				"DownQuery": "DROP INDEX IF EXISTS insights_query_runner_jobs_state_btree;\nDROP TABLE IF EXISTS insights_query_runner_jobs;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395782
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395784,
				"Name": "preview filter fields",
				"UpQuery": "DROP VIEW IF EXISTS branch_changeset_specs_and_changesets;\nDROP VIEW IF EXISTS tracking_changeset_specs_and_changesets;\n\nCREATE VIEW tracking_changeset_specs_and_changesets AS (\n    SELECT\n        changeset_specs.id AS changeset_spec_id,\n        COALESCE(changesets.id, 0::bigint) AS changeset_id,\n        changeset_specs.repo_id,\n        changeset_specs.campaign_spec_id,\n        repo.name AS repo_name,\n        COALESCE(changesets.metadata -\u003e\u003e 'Title'::text, changesets.metadata -\u003e\u003e 'title'::text) AS changeset_name,\n        changesets.external_state,\n        changesets.publication_state,\n        changesets.reconciler_state\n    FROM\n        changeset_specs\n    LEFT JOIN\n        changesets\n    ON\n        changesets.repo_id = changeset_specs.repo_id\n        AND\n        changesets.external_id = changeset_specs.external_id\n    JOIN\n        repo\n    ON\n        changeset_specs.repo_id = repo.id\n    WHERE\n        changeset_specs.external_id IS NOT NULL\n        AND\n        repo.deleted_at IS NULL\n);\n\nCREATE VIEW branch_changeset_specs_and_changesets AS (\n    SELECT\n        changeset_specs.id AS changeset_spec_id,\n        COALESCE(changesets.id, 0::bigint) AS changeset_id,\n        changeset_specs.repo_id,\n        changeset_specs.campaign_spec_id,\n        changesets.owned_by_campaign_id AS owner_campaign_id,\n        repo.name AS repo_name,\n        changeset_specs.title AS changeset_name,\n        changesets.external_state,\n        changesets.publication_state,\n        changesets.reconciler_state\n    FROM changeset_specs\n    LEFT JOIN\n        changesets\n    ON\n        changesets.repo_id = changeset_specs.repo_id\n        AND\n        changesets.current_spec_id IS NOT NULL\n        AND\n        EXISTS (\n            SELECT 1\n            FROM changeset_specs changeset_specs_1\n            WHERE\n                changeset_specs_1.id = changesets.current_spec_id\n                AND\n                changeset_specs_1.head_ref = changeset_specs.head_ref\n        )\n    JOIN\n        repo\n    ON\n        changeset_specs.repo_id = repo.id\n    WHERE\n        changeset_specs.external_id IS NULL\n        AND\n        repo.deleted_at IS NULL\n);\n\nCREATE INDEX IF NOT EXISTS\n    changesets_external_state_idx\nON\n    changesets (external_state);\n\nCREATE INDEX IF NOT EXISTS\n    changesets_publication_state_idx\nON\n    changesets (publication_state);\n\nCREATE INDEX IF NOT EXISTS\n    changesets_reconciler_state_idx\nON\n    changesets (reconciler_state);",
				"DownQuery": "DROP VIEW IF EXISTS branch_changeset_specs_and_changesets;\nDROP VIEW IF EXISTS tracking_changeset_specs_and_changesets;\n\nCREATE VIEW tracking_changeset_specs_and_changesets AS (\n    SELECT\n        changeset_specs.id AS changeset_spec_id,\n        COALESCE(changesets.id, 0::bigint) AS changeset_id,\n        changeset_specs.repo_id,\n        changeset_specs.campaign_spec_id,\n        repo.name AS repo_name,\n        COALESCE(changesets.metadata -\u003e\u003e 'Title'::text, changesets.metadata -\u003e\u003e 'title'::text) AS changeset_name\n    FROM\n        changeset_specs\n    LEFT JOIN\n        changesets\n    ON\n        changesets.repo_id = changeset_specs.repo_id\n        AND\n        changesets.external_id = changeset_specs.external_id\n    JOIN\n        repo\n    ON\n        changeset_specs.repo_id = repo.id\n    WHERE\n        changeset_specs.external_id IS NOT NULL\n        AND\n        repo.deleted_at IS NULL\n);\n\nCREATE VIEW branch_changeset_specs_and_changesets AS (\n    SELECT\n        changeset_specs.id AS changeset_spec_id,\n        COALESCE(changesets.id, 0::bigint) AS changeset_id,\n        changeset_specs.repo_id,\n        changeset_specs.campaign_spec_id,\n        changesets.owned_by_campaign_id AS owner_campaign_id,\n        repo.name AS repo_name,\n        changeset_specs.title AS changeset_name\n    FROM changeset_specs\n    LEFT JOIN\n        changesets\n    ON\n        changesets.repo_id = changeset_specs.repo_id\n        AND\n        changesets.current_spec_id IS NOT NULL\n        AND\n        EXISTS (\n            SELECT 1\n            FROM changeset_specs changeset_specs_1\n            WHERE\n                changeset_specs_1.id = changesets.current_spec_id\n                AND\n                changeset_specs_1.head_ref = changeset_specs.head_ref\n        )\n    JOIN\n        repo\n    ON\n        changeset_specs.repo_id = repo.id\n    WHERE\n        changeset_specs.external_id IS NULL\n        AND\n        repo.deleted_at IS NULL\n);\n\nDROP INDEX IF EXISTS changesets_external_state_idx;\nDROP INDEX IF EXISTS changesets_publication_state_idx;\nDROP INDEX IF EXISTS changesets_reconciler_state_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395783
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395785,
				"Name": "out of band migration table",
				"UpQuery": "CREATE TABLE out_of_band_migrations (\n    id               serial primary key,\n    team             text not null,\n    component        text not null,\n    description      text not null,\n    introduced       text not null,\n    deprecated       text,\n    progress         float default 0 not null,\n    created          timestamp with time zone not null default now(),\n    last_updated     timestamp with time zone,\n    non_destructive  boolean not null,\n    apply_reverse    boolean default false not null\n);\n\nCOMMENT ON TABLE out_of_band_migrations IS 'Stores metadata and progress about an out-of-band migration routine.';\nCOMMENT ON COLUMN out_of_band_migrations.id IS 'A globally unique primary key for this migration. The same key is used consistently across all Sourcegraph instances for the same migration.';\nCOMMENT ON COLUMN out_of_band_migrations.team IS 'The name of the engineering team responsible for the migration.';\nCOMMENT ON COLUMN out_of_band_migrations.component IS 'The name of the component undergoing a migration.';\nCOMMENT ON COLUMN out_of_band_migrations.description IS 'A brief description about the migration.';\nCOMMENT ON COLUMN out_of_band_migrations.introduced IS 'The Sourcegraph version in which this migration was first introduced.';\nCOMMENT ON COLUMN out_of_band_migrations.deprecated IS 'The lowest Sourcegraph version that assumes the migration has completed.';\nCOMMENT ON COLUMN out_of_band_migrations.progress IS 'The percentage progress in the up direction (0=0%, 1=100%).';\nCOMMENT ON COLUMN out_of_band_migrations.created IS 'The date and time the migration was inserted into the database (via an upgrade).';\nCOMMENT ON COLUMN out_of_band_migrations.last_updated IS 'The date and time the migration was last updated.';\nCOMMENT ON COLUMN out_of_band_migrations.non_destructive IS 'Whether or not this migration alters data so it can no longer be read by the previous Sourcegraph instance.';\nCOMMENT ON COLUMN out_of_band_migrations.apply_reverse IS 'Whether this migration should run in the opposite direction (to support an upcoming downgrade).';\n\nALTER TABLE out_of_band_migrations ADD CONSTRAINT out_of_band_migrations_team_nonempty CHECK (team \u003c\u003e '');\nALTER TABLE out_of_band_migrations ADD CONSTRAINT out_of_band_migrations_component_nonempty CHECK (component \u003c\u003e '');\nALTER TABLE out_of_band_migrations ADD CONSTRAINT out_of_band_migrations_description_nonempty CHECK (description \u003c\u003e '');\nALTER TABLE out_of_band_migrations ADD CONSTRAINT out_of_band_migrations_introduced_valid_version CHECK (introduced ~ '^(\\d+)\\.(\\d+)\\.(\\d+)$'::text);\nALTER TABLE out_of_band_migrations ADD CONSTRAINT out_of_band_migrations_deprecated_valid_version CHECK (deprecated ~ '^(\\d+)\\.(\\d+)\\.(\\d+)$'::text);\nALTER TABLE out_of_band_migrations ADD CONSTRAINT out_of_band_migrations_progress_range CHECK (progress \u003e= 0 AND progress \u003c= 1);\n\nCREATE TABLE out_of_band_migrations_errors (\n    id            serial primary key,\n    migration_id  int not null,\n    message       text not null,\n    created       timestamp with time zone not null default now()\n);\n\nALTER TABLE out_of_band_migrations_errors ADD FOREIGN KEY (migration_id) REFERENCES out_of_band_migrations(id) ON DELETE CASCADE;\nALTER TABLE out_of_band_migrations_errors ADD CONSTRAINT out_of_band_migrations_errors_message_nonempty CHECK (message \u003c\u003e '');\n\nCOMMENT ON TABLE out_of_band_migrations_errors IS 'Stores errors that occurred while performing an out-of-band migration.';\nCOMMENT ON COLUMN out_of_band_migrations_errors.id IS 'A unique identifer.';\nCOMMENT ON COLUMN out_of_band_migrations_errors.migration_id IS 'The identifier of the migration.';\nCOMMENT ON COLUMN out_of_band_migrations_errors.message IS 'The error message.';\nCOMMENT ON COLUMN out_of_band_migrations_errors.created IS 'The date and time the error occurred.';",
				"DownQuery": "DROP TABLE IF EXISTS out_of_band_migrations_errors;\nDROP TABLE IF EXISTS out_of_band_migrations;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395784
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395786,
				"Name": "diagnostic counts migration",
				"UpQuery": "INSERT INTO out_of_band_migrations (id, team, component, description, introduced, non_destructive)\nVALUES (1, 'code-intelligence', 'codeintel-db.lsif_data_documents', 'Populate num_diagnostics from gob-encoded payload', '3.25.0', true)\nON CONFLICT DO NOTHING;",
				"DownQuery": "-- Nothing to do.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395785
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395787,
				"Name": "reconciler changesets view",
				"UpQuery": "CREATE VIEW reconciler_changesets AS\n    SELECT c.* FROM changesets c\n    INNER JOIN repo r on r.id = c.repo_id\n    WHERE\n        r.deleted_at IS NULL AND\n        EXISTS (\n            SELECT 1 FROM campaigns\n            LEFT JOIN users namespace_user ON campaigns.namespace_user_id = namespace_user.id\n            LEFT JOIN orgs namespace_org ON campaigns.namespace_org_id = namespace_org.id\n            WHERE\n                c.campaign_ids ? campaigns.id::text AND\n                namespace_user.deleted_at IS NULL AND\n                namespace_org.deleted_at IS NULL\n        )\n;",
				"DownQuery": "DROP VIEW IF EXISTS reconciler_changesets;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395786
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395788,
				"Name": "campaigns ssh key migration",
				"UpQuery": "INSERT INTO out_of_band_migrations (id, team, component, description, introduced, deprecated, non_destructive)\nVALUES (2, 'campaigns', 'frontend-db.authenticators', 'Prepare for SSH pushes to code hosts', '3.26.0', '3.27.0', true)\nON CONFLICT DO NOTHING;",
				"DownQuery": "-- Nothing to do.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395787
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395789,
				"Name": "add encryption key ident",
				"UpQuery": "ALTER TABLE external_services ADD COLUMN IF NOT EXISTS encryption_key_id text NOT NULL DEFAULT '';",
				"DownQuery": "ALTER TABLE external_services DROP COLUMN IF EXISTS encryption_key_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395788
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395790,
				"Name": "create gitserver repos",
				"UpQuery": "CREATE TABLE IF NOT EXISTS gitserver_repos\n(\n    repo_id int REFERENCES repo(id) PRIMARY KEY,\n    clone_status text NOT NULL default 'not_cloned',\n    last_external_service bigint,\n    shard_id text NOT NULL,\n    last_error text,\n    updated_at timestamp WITH TIME ZONE default now() not null\n);",
				"DownQuery": "DROP TABLE IF EXISTS gitserver_repos;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395789
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395791,
				"Name": "insights query runner jobs record time",
				"UpQuery": "ALTER TABLE insights_query_runner_jobs ADD COLUMN record_time timestamptz;",
				"DownQuery": "ALTER TABLE insights_query_runner_jobs DROP COLUMN record_time;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395790
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395792,
				"Name": "add user public repos",
				"UpQuery": "CREATE TABLE IF NOT EXISTS user_public_repos (\n    user_id integer NOT NULL,\n    repo_uri text NOT NULL,\n    repo_id integer NOT NULL,\n    UNIQUE(user_id, repo_id),\n    FOREIGN KEY (user_id) REFERENCES users (id) ON DELETE CASCADE,\n    FOREIGN KEY (repo_id) REFERENCES repo (id) ON DELETE CASCADE\n);",
				"DownQuery": "DROP TABLE IF EXISTS user_public_repos;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395791
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395793,
				"Name": "fix invalid changeset reconciler states",
				"UpQuery": "UPDATE changesets SET reconciler_state = 'queued' WHERE reconciler_state = 'QUEUED';",
				"DownQuery": "UPDATE changesets SET reconciler_state = 'QUEUED' WHERE reconciler_state = 'queued';",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395792
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395794,
				"Name": "campaigns rename",
				"UpQuery": "UPDATE user_credentials SET domain = 'batches' WHERE domain = 'campaigns';\nALTER TABLE IF EXISTS campaign_specs RENAME TO batch_specs;\nALTER TABLE IF EXISTS campaigns RENAME TO batch_changes;\nALTER TABLE IF EXISTS batch_changes RENAME COLUMN campaign_spec_id TO batch_spec_id;\nALTER TABLE IF EXISTS changeset_specs RENAME COLUMN campaign_spec_id TO batch_spec_id;\nDROP VIEW IF EXISTS reconciler_changesets;\nDROP VIEW IF EXISTS branch_changeset_specs_and_changesets;\nDROP VIEW IF EXISTS tracking_changeset_specs_and_changesets;\nALTER TABLE IF EXISTS changesets RENAME COLUMN campaign_ids TO batch_change_ids;\nALTER TABLE IF EXISTS changesets RENAME COLUMN owned_by_campaign_id TO owned_by_batch_change_id;\nCREATE VIEW tracking_changeset_specs_and_changesets AS (\n    SELECT\n        changeset_specs.id AS changeset_spec_id,\n        COALESCE(changesets.id, 0::bigint) AS changeset_id,\n        changeset_specs.repo_id,\n        changeset_specs.batch_spec_id,\n        repo.name AS repo_name,\n        COALESCE(changesets.metadata -\u003e\u003e 'Title'::text, changesets.metadata -\u003e\u003e 'title'::text) AS changeset_name,\n        changesets.external_state,\n        changesets.publication_state,\n        changesets.reconciler_state\n    FROM\n        changeset_specs\n    LEFT JOIN\n        changesets\n    ON\n        changesets.repo_id = changeset_specs.repo_id\n        AND\n        changesets.external_id = changeset_specs.external_id\n    JOIN\n        repo\n    ON\n        changeset_specs.repo_id = repo.id\n    WHERE\n        changeset_specs.external_id IS NOT NULL\n        AND\n        repo.deleted_at IS NULL\n);\nCREATE VIEW branch_changeset_specs_and_changesets AS (\n    SELECT\n        changeset_specs.id AS changeset_spec_id,\n        COALESCE(changesets.id, 0::bigint) AS changeset_id,\n        changeset_specs.repo_id,\n        changeset_specs.batch_spec_id,\n        changesets.owned_by_batch_change_id AS owner_batch_change_id,\n        repo.name AS repo_name,\n        changeset_specs.title AS changeset_name,\n        changesets.external_state,\n        changesets.publication_state,\n        changesets.reconciler_state\n    FROM changeset_specs\n    LEFT JOIN\n        changesets\n    ON\n        changesets.repo_id = changeset_specs.repo_id\n        AND\n        changesets.current_spec_id IS NOT NULL\n        AND\n        EXISTS (\n            SELECT 1\n            FROM changeset_specs changeset_specs_1\n            WHERE\n                changeset_specs_1.id = changesets.current_spec_id\n                AND\n                changeset_specs_1.head_ref = changeset_specs.head_ref\n        )\n    JOIN\n        repo\n    ON\n        changeset_specs.repo_id = repo.id\n    WHERE\n        changeset_specs.external_id IS NULL\n        AND\n        repo.deleted_at IS NULL\n);\nCREATE VIEW reconciler_changesets AS\n    SELECT c.* FROM changesets c\n    INNER JOIN repo r on r.id = c.repo_id\n    WHERE\n        r.deleted_at IS NULL AND\n        EXISTS (\n            SELECT 1 FROM batch_changes\n            LEFT JOIN users namespace_user ON batch_changes.namespace_user_id = namespace_user.id\n            LEFT JOIN orgs namespace_org ON batch_changes.namespace_org_id = namespace_org.id\n            WHERE\n                c.batch_change_ids ? batch_changes.id::text AND\n                namespace_user.deleted_at IS NULL AND\n                namespace_org.deleted_at IS NULL\n        )\n;\nDROP TRIGGER IF EXISTS trig_delete_campaign_reference_on_changesets ON batch_changes;\nDROP FUNCTION IF EXISTS delete_campaign_reference_on_changesets();\nCREATE FUNCTION delete_batch_change_reference_on_changesets() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$\n    BEGIN\n        UPDATE\n          changesets\n        SET\n          batch_change_ids = changesets.batch_change_ids - OLD.id::text\n        WHERE\n          changesets.batch_change_ids ? OLD.id::text;\n\n        RETURN OLD;\n    END;\n$$;\nCREATE TRIGGER trig_delete_batch_change_reference_on_changesets AFTER DELETE ON batch_changes FOR EACH ROW EXECUTE PROCEDURE delete_batch_change_reference_on_changesets();\nALTER SEQUENCE campaigns_id_seq RENAME TO batch_changes_id_seq;\nALTER SEQUENCE campaign_specs_id_seq RENAME TO batch_specs_id_seq;\nALTER TABLE batch_changes RENAME CONSTRAINT \"campaigns_campaign_spec_id_fkey\" TO \"batch_changes_batch_spec_id_fkey\";\nALTER TABLE batch_changes RENAME CONSTRAINT \"campaigns_initial_applier_id_fkey\" TO \"batch_changes_initial_applier_id_fkey\";\nALTER TABLE batch_changes RENAME CONSTRAINT \"campaigns_last_applier_id_fkey\" TO \"batch_changes_last_applier_id_fkey\";\nALTER TABLE batch_changes RENAME CONSTRAINT \"campaigns_namespace_org_id_fkey\" TO \"batch_changes_namespace_org_id_fkey\";\nALTER TABLE batch_changes RENAME CONSTRAINT \"campaigns_namespace_user_id_fkey\" TO \"batch_changes_namespace_user_id_fkey\";\nALTER TABLE batch_changes RENAME CONSTRAINT \"campaigns_has_1_namespace\" TO \"batch_changes_has_1_namespace\";\nALTER TABLE batch_changes RENAME CONSTRAINT \"campaigns_name_not_blank\" TO \"batch_changes_name_not_blank\";\nALTER INDEX IF EXISTS campaigns_pkey RENAME TO batch_changes_pkey;\nALTER INDEX IF EXISTS campaigns_namespace_org_id RENAME TO batch_changes_namespace_org_id;\nALTER INDEX IF EXISTS campaigns_namespace_user_id RENAME TO batch_changes_namespace_user_id;\nALTER TABLE batch_specs RENAME CONSTRAINT \"campaign_specs_has_1_namespace\" TO \"batch_specs_has_1_namespace\";\nALTER TABLE batch_specs RENAME CONSTRAINT \"campaign_specs_user_id_fkey\" TO \"batch_specs_user_id_fkey\";\nALTER INDEX IF EXISTS campaign_specs_pkey RENAME TO batch_specs_pkey;\nALTER INDEX IF EXISTS campaign_specs_rand_id RENAME TO batch_specs_rand_id;\nALTER TABLE changeset_specs RENAME CONSTRAINT \"changeset_specs_campaign_spec_id_fkey\" TO \"changeset_specs_batch_spec_id_fkey\";\nALTER TABLE changesets RENAME CONSTRAINT \"changesets_owned_by_campaign_id_fkey\" TO \"changesets_owned_by_batch_spec_id_fkey\";\nALTER TABLE changesets RENAME CONSTRAINT \"changesets_campaign_ids_check\" TO \"changesets_batch_change_ids_check\";",
				"DownQuery": "UPDATE user_credentials SET domain = 'campaigns' WHERE domain = 'batches';\nALTER TABLE IF EXISTS batch_specs RENAME TO campaign_specs;\nALTER TABLE IF EXISTS batch_changes RENAME TO campaigns;\nALTER TABLE IF EXISTS campaigns RENAME COLUMN batch_spec_id TO campaign_spec_id;\nALTER TABLE IF EXISTS changeset_specs RENAME COLUMN batch_spec_id TO campaign_spec_id;\nDROP VIEW IF EXISTS reconciler_changesets;\nDROP VIEW IF EXISTS branch_changeset_specs_and_changesets;\nDROP VIEW IF EXISTS tracking_changeset_specs_and_changesets;\nALTER TABLE IF EXISTS changesets RENAME COLUMN batch_change_ids TO campaign_ids;\nALTER TABLE IF EXISTS changesets RENAME COLUMN owned_by_batch_change_id TO owned_by_campaign_id;\nCREATE VIEW tracking_changeset_specs_and_changesets AS (\n    SELECT\n        changeset_specs.id AS changeset_spec_id,\n        COALESCE(changesets.id, 0::bigint) AS changeset_id,\n        changeset_specs.repo_id,\n        changeset_specs.campaign_spec_id,\n        repo.name AS repo_name,\n        COALESCE(changesets.metadata -\u003e\u003e 'Title'::text, changesets.metadata -\u003e\u003e 'title'::text) AS changeset_name,\n        changesets.external_state,\n        changesets.publication_state,\n        changesets.reconciler_state\n    FROM\n        changeset_specs\n    LEFT JOIN\n        changesets\n    ON\n        changesets.repo_id = changeset_specs.repo_id\n        AND\n        changesets.external_id = changeset_specs.external_id\n    JOIN\n        repo\n    ON\n        changeset_specs.repo_id = repo.id\n    WHERE\n        changeset_specs.external_id IS NOT NULL\n        AND\n        repo.deleted_at IS NULL\n);\nCREATE VIEW branch_changeset_specs_and_changesets AS (\n    SELECT\n        changeset_specs.id AS changeset_spec_id,\n        COALESCE(changesets.id, 0::bigint) AS changeset_id,\n        changeset_specs.repo_id,\n        changeset_specs.campaign_spec_id,\n        changesets.owned_by_campaign_id AS owner_campaign_id,\n        repo.name AS repo_name,\n        changeset_specs.title AS changeset_name,\n        changesets.external_state,\n        changesets.publication_state,\n        changesets.reconciler_state\n    FROM changeset_specs\n    LEFT JOIN\n        changesets\n    ON\n        changesets.repo_id = changeset_specs.repo_id\n        AND\n        changesets.current_spec_id IS NOT NULL\n        AND\n        EXISTS (\n            SELECT 1\n            FROM changeset_specs changeset_specs_1\n            WHERE\n                changeset_specs_1.id = changesets.current_spec_id\n                AND\n                changeset_specs_1.head_ref = changeset_specs.head_ref\n        )\n    JOIN\n        repo\n    ON\n        changeset_specs.repo_id = repo.id\n    WHERE\n        changeset_specs.external_id IS NULL\n        AND\n        repo.deleted_at IS NULL\n);\nCREATE VIEW reconciler_changesets AS\n    SELECT c.* FROM changesets c\n    INNER JOIN repo r on r.id = c.repo_id\n    WHERE\n        r.deleted_at IS NULL AND\n        EXISTS (\n            SELECT 1 FROM campaigns\n            LEFT JOIN users namespace_user ON campaigns.namespace_user_id = namespace_user.id\n            LEFT JOIN orgs namespace_org ON campaigns.namespace_org_id = namespace_org.id\n            WHERE\n                c.campaign_ids ? campaigns.id::text AND\n                namespace_user.deleted_at IS NULL AND\n                namespace_org.deleted_at IS NULL\n        )\n;\nDROP TRIGGER IF EXISTS trig_delete_batch_change_reference_on_changesets ON campaigns;\nDROP FUNCTION IF EXISTS delete_batch_change_reference_on_changesets();\nCREATE FUNCTION delete_campaign_reference_on_changesets() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$\n    BEGIN\n        UPDATE\n          changesets\n        SET\n          batch_change_ids = changesets.batch_change_ids - OLD.id::text\n        WHERE\n          changesets.batch_change_ids ? OLD.id::text;\n\n        RETURN OLD;\n    END;\n$$;\nCREATE TRIGGER trig_delete_campaign_reference_on_changesets AFTER DELETE ON campaigns FOR EACH ROW EXECUTE PROCEDURE delete_campaign_reference_on_changesets();\nALTER SEQUENCE batch_changes_id_seq RENAME TO campaigns_id_seq;\nALTER SEQUENCE batch_specs_id_seq RENAME TO campaign_specs_id_seq;\nALTER TABLE campaigns RENAME CONSTRAINT \"batch_changes_batch_spec_id_fkey\" TO \"campaigns_campaign_spec_id_fkey\";\nALTER TABLE campaigns RENAME CONSTRAINT \"batch_changes_initial_applier_id_fkey\" TO \"campaigns_initial_applier_id_fkey\";\nALTER TABLE campaigns RENAME CONSTRAINT \"batch_changes_last_applier_id_fkey\" TO \"campaigns_last_applier_id_fkey\";\nALTER TABLE campaigns RENAME CONSTRAINT \"batch_changes_namespace_org_id_fkey\" TO \"campaigns_namespace_org_id_fkey\";\nALTER TABLE campaigns RENAME CONSTRAINT \"batch_changes_namespace_user_id_fkey\" TO \"campaigns_namespace_user_id_fkey\";\nALTER TABLE campaigns RENAME CONSTRAINT \"batch_changes_has_1_namespace\" TO \"campaigns_has_1_namespace\";\nALTER TABLE campaigns RENAME CONSTRAINT \"batch_changes_name_not_blank\" TO \"campaigns_name_not_blank\";\nALTER INDEX IF EXISTS batch_changes_pkey RENAME TO campaigns_pkey;\nALTER INDEX IF EXISTS batch_changes_namespace_org_id RENAME TO campaigns_namespace_org_id;\nALTER INDEX IF EXISTS batch_changes_namespace_user_id RENAME TO campaigns_namespace_user_id;\nALTER TABLE campaign_specs RENAME CONSTRAINT \"batch_specs_has_1_namespace\" TO \"campaign_specs_has_1_namespace\";\nALTER TABLE campaign_specs RENAME CONSTRAINT \"batch_specs_user_id_fkey\" TO \"campaign_specs_user_id_fkey\";\nALTER INDEX IF EXISTS batch_specs_pkey RENAME TO campaign_specs_pkey;\nALTER INDEX IF EXISTS batch_specs_rand_id RENAME TO campaign_specs_rand_id;\nALTER TABLE changeset_specs RENAME CONSTRAINT \"changeset_specs_batch_spec_id_fkey\" TO \"changeset_specs_campaign_spec_id_fkey\";\nALTER TABLE changesets RENAME CONSTRAINT \"changesets_owned_by_batch_spec_id_fkey\" TO \"changesets_owned_by_campaign_id_fkey\";\nALTER TABLE changesets RENAME CONSTRAINT \"changesets_batch_change_ids_check\" TO \"changesets_campaign_ids_check\";",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395793
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395795,
				"Name": "add clone status index to gitserver repos",
				"UpQuery": "CREATE INDEX IF NOT EXISTS gitserver_repos_clone_status_idx ON gitserver_repos (clone_status);",
				"DownQuery": "DROP INDEX IF EXISTS gitserver_repos_clone_status_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395794
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395796,
				"Name": "alter cloud default constraint",
				"UpQuery": "DROP INDEX IF EXISTS kind_cloud_default;\nCREATE UNIQUE INDEX IF NOT EXISTS kind_cloud_default ON external_services (kind, cloud_default)\n    WHERE cloud_default = true AND deleted_at IS NULL;",
				"DownQuery": "DROP INDEX IF EXISTS kind_cloud_default;\nCREATE UNIQUE INDEX IF NOT EXISTS kind_cloud_default ON external_services (kind, cloud_default)\n    WHERE cloud_default = true;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395795
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395797,
				"Name": "faster changeset lookups",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS changesets_batch_change_ids ON changesets USING GIN (batch_change_ids jsonb_ops);",
				"DownQuery": "DROP INDEX IF EXISTS changesets_batch_change_ids;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395796
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "changesets",
					"IndexName": "changesets_batch_change_ids"
				}
			},
			{
				"ID": 1528395798,
				"Name": "changeset title",
				"UpQuery": "-- Note that we have to regenerate the reconciler_changesets view, as the SELECT\n-- c.* in the view definition isn't refreshed when the fields change within the\n-- changesets table.\nDROP VIEW IF EXISTS\n    reconciler_changesets;\n\nALTER TABLE changesets ADD COLUMN IF NOT EXISTS external_title text;\nCOMMENT ON COLUMN changesets.external_title IS 'Normalized property generated on save using Changeset.Title()';\n\nUPDATE changesets SET external_title = COALESCE(changesets.metadata-\u003e\u003e'Title', changesets.metadata-\u003e\u003e'title', NULL);\n\nCREATE INDEX IF NOT EXISTS changesets_external_title_idx ON changesets USING BTREE(external_title);\n\nCREATE VIEW reconciler_changesets AS\n    SELECT c.* FROM changesets c\n    INNER JOIN repo r on r.id = c.repo_id\n    WHERE\n        r.deleted_at IS NULL AND\n        EXISTS (\n            SELECT 1 FROM batch_changes\n            LEFT JOIN users namespace_user ON batch_changes.namespace_user_id = namespace_user.id\n            LEFT JOIN orgs namespace_org ON batch_changes.namespace_org_id = namespace_org.id\n            WHERE\n                c.batch_change_ids ? batch_changes.id::text AND\n                namespace_user.deleted_at IS NULL AND\n                namespace_org.deleted_at IS NULL\n        )\n;",
				"DownQuery": "-- Note that we have to regenerate the reconciler_changesets view, as the SELECT\n-- c.* in the view definition isn't refreshed when the fields change within the\n-- changesets table.\nDROP VIEW IF EXISTS\n    reconciler_changesets;\n\nDROP INDEX IF EXISTS changesets_external_title_idx;\nALTER TABLE changesets DROP COLUMN IF EXISTS external_title;\n\nCREATE VIEW reconciler_changesets AS\n    SELECT c.* FROM changesets c\n    INNER JOIN repo r on r.id = c.repo_id\n    WHERE\n        r.deleted_at IS NULL AND\n        EXISTS (\n            SELECT 1 FROM batch_changes\n            LEFT JOIN users namespace_user ON batch_changes.namespace_user_id = namespace_user.id\n            LEFT JOIN orgs namespace_org ON batch_changes.namespace_org_id = namespace_org.id\n            WHERE\n                c.batch_change_ids ? batch_changes.id::text AND\n                namespace_user.deleted_at IS NULL AND\n                namespace_org.deleted_at IS NULL\n        )\n;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395797
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395799,
				"Name": "add clone status conditional indexes",
				"UpQuery": "-- Having three partial indexes should be faster since when the condition is met the index used will be\n-- smaller meaning it will be faster to scan.\nCREATE INDEX IF NOT EXISTS gitserver_repos_cloned_status_idx ON gitserver_repos (repo_id) WHERE clone_status = 'cloned';\nCREATE INDEX IF NOT EXISTS gitserver_repos_not_cloned_status_idx ON gitserver_repos (repo_id) WHERE clone_status = 'not_cloned';\nCREATE INDEX IF NOT EXISTS gitserver_repos_cloning_status_idx ON gitserver_repos (repo_id) WHERE clone_status = 'cloning';\n\nDROP INDEX IF EXISTS gitserver_repos_clone_status_idx;",
				"DownQuery": "DROP INDEX IF EXISTS gitserver_repos_cloned_status_idx;\nDROP INDEX IF EXISTS gitserver_repos_not_cloned_status_idx;\nDROP INDEX IF EXISTS gitserver_repos_cloning_status_idx;\nCREATE INDEX IF NOT EXISTS gitserver_repos_clone_status_idx ON gitserver_repos (repo_id);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395798
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395800,
				"Name": "add external service repos index",
				"UpQuery": "CREATE INDEX external_service_repos_idx ON external_service_repos(external_service_id, repo_id);",
				"DownQuery": "DROP INDEX IF EXISTS external_service_repos_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395799
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395801,
				"Name": "search contexts",
				"UpQuery": "CREATE TABLE IF NOT EXISTS search_contexts (\n    id BIGSERIAL PRIMARY KEY,\n    name citext NOT NULL,\n    description text NOT NULL,\n    public boolean NOT NULL,\n    namespace_user_id integer,\n    namespace_org_id integer,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    deleted_at timestamp with time zone,\n\n    CONSTRAINT search_contexts_has_one_or_no_namespace CHECK (((namespace_user_id IS NULL) OR (namespace_org_id IS NULL))),\n\n    CONSTRAINT search_contexts_namespace_user_id_fk\n        FOREIGN KEY (namespace_user_id)\n            REFERENCES users (id)\n            ON DELETE CASCADE,\n\n    CONSTRAINT search_contexts_namespace_org_id_fk\n        FOREIGN KEY (namespace_org_id)\n            REFERENCES orgs (id)\n            ON DELETE CASCADE\n);\n\nCREATE UNIQUE INDEX search_contexts_name_namespace_user_id_unique\n    ON search_contexts (name, namespace_user_id)\n    WHERE namespace_user_id IS NOT NULL;\n\nCREATE UNIQUE INDEX search_contexts_name_namespace_org_id_unique\n    ON search_contexts (name, namespace_org_id)\n    WHERE namespace_org_id IS NOT NULL;\n\nCREATE UNIQUE INDEX search_contexts_name_without_namespace_unique\n    ON search_contexts (name)\n    WHERE namespace_user_id IS NULL AND namespace_org_id IS NULL;\n\nCREATE TABLE IF NOT EXISTS search_context_repos (\n    search_context_id bigint NOT NULL,\n    repo_id integer NOT NULL,\n    revision text NOT NULL,\n\n    CONSTRAINT search_context_repos_search_context_id_fk\n        FOREIGN KEY (search_context_id)\n            REFERENCES search_contexts (id)\n            ON DELETE CASCADE,\n\n    CONSTRAINT search_context_repos_repo_id_fk\n        FOREIGN KEY (repo_id)\n            REFERENCES repo (id)\n            ON DELETE CASCADE,\n\n    CONSTRAINT search_context_repos_search_context_id_repo_id_revision_unique UNIQUE (search_context_id, repo_id, revision)\n);",
				"DownQuery": "DROP TABLE IF EXISTS search_context_repos;\n\nDROP TABLE IF EXISTS search_contexts;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395800
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395802,
				"Name": "external service config migration",
				"UpQuery": "INSERT INTO out_of_band_migrations (id, team, component, description, introduced, deprecated, non_destructive)\nVALUES (3, 'core-application', 'frontend-db.external-services', 'Encrypt configuration', '3.26.0', '3.27.0', true)\nON CONFLICT DO NOTHING;",
				"DownQuery": "-- Nothing to do.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395801
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395803,
				"Name": "drop trig soft delete orphan repo by external service repo",
				"UpQuery": "-- Drop trigger as we don't want it to fire anymore.\nDROP TRIGGER IF EXISTS trig_soft_delete_orphan_repo_by_external_service_repo ON external_service_repos;\nDROP FUNCTION IF EXISTS soft_delete_orphan_repo_by_external_service_repos() ;\n\n-- Rewrite the previous function as a standalone function.\n-- The function will be run manually whenever we delete an external service.\nCREATE FUNCTION soft_delete_orphan_repo_by_external_service_repos() RETURNS void\n    AS $$\nBEGIN\n    -- When an external service is soft or hard-deleted,\n    -- performs a clean up to soft-delete orphan repositories.\n    UPDATE\n        repo\n    SET\n        name = soft_deleted_repository_name(name),\n        deleted_at = transaction_timestamp()\n    WHERE\n      deleted_at IS NULL\n      AND NOT EXISTS (\n        SELECT FROM external_service_repos WHERE repo_id = repo.id\n      );\nEND;\n$$ LANGUAGE plpgsql;",
				"DownQuery": "DROP FUNCTION IF EXISTS soft_delete_orphan_repo_by_external_service_repos();\n\nCREATE FUNCTION soft_delete_orphan_repo_by_external_service_repos() RETURNS trigger\n    LANGUAGE plpgsql\nAS $$\nBEGIN\n    -- When an external service is soft or hard-deleted,\n    -- performs a clean up to soft-delete orphan repositories.\n    UPDATE\n        repo\n    SET\n        name = soft_deleted_repository_name(name),\n        deleted_at = transaction_timestamp()\n    WHERE\n      deleted_at IS NULL\n      AND NOT EXISTS (\n        SELECT FROM external_service_repos WHERE repo_id = repo.id\n    );\n\n    RETURN NULL;\nEND;\n$$;\n\nCREATE TRIGGER trig_soft_delete_orphan_repo_by_external_service_repo\n    AFTER DELETE ON external_service_repos\n    FOR EACH STATEMENT EXECUTE PROCEDURE soft_delete_orphan_repo_by_external_service_repos();",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395802
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395804,
				"Name": "batch changes site credentials",
				"UpQuery": "CREATE TABLE IF NOT EXISTS batch_changes_site_credentials (\n    id BIGSERIAL PRIMARY KEY,\n    external_service_type text NOT NULL,\n    external_service_id text NOT NULL,\n    credential text NOT NULL,\n    created_at timestamp with time zone NOT NULL DEFAULT now(),\n    updated_at timestamp with time zone NOT NULL DEFAULT now()\n);\n\nCREATE UNIQUE INDEX batch_changes_site_credentials_unique ON batch_changes_site_credentials(external_service_type, external_service_id);",
				"DownQuery": "DROP TABLE IF EXISTS batch_changes_site_credentials;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395803
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395805,
				"Name": "delete external service trigger",
				"UpQuery": "DROP TRIGGER IF EXISTS trig_delete_external_service_ref_on_external_service_repos\nON external_services;\n\nDROP FUNCTION IF EXISTS delete_external_service_ref_on_external_service_repos();",
				"DownQuery": "CREATE FUNCTION delete_external_service_ref_on_external_service_repos() RETURNS trigger\n    LANGUAGE plpgsql\nAS $$\nBEGIN\n    -- if an external service is soft-deleted, delete every row that references it\n    IF (OLD.deleted_at IS NULL AND NEW.deleted_at IS NOT NULL) THEN\n        DELETE FROM\n            external_service_repos\n        WHERE\n                external_service_id = OLD.id;\n    END IF;\n\n    RETURN OLD;\nEND;\n$$;\n\nCREATE TRIGGER trig_delete_external_service_ref_on_external_service_repos\n    AFTER UPDATE OF deleted_at ON external_services FOR EACH ROW EXECUTE PROCEDURE delete_external_service_ref_on_external_service_repos();",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395804
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395806,
				"Name": "add encryption key ident",
				"UpQuery": "ALTER TABLE user_external_accounts ADD COLUMN IF NOT EXISTS encryption_key_id text NOT NULL DEFAULT '';",
				"DownQuery": "ALTER TABLE user_external_accounts DROP COLUMN IF EXISTS encryption_key_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395805
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395807,
				"Name": "lsif locations migration",
				"UpQuery": "INSERT INTO out_of_band_migrations (id, team, component, description, introduced, non_destructive)\nVALUES (4, 'code-intelligence', 'codeintel-db.lsif_data_definitions', 'Populate num_locations from gob-encoded payload', '3.26.0', true)\nON CONFLICT DO NOTHING;\n\nINSERT INTO out_of_band_migrations (id, team, component, description, introduced, non_destructive)\nVALUES (5, 'code-intelligence', 'codeintel-db.lsif_data_references', 'Populate num_locations from gob-encoded payload', '3.26.0', true)\nON CONFLICT DO NOTHING;",
				"DownQuery": "-- Nothing to do.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395806
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395808,
				"Name": "add user id column to external service repos",
				"UpQuery": "ALTER TABLE external_service_repos ADD COLUMN user_id int REFERENCES users(id) ON DELETE CASCADE DEFERRABLE;\n\nUPDATE external_service_repos\nSET user_id = es.namespace_user_id\nFROM external_services es\nWHERE es.id = external_service_id AND es.namespace_user_id IS NOT NULL;\n\nCREATE INDEX external_service_user_repos_idx ON external_service_repos(user_id, repo_id) WHERE user_id IS NOT NULL;",
				"DownQuery": "DROP INDEX external_service_user_repos_idx;\nALTER TABLE external_service_repos DROP COLUMN user_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395807
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395809,
				"Name": "external account migration",
				"UpQuery": "INSERT INTO out_of_band_migrations (id, team, component, description, introduced, non_destructive)\nVALUES (6, 'core-application', 'frontend-db.external-accounts', 'Encrypt auth data', '3.26.0', true)\nON CONFLICT DO NOTHING;",
				"DownQuery": "-- Nothing to do.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395808
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395810,
				"Name": "split document payload",
				"UpQuery": "INSERT INTO out_of_band_migrations (id, team, component, description, introduced, non_destructive)\nVALUES (7, 'code-intelligence', 'codeintel-db.lsif_data_documents', 'Split payload into multiple columns', '3.27.0', false)\nON CONFLICT DO NOTHING;",
				"DownQuery": "-- Nothing to do.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395809
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395811,
				"Name": "add gitserver repos last error idx",
				"UpQuery": "CREATE INDEX IF NOT EXISTS\n    gitserver_repos_last_error_idx ON gitserver_repos(last_error) WHERE last_error IS NOT NULL;",
				"DownQuery": "DROP INDEX IF EXISTS gitserver_repos_last_error_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395810
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395812,
				"Name": "drop global state mgmt password columns",
				"UpQuery": "ALTER TABLE global_state\nDROP COLUMN IF EXISTS mgmt_password_plaintext,\nDROP COLUMN IF EXISTS mgmt_password_bcrypt;",
				"DownQuery": "ALTER TABLE global_state\nADD COLUMN IF NOT EXISTS mgmt_password_plaintext TEXT NOT NULL DEFAULT '',\nADD COLUMN IF NOT EXISTS mgmt_password_bcrypt TEXT NOT NULL DEFAULT '';",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395811
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395813,
				"Name": "gitserver repos add cascade delete",
				"UpQuery": "SET CONSTRAINTS ALL DEFERRED;\n\nALTER TABLE gitserver_repos\n    DROP CONSTRAINT gitserver_repos_repo_id_fkey,\n    ADD CONSTRAINT gitserver_repos_repo_id_fkey\n        FOREIGN KEY (repo_id)\n            REFERENCES repo (id)\n            ON DELETE CASCADE;",
				"DownQuery": "SET CONSTRAINTS ALL DEFERRED;\n\nALTER TABLE gitserver_repos\n    DROP CONSTRAINT gitserver_repos_repo_id_fkey,\n    ADD CONSTRAINT gitserver_repos_repo_id_fkey\n        FOREIGN KEY (repo_id)\n            REFERENCES repo (id);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395812
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395814,
				"Name": "add cascase delete on external service sync jobs",
				"UpQuery": "SET CONSTRAINTS ALL DEFERRED;\n\nALTER TABLE external_service_sync_jobs\n    DROP CONSTRAINT external_services_id_fk,\n    ADD CONSTRAINT external_services_id_fk\n        FOREIGN KEY (external_service_id)\n            REFERENCES external_services (id)\n            ON DELETE CASCADE;",
				"DownQuery": "SET CONSTRAINTS ALL DEFERRED;\n\nALTER TABLE external_service_sync_jobs\n    DROP CONSTRAINT external_services_id_fk,\n    ADD CONSTRAINT external_services_id_fk\n        FOREIGN KEY (external_service_id)\n            REFERENCES external_services (id);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395813
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395815,
				"Name": "undeprecate oob migrations",
				"UpQuery": "-- No out of band migrations should be marked as deprecated yet\n-- as we don't have any utilities in place to check whether or\n-- not migrations have yet completed.\n\nUPDATE out_of_band_migrations SET deprecated = NULL;",
				"DownQuery": "-- Nothing to do.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395814
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395816,
				"Name": "changeset bulk jobs table",
				"UpQuery": "CREATE TABLE IF NOT EXISTS changeset_jobs (\n    id BIGSERIAL PRIMARY KEY,\n    bulk_group text NOT NULL,\n    user_id integer NOT NULL REFERENCES users(id) ON DELETE CASCADE DEFERRABLE,\n    batch_change_id integer NOT NULL REFERENCES batch_changes(id) ON DELETE CASCADE DEFERRABLE,\n    changeset_id integer NOT NULL REFERENCES changesets(id) ON DELETE CASCADE DEFERRABLE,\n\n    job_type text NOT NULL,\n    payload jsonb DEFAULT '{}'::jsonb CHECK (jsonb_typeof(payload) = 'object'::text),\n\n    state text DEFAULT 'queued'::text,\n    failure_message text,\n    started_at timestamp with time zone,\n    finished_at timestamp with time zone,\n    process_after timestamp with time zone,\n    num_resets integer NOT NULL DEFAULT 0,\n    num_failures integer NOT NULL DEFAULT 0,\n    execution_logs json[],\n\n    created_at timestamp with time zone NOT NULL DEFAULT now(),\n    updated_at timestamp with time zone NOT NULL DEFAULT now()\n);",
				"DownQuery": "DROP TABLE IF EXISTS changeset_jobs;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395815
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395817,
				"Name": "lsif uploads committed at",
				"UpQuery": "ALTER TABLE lsif_uploads ADD COLUMN committed_at timestamp with time zone;\nCREATE INDEX lsif_uploads_committed_at ON lsif_uploads (committed_at) WHERE state = 'completed';\n\nINSERT INTO out_of_band_migrations (id, team, component, description, introduced, non_destructive)\nVALUES (8, 'code-intelligence', 'frontend-db.lsif_uploads', 'Backfill committed_at', '3.28.0', true)\nON CONFLICT DO NOTHING;",
				"DownQuery": "DROP INDEX lsif_uploads_committed_at;\nALTER TABLE lsif_uploads DROP COLUMN committed_at;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395816
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395818,
				"Name": "commit last checked at",
				"UpQuery": "ALTER TABLE lsif_uploads ADD COLUMN commit_last_checked_at timestamp with time zone;\nCREATE INDEX lsif_uploads_commit_last_checked_at ON lsif_uploads (commit_last_checked_at) WHERE state != 'deleted';\nALTER TABLE lsif_indexes ADD COLUMN commit_last_checked_at timestamp with time zone;\nCREATE INDEX lsif_indexes_commit_last_checked_at ON lsif_indexes (commit_last_checked_at) WHERE state != 'deleted';",
				"DownQuery": "DROP INDEX lsif_uploads_commit_last_checked_at;\nALTER TABLE lsif_uploads DROP COLUMN commit_last_checked_at;\nDROP INDEX lsif_indexes_commit_last_checked_at;\nALTER TABLE lsif_indexes DROP COLUMN commit_last_checked_at;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395817
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395819,
				"Name": "oob credential encryption",
				"UpQuery": "INSERT INTO out_of_band_migrations (id, team, component, description, introduced, non_destructive)\nVALUES (\n    9,                                          -- This must be consistent across all Sourcegraph instances\n    'batch-changes',                            -- Team owning migration\n    'frontend-db.user-credentials',             -- Component being migrated\n    'Encrypt batch changes user credentials',   -- Description\n    '3.28.0',                                   -- The next minor release\n    false                                       -- Can be read with previous version without down migration\n)\nON CONFLICT DO NOTHING;\n\nALTER TABLE\n    user_credentials\nADD COLUMN IF NOT EXISTS\n    credential_enc BYTEA NULL,\nADD COLUMN IF NOT EXISTS\n    ssh_migration_applied BOOLEAN NOT NULL DEFAULT FALSE,\nALTER COLUMN\n    credential DROP NOT NULL,\nDROP CONSTRAINT IF EXISTS\n    user_credentials_there_can_be_only_one,\nADD CONSTRAINT\n    user_credentials_there_can_be_only_one\n    CHECK\n    (num_nonnulls(credential, credential_enc) = 1);\n\n-- Calculate the ssh_migration_applied field using the same algorithm as the\n-- previous version of the SSH migrator.\nUPDATE\n    user_credentials\nSET\n    ssh_migration_applied = TRUE\nWHERE\n    credential IS NOT NULL\n    AND domain = 'batches'\n    AND (credential::json-\u003e'Type')::text NOT IN (\n        'BasicAuth',\n        'OAuthBearerToken'\n    );\n\n-- Create an index on credential_enc, since we want to quickly check its null\n-- state when calculating the progress of the OOB migration. Note that we can't\n-- apply an index to the actual field because it may be (and in many cases\n-- probably is) beyond the limit for a B-tree index.\nCREATE INDEX IF NOT EXISTS\n    user_credentials_credential_enc_idx\nON\n    user_credentials ((credential_enc IS NULL));",
				"DownQuery": "-- We need to leave the new column in place here for the OOB down migration, so\n-- no changes here.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395818
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395820,
				"Name": "changeset job indexes",
				"UpQuery": "-- Create an index on state, so the dbworker can fetch pending jobs faster.\nCREATE INDEX IF NOT EXISTS changeset_jobs_state_idx ON changeset_jobs USING BTREE(state);\n-- Create an index on the bulk_group column. We use this as sort of a second-line\n-- primary key, because the bulk_group entity doesn't really exist.\nCREATE INDEX IF NOT EXISTS changeset_jobs_bulk_group_idx ON changeset_jobs USING BTREE(bulk_group);",
				"DownQuery": "DROP INDEX IF EXISTS changeset_jobs_state_idx;\nDROP INDEX IF EXISTS changeset_jobs_bulk_group_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395819
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395821,
				"Name": "oob site credential encryption",
				"UpQuery": "INSERT INTO out_of_band_migrations (id, team, component, description, introduced, non_destructive)\nVALUES (\n    10,                                         -- This must be consistent across all Sourcegraph instances\n    'batch-changes',                            -- Team owning migration\n    'frontend-db.site-credentials',             -- Component being migrated\n    'Encrypt batch changes site credentials',   -- Description\n    '3.28.0',                                   -- The next minor release\n    false                                       -- Can be read with previous version without down migration\n)\nON CONFLICT DO NOTHING;\n\nALTER TABLE\n    batch_changes_site_credentials\nADD COLUMN IF NOT EXISTS\n    credential_enc BYTEA NULL,\nALTER COLUMN\n    credential DROP NOT NULL,\nDROP CONSTRAINT IF EXISTS\n    batch_changes_site_credentials_there_can_be_only_one,\nADD CONSTRAINT\n    batch_changes_site_credentials_there_can_be_only_one\n    CHECK\n    (num_nonnulls(credential, credential_enc) = 1);\n\n-- Create an index on credential_enc, since we want to quickly check its null\n-- state when calculating the progress of the OOB migration. Note that we can't\n-- apply an index to the actual field because it may be (and in many cases\n-- probably is) beyond the limit for a B-tree index.\nCREATE INDEX IF NOT EXISTS\n    batch_changes_site_credentials_credential_enc_idx\nON\n    batch_changes_site_credentials ((credential_enc IS NULL));",
				"DownQuery": "-- We need to leave the new column in place here for the OOB down migration, so\n-- no changes here.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395820
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395822,
				"Name": "track encryption key",
				"UpQuery": "-- We're going to unify the credential columns here. This means that we need to\n-- preserve the value in credential if the OOB migrator hasn't run since the\n-- previous credential migrations.\n--\n-- Since this will break the constraint we added previously, first we have to\n-- drop that.\n\nALTER TABLE\n    batch_changes_site_credentials\nADD COLUMN IF NOT EXISTS\n    encryption_key_id TEXT NOT NULL DEFAULT '',\nDROP CONSTRAINT IF EXISTS\n    batch_changes_site_credentials_there_can_be_only_one;\n\nALTER TABLE\n    user_credentials\nADD COLUMN IF NOT EXISTS\n    encryption_key_id TEXT NOT NULL DEFAULT '',\nDROP CONSTRAINT IF EXISTS\n    user_credentials_there_can_be_only_one;\n\n-- Previously upgraded credentials with encryption need a placeholder encryption\n-- ID so that we can replace it with a real one later in the OOB migrator.\n--\n-- Unfortunately, the lack of inline metadata means that we have to use a\n-- heuristic to determine if the credential was _actually_ encrypted or not.\n-- Practically speaking, this only matters for users who (a) enabled encryption\n-- for Batch Changes, and (b) ran a version of Sourcegraph between May 4 and May\n-- 6. That's only going to be two developers on the Batch Changes team, so this\n-- leaky heuristic should be fine.\n\nUPDATE\n    batch_changes_site_credentials\nSET\n    encryption_key_id = 'previously-migrated'\nWHERE\n    credential_enc IS NOT NULL\n    AND NOT (\n        LEFT(ENCODE(credential_enc, 'escape'), 1) = '{'\n        AND RIGHT(ENCODE(credential_enc, 'escape'), 1) = '}'\n    );\n\nUPDATE\n    user_credentials\nSET\n    encryption_key_id = 'previously-migrated'\nWHERE\n    credential_enc IS NOT NULL\n    AND NOT (\n        LEFT(ENCODE(credential_enc, 'escape'), 1) = '{'\n        AND RIGHT(ENCODE(credential_enc, 'escape'), 1) = '}'\n    );\n\n-- Now we shift credentials into the new field.\n\nUPDATE\n    batch_changes_site_credentials\nSET\n    credential_enc = CONVERT_TO(credential, 'UTF8')\nWHERE\n    credential_enc IS NULL;\n\nUPDATE\n    user_credentials\nSET\n    credential_enc = CONVERT_TO(credential, 'UTF8')\nWHERE\n    credential_enc IS NULL;\n\n-- And finally we can rename the field and update the indexes on the tables.\n\nDROP INDEX IF EXISTS\n    batch_changes_site_credentials_credential_enc_idx,\n    batch_changes_site_credentials_credential_idx,\n    user_credentials_credential_enc_idx,\n    user_credentials_credential_idx;\n\nALTER TABLE\n    batch_changes_site_credentials\nDROP COLUMN IF EXISTS\n    credential,\nALTER COLUMN\n    credential_enc SET NOT NULL;\n\nALTER TABLE\n    batch_changes_site_credentials\nRENAME COLUMN\n    credential_enc TO credential;\n\nALTER TABLE\n    user_credentials\nDROP COLUMN IF EXISTS\n    credential,\nALTER COLUMN\n    credential_enc SET NOT NULL;\n\nALTER TABLE\n    user_credentials\nRENAME COLUMN\n    credential_enc TO credential;\n\nCREATE INDEX IF NOT EXISTS\n    batch_changes_site_credentials_credential_idx\nON\n    batch_changes_site_credentials ((encryption_key_id IN ('', 'previously-migrated')));\n\nCREATE INDEX IF NOT EXISTS\n    user_credentials_credential_idx\nON\n    user_credentials ((encryption_key_id IN ('', 'previously-migrated')));",
				"DownQuery": "-- Where we're going, we don't need indexes. (Yet.)\n\nDROP INDEX IF EXISTS\n    batch_changes_site_credentials_credential_enc_idx,\n    batch_changes_site_credentials_credential_idx,\n    user_credentials_credential_enc_idx,\n    user_credentials_credential_idx;\n\n-- Reinstate the old credential field.\n\nALTER TABLE\n    batch_changes_site_credentials\nRENAME COLUMN\n    credential TO credential_enc;\n\nALTER TABLE\n    batch_changes_site_credentials\nADD COLUMN IF NOT EXISTS\n    credential TEXT NULL DEFAULT NULL,\nALTER COLUMN\n    credential_enc DROP NOT NULL,\nDROP CONSTRAINT IF EXISTS\n    batch_changes_site_credentials_there_can_be_only_one,\nADD CONSTRAINT\n    batch_changes_site_credentials_there_can_be_only_one\n    CHECK\n    (num_nonnulls(credential, credential_enc) = 1);\n\nALTER TABLE\n    user_credentials\nRENAME COLUMN\n    credential TO credential_enc;\n\nALTER TABLE\n    user_credentials\nADD COLUMN IF NOT EXISTS\n    credential TEXT NULL DEFAULT NULL,\nALTER COLUMN\n    credential_enc DROP NOT NULL,\nDROP CONSTRAINT IF EXISTS\n    user_credentials_there_can_be_only_one,\nADD CONSTRAINT\n    user_credentials_there_can_be_only_one\n    CHECK\n    (num_nonnulls(credential, credential_enc) = 1);\n\nUPDATE\n    batch_changes_site_credentials\nSET\n    credential = ENCODE(credential_enc, 'escape'),\n    credential_enc = NULL\nWHERE\n    encryption_key_id = '';\n\nUPDATE\n    user_credentials\nSET\n    credential = ENCODE(credential_enc, 'escape'),\n    credential_enc = NULL\nWHERE\n    encryption_key_id = '';\n\n-- Put the indexes back.\n\nCREATE INDEX IF NOT EXISTS\n    user_credentials_credential_enc_idx\nON\n    user_credentials ((credential_enc IS NULL));\n\nCREATE INDEX IF NOT EXISTS\n    batch_changes_site_credentials_credential_enc_idx\nON\n    batch_changes_site_credentials ((credential_enc IS NULL));\n\n-- Get rid of the new encryption_key_id field.\n\nALTER TABLE\n    batch_changes_site_credentials\nDROP COLUMN IF EXISTS\n    encryption_key_id;\n\nALTER TABLE\n    user_credentials\nDROP COLUMN IF EXISTS\n    encryption_key_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395821
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395823,
				"Name": "feature flags",
				"UpQuery": "CREATE TYPE feature_flag_type AS ENUM ('bool', 'rollout');\n\nCREATE TABLE IF NOT EXISTS feature_flags (\n\tflag_name text NOT NULL PRIMARY KEY,\n\tflag_type feature_flag_type NOT NULL,\n\tbool_value boolean,\n\trollout integer CHECK (rollout \u003e= 0 AND rollout \u003c= 10000),\n\n\tcreated_at timestamp with time zone DEFAULT now() NOT NULL,\n\tupdated_at timestamp with time zone DEFAULT now() NOT NULL,\n\tdeleted_at timestamp with time zone,\n\n\tCONSTRAINT required_bool_fields\tCHECK ( 1 = CASE\n\t\tWHEN flag_type = 'bool' AND bool_value IS NULL THEN 0\n\t\tWHEN flag_type \u003c\u003e 'bool' AND bool_value IS NOT NULL THEN 0\n\t\tELSE 1\n\tEND),\n\n\tCONSTRAINT required_rollout_fields CHECK (1 = CASE\n\t\tWHEN flag_type = 'rollout' AND rollout IS NULL THEN 0\n\t\tWHEN flag_type \u003c\u003e 'rollout' AND rollout IS NOT NULL THEN 0\n\t\tELSE 1\n\tEND)\n);\n\nCOMMENT ON COLUMN feature_flags.bool_value IS 'Bool value only defined when flag_type is bool';\nCOMMENT ON COLUMN feature_flags.rollout IS 'Rollout only defined when flag_type is rollout. Increments of 0.01%';\nCOMMENT ON CONSTRAINT required_bool_fields ON feature_flags IS 'Checks that bool_value is set IFF flag_type = bool';\nCOMMENT ON CONSTRAINT required_rollout_fields ON feature_flags IS 'Checks that rollout is set IFF flag_type = rollout';\n\nCREATE TABLE IF NOT EXISTS feature_flag_overrides (\n\tnamespace_org_id integer,\n\tnamespace_user_id integer,\n\tflag_name text NOT NULL,\n\tflag_value boolean NOT NULL,\n\tcreated_at timestamp with time zone DEFAULT now() NOT NULL,\n\tupdated_at timestamp with time zone DEFAULT now() NOT NULL,\n\tdeleted_at timestamp with time zone,\n\n\tCONSTRAINT feature_flag_overrides_unique_user_flag \n\t\tUNIQUE (namespace_user_id, flag_name),\n\n\tCONSTRAINT feature_flag_overrides_unique_org_flag \n\t\tUNIQUE (namespace_org_id, flag_name),\n\n\tCONSTRAINT feature_flag_overrides_has_org_or_user_id CHECK(\n\t\t(namespace_org_id IS NOT NULL) OR (namespace_user_id IS NOT NULL)),\n\n\tFOREIGN KEY (flag_name) REFERENCES feature_flags (flag_name) ON DELETE CASCADE,\n\tFOREIGN KEY (namespace_org_id) REFERENCES orgs (id) ON DELETE CASCADE,\n\tFOREIGN KEY (namespace_user_id) REFERENCES users (id) ON DELETE CASCADE\n);\n\nCREATE INDEX feature_flag_overrides_org_id\n\tON feature_flag_overrides (namespace_org_id)\n\tWHERE namespace_org_id IS NOT NULL;\n\nCREATE INDEX feature_flag_overrides_user_id\n\tON feature_flag_overrides (namespace_user_id)\n\tWHERE namespace_user_id IS NOT NULL;",
				"DownQuery": "DROP TABLE IF EXISTS feature_flag_overrides;\n\nDROP TABLE IF EXISTS feature_flags;\n\nDROP TYPE feature_flag_type;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395822
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395824,
				"Name": "fix lsif upload state casing",
				"UpQuery": "UPDATE lsif_uploads SET state = 'deleted' WHERE state = 'DELETED';",
				"DownQuery": "-- Nothing to do",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395823
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395825,
				"Name": "add upload dependency indexing jobs",
				"UpQuery": "CREATE TABLE lsif_dependency_indexing_jobs (\n    id serial PRIMARY KEY,\n    state text DEFAULT 'queued' NOT NULL,\n    failure_message text,\n    queued_at timestamp with time zone DEFAULT NOW() NOT NULL,\n    started_at timestamp with time zone,\n    finished_at timestamp with time zone,\n    process_after timestamp with time zone,\n    num_resets integer DEFAULT 0 NOT NULL,\n    num_failures integer DEFAULT 0 NOT NULL,\n    execution_logs json[],\n    upload_id integer REFERENCES lsif_uploads(id) ON DELETE CASCADE\n);\n\nCOMMENT ON TABLE lsif_dependency_indexing_jobs IS 'Tracks jobs that scan imports of indexes to schedule auto-index jobs.';\nCOMMENT ON COLUMN lsif_dependency_indexing_jobs.upload_id IS 'The identifier of the triggering upload record.';",
				"DownQuery": "DROP TABLE lsif_dependency_indexing_jobs;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395824
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395826,
				"Name": "track first version",
				"UpQuery": "ALTER TABLE versions ADD COLUMN first_version text;\nUPDATE versions set first_version = version;\nALTER TABLE versions ALTER COLUMN first_version SET NOT NULL;",
				"DownQuery": "ALTER TABLE versions DROP COLUMN first_version;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395825
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395827,
				"Name": "oob enterprise flag",
				"UpQuery": "-- Add enterprise flag to out of band migrations so we know what to ignore in OSS\n-- If we don't run the migrators but the progress for the enterprise migration\n-- record stays at 0% it will block all upgrades after the migration deprecation.\n\nALTER TABLE out_of_band_migrations ADD COLUMN is_enterprise boolean DEFAULT false;\nUPDATE out_of_band_migrations SET is_enterprise = true WHERE id NOT IN (3, 6);\nALTER TABLE out_of_band_migrations ALTER COLUMN is_enterprise SET NOT NULL;\n\nCOMMENT ON COLUMN out_of_band_migrations.is_enterprise IS 'When true, these migrations are invisible to OSS mode.';",
				"DownQuery": "ALTER TABLE out_of_band_migrations DROP COLUMN is_enterprise;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395826
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395828,
				"Name": "split oob version columns",
				"UpQuery": "--\n-- Switch out introduced column\n\nALTER TABLE out_of_band_migrations ADD COLUMN introduced_version_major int;\nALTER TABLE out_of_band_migrations ADD COLUMN introduced_version_minor int;\n\nWITH t(id, parts) AS (\n    SELECT\n        id,\n        regexp_matches(introduced, E'^(\\\\d+)\\.(\\\\d+)')\n    FROM\n        out_of_band_migrations\n)\nUPDATE out_of_band_migrations SET\n    introduced_version_major = parts[1]::int,\n    introduced_version_minor = parts[2]::int\nFROM t WHERE t.id = out_of_band_migrations.id;\n\nALTER TABLE out_of_band_migrations ALTER COLUMN introduced_version_major SET NOT NULL;\nALTER TABLE out_of_band_migrations ALTER COLUMN introduced_version_minor SET NOT NULL;\nALTER TABLE out_of_band_migrations DROP COLUMN introduced;\n\n--\n-- Switch out deprecation column (keep nullable, no data exists yet)\n\nALTER TABLE out_of_band_migrations ADD COLUMN deprecated_version_major int;\nALTER TABLE out_of_band_migrations ADD COLUMN deprecated_version_minor int;\nALTER TABLE out_of_band_migrations DROP COLUMN deprecated;\n\nCOMMENT ON COLUMN out_of_band_migrations.introduced_version_major IS 'The Sourcegraph version (major component) in which this migration was first introduced.';\nCOMMENT ON COLUMN out_of_band_migrations.introduced_version_minor IS 'The Sourcegraph version (minor component) in which this migration was first introduced.';\nCOMMENT ON COLUMN out_of_band_migrations.deprecated_version_major IS 'The lowest Sourcegraph version (major component) that assumes the migration has completed.';\nCOMMENT ON COLUMN out_of_band_migrations.deprecated_version_minor IS 'The lowest Sourcegraph version (minor component) that assumes the migration has completed.';",
				"DownQuery": "ALTER TABLE out_of_band_migrations ADD COLUMN introduced text;\nUPDATE out_of_band_migrations SET introduced = concat(introduced_version_major, '.', introduced_version_minor);\nALTER TABLE out_of_band_migrations ALTER COLUMN introduced SET NOT NULL;\nALTER TABLE out_of_band_migrations DROP COLUMN introduced_version_major;\nALTER TABLE out_of_band_migrations DROP COLUMN introduced_version_minor;\n\nALTER TABLE out_of_band_migrations ADD COLUMN deprecated text;\nUPDATE out_of_band_migrations SET deprecated = concat(deprecated_version_major, '.', deprecated_version_minor) WHERE deprecated_version_major IS NOT NULL;\nALTER TABLE out_of_band_migrations DROP COLUMN deprecated_version_major;\nALTER TABLE out_of_band_migrations DROP COLUMN deprecated_version_minor;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395827
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395829,
				"Name": "first version trigger",
				"UpQuery": "CREATE OR REPLACE FUNCTION versions_insert_row_trigger() RETURNS trigger LANGUAGE plpgsql AS $lang$\nBEGIN\n    NEW.first_version = NEW.version;\n    RETURN NEW;\nEND $lang$;\n\nCREATE TRIGGER versions_insert BEFORE INSERT ON versions FOR EACH ROW EXECUTE PROCEDURE versions_insert_row_trigger();",
				"DownQuery": "DROP TRIGGER versions_insert ON versions;\nDROP FUNCTION versions_insert_row_trigger;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395828
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395830,
				"Name": "index associated index id",
				"UpQuery": "CREATE INDEX lsif_uploads_associated_index_id ON lsif_uploads(associated_index_id);",
				"DownQuery": "DROP INDEX lsif_uploads_associated_index_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395829
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395831,
				"Name": "add stars column to repo",
				"UpQuery": "ALTER TABLE repo ADD COLUMN IF NOT EXISTS stars int;\n\nUPDATE repo SET stars = (metadata-\u003e\u003e'StargazerCount')::int\nWHERE external_service_type = 'github'\nAND stars IS NULL\nAND metadata ? 'StargazerCount';\n\nCREATE INDEX IF NOT EXISTS repo_stars_idx ON repo USING BTREE (stars DESC NULLS LAST);",
				"DownQuery": "DROP INDEX IF EXISTS repo_stars_idx;\n\nALTER TABLE repo DROP COLUMN IF EXISTS stars;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395830
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395832,
				"Name": "create security event logs sql",
				"UpQuery": "CREATE TABLE IF NOT EXISTS security_event_logs (\n    id                BIGSERIAL PRIMARY KEY,\n    name              TEXT      NOT NULL,\n    url               TEXT      NOT NULL,\n    user_id           INTEGER   NOT NULL,\n    anonymous_user_id TEXT      NOT NULL,\n    source            TEXT      NOT NULL,\n    argument          JSONB     NOT NULL,\n    version           TEXT      NOT NULL,\n    \"timestamp\"       TIMESTAMP WITH TIME ZONE NOT NULL,\n\n    CONSTRAINT security_event_logs_check_has_user          CHECK ((((user_id = 0) AND (anonymous_user_id \u003c\u003e ''::text)) OR ((user_id \u003c\u003e 0) AND (anonymous_user_id = ''::text)) OR ((user_id \u003c\u003e 0) AND (anonymous_user_id \u003c\u003e ''::text)))),\n    CONSTRAINT security_event_logs_check_name_not_empty    CHECK ((name \u003c\u003e ''::text)),\n    CONSTRAINT security_event_logs_check_source_not_empty  CHECK ((source \u003c\u003e ''::text)),\n    CONSTRAINT security_event_logs_check_version_not_empty CHECK ((version \u003c\u003e ''::text))\n);\n\nCREATE INDEX security_event_logs_user_id           ON security_event_logs USING btree (user_id);\nCREATE INDEX security_event_logs_anonymous_user_id ON security_event_logs USING btree (anonymous_user_id);\nCREATE INDEX security_event_logs_name              ON security_event_logs USING btree (name);\nCREATE INDEX security_event_logs_source            ON security_event_logs USING btree (source);\nCREATE INDEX security_event_logs_timestamp         ON security_event_logs USING btree (\"timestamp\");\nCREATE INDEX security_event_logs_timestamp_at_utc  ON security_event_logs USING btree (date(timezone('UTC'::text, \"timestamp\")));\n\nCOMMENT ON TABLE  security_event_logs                   IS 'Contains security-relevant events with a long time horizon for storage.';\nCOMMENT ON COLUMN security_event_logs.name              IS 'The event name as a CAPITALIZED_SNAKE_CASE string.';\nCOMMENT ON COLUMN security_event_logs.url               IS 'The URL within the Sourcegraph app which generated the event.';\nCOMMENT ON COLUMN security_event_logs.user_id           IS 'The ID of the actor associated with the event.';\nCOMMENT ON COLUMN security_event_logs.anonymous_user_id IS 'The UUID of the actor associated with the event.';\nCOMMENT ON COLUMN security_event_logs.source            IS 'The site section (WEB, BACKEND, etc.) that generated the event.';\nCOMMENT ON COLUMN security_event_logs.argument          IS 'An arbitrary JSON blob containing event data.';\nCOMMENT ON COLUMN security_event_logs.version           IS 'The version of Sourcegraph which generated the event.';",
				"DownQuery": "DROP TABLE IF EXISTS security_event_logs;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395831
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395833,
				"Name": "feature flag events",
				"UpQuery": "ALTER TABLE event_logs\nADD COLUMN feature_flags jsonb;",
				"DownQuery": "ALTER TABLE event_logs\nDROP COLUMN feature_flags;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395832
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395834,
				"Name": "add autoindex enable",
				"UpQuery": "ALTER TABLE lsif_index_configuration\n  ADD COLUMN \"autoindex_enabled\" BOOLEAN NOT NULL DEFAULT TRUE;\n\nCOMMENT ON COLUMN lsif_index_configuration.autoindex_enabled IS 'Whether or not auto-indexing should be attempted on this repo. Index jobs may be inferred from the repository contents if data is empty.';",
				"DownQuery": "ALTER TABLE lsif_index_configuration\n  DROP COLUMN IF EXISTS \"autoindex_enabled\";",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395833
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395835,
				"Name": "cohort id",
				"UpQuery": "ALTER TABLE event_logs\nADD COLUMN cohort_id date;",
				"DownQuery": "ALTER TABLE event_logs\nDROP COLUMN cohort_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395834
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395836,
				"Name": "dbworkers worker hostname",
				"UpQuery": "-- Note that we have to regenerate the reconciler_changesets view, as the SELECT\n-- c.* in the view definition isn't refreshed when the fields change within the\n-- changesets table.\nDROP VIEW IF EXISTS\n    reconciler_changesets;\n\nALTER TABLE changesets ADD COLUMN IF NOT EXISTS worker_hostname text NOT NULL DEFAULT '';\n\nCREATE VIEW reconciler_changesets AS\n    SELECT c.* FROM changesets c\n    INNER JOIN repo r on r.id = c.repo_id\n    WHERE\n        r.deleted_at IS NULL AND\n        EXISTS (\n            SELECT 1 FROM batch_changes\n            LEFT JOIN users namespace_user ON batch_changes.namespace_user_id = namespace_user.id\n            LEFT JOIN orgs namespace_org ON batch_changes.namespace_org_id = namespace_org.id\n            WHERE\n                c.batch_change_ids ? batch_changes.id::text AND\n                namespace_user.deleted_at IS NULL AND\n                namespace_org.deleted_at IS NULL\n        )\n;\n\nALTER TABLE changeset_jobs ADD COLUMN worker_hostname text NOT NULL DEFAULT '';\nALTER TABLE cm_action_jobs ADD COLUMN IF NOT EXISTS worker_hostname text NOT NULL DEFAULT '';\nALTER TABLE cm_trigger_jobs ADD COLUMN IF NOT EXISTS worker_hostname text NOT NULL DEFAULT '';\nALTER TABLE external_service_sync_jobs ADD COLUMN IF NOT EXISTS worker_hostname text NOT NULL DEFAULT '';\nALTER TABLE insights_query_runner_jobs ADD COLUMN IF NOT EXISTS worker_hostname text NOT NULL DEFAULT '';\nALTER TABLE lsif_dependency_indexing_jobs ADD COLUMN IF NOT EXISTS worker_hostname text NOT NULL DEFAULT '';\nALTER TABLE lsif_indexes ADD COLUMN IF NOT EXISTS worker_hostname text NOT NULL DEFAULT '';\nALTER TABLE lsif_uploads ADD COLUMN IF NOT EXISTS worker_hostname text NOT NULL DEFAULT '';",
				"DownQuery": "-- Note that we have to regenerate the reconciler_changesets view, as the SELECT\n-- c.* in the view definition isn't refreshed when the fields change within the\n-- changesets table.\nDROP VIEW IF EXISTS\n    reconciler_changesets;\n\nALTER TABLE changesets DROP COLUMN IF EXISTS worker_hostname;\n\nCREATE VIEW reconciler_changesets AS\n    SELECT c.* FROM changesets c\n    INNER JOIN repo r on r.id = c.repo_id\n    WHERE\n        r.deleted_at IS NULL AND\n        EXISTS (\n            SELECT 1 FROM batch_changes\n            LEFT JOIN users namespace_user ON batch_changes.namespace_user_id = namespace_user.id\n            LEFT JOIN orgs namespace_org ON batch_changes.namespace_org_id = namespace_org.id\n            WHERE\n                c.batch_change_ids ? batch_changes.id::text AND\n                namespace_user.deleted_at IS NULL AND\n                namespace_org.deleted_at IS NULL\n        )\n;\n\nALTER TABLE changeset_jobs DROP COLUMN IF EXISTS worker_hostname;\nALTER TABLE cm_action_jobs DROP COLUMN IF EXISTS worker_hostname;\nALTER TABLE cm_trigger_jobs DROP COLUMN IF EXISTS worker_hostname;\nALTER TABLE external_service_sync_jobs DROP COLUMN IF EXISTS worker_hostname;\nALTER TABLE insights_query_runner_jobs DROP COLUMN IF EXISTS worker_hostname;\nALTER TABLE lsif_dependency_indexing_jobs DROP COLUMN IF EXISTS worker_hostname;\nALTER TABLE lsif_indexes DROP COLUMN IF EXISTS worker_hostname;\nALTER TABLE lsif_uploads DROP COLUMN IF EXISTS worker_hostname;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395835
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395837,
				"Name": "mark unmigrated credentials",
				"UpQuery": "-- Previously, we conflated unmigrated user and site credentials with\n-- unencrypted ones. Instead, we should separate these states with a placeholder\n-- so the out of band migration responsible for encrypting credentials reports\n-- its progress correctly.\n\nUPDATE\n    user_credentials\nSET\n    encryption_key_id = 'unmigrated'\nWHERE\n    encryption_key_id = '';\n\nUPDATE\n    batch_changes_site_credentials\nSET\n    encryption_key_id = 'unmigrated'\nWHERE\n    encryption_key_id = '';",
				"DownQuery": "UPDATE\n    user_credentials\nSET\n    encryption_key_id = ''\nWHERE\n    encryption_key_id = 'unmigrated';\n\nUPDATE\n    batch_changes_site_credentials\nSET\n    encryption_key_id = ''\nWHERE\n    encryption_key_id = 'unmigrated';",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395836
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395838,
				"Name": "add blocked column to repo table",
				"UpQuery": "ALTER TABLE IF EXISTS repo ADD COLUMN blocked jsonb;\n\nCREATE OR REPLACE FUNCTION repo_block(reason text, at timestamptz) RETURNS jsonb AS\n$$\nSELECT jsonb_build_object(\n    'reason', reason,\n    'at', extract(epoch from timezone('utc', at))::bigint\n);\n$$ LANGUAGE SQL STRICT IMMUTABLE;\n\nCREATE INDEX repo_blocked_idx ON repo USING BTREE ((blocked IS NOT NULL));\nCREATE INDEX repo_is_not_blocked_idx ON repo USING BTREE ((blocked IS NULL));",
				"DownQuery": "DROP INDEX IF EXISTS repo_is_blocked_idx;\nDROP INDEX IF EXISTS repo_is_not_blocked_idx;\n\nDROP FUNCTION IF EXISTS repo_block;\n\nALTER TABLE IF EXISTS repo DROP COLUMN IF EXISTS blocked;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395837
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395839,
				"Name": "ui publish state",
				"UpQuery": "CREATE TYPE\n    batch_changes_changeset_ui_publication_state\nAS ENUM (\n    'UNPUBLISHED',\n    'DRAFT',\n    'PUBLISHED'\n);\n\n-- Note that we have to regenerate the reconciler_changesets view, as the SELECT\n-- c.* in the view definition isn't refreshed when the fields change within the\n-- changesets table.\nDROP VIEW IF EXISTS\n    reconciler_changesets;\n\nALTER TABLE\n    changesets\nADD COLUMN IF NOT EXISTS\n    ui_publication_state batch_changes_changeset_ui_publication_state NULL DEFAULT NULL;\n\nCREATE VIEW reconciler_changesets AS\n    SELECT c.* FROM changesets c\n    INNER JOIN repo r on r.id = c.repo_id\n    WHERE\n        r.deleted_at IS NULL AND\n        EXISTS (\n            SELECT 1 FROM batch_changes\n            LEFT JOIN users namespace_user ON batch_changes.namespace_user_id = namespace_user.id\n            LEFT JOIN orgs namespace_org ON batch_changes.namespace_org_id = namespace_org.id\n            WHERE\n                c.batch_change_ids ? batch_changes.id::text AND\n                namespace_user.deleted_at IS NULL AND\n                namespace_org.deleted_at IS NULL\n        )\n;",
				"DownQuery": "-- Note that we have to regenerate the reconciler_changesets view, as the SELECT\n-- c.* in the view definition isn't refreshed when the fields change within the\n-- changesets table.\nDROP VIEW IF EXISTS\n    reconciler_changesets;\n\nALTER TABLE\n    changesets\nDROP COLUMN IF EXISTS\n    ui_publication_state;\n\nDROP TYPE IF EXISTS\n    batch_changes_changeset_ui_publication_state;\n\nCREATE VIEW reconciler_changesets AS\n    SELECT c.* FROM changesets c\n    INNER JOIN repo r on r.id = c.repo_id\n    WHERE\n        r.deleted_at IS NULL AND\n        EXISTS (\n            SELECT 1 FROM batch_changes\n            LEFT JOIN users namespace_user ON batch_changes.namespace_user_id = namespace_user.id\n            LEFT JOIN orgs namespace_org ON batch_changes.namespace_org_id = namespace_org.id\n            WHERE\n                c.batch_change_ids ? batch_changes.id::text AND\n                namespace_user.deleted_at IS NULL AND\n                namespace_org.deleted_at IS NULL\n        )\n;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395838
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395840,
				"Name": "create sg service role",
				"UpQuery": "-- We encountered performance issues for our use cases when we deployed\n-- RLS to production. We made the decision to back that approach out and\n-- solve the security concerns in application-level code instead.\n--\n-- ref migrations/frontend/1528395860_remove_repo_table_policy.up.sql\n-- ref migrations/frontend/1528395861_remove_sg_service_grants.up.sql\n-- ref migrations/frontend/1528395862_remove_sg_service_role.up.sql",
				"DownQuery": "-- We encountered performance issues for our use cases when we deployed\n-- RLS to production. We made the decision to back that approach out and\n-- solve the security concerns in application-level code instead.\n--\n-- ref migrations/frontend/1528395860_remove_repo_table_policy.up.sql\n-- ref migrations/frontend/1528395861_remove_sg_service_grants.up.sql\n-- ref migrations/frontend/1528395862_remove_sg_service_role.up.sql",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395839
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395841,
				"Name": "add repo table policy",
				"UpQuery": "-- We encountered performance issues for our use cases when we deployed\n-- RLS to production. We made the decision to back that approach out and\n-- solve the security concerns in application-level code instead.\n--\n-- ref migrations/frontend/1528395860_remove_repo_table_policy.up.sql\n-- ref migrations/frontend/1528395861_remove_sg_service_grants.up.sql\n-- ref migrations/frontend/1528395862_remove_sg_service_role.up.sql",
				"DownQuery": "-- We encountered performance issues for our use cases when we deployed\n-- RLS to production. We made the decision to back that approach out and\n-- solve the security concerns in application-level code instead.\n--\n-- ref migrations/frontend/1528395860_remove_repo_table_policy.up.sql\n-- ref migrations/frontend/1528395861_remove_sg_service_grants.up.sql\n-- ref migrations/frontend/1528395862_remove_sg_service_role.up.sql",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395840
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395842,
				"Name": "add settings user id index",
				"UpQuery": "CREATE INDEX IF NOT EXISTS settings_user_id_idx ON settings USING BTREE (user_id);",
				"DownQuery": "DROP INDEX IF EXISTS settings_user_id_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395841
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395843,
				"Name": "batch spec executions table",
				"UpQuery": "CREATE TABLE IF NOT EXISTS batch_spec_executions (\n  id              BIGSERIAL PRIMARY KEY,\n  state           TEXT DEFAULT 'queued',\n  failure_message TEXT,\n  started_at      TIMESTAMP WITH TIME ZONE,\n  finished_at     TIMESTAMP WITH TIME ZONE,\n  process_after   TIMESTAMP WITH TIME ZONE,\n  num_resets      INTEGER NOT NULL DEFAULT 0,\n  num_failures    INTEGER NOT NULL DEFAULT 0,\n  execution_logs  JSON[],\n  worker_hostname TEXT NOT NULL DEFAULT '',\n\n  created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n  updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n\n  batch_spec TEXT NOT NULL,\n  batch_spec_id integer REFERENCES batch_specs(id)\n);",
				"DownQuery": "DROP TABLE IF EXISTS batch_spec_executions;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395842
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395844,
				"Name": "add user id to bach spec executions",
				"UpQuery": "ALTER TABLE IF EXISTS batch_spec_executions ADD COLUMN IF NOT EXISTS user_id int REFERENCES users(id) DEFERRABLE;",
				"DownQuery": "ALTER TABLE IF EXISTS batch_spec_executions DROP COLUMN IF EXISTS user_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395843
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395845,
				"Name": "batch spec execution namespace",
				"UpQuery": "ALTER TABLE IF EXISTS batch_spec_executions ADD COLUMN IF NOT EXISTS namespace_user_id integer REFERENCES users(id) DEFERRABLE;\nALTER TABLE IF EXISTS batch_spec_executions ADD COLUMN IF NOT EXISTS namespace_org_id integer REFERENCES orgs(id) DEFERRABLE;\nUPDATE batch_spec_executions SET namespace_user_id = user_id;\nALTER TABLE IF EXISTS batch_spec_executions ADD CONSTRAINT batch_spec_executions_has_1_namespace CHECK ((namespace_user_id IS NULL) \u003c\u003e (namespace_org_id IS NULL));",
				"DownQuery": "ALTER TABLE IF EXISTS batch_spec_executions DROP CONSTRAINT batch_spec_executions_has_1_namespace;\nALTER TABLE IF EXISTS batch_spec_executions DROP COLUMN IF EXISTS namespace_user_id;\nALTER TABLE IF EXISTS batch_spec_executions DROP COLUMN IF EXISTS namespace_org_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395844
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395846,
				"Name": "expand visible lsif uploads",
				"UpQuery": "ALTER TABLE lsif_uploads_visible_at_tip ADD COLUMN branch_or_tag_name text NOT NULL DEFAULT '';\nALTER TABLE lsif_uploads_visible_at_tip ADD COLUMN is_default_branch boolean NOT NULL DEFAULT false;\n\nCOMMENT ON COLUMN lsif_uploads_visible_at_tip.upload_id IS 'The identifier of the upload visible from the tip of the specified branch or tag.';\nCOMMENT ON COLUMN lsif_uploads_visible_at_tip.branch_or_tag_name IS 'The name of the branch or tag.';\nCOMMENT ON COLUMN lsif_uploads_visible_at_tip.is_default_branch IS  'Whether the specified branch is the default of the repository. Always false for tags.';\n\n-- Update all existing visible uploads to be the default branch, which is true until\n-- we start recalcaulting the commit graph with tags and non-default branches.\nUPDATE lsif_uploads_visible_at_tip SET is_default_branch = true;\n\n-- Mark every graph as dirty so we recalculate retention correctly once the instance\n-- boots up.\nUPDATE lsif_dirty_repositories SET dirty_token = dirty_token + 1;",
				"DownQuery": "ALTER TABLE lsif_uploads_visible_at_tip DROP COLUMN branch_or_tag_name;\nALTER TABLE lsif_uploads_visible_at_tip DROP COLUMN is_default_branch;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395845
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395847,
				"Name": "codeintel eviction ages",
				"UpQuery": "CREATE TABLE lsif_retention_configuration (\n    id serial PRIMARY KEY,\n    repository_id integer UNIQUE NOT NULL REFERENCES repo(id) ON DELETE CASCADE,\n    max_age_for_non_stale_branches_seconds integer NOT NULL,\n    max_age_for_non_stale_tags_seconds integer NOT NULL\n);\n\nCOMMENT ON TABLE lsif_retention_configuration IS 'Stores the retention policy of code intellience data for a repository.';\nCOMMENT ON COLUMN lsif_retention_configuration.max_age_for_non_stale_branches_seconds IS 'The number of seconds since the last modification of a branch until it is considered stale.';\nCOMMENT ON COLUMN lsif_retention_configuration.max_age_for_non_stale_tags_seconds IS 'The nujmber of seconds since the commit date of a tagged commit until it is considered stale.';",
				"DownQuery": "DROP TABLE lsif_retention_configuration;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395846
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395848,
				"Name": "drop default repos",
				"UpQuery": "DROP TABLE IF EXISTS default_repos;",
				"DownQuery": "CREATE TABLE default_repos (\n    repo_id integer NOT NULL\n);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395847
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395849,
				"Name": "drop unused indexes",
				"UpQuery": "-- Covered by external_service_repos_idx (external_service_id, repo_id)\nDROP INDEX IF EXISTS external_service_repos_external_service_id;",
				"DownQuery": "CREATE INDEX external_service_repos_external_service_id ON external_service_repos USING btree (external_service_id);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395848
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395850,
				"Name": "add rand id to batch spec executions",
				"UpQuery": "ALTER TABLE IF EXISTS batch_spec_executions ADD COLUMN IF NOT EXISTS rand_id text NOT NULL;\n\nCREATE INDEX batch_spec_executions_rand_id ON batch_spec_executions USING btree (rand_id);",
				"DownQuery": "DROP INDEX IF EXISTS batch_spec_executions_rand_id;\n\nALTER TABLE IF EXISTS batch_spec_executions DROP COLUMN IF EXISTS rand_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395849
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395851,
				"Name": "workerutil last updated at",
				"UpQuery": "ALTER TABLE batch_spec_executions ADD COLUMN last_heartbeat_at timestamp with time zone;\nALTER TABLE changeset_jobs ADD COLUMN last_heartbeat_at timestamp with time zone;\nALTER TABLE changesets ADD COLUMN last_heartbeat_at timestamp with time zone;\nALTER TABLE cm_action_jobs ADD COLUMN last_heartbeat_at timestamp with time zone;\nALTER TABLE cm_trigger_jobs ADD COLUMN last_heartbeat_at timestamp with time zone;\nALTER TABLE external_service_sync_jobs ADD COLUMN last_heartbeat_at timestamp with time zone;\nALTER TABLE insights_query_runner_jobs ADD COLUMN last_heartbeat_at timestamp with time zone;\nALTER TABLE lsif_dependency_indexing_jobs ADD COLUMN last_heartbeat_at timestamp with time zone;\nALTER TABLE lsif_indexes ADD COLUMN last_heartbeat_at timestamp with time zone;\nALTER TABLE lsif_uploads ADD COLUMN last_heartbeat_at timestamp with time zone;",
				"DownQuery": "-- Note that we have to regenerate the reconciler_changesets view, as the SELECT\n-- c.* in the view definition isn't refreshed when the fields change within the\n-- changesets table.\nDROP VIEW IF EXISTS\n    reconciler_changesets;\n\nALTER TABLE batch_spec_executions DROP COLUMN last_heartbeat_at;\nALTER TABLE changeset_jobs DROP COLUMN last_heartbeat_at;\nALTER TABLE changesets DROP COLUMN last_heartbeat_at;\nALTER TABLE cm_action_jobs DROP COLUMN last_heartbeat_at;\nALTER TABLE cm_trigger_jobs DROP COLUMN last_heartbeat_at;\nALTER TABLE external_service_sync_jobs DROP COLUMN last_heartbeat_at;\nALTER TABLE insights_query_runner_jobs DROP COLUMN last_heartbeat_at;\nALTER TABLE lsif_dependency_indexing_jobs DROP COLUMN last_heartbeat_at;\nALTER TABLE lsif_indexes DROP COLUMN last_heartbeat_at;\nALTER TABLE lsif_uploads DROP COLUMN last_heartbeat_at;\n\nCREATE VIEW reconciler_changesets AS\n    SELECT c.* FROM changesets c\n    INNER JOIN repo r on r.id = c.repo_id\n    WHERE\n        r.deleted_at IS NULL AND\n        EXISTS (\n            SELECT 1 FROM batch_changes\n            LEFT JOIN users namespace_user ON batch_changes.namespace_user_id = namespace_user.id\n            LEFT JOIN orgs namespace_org ON batch_changes.namespace_org_id = namespace_org.id\n            WHERE\n                c.batch_change_ids ? batch_changes.id::text AND\n                namespace_user.deleted_at IS NULL AND\n                namespace_org.deleted_at IS NULL\n        )\n;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395850
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395852,
				"Name": "lsif add covering index",
				"UpQuery": "CREATE INDEX lsif_packages_scheme_name_version_dump_id ON lsif_packages(scheme, name, version, dump_id);\nDROP INDEX lsif_packages_scheme_name_version;\n\nCREATE INDEX lsif_references_scheme_name_version_dump_id ON lsif_references(scheme, name, version, dump_id);\nDROP INDEX lsif_references_package;",
				"DownQuery": "CREATE INDEX lsif_packages_scheme_name_version ON lsif_packages(scheme, name, version);\nDROP INDEX lsif_packages_scheme_name_version_dump_id;\n\nCREATE INDEX lsif_references_package ON lsif_references(scheme, name, version);\nDROP INDEX lsif_references_scheme_name_version_dump_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395851
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395853,
				"Name": "add deleting state",
				"UpQuery": "DROP VIEW lsif_dumps_with_repository_name;\nDROP VIEW lsif_dumps;\n\nCREATE VIEW lsif_dumps AS SELECT u.id,\n    u.commit,\n    u.root,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.finished_at AS processed_at\nFROM lsif_uploads u\nWHERE u.state = 'completed'::text OR u.state = 'deleting';\n\nCREATE VIEW lsif_dumps_with_repository_name AS SELECT u.id,\n    u.commit,\n    u.root,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.processed_at,\n    r.name AS repository_name\nFROM lsif_dumps u\nJOIN repo r ON r.id = u.repository_id\nWHERE r.deleted_at IS NULL;",
				"DownQuery": "DROP VIEW lsif_dumps_with_repository_name;\nDROP VIEW lsif_dumps;\n\nCREATE VIEW lsif_dumps AS SELECT u.id,\n    u.commit,\n    u.root,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.finished_at AS processed_at\nFROM lsif_uploads u WHERE u.state = 'completed'::text;\n\nCREATE VIEW lsif_dumps_with_repository_name AS SELECT u.id,\n    u.commit,\n    u.root,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.processed_at,\n    r.name AS repository_name\nFROM lsif_dumps u JOIN repo r ON r.id = u.repository_id WHERE r.deleted_at IS NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395852
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395854,
				"Name": "add priority insights queryrunner",
				"UpQuery": "ALTER TABLE insights_query_runner_jobs\n    ADD COLUMN priority INT NOT NULL DEFAULT 1;\n\nALTER TABLE insights_query_runner_jobs\n    ADD COLUMN cost INT NOT NULL DEFAULT 500;\n\nCOMMENT ON COLUMN insights_query_runner_jobs.priority IS 'Integer representing a category of priority for this query. Priority in this context is ambiguously defined for consumers to decide an interpretation.';\nCOMMENT ON COLUMN insights_query_runner_jobs.cost IS 'Integer representing a cost approximation of executing this search query.';\n\nCREATE INDEX insights_query_runner_jobs_priority_idx on insights_query_runner_jobs(priority);\nCREATE INDEX insights_query_runner_jobs_cost_idx on insights_query_runner_jobs(cost);",
				"DownQuery": "ALTER TABLE insights_query_runner_jobs\n    DROP COLUMN priority;\n\nALTER TABLE insights_query_runner_jobs\n    DROP COLUMN cost;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395853
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395855,
				"Name": "add-missing-execution-logs-cols",
				"UpQuery": "ALTER TABLE IF EXISTS cm_trigger_jobs ADD COLUMN IF NOT EXISTS execution_logs JSON[];\nALTER TABLE IF EXISTS cm_action_jobs  ADD COLUMN IF NOT EXISTS execution_logs JSON[];",
				"DownQuery": "ALTER TABLE IF EXISTS cm_trigger_jobs DROP COLUMN IF EXISTS execution_logs;\nALTER TABLE IF EXISTS cm_action_jobs  DROP COLUMN IF EXISTS execution_logs;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395854
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395856,
				"Name": "add missing execution logs cols for real",
				"UpQuery": "ALTER TABLE IF EXISTS lsif_uploads ADD COLUMN IF NOT EXISTS execution_logs JSON[];",
				"DownQuery": "ALTER TABLE IF EXISTS lsif_uploads DROP COLUMN IF EXISTS execution_logs;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395855
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395857,
				"Name": "last fetched",
				"UpQuery": "ALTER TABLE gitserver_repos ADD COLUMN last_fetched TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT now();",
				"DownQuery": "ALTER TABLE gitserver_repos DROP COLUMN last_fetched;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395856
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395858,
				"Name": "drop lsif indexable repositories",
				"UpQuery": "DROP TABLE IF EXISTS lsif_indexable_repositories;",
				"DownQuery": "CREATE TABLE lsif_indexable_repositories (\n    id SERIAL PRIMARY KEY NOT NULL,\n    repository_id integer NOT NULL,\n    search_count integer DEFAULT 0 NOT NULL,\n    precise_count integer DEFAULT 0 NOT NULL,\n    last_index_enqueued_at timestamp with time zone,\n    last_updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    enabled boolean\n);\n\nCREATE UNIQUE INDEX lsif_indexable_repositories_repository_id_key ON lsif_indexable_repositories (repository_id);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395857
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395859,
				"Name": "make batch spec executions batch spec id deferrable",
				"UpQuery": "ALTER TABLE IF EXISTS batch_spec_executions ALTER CONSTRAINT batch_spec_executions_batch_spec_id_fkey DEFERRABLE;",
				"DownQuery": "ALTER TABLE IF EXISTS batch_spec_executions ALTER CONSTRAINT batch_spec_executions_batch_spec_id_fkey NOT DEFERRABLE;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395858
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395860,
				"Name": "remove repo table policy",
				"UpQuery": "-- This removes the row-level security policy (if present), and disables RLS on\n-- the repo table. Both operations are idempotent.\nDROP POLICY IF EXISTS sg_repo_access_policy ON repo;\nALTER TABLE repo DISABLE ROW LEVEL SECURITY;",
				"DownQuery": "-- We do not recreate the policy, as we've shifted our strategy away from row-\n-- level security to application-level code. Prior migrations that created the\n-- policy have also been removed.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395859
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395861,
				"Name": "remove sg service grants",
				"UpQuery": "DO $$\nBEGIN\n    REVOKE ALL PRIVILEGES ON ALL SEQUENCES IN SCHEMA public FROM sg_service;\n    REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA public FROM sg_service;\n    REVOKE USAGE ON SCHEMA public FROM sg_service;\nEXCEPTION WHEN undefined_object THEN\n    -- Roles are visible across databases within a server, and we use templated\n    -- databases for test parallelism, so it's possible in some cases for the\n    -- tests to hit a case where the role can't be dropped because one of the\n    -- test databases still has objects that depend on it.\nEND;\n$$;",
				"DownQuery": "-- We do not recreate the grants, as we've shifted our strategy away from row-\n-- level security to application-level code. Prior migrations that created the\n-- grants have also been removed.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395860
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395862,
				"Name": "remove sg service role",
				"UpQuery": "DO $$\nBEGIN\n    DROP ROLE IF EXISTS sg_service;\nEXCEPTION WHEN dependent_objects_still_exist THEN\n    -- Roles are visible across databases within a server, and we use templated\n    -- databases for test parallelism, so it's possible in some cases for the\n    -- tests to hit a case where the role can't be dropped because one of the\n    -- test databases still has objects that depend on it.\nEND;\n$$;",
				"DownQuery": "-- We do not recreate the role, as we've shifted our strategy away from row-\n-- level security to application-level code. Prior migrations that created the\n-- role have also been removed.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395861
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395863,
				"Name": "event logs public properties column",
				"UpQuery": "ALTER TABLE IF EXISTS event_logs ADD COLUMN IF NOT EXISTS public_argument JSONB DEFAULT '{}'::jsonb NOT NULL;",
				"DownQuery": "ALTER TABLE IF EXISTS event_logs DROP COLUMN IF EXISTS public_argument;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395862
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395864,
				"Name": "create temporary settings",
				"UpQuery": "CREATE TABLE IF NOT EXISTS temporary_settings (\n    id serial NOT NULL PRIMARY KEY,\n    user_id integer NOT NULL UNIQUE,\n    contents jsonb,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n\n    FOREIGN KEY (user_id) REFERENCES users (id) ON DELETE CASCADE\n);\n\nCOMMENT ON TABLE temporary_settings IS 'Stores per-user temporary settings used in the UI, for example, which modals have been dimissed or what theme is preferred.';\nCOMMENT ON COLUMN temporary_settings.user_id IS 'The ID of the user the settings will be saved for.';\nCOMMENT ON COLUMN temporary_settings.contents IS 'JSON-encoded temporary settings.';",
				"DownQuery": "DROP TABLE IF EXISTS temporary_settings;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395863
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395865,
				"Name": "insights job dependencies",
				"UpQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nCREATE TABLE insights_query_runner_jobs_dependencies\n(\n    id             SERIAL    NOT NULL,\n    job_id         INT       NOT NULL,\n    recording_time TIMESTAMP NOT NULL,\n    PRIMARY KEY (id),\n    --  The delete cascade is intentional, these records only have meaning in context of the related job row.\n    CONSTRAINT insights_query_runner_jobs_dependencies_fk_job_id FOREIGN KEY (job_id) REFERENCES insights_query_runner_jobs (id) ON DELETE CASCADE\n);\n\nCOMMENT ON TABLE insights_query_runner_jobs_dependencies IS 'Stores data points for a code insight that do not need to be queried directly, but depend on the result of a query at a different point';\n\nCOMMENT ON COLUMN insights_query_runner_jobs_dependencies.job_id IS 'Foreign key to the job that owns this record.';\nCOMMENT ON COLUMN insights_query_runner_jobs_dependencies.recording_time IS 'The time for which this dependency should be recorded at using the parents value.';",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nDROP TABLE IF EXISTS insights_query_runner_jobs_dependencies;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395864
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395866,
				"Name": "insights queue reset",
				"UpQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\n-- This table is a queue of records that need processing for code insights. Historically this queue grows\n-- unbounded because the historical backfiller operated without state - every time it executed it would\n-- requeue all of the work again. Since then we have added enough state to the backfiller to remove this problem,\n-- but customer instances are going to be full of millions of records that will need processing before we can start\n-- fresh. To avoid this problem, we are going to ship a 'reset' in 3.31 that will clear this queue entirely.\n-- Note: This data is by design ephemeral, so there is no risk of permanent data loss here.\n\nTRUNCATE insights_query_runner_jobs CASCADE;",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395865
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395867,
				"Name": "batch-spec-executions-cancel",
				"UpQuery": "ALTER TABLE IF EXISTS batch_spec_executions ADD COLUMN IF NOT EXISTS cancel BOOL DEFAULT FALSE;",
				"DownQuery": "ALTER TABLE IF EXISTS batch_spec_executions DROP COLUMN IF EXISTS cancel;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395866
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395868,
				"Name": "insights queue dependencies index",
				"UpQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nCREATE INDEX insights_query_runner_jobs_dependencies_job_id_fk_idx ON insights_query_runner_jobs_dependencies(job_id);",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nDROP INDEX IF EXISTS insights_query_runner_jobs_dependencies_job_id_fk_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395867
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395869,
				"Name": "add lsif configuration policy",
				"UpQuery": "CREATE TABLE lsif_configuration_policies (\n    id SERIAL PRIMARY KEY,\n    repository_id int,\n    name text,\n    type text NOT NULL,\n    pattern text NOT NULL,\n    retention_enabled boolean NOT NULL,\n    retention_duration_hours int,\n    retain_intermediate_commits boolean NOT NULL,\n    indexing_enabled boolean NOT NULL,\n    index_commit_max_age_hours int,\n    index_intermediate_commits boolean NOT NULL\n);\n\nCREATE INDEX lsif_configuration_policies_repository_id ON lsif_configuration_policies(repository_id);\n\nCOMMENT ON COLUMN lsif_configuration_policies.repository_id IS 'The identifier of the repository to which this configuration policy applies. If absent, this policy is applied globally.';\nCOMMENT ON COLUMN lsif_configuration_policies.type IS 'The type of Git object (e.g., COMMIT, BRANCH, TAG).';\nCOMMENT ON COLUMN lsif_configuration_policies.pattern IS 'A pattern used to match` names of the associated Git object type.';\nCOMMENT ON COLUMN lsif_configuration_policies.retention_enabled IS 'Whether or not this configuration policy affects data retention rules.';\nCOMMENT ON COLUMN lsif_configuration_policies.retention_duration_hours IS 'The max age of data retained by this configuration policy. If null, the age is unbounded.';\nCOMMENT ON COLUMN lsif_configuration_policies.retain_intermediate_commits IS 'If the matching Git object is a branch, setting this value to true will also retain all data used to resolve queries for any commit on the matching branches. Setting this value to false will only consider the tip of the branch.';\nCOMMENT ON COLUMN lsif_configuration_policies.indexing_enabled IS 'Whether or not this configuration policy affects auto-indexing schedules.';\nCOMMENT ON COLUMN lsif_configuration_policies.index_commit_max_age_hours IS 'The max age of commits indexed by this configuration policy. If null, the age is unbounded.';\nCOMMENT ON COLUMN lsif_configuration_policies.index_intermediate_commits IS 'If the matching Git object is a branch, setting this value to true will also index all commits on the matching branches. Setting this value to false will only consider the tip of the branch.';",
				"DownQuery": "DROP TABLE IF EXISTS lsif_configuration_policies;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395868
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395870,
				"Name": "codeintel dependency repos",
				"UpQuery": "CREATE TABLE IF NOT EXISTS lsif_dependency_repos (\n    id bigserial NOT NULL PRIMARY KEY,\n    name text NOT NULL,\n    version text NOT NULL,\n    scheme text NOT NULL,\n    CONSTRAINT lsif_dependency_repos_unique_triplet\n        UNIQUE (scheme, name, version)\n);",
				"DownQuery": "DROP TABLE IF EXISTS lsif_dependency_repos;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395869
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395871,
				"Name": "insights queue state index",
				"UpQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\nCREATE INDEX IF NOT EXISTS insights_query_runner_jobs_processable_priority_id ON insights_query_runner_jobs (priority, id) WHERE state = 'queued' OR state = 'errored';",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\ndrop index if exists insights_query_runner_jobs_processable_priority_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395870
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395872,
				"Name": "lsif upload reference counts",
				"UpQuery": "ALTER TABLE lsif_uploads ADD COLUMN num_references int;\nCOMMENT ON COLUMN lsif_uploads.num_references IS 'The number of references to this upload data from other upload records (via lsif_references).';",
				"DownQuery": "ALTER TABLE lsif_uploads DROP COLUMN num_references;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395871
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395873,
				"Name": "lsif upload reference counts oob migration",
				"UpQuery": "INSERT INTO out_of_band_migrations (id, team, component, description, introduced_version_major, introduced_version_minor, non_destructive)\nVALUES (11, 'code-intelligence', 'lsif_uploads.num_references', 'Backfill LSIF upload reference counts', 3, 22, true)\nON CONFLICT DO NOTHING;",
				"DownQuery": "-- Do not remove oob migration when downgrading",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395872
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395874,
				"Name": "lsif nearest uploads indexes",
				"UpQuery": "-- Allow for lookup from upload id to commits that the upload can resolve queries for.\nCREATE INDEX lsif_nearest_uploads_uploads ON lsif_nearest_uploads USING GIN(uploads);\n\n-- Allow for lookup from commit to the set of commits that have analogous nearest uploads.\nCREATE INDEX lsif_nearest_uploads_links_repository_id_ancestor_commit_bytea ON lsif_nearest_uploads_links(repository_id, ancestor_commit_bytea);",
				"DownQuery": "DROP INDEX lsif_nearest_uploads_uploads;\nDROP INDEX lsif_nearest_uploads_links_repository_id_ancestor_commit_bytea;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395873
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395875,
				"Name": "lsif upload expired flag",
				"UpQuery": "-- Drop dependent views\nDROP VIEW lsif_dumps_with_repository_name;\nDROP VIEW lsif_dumps;\nDROP VIEW lsif_uploads_with_repository_name;\n\n-- Add new column\nALTER TABLE lsif_uploads ADD COLUMN expired boolean not null default false;\nCOMMENT ON COLUMN lsif_uploads.expired IS 'Whether or not this upload data is no longer protected by any data retention policy.';\n\n-- Update view definitions to include new fields\nCREATE VIEW lsif_uploads_with_repository_name AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.expired,\n        r.name AS repository_name\n    FROM lsif_uploads u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_dumps AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.expired,\n        u.finished_at AS processed_at\n    FROM lsif_uploads u\n    WHERE u.state = 'completed'::text OR u.state = 'deleting'::text;\n\nCREATE VIEW lsif_dumps_with_repository_name AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.expired,\n        u.processed_at,\n        r.name AS repository_name\n    FROM lsif_dumps u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;",
				"DownQuery": "-- Drop dependent views\nDROP VIEW lsif_dumps_with_repository_name;\nDROP VIEW lsif_dumps;\nDROP VIEW lsif_uploads_with_repository_name;\n\n-- Drop new column\nALTER TABLE lsif_uploads DROP COLUMN expired;\n\n-- Restore old views\nCREATE VIEW lsif_uploads_with_repository_name AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        r.name AS repository_name\n    FROM lsif_uploads u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_dumps AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.finished_at AS processed_at\n    FROM lsif_uploads u\n    WHERE u.state = 'completed'::text OR u.state = 'deleting'::text;\n\nCREATE VIEW lsif_dumps_with_repository_name AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.processed_at,\n        r.name AS repository_name\n    FROM lsif_dumps u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395874
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395876,
				"Name": "lsif last retention scan",
				"UpQuery": "-- Drop dependent views\nDROP VIEW lsif_dumps_with_repository_name;\nDROP VIEW lsif_dumps;\nDROP VIEW lsif_uploads_with_repository_name;\n\n-- Create table to rate limit data retention scans of a repository\nCREATE TABLE lsif_last_retention_scan (\n    repository_id int NOT NULL,\n    last_retention_scan_at timestamp with time zone NOT NULL,\n\n    PRIMARY KEY(repository_id)\n);\nCOMMENT ON TABLE lsif_last_retention_scan IS 'Tracks the last time uploads a repository were checked against data retention policies.';\nCOMMENT ON COLUMN lsif_last_retention_scan.last_retention_scan_at IS 'The last time uploads of this repository were checked against data retention policies.';\n\n-- Add column to rate limit scanning of individual upload records\nALTER TABLE lsif_uploads ADD COLUMN last_retention_scan_at timestamp with time zone;\nCOMMENT ON COLUMN lsif_uploads.last_retention_scan_at IS 'The last time this upload was checked against data retention policies.';\n\n-- Update view definitions to include new fields\nCREATE VIEW lsif_uploads_with_repository_name AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.expired,\n        r.name AS repository_name\n    FROM lsif_uploads u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_dumps AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.expired,\n        u.finished_at AS processed_at\n    FROM lsif_uploads u\n    WHERE u.state = 'completed'::text OR u.state = 'deleting'::text;\n\nCREATE VIEW lsif_dumps_with_repository_name AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.expired,\n        u.processed_at,\n        r.name AS repository_name\n    FROM lsif_dumps u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;",
				"DownQuery": "-- Drop dependent views\nDROP VIEW lsif_dumps_with_repository_name;\nDROP VIEW lsif_dumps;\nDROP VIEW lsif_uploads_with_repository_name;\n\n-- Drop new column and table\nALTER TABLE lsif_uploads DROP COLUMN last_retention_scan_at;\nDROP TABLE lsif_last_retention_scan;\n\n-- Restore old views\nCREATE VIEW lsif_uploads_with_repository_name AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        r.name AS repository_name\n    FROM lsif_uploads u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_dumps AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.finished_at AS processed_at\n    FROM lsif_uploads u\n    WHERE u.state = 'completed'::text OR u.state = 'deleting'::text;\n\nCREATE VIEW lsif_dumps_with_repository_name AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.processed_at,\n        r.name AS repository_name\n    FROM lsif_dumps u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395875
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395877,
				"Name": "index-lsif-uploads-repo",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS lsif_uploads_repository_id ON lsif_uploads (repository_id);",
				"DownQuery": "DROP INDEX IF EXISTS lsif_uploads_repository_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395876
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "lsif_uploads",
					"IndexName": "lsif_uploads_repository_id"
				}
			},
			{
				"ID": 1528395878,
				"Name": "index-lsif-indexes-repo",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS lsif_indexes_repository_id_commit ON lsif_indexes (repository_id, commit);",
				"DownQuery": "DROP INDEX IF EXISTS lsif_indexes_repository_id_commit;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395877
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "lsif_indexes",
					"IndexName": "lsif_indexes_repository_id_commit"
				}
			},
			{
				"ID": 1528395879,
				"Name": "repair lsif configuration policies",
				"UpQuery": "DROP TABLE lsif_configuration_policies;\n\nCREATE TABLE lsif_configuration_policies (\n    id SERIAL PRIMARY KEY,\n    repository_id int,\n    name text,\n    type text NOT NULL,\n    pattern text NOT NULL,\n    retention_enabled boolean NOT NULL,\n    retention_duration_hours int,\n    retain_intermediate_commits boolean NOT NULL,\n    indexing_enabled boolean NOT NULL,\n    index_commit_max_age_hours int,\n    index_intermediate_commits boolean NOT NULL\n);\n\nCREATE INDEX lsif_configuration_policies_repository_id ON lsif_configuration_policies(repository_id);\n\nCOMMENT ON COLUMN lsif_configuration_policies.repository_id IS 'The identifier of the repository to which this configuration policy applies. If absent, this policy is applied globally.';\nCOMMENT ON COLUMN lsif_configuration_policies.type IS 'The type of Git object (e.g., COMMIT, BRANCH, TAG).';\nCOMMENT ON COLUMN lsif_configuration_policies.pattern IS 'A pattern used to match` names of the associated Git object type.';\nCOMMENT ON COLUMN lsif_configuration_policies.retention_enabled IS 'Whether or not this configuration policy affects data retention rules.';\nCOMMENT ON COLUMN lsif_configuration_policies.retention_duration_hours IS 'The max age of data retained by this configuration policy. If null, the age is unbounded.';\nCOMMENT ON COLUMN lsif_configuration_policies.retain_intermediate_commits IS 'If the matching Git object is a branch, setting this value to true will also retain all data used to resolve queries for any commit on the matching branches. Setting this value to false will only consider the tip of the branch.';\nCOMMENT ON COLUMN lsif_configuration_policies.indexing_enabled IS 'Whether or not this configuration policy affects auto-indexing schedules.';\nCOMMENT ON COLUMN lsif_configuration_policies.index_commit_max_age_hours IS 'The max age of commits indexed by this configuration policy. If null, the age is unbounded.';\nCOMMENT ON COLUMN lsif_configuration_policies.index_intermediate_commits IS 'If the matching Git object is a branch, setting this value to true will also index all commits on the matching branches. Setting this value to false will only consider the tip of the branch.';",
				"DownQuery": "-- Nothing on down",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395878
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395880,
				"Name": "insights queue persist mode",
				"UpQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nCREATE TYPE PersistMode AS ENUM ('record', 'snapshot');\n\nALTER TABLE insights_query_runner_jobs\n    ADD persist_mode PersistMode DEFAULT 'record' NOT NULL;\n\nCOMMENT ON COLUMN insights_query_runner_jobs.persist_mode IS 'The persistence level for this query. This value will determine the lifecycle of the resulting value.';",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nALTER TABLE insights_query_runner_jobs\n    DROP COLUMN persist_mode;\n\nDROP TYPE PersistMode;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395879
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395881,
				"Name": "add batch spec workspaces",
				"UpQuery": "CREATE TABLE IF NOT EXISTS batch_spec_resolution_jobs (\n  id              BIGSERIAL PRIMARY KEY,\n\n  batch_spec_id     INTEGER REFERENCES batch_specs(id) ON DELETE CASCADE DEFERRABLE,\n  allow_unsupported BOOLEAN NOT NULL DEFAULT FALSE,\n  allow_ignored     BOOLEAN NOT NULL DEFAULT FALSE,\n\n  state             TEXT DEFAULT 'queued',\n  failure_message   TEXT,\n  started_at        TIMESTAMP WITH TIME ZONE,\n  finished_at       TIMESTAMP WITH TIME ZONE,\n  process_after     TIMESTAMP WITH TIME ZONE,\n  num_resets        INTEGER NOT NULL DEFAULT 0,\n  num_failures      INTEGER NOT NULL DEFAULT 0,\n  execution_logs    JSON[],\n  worker_hostname   TEXT NOT NULL DEFAULT '',\n  last_heartbeat_at TIMESTAMP WITH TIME ZONE,\n\n  created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n  updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()\n);\n\nCREATE TABLE IF NOT EXISTS batch_spec_workspaces (\n  id              BIGSERIAL PRIMARY KEY,\n\n  batch_spec_id      INTEGER REFERENCES batch_specs(id) ON DELETE CASCADE DEFERRABLE,\n  changeset_spec_ids JSONB DEFAULT '{}'::jsonb,\n\n  repo_id integer      REFERENCES repo(id) DEFERRABLE,\n  branch               TEXT NOT NULL,\n  commit               TEXT NOT NULL,\n  path                 TEXT NOT NULL,\n  file_matches         TEXT[] NOT NULL,\n  only_fetch_workspace BOOLEAN NOT NULL DEFAULT FALSE,\n  steps                JSONB DEFAULT '[]'::jsonb CHECK (jsonb_typeof(steps) = 'array'),\n\n  created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n  updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()\n);\n\nCREATE TABLE IF NOT EXISTS batch_spec_workspace_execution_jobs (\n  id              BIGSERIAL PRIMARY KEY,\n\n  batch_spec_workspace_id  INTEGER REFERENCES batch_spec_workspaces(id) ON DELETE CASCADE DEFERRABLE,\n\n  state             TEXT DEFAULT 'queued',\n  failure_message   TEXT,\n  started_at        TIMESTAMP WITH TIME ZONE,\n  finished_at       TIMESTAMP WITH TIME ZONE,\n  process_after     TIMESTAMP WITH TIME ZONE,\n  num_resets        INTEGER NOT NULL DEFAULT 0,\n  num_failures      INTEGER NOT NULL DEFAULT 0,\n  execution_logs    JSON[],\n  worker_hostname   TEXT NOT NULL DEFAULT '',\n  last_heartbeat_at TIMESTAMP WITH TIME ZONE,\n\n  created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n  updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()\n);",
				"DownQuery": "DROP TABLE IF EXISTS batch_spec_workspace_execution_jobs;\nDROP TABLE IF EXISTS batch_spec_workspaces;\nDROP TABLE IF EXISTS batch_spec_resolution_jobs;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395880
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395882,
				"Name": "lsif configuration protected policies",
				"UpQuery": "ALTER TABLE lsif_configuration_policies ADD COLUMN protected boolean DEFAULT false;\nUPDATE lsif_configuration_policies SET protected = false;\nALTER TABLE lsif_configuration_policies ALTER COLUMN protected SET NOT NULL;\n\nCOMMENT ON COLUMN lsif_configuration_policies.protected IS 'Whether or not this configuration policy is protected from modification of its data retention behavior (except for duration).';",
				"DownQuery": "ALTER TABLE lsif_configuration_policies DROP COLUMN protected;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395881
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395883,
				"Name": "default lsif configuration policies",
				"UpQuery": "INSERT INTO lsif_configuration_policies\n    (\n        name,\n        protected, pattern, type,\n        retention_enabled, retain_intermediate_commits, retention_duration_hours,\n        indexing_enabled, index_intermediate_commits, index_commit_max_age_hours\n    )\nVALUES\n    (\n        'Default tip-of-branch retention policy',\n        true, '*', 'GIT_TREE',\n        true, false, 2016, -- 3 months ~= 2016 hours = 1 week (168 hours) * 4 * 3\n        false, false, 0\n    ), (\n        'Default tag retention policy',\n        true, '*', 'GIT_TAG',\n        true, false, 8064, -- 12 months ~= 8064 hours = 1 week (168 hours) * 4 * 12\n        false, false, 0\n    );",
				"DownQuery": "-- Nothing on down",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395882
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395884,
				"Name": "add cancel to batch spec workspace execution jobs",
				"UpQuery": "ALTER TABLE IF EXISTS batch_spec_workspace_execution_jobs\n  ADD COLUMN IF NOT EXISTS cancel boolean DEFAULT false NOT NULL;\n\nCREATE INDEX IF NOT EXISTS batch_spec_workspace_execution_jobs_cancel\n  ON batch_spec_workspace_execution_jobs (cancel);",
				"DownQuery": "DROP INDEX IF EXISTS batch_spec_workspace_execution_jobs_cancel;\n\nALTER TABLE IF EXISTS batch_spec_workspace_execution_jobs\n  DROP COLUMN IF EXISTS cancel;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395883
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395885,
				"Name": "lsif last retention scan views",
				"UpQuery": "DROP VIEW lsif_dumps_with_repository_name;\nDROP VIEW lsif_dumps;\nDROP VIEW lsif_uploads_with_repository_name;\n\nCREATE VIEW lsif_uploads_with_repository_name AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.expired,\n        u.last_retention_scan_at,\n        r.name AS repository_name\n    FROM lsif_uploads u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_dumps AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.expired,\n        u.last_retention_scan_at,\n        u.finished_at AS processed_at\n    FROM lsif_uploads u\n    WHERE u.state = 'completed'::text OR u.state = 'deleting'::text;\n\nCREATE VIEW lsif_dumps_with_repository_name AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.expired,\n        u.last_retention_scan_at,\n        u.processed_at,\n        r.name AS repository_name\n    FROM lsif_dumps u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;",
				"DownQuery": "DROP VIEW lsif_dumps_with_repository_name;\nDROP VIEW lsif_dumps;\nDROP VIEW lsif_uploads_with_repository_name;\n\nCREATE VIEW lsif_uploads_with_repository_name AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.expired,\n        r.name AS repository_name\n    FROM lsif_uploads u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_dumps AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.expired,\n        u.finished_at AS processed_at\n    FROM lsif_uploads u\n    WHERE u.state = 'completed'::text OR u.state = 'deleting'::text;\n\nCREATE VIEW lsif_dumps_with_repository_name AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.expired,\n        u.processed_at,\n        r.name AS repository_name\n    FROM lsif_dumps u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395884
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395886,
				"Name": "add missing fk indexes1",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS lsif_dependency_indexing_jobs_upload_id ON lsif_dependency_indexing_jobs(upload_id);",
				"DownQuery": "DROP INDEX IF EXISTS lsif_dependency_indexing_jobs_upload_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395885
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "lsif_dependency_indexing_jobs",
					"IndexName": "lsif_dependency_indexing_jobs_upload_id"
				}
			},
			{
				"ID": 1528395887,
				"Name": "add missing fk indexes2",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS lsif_packages_dump_id ON lsif_packages(dump_id);",
				"DownQuery": "DROP INDEX IF EXISTS lsif_packages_dump_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395886
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "lsif_packages",
					"IndexName": "lsif_packages_dump_id"
				}
			},
			{
				"ID": 1528395888,
				"Name": "add missing fk indexes3",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS lsif_references_dump_id ON lsif_references(dump_id);",
				"DownQuery": "DROP INDEX IF EXISTS lsif_references_dump_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395887
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "lsif_references",
					"IndexName": "lsif_references_dump_id"
				}
			},
			{
				"ID": 1528395889,
				"Name": "add metadata column to oobmigration",
				"UpQuery": "ALTER TABLE\n    out_of_band_migrations\nADD COLUMN IF NOT EXISTS\n    metadata jsonb NOT NULL DEFAULT '{}'::jsonb;",
				"DownQuery": "ALTER TABLE\n    out_of_band_migrations\nDROP COLUMN IF EXISTS metadata;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395888
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395890,
				"Name": "drop repo cloned",
				"UpQuery": "ALTER TABLE\n    repo\nDROP COLUMN IF EXISTS cloned;",
				"DownQuery": "-- This migration is destructive since the column has been\n-- deprecated since 3.26\nALTER TABLE\n    repo\nADD COLUMN IF NOT EXISTS\n    cloned bool NOT NULL DEFAULT false;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395889
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395891,
				"Name": "lsif dependency indexing queueing",
				"UpQuery": "ALTER TABLE lsif_dependency_indexing_jobs\nRENAME TO lsif_dependency_syncing_jobs;\n\nCREATE TABLE IF NOT EXISTS lsif_dependency_indexing_jobs (\n    id serial PRIMARY KEY,\n    state text DEFAULT 'queued' NOT NULL,\n    failure_message text,\n    queued_at timestamp with time zone DEFAULT NOW() NOT NULL,\n    started_at timestamp with time zone,\n    finished_at timestamp with time zone,\n    process_after timestamp with time zone,\n    num_resets integer DEFAULT 0 NOT NULL,\n    num_failures integer DEFAULT 0 NOT NULL,\n    execution_logs json[],\n    last_heartbeat_at timestamp with time zone,\n    worker_hostname text NOT NULL DEFAULT '',\n    upload_id integer REFERENCES lsif_uploads(id) ON DELETE CASCADE,\n    external_service_kind text NOT NULL DEFAULT '',\n    external_service_sync timestamp with time zone\n);\n\nCOMMENT ON COLUMN lsif_dependency_indexing_jobs.external_service_kind IS 'Filter the external services for this kind to wait to have synced. If empty, external_service_sync is ignored and no external services are polled for their last sync time.';\nCOMMENT ON COLUMN lsif_dependency_indexing_jobs.external_service_sync IS 'The sync time after which external services of the given kind will have synced/created any repositories referenced by the LSIF upload that are resolvable.';",
				"DownQuery": "DROP TABLE IF EXISTS lsif_dependency_indexing_jobs;\n\nALTER TABLE lsif_dependency_syncing_jobs\nRENAME TO lsif_dependency_indexing_jobs;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395890
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395892,
				"Name": "drop batch spec executions",
				"UpQuery": "DROP TABLE IF EXISTS batch_spec_executions;",
				"DownQuery": "CREATE TABLE IF NOT EXISTS batch_spec_executions (\n  id              BIGSERIAL PRIMARY KEY,\n  rand_id         TEXT NOT NULL,\n\n  state           TEXT DEFAULT 'queued',\n  failure_message TEXT,\n  process_after   TIMESTAMP WITH TIME ZONE,\n  started_at      TIMESTAMP WITH TIME ZONE,\n  finished_at     TIMESTAMP WITH TIME ZONE,\n  last_heartbeat_at TIMESTAMP WITH TIME ZONE,\n  num_resets      INTEGER NOT NULL DEFAULT 0,\n  num_failures    INTEGER NOT NULL DEFAULT 0,\n  execution_logs  JSON[],\n  worker_hostname TEXT NOT NULL DEFAULT '',\n  cancel          BOOL DEFAULT FALSE,\n\n  created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n  updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n\n  batch_spec TEXT NOT NULL,\n  batch_spec_id integer REFERENCES batch_specs(id) DEFERRABLE,\n\n  user_id INTEGER REFERENCES users(id),\n  namespace_org_id INTEGER REFERENCES orgs(id),\n  namespace_user_id INTEGER REFERENCES users(id)\n);\n\nALTER TABLE IF EXISTS batch_spec_executions ADD CONSTRAINT batch_spec_executions_has_1_namespace CHECK ((namespace_user_id IS NULL) \u003c\u003e (namespace_org_id IS NULL));\nCREATE INDEX IF NOT EXISTS batch_spec_executions_rand_id ON batch_spec_executions USING btree (rand_id);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395891
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395893,
				"Name": "fix repo index part one",
				"UpQuery": "-- We have a hand-created but non-codified index in our Cloud environment\n-- called repo_deleted_at_idx which is a partial btree index over deleted_at\n-- where deleted_at is null. This effectively creates a btree index whose only\n-- value is NULL.\n--\n-- Instead, we'll make a partial index on useful fields that can at least help\n-- cover queries that select only/filter by id and/or name.\n\nCREATE INDEX CONCURRENTLY IF NOT EXISTS repo_non_deleted_id_name_idx ON repo(id, name) WHERE deleted_at IS NULL;",
				"DownQuery": "DROP INDEX IF EXISTS repo_non_deleted_id_name_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395892
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "repo",
					"IndexName": "repo_non_deleted_id_name_idx"
				}
			},
			{
				"ID": 1528395894,
				"Name": "gitserver repo shard id index",
				"UpQuery": "-- This speeds up IterateRepoGitserverStatus\nCREATE INDEX CONCURRENTLY IF NOT EXISTS gitserver_repos_shard_id ON gitserver_repos(shard_id, repo_id);",
				"DownQuery": "DROP INDEX IF EXISTS gitserver_repos_shard_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395893
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "gitserver_repos",
					"IndexName": "gitserver_repos_shard_id"
				}
			},
			{
				"ID": 1528395895,
				"Name": "gitserver repos lasterror idx",
				"UpQuery": "DROP INDEX IF EXISTS gitserver_repos_last_error_idx;",
				"DownQuery": "CREATE INDEX gitserver_repos_last_error_idx ON gitserver_repos(last_error) WHERE last_error IS NOT NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395894
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395896,
				"Name": "gitserver repos new lasterror idx",
				"UpQuery": "CREATE INDEX CONCURRENTLY gitserver_repos_last_error_idx ON gitserver_repos(repo_id) WHERE last_error IS NOT NULL;",
				"DownQuery": "DROP INDEX IF EXISTS gitserver_repos_last_error_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395895
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "gitserver_repos",
					"IndexName": "gitserver_repos_last_error_idx"
				}
			},
			{
				"ID": 1528395897,
				"Name": "extensions list missing index",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS registry_extension_releases_registry_extension_id_created_at ON registry_extension_releases(registry_extension_id, created_at) WHERE deleted_at IS NULL;",
				"DownQuery": "DROP INDEX IF EXISTS registry_extension_releases_registry_extension_id_created_at;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395896
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "registry_extension_releases",
					"IndexName": "registry_extension_releases_registry_extension_id_created_at"
				}
			},
			{
				"ID": 1528395898,
				"Name": "codehost connection owned by org",
				"UpQuery": "-- Adds support for organization owning a codehost connection\nBEGIN;\n\nALTER TABLE IF EXISTS external_services ADD COLUMN IF NOT EXISTS namespace_org_id integer REFERENCES orgs(id) ON DELETE CASCADE DEFERRABLE;\nALTER TABLE IF EXISTS external_services ADD CONSTRAINT external_services_max_1_namespace CHECK ((namespace_user_id IS NULL AND namespace_org_id IS NULL) OR ((namespace_user_id IS NULL) \u003c\u003e (namespace_org_id IS NULL)));\nCREATE INDEX external_services_namespace_org_id_idx ON external_services USING btree (namespace_org_id);\n\nEND;",
				"DownQuery": "ALTER TABLE IF EXISTS external_services DROP COLUMN IF EXISTS namespace_org_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395897
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395899,
				"Name": "add index for lsif indexes state",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS lsif_indexes_state ON lsif_indexes(state);",
				"DownQuery": "DROP INDEX IF EXISTS lsif_indexes_state;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395898
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "lsif_indexes",
					"IndexName": "lsif_indexes_state"
				}
			},
			{
				"ID": 1528395900,
				"Name": "add commit to lsif uploads repository index",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS lsif_uploads_repository_id_commit ON lsif_uploads(repository_id, commit);",
				"DownQuery": "DROP INDEX IF EXISTS lsif_uploads_repository_id_commit;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395899
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "lsif_uploads",
					"IndexName": "lsif_uploads_repository_id_commit"
				}
			},
			{
				"ID": 1528395901,
				"Name": "remove duplicate index",
				"UpQuery": "DROP INDEX IF EXISTS lsif_uploads_repository_id;",
				"DownQuery": "CREATE INDEX IF NOT EXISTS lsif_uploads_repository_id ON lsif_uploads(repository_id);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395900
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395902,
				"Name": "drop unused security events index 0",
				"UpQuery": "DROP INDEX IF EXISTS security_event_logs_anonymous_user_id;",
				"DownQuery": "CREATE INDEX IF NOT EXISTS security_event_logs_anonymous_user_id ON security_event_logs USING btree (anonymous_user_id);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395901
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395903,
				"Name": "drop unused security events index 1",
				"UpQuery": "DROP INDEX IF EXISTS security_event_logs_user_id;",
				"DownQuery": "CREATE INDEX IF NOT EXISTS security_event_logs_user_id ON security_event_logs USING btree (user_id);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395902
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395904,
				"Name": "drop unused security events index 2",
				"UpQuery": "DROP INDEX IF EXISTS security_event_logs_name;",
				"DownQuery": "CREATE INDEX IF NOT EXISTS security_event_logs_name ON security_event_logs USING btree (name);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395903
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395905,
				"Name": "drop unused security events index 3",
				"UpQuery": "DROP INDEX IF EXISTS security_event_logs_source;",
				"DownQuery": "CREATE INDEX IF NOT EXISTS security_event_logs_source ON security_event_logs USING btree (source);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395904
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395906,
				"Name": "drop unused security events index 4",
				"UpQuery": "DROP INDEX IF EXISTS security_event_logs_timestamp_at_utc;",
				"DownQuery": "CREATE INDEX IF NOT EXISTS security_event_logs_timestamp_at_utc ON security_event_logs USING btree (date(timezone('UTC'::text, \"timestamp\")));",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395905
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395907,
				"Name": "more default lsif configuration policies",
				"UpQuery": "INSERT INTO lsif_configuration_policies\n    (\n        name,\n        protected, pattern, type,\n        retention_enabled, retain_intermediate_commits, retention_duration_hours,\n        indexing_enabled, index_intermediate_commits, index_commit_max_age_hours\n    )\nVALUES\n    (\n        'Default commit retention policy',\n        true, '*', 'GIT_TREE',\n        true, true, 168, -- 1 week (168 hours) * 4 * 3\n        false, false, 0\n    );",
				"DownQuery": "-- Nothing on down",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395906
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395908,
				"Name": "reverted",
				"UpQuery": "-- Empty migration, this migration was reverted: https://github.com/sourcegraph/sourcegraph/pull/25715",
				"DownQuery": "-- Empty migration, this migration was reverted: https://github.com/sourcegraph/sourcegraph/pull/25715",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395907
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395909,
				"Name": "undo apidocs oob migration",
				"UpQuery": "-- Undo the changes corresponding to https://github.com/sourcegraph/sourcegraph/pull/25715\nDELETE FROM out_of_band_migrations WHERE id=12 AND team='apidocs';",
				"DownQuery": "-- Nothing to do, the up migration undid changes previously made.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395908
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395910,
				"Name": "gitserver last changed",
				"UpQuery": "ALTER TABLE gitserver_repos ADD COLUMN IF NOT EXISTS last_changed TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT now();",
				"DownQuery": "ALTER TABLE gitserver_repos DROP COLUMN last_changed;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395909
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395911,
				"Name": "add access token id to batch spec workspace execution jobs",
				"UpQuery": "ALTER TABLE IF EXISTS batch_spec_workspace_execution_jobs\n  ADD COLUMN IF NOT EXISTS access_token_id bigint REFERENCES access_tokens(id) ON DELETE SET NULL DEFERRABLE DEFAULT NULL;\n\nALTER TABLE IF EXISTS access_tokens\n  ADD COLUMN IF NOT EXISTS internal boolean DEFAULT FALSE;",
				"DownQuery": "ALTER TABLE IF EXISTS batch_spec_workspace_execution_jobs\n  DROP COLUMN IF EXISTS access_token_id;\n\nALTER TABLE IF EXISTS access_tokens\n  DROP COLUMN IF EXISTS internal;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395910
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395912,
				"Name": "apidocs oob search indexing",
				"UpQuery": "-- Create the OOB migration according to doc/dev/background-information/oobmigrations.md\nINSERT INTO out_of_band_migrations (id, team, component, description, introduced_version_major, introduced_version_minor, non_destructive)\nVALUES (\n    12,                                             -- This must be consistent across all Sourcegraph instances\n    'apidocs',                                      -- Team owning migration\n    'codeintel-db.lsif_data_documentation_search',  -- Component being migrated\n    'Index API docs for search',                    -- Description\n    3,                                              -- The next minor release (major version)\n    32,                                             -- The next minor release (minor version)\n    true                                            -- Can be read with previous version without down migration\n)\nON CONFLICT DO NOTHING;",
				"DownQuery": "-- The OOB migration doesn't add any new tables or columns or anything, so we don't need to do\n-- anything on down migration. It migrates data from lsif_data_documentation_pages -\u003e the new\n-- lsif_data_documentation_search_* tables - but it's fine to just leave those.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395911
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395913,
				"Name": "add unique constraint on batch spec resolution jobs",
				"UpQuery": "ALTER TABLE IF EXISTS batch_spec_resolution_jobs\n  ADD CONSTRAINT batch_spec_resolution_jobs_batch_spec_id_unique UNIQUE (batch_spec_id);",
				"DownQuery": "ALTER TABLE IF EXISTS batch_spec_resolution_jobs\n  DROP CONSTRAINT IF EXISTS batch_spec_resolution_jobs_batch_spec_id_unique;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395912
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395914,
				"Name": "add created from raw to batch specs",
				"UpQuery": "ALTER TABLE batch_specs\n  ADD COLUMN IF NOT EXISTS created_from_raw boolean DEFAULT FALSE NOT NULL;",
				"DownQuery": "ALTER TABLE batch_specs\n  DROP COLUMN IF EXISTS created_from_raw;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395913
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395915,
				"Name": "remove raw changeset spec",
				"UpQuery": "ALTER TABLE\n    changeset_specs\nDROP COLUMN IF EXISTS\n    raw_spec;",
				"DownQuery": "-- We don't need to reconstruct the contents of the raw_spec column (and,\n-- indeed, we can't), so we'll just leave it with empty strings.\n\nALTER TABLE\n    changeset_specs\nADD COLUMN IF NOT EXISTS\n    raw_spec TEXT NOT NULL DEFAULT '';",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395914
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395916,
				"Name": "add external service repos org id",
				"UpQuery": "ALTER TABLE external_service_repos ADD COLUMN IF NOT EXISTS org_id INTEGER REFERENCES orgs(id) ON DELETE CASCADE;",
				"DownQuery": "ALTER TABLE external_service_repos DROP COLUMN IF EXISTS org_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395915
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395917,
				"Name": "add index rate limit",
				"UpQuery": "-- Create table to rate limit indexing scans of a repository\nCREATE TABLE lsif_last_index_scan (\n    repository_id int NOT NULL,\n    last_index_scan_at timestamp with time zone NOT NULL,\n\n    PRIMARY KEY(repository_id)\n);\nCOMMENT ON TABLE lsif_last_index_scan IS 'Tracks the last time repository was checked for auto-indexing job scheduling.';\nCOMMENT ON COLUMN lsif_last_index_scan.last_index_scan_at IS 'The last time uploads of this repository were considered for auto-indexing job scheduling.';",
				"DownQuery": "DROP TABLE IF EXISTS lsif_last_index_scan;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395916
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395918,
				"Name": "update batch spec workspaces to persist all",
				"UpQuery": "ALTER TABLE batch_spec_workspaces\n  ADD COLUMN IF NOT EXISTS ignored BOOLEAN NOT NULL DEFAULT FALSE,\n  ADD COLUMN IF NOT EXISTS unsupported BOOLEAN NOT NULL DEFAULT FALSE,\n  ADD COLUMN IF NOT EXISTS skipped BOOLEAN NOT NULL DEFAULT FALSE;\n\nALTER TABLE batch_specs\n  ADD COLUMN IF NOT EXISTS allow_unsupported BOOLEAN NOT NULL DEFAULT FALSE,\n  ADD COLUMN IF NOT EXISTS allow_ignored BOOLEAN NOT NULL DEFAULT FALSE;\n\nALTER TABLE batch_spec_resolution_jobs\n  DROP COLUMN IF EXISTS allow_unsupported,\n  DROP COLUMN IF EXISTS allow_ignored;",
				"DownQuery": "ALTER TABLE batch_spec_workspaces\n  DROP COLUMN IF EXISTS ignored,\n  DROP COLUMN IF EXISTS unsupported,\n  DROP COLUMN IF EXISTS skipped;\n\nALTER TABLE batch_specs\n  DROP COLUMN IF EXISTS allow_unsupported,\n  DROP COLUMN IF EXISTS allow_ignored;\n\nALTER TABLE batch_spec_resolution_jobs\n  ADD COLUMN IF NOT EXISTS allow_unsupported BOOLEAN NOT NULL DEFAULT FALSE,\n  ADD COLUMN IF NOT EXISTS allow_ignored BOOLEAN NOT NULL DEFAULT FALSE;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395917
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395919,
				"Name": "drop soft delete search contexts",
				"UpQuery": "DELETE FROM search_contexts WHERE deleted_at IS NOT NULL;\n\nCOMMENT ON COLUMN search_contexts.deleted_at IS 'This column is unused as of Sourcegraph 3.34. Do not refer to it anymore. It will be dropped in a future version.';\n\nALTER TABLE search_context_repos ADD CONSTRAINT search_context_repos_unique UNIQUE (repo_id, search_context_id, revision);\n\nALTER TABLE search_context_repos DROP CONSTRAINT IF EXISTS search_context_repos_search_context_id_repo_id_revision_unique;",
				"DownQuery": "ALTER TABLE search_context_repos ADD CONSTRAINT search_context_repos_search_context_id_repo_id_revision_unique UNIQUE (search_context_id, repo_id, revision);\n\nALTER TABLE search_context_repos DROP CONSTRAINT IF EXISTS search_context_repos_unique;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395918
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395920,
				"Name": "create sub repo permissions table",
				"UpQuery": "create table sub_repo_permissions\n(\n    repo_id       integer       not null\n        constraint sub_repo_permissions_repo_id_fk\n            references repo\n            on delete cascade,\n    user_id       integer       not null\n        constraint sub_repo_permissions_users_id_fk\n            references users\n            on delete cascade,\n    version       int default 1 not null,\n    path_includes text[],\n    path_excludes text[],\n    updated_at timestamp with time zone default now() not null\n);\n\ncomment on table sub_repo_permissions is 'Responsible for storing permissions at a finer granularity than repo';\n\ncreate unique index sub_repo_permissions_repo_id_user_id_uindex\n    on sub_repo_permissions (repo_id, user_id);\n\ncreate index sub_repo_perms_user_id ON sub_repo_permissions (user_id);\ncreate index sub_repo_perms_repo_id ON sub_repo_permissions (repo_id);",
				"DownQuery": "DROP TABLE IF EXISTS sub_repo_permissions;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395919
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395921,
				"Name": "add version index sub repo permissions",
				"UpQuery": "drop index if exists sub_repo_permissions_repo_id_user_id_uindex;\n\ncreate unique index sub_repo_permissions_repo_id_user_id_version_uindex\n    on sub_repo_permissions (repo_id, user_id, version);\n\ncreate index sub_repo_perms_version ON sub_repo_permissions (version);",
				"DownQuery": "drop index if exists sub_repo_permissions_repo_id_user_id_version_uindex;\ndrop index if exists sub_repo_perms_version;\n\ncreate unique index sub_repo_permissions_repo_id_user_id_uindex\n    on sub_repo_permissions (repo_id, user_id);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395920
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395922,
				"Name": "add external service repos org id index",
				"UpQuery": "CREATE INDEX IF NOT EXISTS external_service_repos_org_id_idx ON external_service_repos USING btree (org_id) WHERE org_id IS NOT NULL;",
				"DownQuery": "DROP INDEX IF EXISTS external_service_repos_org_id_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395921
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395923,
				"Name": "add has webhooks",
				"UpQuery": "ALTER TABLE\n    external_services\nADD COLUMN IF NOT EXISTS\n    has_webhooks BOOLEAN NULL DEFAULT NULL;\n\nCREATE INDEX\n    external_services_has_webhooks_idx\nON\n    external_services (has_webhooks);\n\nINSERT INTO\n    out_of_band_migrations (\n        id,\n        team,\n        component,\n        description,\n        introduced_version_major,\n        introduced_version_minor,\n        non_destructive\n    )\nVALUES (\n    13,\n    'batch-changes',\n    'frontend-db.external_services',\n    'Calculate the webhook state of each external service',\n    3,\n    34,\n    true\n)\nON CONFLICT\n    DO NOTHING\n;",
				"DownQuery": "-- We don't remove the out of band migration when moving down.\n\nALTER TABLE\n    external_services\nDROP COLUMN IF EXISTS\n    has_webhooks;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395922
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395924,
				"Name": "lsif configuration policies repository pattern lookup",
				"UpQuery": "-- Create lookup table for repository pattern matching\nCREATE TABLE IF NOT EXISTS lsif_configuration_policies_repository_pattern_lookup (\n    policy_id INTEGER NOT NULL,\n    repo_id INTEGER NOT NULL,\n    PRIMARY KEY (policy_id, repo_id)\n);\n\nCOMMENT ON TABLE lsif_configuration_policies_repository_pattern_lookup IS 'A lookup table to get all the repository patterns by repository id that apply to a configuration policy.';\nCOMMENT ON COLUMN lsif_configuration_policies_repository_pattern_lookup.policy_id IS 'The policy identifier associated with the repository.';\nCOMMENT ON COLUMN lsif_configuration_policies_repository_pattern_lookup.repo_id IS 'The repository identifier associated with the policy.';\n\n-- Add glob pattern column\nALTER TABLE lsif_configuration_policies ADD COLUMN repository_patterns TEXT[];\nCOMMENT ON COLUMN lsif_configuration_policies.repository_patterns IS 'The name pattern matching repositories to which this configuration policy applies. If absent, all repositories are matched.';\n\n-- Add column to determine the last update of the associated records in lsif_configuration_policies_repository_pattern_lookup\nALTER TABLE lsif_configuration_policies ADD COLUMN last_resolved_at TIMESTAMP WITH TIME ZONE DEFAULT NULL;",
				"DownQuery": "-- Drop new table\nDROP TABLE IF EXISTS lsif_configuration_policies_repository_pattern_lookup;\n\n-- Drop new columns\nALTER TABLE lsif_configuration_policies DROP COLUMN last_resolved_at;\nALTER TABLE lsif_configuration_policies DROP COLUMN repository_patterns;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395923
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395925,
				"Name": "settings global index",
				"UpQuery": "CREATE INDEX IF NOT EXISTS settings_global_id ON settings (id DESC) WHERE user_id IS NULL AND org_id IS NULL;",
				"DownQuery": "DROP INDEX IF EXISTS settings_global_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395924
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395926,
				"Name": "drop redundant sub repo perms index",
				"UpQuery": "DROP INDEX IF EXISTS sub_repo_perms_repo_id;\n\nDROP INDEX IF EXISTS sub_repo_perms_user_id;\n\nDROP INDEX IF EXISTS sub_repo_perms_version;",
				"DownQuery": "CREATE INDEX sub_repo_perms_repo_id ON sub_repo_permissions (repo_id);\n\nCREATE INDEX sub_repo_perms_user_id ON sub_repo_permissions (user_id);\n\nCREATE INDEX sub_repo_perms_version ON sub_repo_permissions (version);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395925
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395927,
				"Name": "webhook logs",
				"UpQuery": "CREATE TABLE IF NOT EXISTS webhook_logs (\n    id BIGSERIAL PRIMARY KEY,\n    received_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n    external_service_id INTEGER NULL REFERENCES external_services (id) ON DELETE CASCADE ON UPDATE CASCADE,\n    status_code INTEGER NOT NULL,\n    request BYTEA NOT NULL,\n    response BYTEA NOT NULL,\n    encryption_key_id TEXT NOT NULL\n);\n\nCREATE INDEX IF NOT EXISTS\n    webhook_logs_received_at_idx\nON\n    webhook_logs (received_at);\n\nCREATE INDEX IF NOT EXISTS\n    webhook_logs_external_service_id_idx\nON\n    webhook_logs (external_service_id);\n\nCREATE INDEX IF NOT EXISTS\n    webhook_logs_status_code_idx\nON\n    webhook_logs (status_code);",
				"DownQuery": "DROP TABLE IF EXISTS webhook_logs;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395926
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395928,
				"Name": "add batch spec execution cache entries",
				"UpQuery": "CREATE TABLE IF NOT EXISTS batch_spec_execution_cache_entries (\n  id           BIGSERIAL PRIMARY KEY,\n\n  key          TEXT NOT NULL,\n  value        TEXT NOT NULL,\n\n  version      INTEGER NOT NULL,\n\n  last_used_at TIMESTAMP WITH TIME ZONE,\n  created_at   TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()\n);",
				"DownQuery": "DROP TABLE IF EXISTS batch_spec_execution_cache_entries;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395927
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395929,
				"Name": "external service repos clone url",
				"UpQuery": "CREATE INDEX IF NOT EXISTS external_service_repos_clone_url_idx ON external_service_repos (clone_url);",
				"DownQuery": "DROP INDEX IF EXISTS external_service_repos_clone_url_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395928
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395930,
				"Name": "drop unused column object ids from user permissions table",
				"UpQuery": "ALTER TABLE IF EXISTS user_permissions DROP COLUMN IF EXISTS object_ids;",
				"DownQuery": "ALTER TABLE IF EXISTS user_permissions ADD COLUMN object_ids bytea NOT NULL default '\\x';",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395929
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395931,
				"Name": "drop unused column user ids from repo permissions table",
				"UpQuery": "ALTER TABLE IF EXISTS repo_permissions DROP COLUMN IF EXISTS user_ids;",
				"DownQuery": "ALTER TABLE IF EXISTS repo_permissions ADD COLUMN user_ids bytea NOT NULL default '\\x';",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395930
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395932,
				"Name": "add cache entry id to batch spec workspaces",
				"UpQuery": "ALTER TABLE batch_spec_workspaces\n  ADD COLUMN IF NOT EXISTS batch_spec_execution_cache_entry_id INTEGER REFERENCES batch_spec_execution_cache_entries(id) DEFERRABLE;",
				"DownQuery": "ALTER TABLE batch_spec_workspaces\n  DROP COLUMN IF EXISTS batch_spec_execution_cache_entry_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395931
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395933,
				"Name": "add cached result found to batch spec workspaces",
				"UpQuery": "ALTER TABLE batch_spec_workspaces\n  ADD COLUMN IF NOT EXISTS cached_result_found BOOLEAN NOT NULL DEFAULT FALSE;\n\nUPDATE\n  batch_spec_workspaces\nSET\n  cached_result_found = true\nWHERE\n  batch_spec_execution_cache_entry_id IS NOT NULL;\n\nALTER TABLE batch_spec_workspaces\n  DROP COLUMN IF EXISTS batch_spec_execution_cache_entry_id;\n\nDELETE FROM\n  batch_spec_execution_cache_entries e1\nWHERE\n  EXISTS (SELECT 1 FROM batch_spec_execution_cache_entries e2 WHERE e1.key = e2.key AND e1.id != e2.id);\n\nALTER TABLE batch_spec_execution_cache_entries\n  ADD CONSTRAINT batch_spec_execution_cache_entries_key_unique UNIQUE (key);",
				"DownQuery": "ALTER TABLE batch_spec_workspaces\n  ADD COLUMN IF NOT EXISTS batch_spec_execution_cache_entry_id INTEGER REFERENCES batch_spec_execution_cache_entries(id) DEFERRABLE;\n\nALTER TABLE batch_spec_workspaces\n  DROP COLUMN IF EXISTS cached_result_found;\n\nALTER TABLE batch_spec_execution_cache_entries\n  DROP CONSTRAINT IF EXISTS batch_spec_execution_cache_entries_key_unique;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395932
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395934,
				"Name": "lsif upload reference counts",
				"UpQuery": "ALTER TABLE lsif_uploads ADD COLUMN reference_count int;\nCOMMENT ON COLUMN lsif_uploads.reference_count IS 'The number of references to this upload data from other upload records (via lsif_references).';\nCOMMENT ON COLUMN lsif_uploads.num_references IS 'Deprecated in favor of reference_count.';",
				"DownQuery": "-- Drop new column\nALTER TABLE lsif_uploads DROP COLUMN reference_count;\n\n-- Restore old comment on deprecated column\nCOMMENT ON COLUMN lsif_uploads.num_references IS 'The number of references to this upload data from other upload records (via lsif_references).';",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395933
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395935,
				"Name": "repo stars desc id desc index",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS repo_stars_desc_id_desc_idx\n    ON repo USING btree (stars DESC NULLS LAST, id DESC) WHERE deleted_at IS NULL AND blocked IS NULL;",
				"DownQuery": "DROP INDEX IF EXISTS repo_stars_desc_id_desc_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395934
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "repo",
					"IndexName": "repo_stars_desc_id_desc_idx"
				}
			},
			{
				"ID": 1528395936,
				"Name": "repo name case sensitive trgm idx",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS repo_name_case_sensitive_trgm_idx ON repo USING gin ((name::text) gin_trgm_ops);",
				"DownQuery": "DROP INDEX IF EXISTS repo_name_case_sensitive_trgm_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395935
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "repo",
					"IndexName": "repo_name_case_sensitive_trgm_idx"
				}
			},
			{
				"ID": 1528395937,
				"Name": "codemonitor webhooks",
				"UpQuery": "-- Begin cm_webhooks\nCREATE TABLE IF NOT EXISTS cm_webhooks (\n\tid BIGSERIAL PRIMARY KEY,\n\tmonitor BIGINT NOT NULL REFERENCES cm_monitors(id) ON DELETE CASCADE,\n\turl TEXT NOT NULL,\n\tenabled BOOLEAN NOT NULL,\n\tcreated_by INTEGER NOT NULL REFERENCES users(id) ON DELETE CASCADE,\n\tcreated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n\tchanged_by INTEGER NOT NULL REFERENCES users(id) ON DELETE CASCADE,\n\tchanged_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()\n);\n\nCREATE INDEX IF NOT EXISTS cm_webhooks_monitor ON cm_webhooks (monitor);\n\nCOMMENT ON TABLE cm_webhooks IS 'Webhook actions configured on code monitors';\nCOMMENT ON COLUMN cm_webhooks.monitor IS 'The code monitor that the action is defined on';\nCOMMENT ON COLUMN cm_webhooks.url IS 'The webhook URL we send the code monitor event to';\nCOMMENT ON COLUMN cm_webhooks.enabled IS 'Whether this webhook action is enabled. When not enabled, the action will not be run when its code monitor generates events';\n-- End cm_webhooks\n\n-- Begin cm_slack_webhooks\nCREATE TABLE IF NOT EXISTS cm_slack_webhooks (\n\tid BIGSERIAL PRIMARY KEY,\n\tmonitor BIGINT NOT NULL REFERENCES cm_monitors(id) ON DELETE CASCADE,\n\turl TEXT NOT NULL,\n\tenabled BOOLEAN NOT NULL,\n\tcreated_by INTEGER NOT NULL REFERENCES users(id) ON DELETE CASCADE,\n\tcreated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n\tchanged_by INTEGER NOT NULL REFERENCES users(id) ON DELETE CASCADE,\n\tchanged_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()\n);\n\nCREATE INDEX IF NOT EXISTS cm_slack_webhooks_monitor ON cm_slack_webhooks (monitor);\n\nCOMMENT ON TABLE cm_slack_webhooks IS 'Slack webhook actions configured on code monitors';\nCOMMENT ON COLUMN cm_slack_webhooks.monitor IS 'The code monitor that the action is defined on';\nCOMMENT ON COLUMN cm_slack_webhooks.url IS 'The Slack webhook URL we send the code monitor event to';\nCOMMENT ON COLUMN cm_webhooks.enabled IS 'Whether this Slack webhook action is enabled. When not enabled, the action will not be run when its code monitor generates events';\n-- End cm_slack_webhooks\n\n-- Begin add non-email actions to cm_triggers\nALTER TABLE cm_action_jobs\n\tALTER COLUMN email DROP NOT NULL, -- make email nullable (drop the not null constraint)\n\tADD COLUMN IF NOT EXISTS webhook BIGINT -- create a nullable webhook column\n\t\tREFERENCES cm_webhooks(id) ON DELETE CASCADE,\n\tADD COLUMN IF NOT EXISTS slack_webhook BIGINT  --create a nullable slack webhook column\n\t\tREFERENCES cm_slack_webhooks(id) ON DELETE CASCADE,\n\tADD CONSTRAINT cm_action_jobs_only_one_action_type CHECK ( -- constrain that only one of email, webhook, and slack_webhook is non-null\n\t\t( \n\t\t\tCASE WHEN email IS NULL THEN 0 ELSE 1 END\n\t\t\t+ CASE WHEN webhook IS NULL THEN 0 ELSE 1 END \n\t\t\t+ CASE WHEN slack_webhook IS NULL THEN 0 ELSE 1 END \n\t\t) = 1\n\t);\n\nCOMMENT ON COLUMN cm_action_jobs.email IS 'The ID of the cm_emails action to execute if this is an email job. Mutually exclusive with webhook and slack_webhook';\nCOMMENT ON COLUMN cm_action_jobs.webhook IS 'The ID of the cm_webhooks action to execute if this is a webhook job. Mutually exclusive with email and slack_webhook';\nCOMMENT ON COLUMN cm_action_jobs.slack_webhook IS 'The ID of the cm_slack_webhook action to execute if this is a slack webhook job. Mutually exclusive with email and webhook';\nCOMMENT ON CONSTRAINT cm_action_jobs_only_one_action_type ON cm_action_jobs IS 'Constrains that each queued code monitor action has exactly one action type';\n-- End add non-email actions to cm_triggers",
				"DownQuery": "ALTER TABLE cm_action_jobs\n\tDROP CONSTRAINT IF EXISTS cm_action_jobs_only_one_action_type,\n\tDROP COLUMN IF EXISTS slack_webhook,\n\tDROP COLUMN IF EXISTS webhook,\n\tALTER COLUMN email SET NOT NULL;\n\nDROP TABLE IF EXISTS cm_slack_webhooks;\nDROP TABLE IF EXISTS cm_webhooks;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395936
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395938,
				"Name": "batch spec no cache",
				"UpQuery": "ALTER TABLE batch_specs ADD COLUMN IF NOT EXISTS no_cache BOOLEAN NOT NULL DEFAULT FALSE;",
				"DownQuery": "ALTER TABLE batch_specs DROP COLUMN IF EXISTS no_cache;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395937
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395939,
				"Name": "batch specs changeset specs delete cascade",
				"UpQuery": "ALTER TABLE changeset_specs\n    DROP CONSTRAINT changeset_specs_batch_spec_id_fkey,\n    ADD CONSTRAINT changeset_specs_batch_spec_id_fkey FOREIGN KEY (batch_spec_id) REFERENCES batch_specs (id) ON DELETE CASCADE DEFERRABLE;",
				"DownQuery": "ALTER TABLE changeset_specs\n    DROP CONSTRAINT changeset_specs_batch_spec_id_fkey,\n    ADD CONSTRAINT changeset_specs_batch_spec_id_fkey FOREIGN KEY (batch_spec_id) REFERENCES batch_specs (id) DEFERRABLE;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395938
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395940,
				"Name": "executor heartbeats",
				"UpQuery": "CREATE TABLE IF NOT EXISTS executor_heartbeats (\n    id SERIAL PRIMARY KEY,\n    hostname TEXT NOT NULL UNIQUE,\n    queue_name TEXT NOT NULL,\n    os TEXT NOT NULL,\n    architecture TEXT NOT NULL,\n    docker_version TEXT NOT NULL,\n    executor_version TEXT NOT NULL,\n    git_version TEXT NOT NULL,\n    ignite_version TEXT NOT NULL,\n    src_cli_version TEXT NOT NULL,\n    first_seen_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n    last_seen_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()\n);\n\nCOMMENT ON TABLE executor_heartbeats IS 'Tracks the most recent activity of executors attached to this Sourcegraph instance.';\nCOMMENT ON COLUMN executor_heartbeats.hostname IS 'The uniquely identifying name of the executor.';\nCOMMENT ON COLUMN executor_heartbeats.queue_name IS 'The queue name that the executor polls for work.';\nCOMMENT ON COLUMN executor_heartbeats.os IS 'The operating system running the executor.';\nCOMMENT ON COLUMN executor_heartbeats.architecture IS 'The machine architure running the executor.';\nCOMMENT ON COLUMN executor_heartbeats.docker_version IS 'The version of Docker used by the executor.';\nCOMMENT ON COLUMN executor_heartbeats.executor_version IS 'The version of the executor.';\nCOMMENT ON COLUMN executor_heartbeats.git_version IS 'The version of Git used by the executor.';\nCOMMENT ON COLUMN executor_heartbeats.ignite_version IS 'The version of Ignite used by the executor.';\nCOMMENT ON COLUMN executor_heartbeats.src_cli_version IS 'The version of src-cli used by the executor.';\nCOMMENT ON COLUMN executor_heartbeats.first_seen_at IS 'The first time a heartbeat from the executor was received.';\nCOMMENT ON COLUMN executor_heartbeats.last_seen_at IS 'The last time a heartbeat from the executor was received.';",
				"DownQuery": "DROP TABLE IF EXISTS executor_heartbeats;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395939
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395941,
				"Name": "remove-org-monitors",
				"UpQuery": "DELETE FROM cm_monitors WHERE namespace_user_id IS NULL;\nCOMMENT ON COLUMN cm_monitors.namespace_org_id IS 'DEPRECATED: code monitors cannot be owned by an org';\n\nALTER TABLE cm_monitors \n\tALTER COLUMN namespace_user_id SET NOT NULL;",
				"DownQuery": "ALTER TABLE cm_monitors\n\tALTER COLUMN namespace_user_id DROP NOT NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395940
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395942,
				"Name": "remove-org-saved-searches",
				"UpQuery": "-- NOTE: this migration deleted saved searches belonging to orgs when what we should have done\n-- was remove notifications from saved searches. Saved searches are still used (and useful) as\n-- a bookmarking feature, and are not deprecated. Saved search notifications, however, are\n-- deprecated, and will be removed in v3.34.0 by removing the query runner service. \n\n-- DELETE FROM saved_searches WHERE user_id IS NULL;\n\n-- ALTER TABLE saved_searches\n-- \tALTER COLUMN user_id SET NOT NULL;\n\n-- COMMENT ON COLUMN saved_searches.org_id IS 'DEPRECATED: saved searches must be owned by a user';",
				"DownQuery": "-- ALTER TABLE saved_searches\n-- \tALTER COLUMN user_id DROP NOT NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395941
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395943,
				"Name": "disable-saved-search-notifications",
				"UpQuery": "UPDATE saved_searches\nSET (notify_owner, notify_slack) = (false, false);\n\nALTER TABLE saved_searches\n\tADD CONSTRAINT saved_searches_notifications_disabled CHECK (\n\t\tnotify_owner = false\n\t\tAND notify_slack = false\n\t);\n\nALTER TABLE IF EXISTS saved_searches\n\tALTER COLUMN user_id DROP NOT NULL;",
				"DownQuery": "ALTER TABLE IF EXISTS saved_searches\n\tDROP CONSTRAINT IF EXISTS saved_searches_notifications_disabled;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395942
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395944,
				"Name": "reenable-code-monitors",
				"UpQuery": "-- If code monitors were disabled by a manual step, make\n\t-- it possible to re-enable them by removing the constraint.\n\t-- If an admin wants to restore the previous enabled state\n\t-- from the backup table, they can run something like the following:\n\t--     UPDATE cm_monitors\n\t--     SET enabled = cm_monitors_enabled_backup.enabled\n\t--     FROM cm_monitors_enabled_backup\n\t--     WHERE cm_monitors.id = cm_monitors_enabled_backup.id;\n\tALTER TABLE cm_monitors\n\tDROP CONSTRAINT IF EXISTS cm_monitors_cannot_be_enabled;",
				"DownQuery": "",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395943
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395945,
				"Name": "make batch change last applied at nullable",
				"UpQuery": "-- NO-OP to fix out of sequence migrations",
				"DownQuery": "-- NO-OP to fix out of sequence migrations",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395944
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395946,
				"Name": "drop unused last external service column",
				"UpQuery": "-- NO-OP to fix out of sequence migrations",
				"DownQuery": "-- NO-OP to fix out of sequence migrations",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395945
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395947,
				"Name": "settings migration out of band",
				"UpQuery": "-- NO-OP to fix out of sequence migrations",
				"DownQuery": "-- NO-OP to fix out of sequence migrations",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395946
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395948,
				"Name": "cache entry persist",
				"UpQuery": "-- NO-OP to fix out of sequence migrations",
				"DownQuery": "-- NO-OP to fix out of sequence migrations",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395947
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395949,
				"Name": "repo stars null to zero",
				"UpQuery": "CREATE OR REPLACE PROCEDURE set_repo_stars_null_to_zero() AS\n$BODY$\nDECLARE\n  done boolean;\n  total integer = 0;\n  updated integer = 0;\n\nBEGIN\n  SELECT COUNT(*) INTO total FROM repo WHERE stars IS NULL;\n\n  RAISE NOTICE 'repo_stars_null_to_zero: updating % rows', total;\n\n  done := total = 0;\n\n  WHILE NOT done LOOP\n    UPDATE repo SET stars = 0\n    FROM (\n      SELECT id FROM repo\n      WHERE stars IS NULL\n      LIMIT 10000\n      FOR UPDATE SKIP LOCKED\n    ) s\n    WHERE repo.id = s.id;\n\n    COMMIT;\n\n    SELECT COUNT(*) = 0 INTO done FROM repo WHERE stars IS NULL LIMIT 1;\n\n    updated := updated + 10000;\n\n    RAISE NOTICE 'repo_stars_null_to_zero: updated % of % rows', updated, total;\n  END LOOP;\nEND\n$BODY$\nLANGUAGE plpgsql;",
				"DownQuery": "DROP PROCEDURE IF EXISTS set_repo_stars_null_to_zero;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395948
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395950,
				"Name": "repo stars call null to zero",
				"UpQuery": "WITH locked AS (\n\t\t\t\tSELECT id FROM repo\n\t\t\t\tWHERE stars IS NULL\n\t\t\t\tFOR UPDATE\n\t\t\t)\n\t\t\tUPDATE repo SET stars = 0\n\t\t\tFROM locked s WHERE repo.id = s.id",
				"DownQuery": "",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395949
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395951,
				"Name": "repo stars not null",
				"UpQuery": "ALTER TABLE repo\n  ALTER COLUMN stars SET NOT NULL,\n  ALTER COLUMN stars SET DEFAULT 0;",
				"DownQuery": "ALTER TABLE repo\n  ALTER COLUMN stars DROP NOT NULL,\n  ALTER COLUMN stars DROP DEFAULT;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395950
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395952,
				"Name": "notebooks",
				"UpQuery": "CREATE TABLE IF NOT EXISTS notebooks (\n    id BIGSERIAL PRIMARY KEY,\n    title CITEXT NOT NULL,\n    blocks JSONB DEFAULT '[]'::JSONB NOT NULL,\n    public BOOLEAN NOT NULL,\n    creator_user_id INTEGER REFERENCES users(id) ON DELETE SET NULL DEFERRABLE,\n    created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n    updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n\n    CONSTRAINT blocks_is_array CHECK (jsonb_typeof(blocks) = 'array')\n);",
				"DownQuery": "DROP TABLE IF EXISTS notebooks;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395951
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395953,
				"Name": "enable pgcrypto",
				"UpQuery": "CREATE EXTENSION IF NOT EXISTS pgcrypto;",
				"DownQuery": "DROP EXTENSION IF EXISTS pgcrypto;",
				"Privileged": true,
				"NonIdempotent": false,
				"Parents": [
					1528395952
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395954,
				"Name": "add repo hashed name index",
				"UpQuery": "-- Should run as single non-transaction block\nCREATE INDEX CONCURRENTLY IF NOT EXISTS repo_hashed_name_idx ON repo USING BTREE (sha256(lower(name)::bytea)) WHERE deleted_at IS NULL;",
				"DownQuery": "-- Should run as single non-transaction block\nDROP INDEX CONCURRENTLY IF EXISTS repo_hashed_name_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395953
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "repo",
					"IndexName": "repo_hashed_name_idx"
				}
			},
			{
				"ID": 1528395955,
				"Name": "add user id to batch spec execution cache entries",
				"UpQuery": "-- Bust the cache, since we can't recreate the user_id for existing cache entries.\nDELETE FROM batch_spec_execution_cache_entries;\n\nALTER TABLE batch_spec_execution_cache_entries\n  ADD COLUMN IF NOT EXISTS user_id INTEGER NOT NULL REFERENCES users(id) ON DELETE CASCADE DEFERRABLE,\n  DROP CONSTRAINT IF EXISTS batch_spec_execution_cache_entries_key_unique,\n    DROP CONSTRAINT IF EXISTS batch_spec_execution_cache_entries_user_id_key_unique,\n  ADD CONSTRAINT batch_spec_execution_cache_entries_user_id_key_unique UNIQUE (user_id, key);",
				"DownQuery": "-- Bust the cache, since we might run into unique key constraint errors.\nDELETE FROM batch_spec_execution_cache_entries;\n\nALTER TABLE batch_spec_execution_cache_entries\n  DROP CONSTRAINT IF EXISTS batch_spec_execution_cache_entries_user_id_key_unique,\n  DROP COLUMN IF EXISTS user_id,\n  DROP CONSTRAINT IF EXISTS batch_spec_execution_cache_entries_key_unique,\n  ADD CONSTRAINT batch_spec_execution_cache_entries_key_unique UNIQUE (key);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395954
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395956,
				"Name": "add org stats table",
				"UpQuery": "CREATE TABLE IF NOT EXISTS org_stats\n(\n    org_id INTEGER\n        REFERENCES orgs(id) ON DELETE CASCADE DEFERRABLE\n            PRIMARY KEY,\n    code_host_repo_count INTEGER DEFAULT 0,\n    updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()\n);\n\nCOMMENT ON TABLE org_stats IS 'Business statistics for organizations';\nCOMMENT ON COLUMN org_stats.org_id IS 'Org ID that the stats relate to.';\nCOMMENT ON COLUMN org_stats.code_host_repo_count IS 'Count of repositories accessible on all code hosts for this organization.';",
				"DownQuery": "DROP TABLE IF EXISTS org_stats;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395955
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395957,
				"Name": "notebooks text search indices",
				"UpQuery": "-- We add a generated column that will contain a tsvector representation of strings contained in the blocks array (extracted with the jsonb_to_tsvector expression).\nALTER TABLE notebooks ADD COLUMN IF NOT EXISTS blocks_tsvector TSVECTOR GENERATED ALWAYS AS (jsonb_to_tsvector('english', blocks, '[\"string\"]')) STORED;\n\n-- Postgres does not support trigram indices on a CITEXT column. We have to revert it back to a regular TEXT column to apply a trigram index.\nALTER TABLE notebooks ALTER COLUMN title TYPE TEXT;\n\nCREATE INDEX IF NOT EXISTS notebooks_title_trgm_idx ON notebooks USING GIN (title gin_trgm_ops);\n\n-- TSVECTOR columns do not support a gin_trgm_ops index, so we omit it here.\nCREATE INDEX IF NOT EXISTS notebooks_blocks_tsvector_idx ON notebooks USING GIN (blocks_tsvector);",
				"DownQuery": "ALTER TABLE notebooks DROP COLUMN IF EXISTS blocks_tsvector;\n\nALTER TABLE notebooks ALTER COLUMN title TYPE CITEXT;\n\nDROP INDEX IF EXISTS notebooks_title_trgm_idx;\n\nDROP INDEX IF EXISTS notebooks_blocks_tsvector_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395956
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395958,
				"Name": "tos accepted",
				"UpQuery": "ALTER TABLE IF EXISTS users ADD COLUMN IF NOT EXISTS tos_accepted BOOLEAN NOT NULL DEFAULT FALSE;",
				"DownQuery": "ALTER TABLE IF EXISTS users DROP COLUMN IF EXISTS tos_accepted;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395957
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395959,
				"Name": "batch change creator id",
				"UpQuery": "DO $$\nBEGIN\n    IF EXISTS (SELECT 1 FROM information_schema.columns WHERE table_name = 'batch_changes' AND column_name = 'initial_applier_id')\n    THEN\n        ALTER TABLE batch_changes RENAME COLUMN initial_applier_id TO creator_id;\n    END IF;\nEND $$;",
				"DownQuery": "DO $$\nBEGIN\n    IF EXISTS (SELECT 1 FROM information_schema.columns WHERE table_name = 'batch_changes' AND column_name = 'creator_id')\n    THEN\n        ALTER TABLE batch_changes RENAME COLUMN creator_id TO initial_applier_id;\n    END IF;\nEND $$;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395958
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395960,
				"Name": "batch spec workspace skipped steps",
				"UpQuery": "ALTER TABLE batch_spec_workspaces ADD COLUMN IF NOT EXISTS skipped_steps integer[] NOT NULL DEFAULT '{}';",
				"DownQuery": "ALTER TABLE batch_spec_workspaces DROP COLUMN IF EXISTS skipped_steps;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395959
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395961,
				"Name": "make batch change last applied at nullable",
				"UpQuery": "ALTER TABLE IF EXISTS batch_changes\n    ALTER COLUMN last_applied_at DROP NOT NULL,\n    ALTER COLUMN last_applied_at DROP DEFAULT;",
				"DownQuery": "UPDATE batch_changes SET last_applied_at = TO_TIMESTAMP(0) WHERE last_applied_at IS NULL;\n\nALTER TABLE IF EXISTS batch_changes\n    ALTER COLUMN last_applied_at SET DEFAULT NOW(),\n    ALTER COLUMN last_applied_at SET NOT NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395960
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395962,
				"Name": "drop unused last external service column",
				"UpQuery": "ALTER TABLE IF EXISTS gitserver_repos DROP COLUMN IF EXISTS last_external_service;",
				"DownQuery": "ALTER TABLE IF EXISTS gitserver_repos ADD COLUMN IF NOT EXISTS last_external_service bigint;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395961
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395963,
				"Name": "settings migration out of band",
				"UpQuery": "CREATE TABLE IF NOT EXISTS insights_settings_migration_jobs\n(\n    id SERIAL NOT NULL,\n    user_id int,\n    org_id int,\n    global boolean,\n    settings_id int NOT NULL, -- non-constrained foreign key to settings object that should be migrated\n    total_insights int NOT NULL DEFAULT 0,\n    migrated_insights int NOT NULL DEFAULT 0,\n    total_dashboards int NOT NULL DEFAULT 0,\n    migrated_dashboards int NOT NULL DEFAULT 0,\n    runs int NOT NULL DEFAULT 0,\n    completed_at timestamp\n);\n\nTRUNCATE insights_settings_migration_jobs;\n\n-- We go in this order (global, org, user) such that we migrate any higher level shared insights first. This way\n-- we can just go in the order of id rather than have a secondary index.\n\n-- global\nINSERT INTO insights_settings_migration_jobs (settings_id, global)\nSELECT id, TRUE\nFROM settings\nWHERE user_id IS NULL AND org_id IS NULL\nORDER BY id DESC\nLIMIT 1;\n\n-- org\nINSERT INTO insights_settings_migration_jobs (settings_id, org_id)\nSELECT DISTINCT ON (org_id) id, org_id\nFROM settings\nWHERE org_id IS NOT NULL\nORDER BY org_id, id DESC;\n\n--  user\nINSERT INTO insights_settings_migration_jobs (settings_id, user_id)\nSELECT DISTINCT ON (user_id) id, user_id\nFROM settings\nWHERE user_id IS NOT NULL\nORDER BY user_id, id DESC;\n\n\nINSERT INTO out_of_band_migrations(id, team, component, description, non_destructive,\n                                   apply_reverse, is_enterprise, introduced_version_major, introduced_version_minor)\nVALUES (14, 'code-insights', 'db.insights_settings_migration_jobs',\n        'Migrating insight definitions from settings files to database tables as a last stage to use the GraphQL API.',\n        TRUE, FALSE, TRUE, 3, 35)\nON CONFLICT DO NOTHING;",
				"DownQuery": "DROP TABLE IF EXISTS insights_settings_migration_jobs;\n\nDELETE\nFROM out_of_band_migrations\nWHERE id = 14;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395962
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395964,
				"Name": "cache entry persist",
				"UpQuery": "ALTER TABLE batch_spec_workspaces ADD COLUMN IF NOT EXISTS step_cache_results JSONB NOT NULL DEFAULT '{}';",
				"DownQuery": "ALTER TABLE batch_spec_workspaces DROP COLUMN IF EXISTS step_cache_results;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395963
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395965,
				"Name": "add search contexts query",
				"UpQuery": "ALTER TABLE search_contexts ADD COLUMN IF NOT EXISTS query TEXT;\n\nCREATE INDEX IF NOT EXISTS search_contexts_query_idx ON search_contexts USING BTREE (query);",
				"DownQuery": "ALTER TABLE search_contexts DROP COLUMN IF EXISTS query;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395964
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395966,
				"Name": "add changeset external fork namespace",
				"UpQuery": "-- Note that we have to regenerate the reconciler_changesets view, as the SELECT\n-- c.* in the view definition isn't refreshed when the fields change within the\n-- changesets table.\nDROP VIEW IF EXISTS\n    reconciler_changesets;\n\nALTER TABLE\n  changesets\nADD COLUMN IF NOT EXISTS\n  external_fork_namespace CITEXT NULL;\n\nCREATE VIEW reconciler_changesets AS\n    SELECT c.* FROM changesets c\n    INNER JOIN repo r on r.id = c.repo_id\n    WHERE\n        r.deleted_at IS NULL AND\n        EXISTS (\n            SELECT 1 FROM batch_changes\n            LEFT JOIN users namespace_user ON batch_changes.namespace_user_id = namespace_user.id\n            LEFT JOIN orgs namespace_org ON batch_changes.namespace_org_id = namespace_org.id\n            WHERE\n                c.batch_change_ids ? batch_changes.id::text AND\n                namespace_user.deleted_at IS NULL AND\n                namespace_org.deleted_at IS NULL\n        )\n;",
				"DownQuery": "-- Note that we have to regenerate the reconciler_changesets view, as the SELECT\n-- c.* in the view definition isn't refreshed when the fields change within the\n-- changesets table.\nDROP VIEW IF EXISTS\n    reconciler_changesets;\n\nALTER TABLE\n  changesets\nDROP COLUMN IF EXISTS\n  external_fork_namespace;\n\nCREATE VIEW reconciler_changesets AS\n    SELECT c.* FROM changesets c\n    INNER JOIN repo r on r.id = c.repo_id\n    WHERE\n        r.deleted_at IS NULL AND\n        EXISTS (\n            SELECT 1 FROM batch_changes\n            LEFT JOIN users namespace_user ON batch_changes.namespace_user_id = namespace_user.id\n            LEFT JOIN orgs namespace_org ON batch_changes.namespace_org_id = namespace_org.id\n            WHERE\n                c.batch_change_ids ? batch_changes.id::text AND\n                namespace_user.deleted_at IS NULL AND\n                namespace_org.deleted_at IS NULL\n        )\n;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395965
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395967,
				"Name": "notebook stars",
				"UpQuery": "CREATE TABLE IF NOT EXISTS notebook_stars (\n    notebook_id INTEGER NOT NULL REFERENCES notebooks(id) ON DELETE CASCADE DEFERRABLE,\n    user_id INTEGER NOT NULL REFERENCES users(id) ON DELETE CASCADE DEFERRABLE,\n    created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n\n    PRIMARY KEY (notebook_id, user_id)\n);\n\nCREATE INDEX IF NOT EXISTS notebook_stars_user_id_idx ON notebook_stars USING btree (user_id);",
				"DownQuery": "DROP INDEX IF EXISTS notebook_stars_user_id_idx;\n\nDROP TABLE IF EXISTS notebook_stars;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395966
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395968,
				"Name": "track fork namespace on spec",
				"UpQuery": "ALTER TABLE\n  changeset_specs\nADD COLUMN IF NOT EXISTS\n  fork_namespace CITEXT NULL;",
				"DownQuery": "ALTER TABLE\n  changeset_specs\nDROP COLUMN IF EXISTS\n  fork_namespace;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395967
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395969,
				"Name": "add org invitation fields",
				"UpQuery": "ALTER TABLE IF EXISTS org_invitations\n  ADD COLUMN IF NOT EXISTS recipient_email CITEXT,\n  ADD COLUMN IF NOT EXISTS expires_at timestamp with time zone;",
				"DownQuery": "ALTER TABLE IF EXISTS org_invitations\n  DROP COLUMN IF EXISTS recipient_email,\n  DROP COLUMN IF EXISTS expires_at;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395968
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395970,
				"Name": "save code monitor payload",
				"UpQuery": "ALTER TABLE cm_trigger_jobs\n    DROP CONSTRAINT IF EXISTS search_results_is_array,\n    ADD COLUMN IF NOT EXISTS search_results JSONB,\n    ADD CONSTRAINT search_results_is_array CHECK (jsonb_typeof(search_results) = 'array');\n\nCOMMENT ON COLUMN cm_trigger_jobs.results IS 'DEPRECATED: replaced by len(search_results) \u003e 0. Can be removed after version 3.37 release cut';\nCOMMENT ON COLUMN cm_trigger_jobs.num_results IS 'DEPRECATED: replaced by len(search_results). Can be removed after version 3.37 release cut';",
				"DownQuery": "ALTER TABLE cm_trigger_jobs\n    DROP COLUMN IF EXISTS search_results;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395969
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395971,
				"Name": "add notebook namespaces",
				"UpQuery": "ALTER TABLE IF EXISTS notebooks\n    ADD COLUMN IF NOT EXISTS namespace_user_id integer REFERENCES users(id) ON DELETE SET NULL DEFERRABLE,\n    ADD COLUMN IF NOT EXISTS namespace_org_id integer REFERENCES orgs(id) ON DELETE SET NULL DEFERRABLE,\n    ADD COLUMN IF NOT EXISTS updater_user_id integer REFERENCES users(id) ON DELETE SET NULL DEFERRABLE,\n    DROP CONSTRAINT IF EXISTS notebooks_has_max_1_namespace,\n    ADD CONSTRAINT notebooks_has_max_1_namespace CHECK ((namespace_user_id IS NULL AND namespace_org_id IS NULL) OR ((namespace_user_id IS NULL) \u003c\u003e (namespace_org_id IS NULL)));\n\nCREATE INDEX IF NOT EXISTS notebooks_namespace_user_id_idx ON notebooks USING btree (namespace_user_id);\n\nCREATE INDEX IF NOT EXISTS notebooks_namespace_org_id_idx ON notebooks USING btree (namespace_org_id);\n\nUPDATE notebooks SET namespace_user_id = creator_user_id;",
				"DownQuery": "ALTER TABLE IF EXISTS notebooks\n    DROP COLUMN IF EXISTS namespace_user_id,\n    DROP COLUMN IF EXISTS namespace_org_id,\n    DROP COLUMN IF EXISTS updater_user_id,\n    DROP CONSTRAINT IF EXISTS notebooks_has_max_1_namespace;\n\nDROP INDEX IF EXISTS notebooks_namespace_user_id_idx;\n\nDROP INDEX IF EXISTS notebooks_namespace_org_id_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395970
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395972,
				"Name": "no steps persisted",
				"UpQuery": "ALTER TABLE batch_spec_workspaces DROP COLUMN IF EXISTS steps;\nALTER TABLE batch_spec_workspaces DROP COLUMN IF EXISTS skipped_steps;",
				"DownQuery": "ALTER TABLE batch_spec_workspaces ADD COLUMN IF NOT EXISTS steps JSONB DEFAULT '[]'::JSONB CHECK (jsonb_typeof(steps) = 'array'::TEXT);\nALTER TABLE batch_spec_workspaces ADD COLUMN IF NOT EXISTS skipped_steps INTEGER[] NOT NULL DEFAULT '{}'::INTEGER[];",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395971
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395973,
				"Name": "return user_id index to sub_repo_permissions table",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS sub_repo_perms_user_id ON sub_repo_permissions (user_id);",
				"DownQuery": "DROP INDEX IF EXISTS sub_repo_perms_user_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395972
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "sub_repo_permissions",
					"IndexName": "sub_repo_perms_user_id"
				}
			},
			{
				"ID": 1644471839,
				"Name": "codemonitor results in notifications",
				"UpQuery": "ALTER TABLE cm_emails\n    ADD COLUMN IF NOT EXISTS include_results BOOLEAN NOT NULL DEFAULT FALSE;\nALTER TABLE cm_webhooks\n    ADD COLUMN IF NOT EXISTS include_results BOOLEAN NOT NULL DEFAULT FALSE;\nALTER TABLE cm_slack_webhooks\n    ADD COLUMN IF NOT EXISTS include_results BOOLEAN NOT NULL DEFAULT FALSE;",
				"DownQuery": "ALTER TABLE cm_emails\n    DROP COLUMN IF EXISTS include_results;\nALTER TABLE cm_webhooks\n    DROP COLUMN IF EXISTS include_results;\nALTER TABLE cm_slack_webhooks\n    DROP COLUMN IF EXISTS include_results;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395973
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1644515056,
				"Name": "allow org invitation user id to be nullable",
				"UpQuery": "ALTER TABLE IF EXISTS org_invitations ALTER COLUMN recipient_user_id DROP NOT NULL;\nALTER TABLE IF EXISTS org_invitations\n    DROP CONSTRAINT IF EXISTS either_user_id_or_email_defined,\n  ADD CONSTRAINT either_user_id_or_email_defined CHECK ((recipient_user_id IS NULL) != (recipient_email IS NULL));",
				"DownQuery": "-- Undo the changes made in the up migration\nALTER TABLE IF EXISTS org_invitations ALTER COLUMN recipient_user_id SET NOT NULL;\nALTER TABLE IF EXISTS org_invitations DROP CONSTRAINT IF EXISTS either_user_id_or_email_defined;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395973
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1644583379,
				"Name": "set_expiry_date_for_existing_invitations",
				"UpQuery": "-- If we have invitations that are not deleted, not revoked, not responded to and with no expiry time\n-- set the default expiry time to 7 days from now\nUPDATE\n    org_invitations\nSET\n    expires_at = now() + interval '7 days'\nWHERE\n    deleted_at IS NULL\n    AND revoked_at IS NULL\n    AND responded_at IS NULL\n    AND expires_at IS NULL;",
				"DownQuery": "-- Undo the changes made in the up migration\nUPDATE org_invitations SET expires_at = NULL WHERE expires_at IS NOT NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1644515056
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1644868458,
				"Name": "unqiue batch changes",
				"UpQuery": "CREATE UNIQUE INDEX IF NOT EXISTS batch_changes_unique_user_id ON batch_changes (name, namespace_user_id) WHERE namespace_user_id IS NOT NULL;\nCREATE UNIQUE INDEX IF NOT EXISTS batch_changes_unique_org_id ON batch_changes (name, namespace_org_id) WHERE namespace_org_id IS NOT NULL;",
				"DownQuery": "DROP INDEX IF EXISTS batch_changes_unique_user_id;\nDROP INDEX IF EXISTS batch_changes_unique_org_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1644471839,
					1644583379
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1645106226,
				"Name": "user opt in or out from org invite search",
				"UpQuery": "ALTER TABLE IF EXISTS users ADD COLUMN IF NOT EXISTS searchable BOOLEAN NOT NULL DEFAULT TRUE;",
				"DownQuery": "ALTER TABLE IF EXISTS users DROP COLUMN IF EXISTS searchable;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1644868458
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1645554732,
				"Name": "default-settings-value",
				"UpQuery": "ALTER TABLE settings\n    ALTER COLUMN contents SET DEFAULT '{}';\n\nUPDATE settings\nSET contents = '{}'\nWHERE contents = NULL\n    OR contents = '';\n\nALTER TABLE settings\n    ALTER COLUMN contents SET NOT NULL,\n    DROP CONSTRAINT IF EXISTS settings_no_empty_contents,\n    ADD CONSTRAINT settings_no_empty_contents CHECK ( contents \u003c\u003e '' );",
				"DownQuery": "ALTER TABLE settings\n    ALTER COLUMN contents DROP NOT NULL;\n\nALTER TABLE settings\n    ALTER COLUMN contents DROP DEFAULT,\n    DROP CONSTRAINT IF EXISTS settings_no_empty_contents;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1645106226
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1645635177,
				"Name": "allow_another_invitation_after_previous_expired",
				"UpQuery": "DROP INDEX IF EXISTS org_invitations_singleflight;",
				"DownQuery": "CREATE UNIQUE INDEX IF NOT EXISTS org_invitations_singleflight ON org_invitations USING btree (org_id, recipient_user_id) WHERE ((responded_at IS NULL) AND (revoked_at IS NULL) AND (deleted_at IS NULL));",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1645554732
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1646027072,
				"Name": "add external_services.token_expires_at column",
				"UpQuery": "ALTER TABLE external_services ADD COLUMN IF NOT EXISTS token_expires_at TIMESTAMP WITH TIME ZONE;",
				"DownQuery": "ALTER TABLE external_services DROP COLUMN IF EXISTS token_expires_at;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1645554732
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1646153853,
				"Name": "add-created-at-to-external-service-repos",
				"UpQuery": "ALTER TABLE IF EXISTS external_service_repos\n    ADD COLUMN IF NOT EXISTS created_at timestamp with time zone DEFAULT transaction_timestamp();",
				"DownQuery": "ALTER TABLE IF EXISTS external_service_repos\n    DROP COLUMN IF EXISTS created_at;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1645554732
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1646239940,
				"Name": "non-nullable-created-at-external-service-repos",
				"UpQuery": "ALTER TABLE IF EXISTS external_service_repos\n    ALTER COLUMN created_at SET NOT NULL ;",
				"DownQuery": "ALTER TABLE IF EXISTS external_service_repos\n    ALTER COLUMN created_at DROP NOT NULL ;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1645635177,
					1646153853
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1646306565,
				"Name": "drop-binary-permissions-columns",
				"UpQuery": "ALTER TABLE repo_pending_permissions DROP COLUMN IF EXISTS user_ids;\nALTER TABLE user_pending_permissions DROP COLUMN IF EXISTS object_ids;",
				"DownQuery": "ALTER TABLE repo_pending_permissions ADD COLUMN IF NOT EXISTS user_ids bytea NOT NULL DEFAULT '\\x'::bytea;\nALTER TABLE user_pending_permissions ADD COLUMN IF NOT EXISTS object_ids bytea NOT NULL DEFAULT '\\x'::bytea;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1646027072,
					1646239940
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1646652951,
				"Name": "store_org_open_beta_metadata",
				"UpQuery": "-- Perform migration here.\n--\n-- See /migrations/README.md. Highlights:\n--  * Make migrations idempotent (use IF EXISTS)\n--  * Make migrations backwards-compatible (old readers/writers must continue to work)\n--  * If you are using CREATE INDEX CONCURRENTLY, then make sure that only one statement\n--    is defined per file, and that each such statement is NOT wrapped in a transaction.\n--    Each such migration must also declare \"createIndexConcurrently: true\" in their\n--    associated metadata.yaml file.\nCREATE TABLE IF NOT EXISTS orgs_open_beta_stats (\n    id uuid PRIMARY KEY DEFAULT gen_random_uuid(),\n    user_id integer,\n    org_id integer,\n    created_at timestamptz DEFAULT now(),\n    data jsonb NOT NULL DEFAULT '{}'\n);",
				"DownQuery": "-- Undo the changes made in the up migration\nDROP TABLE IF EXISTS orgs_open_beta_stats;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1646306565
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1646741362,
				"Name": "add_gitserver_repos_repo_size_bytes_column",
				"UpQuery": "ALTER TABLE IF EXISTS gitserver_repos\n    ADD COLUMN IF NOT EXISTS repo_size_bytes BIGINT;",
				"DownQuery": "ALTER TABLE IF EXISTS gitserver_repos\n    DROP COLUMN IF EXISTS repo_size_bytes;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1646306565
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1646848295,
				"Name": "indexer version",
				"UpQuery": "ALTER TABLE lsif_uploads ADD COLUMN IF NOT EXISTS indexer_version text;\nCOMMENT ON COLUMN lsif_uploads.indexer_version IS 'The version of the indexer that produced the index file. If not supplied by the user it will be pulled from the index metadata.';\n\nDROP VIEW IF EXISTS lsif_uploads_with_repository_name;\nDROP VIEW IF EXISTS lsif_dumps_with_repository_name;\nDROP VIEW IF EXISTS lsif_dumps;\n\nCREATE VIEW lsif_uploads_with_repository_name AS\nSELECT\n    u.id,\n    u.commit,\n    u.root,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.indexer_version,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.expired,\n    u.last_retention_scan_at,\n    r.name AS repository_name\nFROM lsif_uploads u\nJOIN repo r ON r.id = u.repository_id\nWHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_dumps AS\nSELECT\n    u.id,\n    u.commit,\n    u.root,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.indexer_version,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.expired,\n    u.last_retention_scan_at,\n    u.finished_at AS processed_at\nFROM lsif_uploads u\nWHERE u.state = 'completed'::text OR u.state = 'deleting'::text;\n\nCREATE VIEW lsif_dumps_with_repository_name AS\nSELECT\n    u.id,\n    u.commit,\n    u.root,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.indexer_version,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.expired,\n    u.last_retention_scan_at,\n    u.processed_at,\n    r.name AS repository_name\nFROM lsif_dumps u\nJOIN repo r ON r.id = u.repository_id\nWHERE r.deleted_at IS NULL;",
				"DownQuery": "DROP VIEW IF EXISTS lsif_uploads_with_repository_name;\nDROP VIEW IF EXISTS lsif_dumps_with_repository_name;\nDROP VIEW IF EXISTS lsif_dumps;\n\nALTER TABLE lsif_uploads DROP COLUMN IF EXISTS indexer_version;\n\nCREATE VIEW lsif_uploads_with_repository_name AS\nSELECT\n    u.id,\n    u.commit,\n    u.root,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.expired,\n    u.last_retention_scan_at,\n    r.name AS repository_name\nFROM lsif_uploads u\nJOIN repo r ON r.id = u.repository_id\nWHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_dumps AS\nSELECT\n    u.id,\n    u.commit,\n    u.root,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.expired,\n    u.last_retention_scan_at,\n    u.finished_at AS processed_at\nFROM lsif_uploads u\nWHERE u.state = 'completed'::text OR u.state = 'deleting'::text;\n\nCREATE VIEW lsif_dumps_with_repository_name AS\nSELECT\n    u.id,\n    u.commit,\n    u.root,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.expired,\n    u.last_retention_scan_at,\n    u.processed_at,\n    r.name AS repository_name\nFROM lsif_dumps u\nJOIN repo r ON r.id = u.repository_id\nWHERE r.deleted_at IS NULL;\n\nDROP VIEW IF EXISTS lsif_indexes_with_repository_name;\nALTER TABLE lsif_indexes DROP COLUMN IF EXISTS indexer_version;\n\nCREATE VIEW lsif_indexes_with_repository_name AS\nSELECT\n    u.id,\n    u.commit,\n    u.queued_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.process_after,\n    u.num_resets,\n    u.num_failures,\n    u.docker_steps,\n    u.root,\n    u.indexer,\n    u.indexer_args,\n    u.outfile,\n    u.log_contents,\n    u.execution_logs,\n    u.local_steps,\n    r.name AS repository_name\nFROM lsif_indexes u\nJOIN repo r ON r.id = u.repository_id\nWHERE r.deleted_at IS NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1646741362
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1646847163,
				"Name": "code monitor last searched",
				"UpQuery": "-- Perform migration here.\n--\n-- See /migrations/README.md. Highlights:\n--  * Make migrations idempotent (use IF EXISTS)\n--  * Make migrations backwards-compatible (old readers/writers must continue to work)\n--  * If you are using CREATE INDEX CONCURRENTLY, then make sure that only one statement\n--    is defined per file, and that each such statement is NOT wrapped in a transaction.\n--    Each such migration must also declare \"createIndexConcurrently: true\" in their\n--    associated metadata.yaml file.\n--  * If you are modifying Postgres extensions, you must also declare \"privileged: true\"\n--    in the associated metadata.yaml file.\n\nCREATE TABLE IF NOT EXISTS cm_last_searched (\n    monitor_id BIGINT NOT NULL REFERENCES cm_monitors(id) ON DELETE CASCADE,\n    args_hash BIGINT NOT NULL,\n    commit_oids text[] NOT NULL,\n    PRIMARY KEY (monitor_id, args_hash)\n);\n\nCOMMENT ON TABLE cm_last_searched\n    IS 'The last searched commit hashes for the given code monitor and unique set of search arguments';\nCOMMENT ON COLUMN cm_last_searched.args_hash\n    IS 'A unique hash of the gitserver search arguments to identify this search job';\nCOMMENT ON COLUMN cm_last_searched.commit_oids\n    IS 'The set of commit OIDs that was previously successfully searched and should be excluded on the next run';",
				"DownQuery": "-- Undo the changes made in the up migration\n\nDROP TABLE IF EXISTS cm_last_searched;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1646306565
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1647282553,
				"Name": "Add queued_at to workerutil tables",
				"UpQuery": "ALTER TABLE batch_spec_resolution_jobs ADD COLUMN IF NOT EXISTS queued_at timestamptz DEFAULT NOW();\nALTER TABLE batch_spec_workspace_execution_jobs ADD COLUMN IF NOT EXISTS queued_at timestamptz DEFAULT NOW();\nALTER TABLE changeset_jobs ADD COLUMN IF NOT EXISTS queued_at timestamptz DEFAULT NOW();\nALTER TABLE changesets ADD COLUMN IF NOT EXISTS queued_at timestamptz DEFAULT NOW();\nALTER TABLE cm_action_jobs ADD COLUMN IF NOT EXISTS queued_at timestamptz DEFAULT NOW();\nALTER TABLE cm_trigger_jobs ADD COLUMN IF NOT EXISTS queued_at timestamptz DEFAULT NOW();\nALTER TABLE external_service_sync_jobs ADD COLUMN IF NOT EXISTS queued_at timestamptz DEFAULT NOW();\nALTER TABLE insights_query_runner_jobs ADD COLUMN IF NOT EXISTS queued_at timestamptz DEFAULT NOW();\n\n-- LSIF upload records are not queued when created; they begin in an extra state called \"uploading\" and only\n-- after the payload has been received in full do we mark the record ready for processing. We update this field\n--- manually at that point.\nALTER TABLE lsif_uploads ADD COLUMN IF NOT EXISTS queued_at timestamptz;\n\n--\n-- Drop views that require new column\n\nDROP VIEW IF EXISTS external_service_sync_jobs_with_next_sync_at;\nDROP VIEW IF EXISTS lsif_dumps_with_repository_name;\nDROP VIEW IF EXISTS lsif_uploads_with_repository_name;\nDROP VIEW IF EXISTS lsif_dumps;\nDROP VIEW IF EXISTS reconciler_changesets;\n\n--\n-- Recreate views with new column\n\nCREATE VIEW external_service_sync_jobs_with_next_sync_at AS\nSELECT j.id,\n    j.state,\n    j.failure_message,\n    j.queued_at,\n    j.started_at,\n    j.finished_at,\n    j.process_after,\n    j.num_resets,\n    j.num_failures,\n    j.execution_logs,\n    j.external_service_id,\n    e.next_sync_at\nFROM external_services e\nJOIN external_service_sync_jobs j ON e.id = j.external_service_id;\n\nCREATE VIEW lsif_dumps AS\nSELECT u.id,\n    u.commit,\n    u.root,\n    u.queued_at,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.indexer_version,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.expired,\n    u.last_retention_scan_at,\n    u.finished_at AS processed_at\nFROM lsif_uploads u\nWHERE u.state = 'completed'::text OR u.state = 'deleting'::text;\n\nCREATE VIEW lsif_dumps_with_repository_name AS\nSELECT u.id,\n    u.commit,\n    u.root,\n    u.queued_at,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.indexer_version,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.expired,\n    u.last_retention_scan_at,\n    u.processed_at,\n    r.name AS repository_name\nFROM lsif_dumps u JOIN repo r ON r.id = u.repository_id\nWHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_uploads_with_repository_name AS\nSELECT u.id,\n    u.commit,\n    u.root,\n    u.queued_at,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.indexer_version,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.expired,\n    u.last_retention_scan_at,\n    r.name AS repository_name\nFROM lsif_uploads u\nJOIN repo r ON r.id = u.repository_id\nWHERE r.deleted_at IS NULL;\n\nCREATE VIEW reconciler_changesets AS\nSELECT c.id,\n    c.batch_change_ids,\n    c.repo_id,\n    c.queued_at,\n    c.created_at,\n    c.updated_at,\n    c.metadata,\n    c.external_id,\n    c.external_service_type,\n    c.external_deleted_at,\n    c.external_branch,\n    c.external_updated_at,\n    c.external_state,\n    c.external_review_state,\n    c.external_check_state,\n    c.diff_stat_added,\n    c.diff_stat_changed,\n    c.diff_stat_deleted,\n    c.sync_state,\n    c.current_spec_id,\n    c.previous_spec_id,\n    c.publication_state,\n    c.owned_by_batch_change_id,\n    c.reconciler_state,\n    c.failure_message,\n    c.started_at,\n    c.finished_at,\n    c.process_after,\n    c.num_resets,\n    c.closing,\n    c.num_failures,\n    c.log_contents,\n    c.execution_logs,\n    c.syncer_error,\n    c.external_title,\n    c.worker_hostname,\n    c.ui_publication_state,\n    c.last_heartbeat_at,\n    c.external_fork_namespace\nFROM changesets c\nJOIN repo r ON r.id = c.repo_id\nWHERE r.deleted_at IS NULL AND EXISTS (\n    SELECT 1\n    FROM batch_changes\n    LEFT JOIN users namespace_user ON batch_changes.namespace_user_id = namespace_user.id\n    LEFT JOIN orgs namespace_org ON batch_changes.namespace_org_id = namespace_org.id\n    WHERE c.batch_change_ids ? batch_changes.id::text AND namespace_user.deleted_at IS NULL AND namespace_org.deleted_at IS NULL\n);",
				"DownQuery": "--\n-- Drop views that added new column\n\nDROP VIEW IF EXISTS external_service_sync_jobs_with_next_sync_at;\nDROP VIEW IF EXISTS lsif_dumps_with_repository_name;\nDROP VIEW IF EXISTS lsif_uploads_with_repository_name;\nDROP VIEW IF EXISTS lsif_dumps;\nDROP VIEW IF EXISTS reconciler_changesets;\n\n--\n-- Recreate old views\n\nCREATE VIEW external_service_sync_jobs_with_next_sync_at AS\nSELECT j.id,\n    j.state,\n    j.failure_message,\n    j.started_at,\n    j.finished_at,\n    j.process_after,\n    j.num_resets,\n    j.num_failures,\n    j.execution_logs,\n    j.external_service_id,\n    e.next_sync_at\nFROM external_services e\nJOIN external_service_sync_jobs j ON e.id = j.external_service_id;\n\nCREATE VIEW lsif_dumps AS\nSELECT u.id,\n    u.commit,\n    u.root,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.indexer_version,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.expired,\n    u.last_retention_scan_at,\n    u.finished_at AS processed_at\nFROM lsif_uploads u\nWHERE u.state = 'completed'::text OR u.state = 'deleting'::text;\n\nCREATE VIEW lsif_dumps_with_repository_name AS\nSELECT u.id,\n    u.commit,\n    u.root,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.indexer_version,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.expired,\n    u.last_retention_scan_at,\n    u.processed_at,\n    r.name AS repository_name\nFROM lsif_dumps u JOIN repo r ON r.id = u.repository_id\nWHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_uploads_with_repository_name AS\nSELECT u.id,\n    u.commit,\n    u.root,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.indexer_version,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.expired,\n    u.last_retention_scan_at,\n    r.name AS repository_name\nFROM lsif_uploads u\nJOIN repo r ON r.id = u.repository_id\nWHERE r.deleted_at IS NULL;\n\nCREATE VIEW reconciler_changesets AS\nSELECT c.id,\n    c.batch_change_ids,\n    c.repo_id,\n    c.created_at,\n    c.updated_at,\n    c.metadata,\n    c.external_id,\n    c.external_service_type,\n    c.external_deleted_at,\n    c.external_branch,\n    c.external_updated_at,\n    c.external_state,\n    c.external_review_state,\n    c.external_check_state,\n    c.diff_stat_added,\n    c.diff_stat_changed,\n    c.diff_stat_deleted,\n    c.sync_state,\n    c.current_spec_id,\n    c.previous_spec_id,\n    c.publication_state,\n    c.owned_by_batch_change_id,\n    c.reconciler_state,\n    c.failure_message,\n    c.started_at,\n    c.finished_at,\n    c.process_after,\n    c.num_resets,\n    c.closing,\n    c.num_failures,\n    c.log_contents,\n    c.execution_logs,\n    c.syncer_error,\n    c.external_title,\n    c.worker_hostname,\n    c.ui_publication_state,\n    c.last_heartbeat_at,\n    c.external_fork_namespace\nFROM changesets c\nJOIN repo r ON r.id = c.repo_id\nWHERE r.deleted_at IS NULL AND EXISTS (\n    SELECT 1\n    FROM batch_changes\n    LEFT JOIN users namespace_user ON batch_changes.namespace_user_id = namespace_user.id\n    LEFT JOIN orgs namespace_org ON batch_changes.namespace_org_id = namespace_org.id\n    WHERE c.batch_change_ids ? batch_changes.id::text AND namespace_user.deleted_at IS NULL AND namespace_org.deleted_at IS NULL\n);\n\n--\n-- Drop new columns\n\nALTER TABLE batch_spec_resolution_jobs DROP COLUMN IF EXISTS queued_at;\nALTER TABLE batch_spec_workspace_execution_jobs DROP COLUMN IF EXISTS queued_at;\nALTER TABLE changeset_jobs DROP COLUMN IF EXISTS queued_at;\nALTER TABLE changesets DROP COLUMN IF EXISTS queued_at;\nALTER TABLE cm_action_jobs DROP COLUMN IF EXISTS queued_at;\nALTER TABLE cm_trigger_jobs DROP COLUMN IF EXISTS queued_at;\nALTER TABLE external_service_sync_jobs DROP COLUMN IF EXISTS queued_at;\nALTER TABLE insights_query_runner_jobs DROP COLUMN IF EXISTS queued_at;\nALTER TABLE lsif_uploads DROP COLUMN IF EXISTS queued_at;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1646847163,
					1646848295
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1647849753,
				"Name": "drop backup tables",
				"UpQuery": "DROP TABLE IF EXISTS org_members_bkup_1514536731;\nDROP TABLE IF EXISTS settings_bkup_1514702776;",
				"DownQuery": "-- Nothing to do, actually. We have not been using these backup tables since 2018.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1646652951,
					1647282553
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1647860082,
				"Name": "add_localclone_worker_table",
				"UpQuery": "CREATE TABLE IF NOT EXISTS gitserver_localclone_jobs (\n    id                  SERIAL PRIMARY KEY,\n    state               text DEFAULT 'queued',\n    failure_message     text,\n    started_at          timestamp with time zone,\n    finished_at         timestamp with time zone,\n    process_after       timestamp with time zone,\n    num_resets          integer not null default 0,\n    num_failures        integer not null default 0,\n    last_heartbeat_at   timestamp with time zone,\n    execution_logs      json[],\n    worker_hostname     text not null default '',\n\n    repo_id             integer not null,\n    source_hostname     text not null,\n    dest_hostname       text not null,\n    delete_source       boolean not null default false\n);",
				"DownQuery": "DROP TABLE IF EXISTS gitserver_localclone_jobs;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1646652951,
					1647282553
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1648051770,
				"Name": "cascade feature flag updates",
				"UpQuery": "-- Perform migration here.\n--\n-- See /migrations/README.md. Highlights:\n--  * Make migrations idempotent (use IF EXISTS)\n--  * Make migrations backwards-compatible (old readers/writers must continue to work)\n--  * If you are using CREATE INDEX CONCURRENTLY, then make sure that only one statement\n--    is defined per file, and that each such statement is NOT wrapped in a transaction.\n--    Each such migration must also declare \"createIndexConcurrently: true\" in their\n--    associated metadata.yaml file.\n--  * If you are modifying Postgres extensions, you must also declare \"privileged: true\"\n--    in the associated metadata.yaml file.\n\nALTER TABLE feature_flag_overrides\n    DROP CONSTRAINT feature_flag_overrides_flag_name_fkey;\n\nALTER TABLE feature_flag_overrides\n    ADD CONSTRAINT feature_flag_overrides_flag_name_fkey\n    FOREIGN KEY (flag_name)\n    REFERENCES feature_flags(flag_name)\n    ON DELETE CASCADE\n    ON UPDATE CASCADE;",
				"DownQuery": "-- Undo the changes made in the up migration\n\nALTER TABLE feature_flag_overrides\n    DROP CONSTRAINT feature_flag_overrides_flag_name_fkey;\n\nALTER TABLE feature_flag_overrides\n    ADD CONSTRAINT feature_flag_overrides_flag_name_fkey\n    FOREIGN KEY (flag_name)\n    REFERENCES feature_flags(flag_name)\n    ON DELETE CASCADE;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1647849753,
					1647860082
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1648115472,
				"Name": "add_localclone_worker_view",
				"UpQuery": "CREATE OR REPLACE VIEW gitserver_localclone_jobs_with_repo_name AS\n  SELECT glj.*, r.name AS repo_name\n  FROM gitserver_localclone_jobs glj\n  JOIN repo r ON r.id = glj.repo_id;",
				"DownQuery": "DROP VIEW IF EXISTS gitserver_localclone_jobs_with_repo_name;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1647849753,
					1647860082
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1648195639,
				"Name": "add_localclone_worker_queued_at",
				"UpQuery": "ALTER TABLE gitserver_localclone_jobs ADD COLUMN IF NOT EXISTS queued_at timestamptz DEFAULT NOW();\n\n-- drop view and recreate it with the new column\n\nDROP VIEW IF EXISTS gitserver_localclone_jobs_with_repo_name;\n\nCREATE OR REPLACE VIEW gitserver_localclone_jobs_with_repo_name AS\n  SELECT glj.*, r.name AS repo_name\n  FROM gitserver_localclone_jobs glj\n  JOIN repo r ON r.id = glj.repo_id;",
				"DownQuery": "-- drop view\nDROP VIEW IF EXISTS gitserver_localclone_jobs_with_repo_name;\n\n-- drop the column\nALTER TABLE gitserver_localclone_jobs DROP COLUMN IF EXISTS queued_at;\n\n-- recreate the view without the column\nCREATE OR REPLACE VIEW gitserver_localclone_jobs_with_repo_name AS\n  SELECT glj.*, r.name AS repo_name\n  FROM gitserver_localclone_jobs glj\n  JOIN repo r ON r.id = glj.repo_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1648051770,
					1648115472
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1648524019,
				"Name": "int64-ids-user-pending-permissions",
				"UpQuery": "TRUNCATE TABLE user_pending_permissions;\nTRUNCATE TABLE repo_pending_permissions;\n\nALTER TABLE IF EXISTS user_pending_permissions ALTER COLUMN id TYPE BIGINT;\nALTER TABLE IF EXISTS repo_pending_permissions ALTER COLUMN user_ids_ints TYPE BIGINT[];\n\nALTER SEQUENCE IF EXISTS user_pending_permissions_id_seq RESTART;",
				"DownQuery": "TRUNCATE TABLE user_pending_permissions;\nTRUNCATE TABLE repo_pending_permissions;\n\nALTER TABLE IF EXISTS user_pending_permissions ALTER COLUMN id TYPE int;\nALTER TABLE IF EXISTS repo_pending_permissions ALTER COLUMN user_ids_ints TYPE int[];\n\nALTER SEQUENCE IF EXISTS user_pending_permissions_id_seq RESTART;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1648195639
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1648628900,
				"Name": "rename_localclone_worker_table",
				"UpQuery": "-- drop view\nDROP VIEW IF EXISTS gitserver_localclone_jobs_with_repo_name;\n\n-- drop the table\nDROP TABLE IF EXISTS gitserver_localclone_jobs;\n\n-- create the new table\nCREATE TABLE IF NOT EXISTS gitserver_relocator_jobs (\n    id                  SERIAL PRIMARY KEY,\n    state               text DEFAULT 'queued',\n    queued_at           timestamptz DEFAULT NOW(),\n    failure_message     text,\n    started_at          timestamp with time zone,\n    finished_at         timestamp with time zone,\n    process_after       timestamp with time zone,\n    num_resets          integer not null DEFAULT 0,\n    num_failures        integer not null DEFAULT 0,\n    last_heartbeat_at   timestamp with time zone,\n    execution_logs      json[],\n    worker_hostname     text not null DEFAULT '',\n\n    repo_id             integer not null,\n    source_hostname     text not null,\n    dest_hostname       text not null,\n    delete_source       boolean not null DEFAULT false\n);\n\n-- create the view\nCREATE OR REPLACE VIEW gitserver_relocator_jobs_with_repo_name AS\n  SELECT glj.*, r.name AS repo_name\n  FROM gitserver_relocator_jobs glj\n  JOIN repo r ON r.id = glj.repo_id;",
				"DownQuery": "-- drop view\nDROP VIEW IF EXISTS gitserver_relocator_jobs_with_repo_name;\n\n-- drop the table\nDROP TABLE IF EXISTS gitserver_relocator_jobs;\n\n-- create the old table\nCREATE TABLE IF NOT EXISTS gitserver_localclone_jobs (\n    id                  SERIAL PRIMARY KEY,\n    state               text DEFAULT 'queued',\n    queued_at           timestamptz DEFAULT NOW(),\n    failure_message     text,\n    started_at          timestamp with time zone,\n    finished_at         timestamp with time zone,\n    process_after       timestamp with time zone,\n    num_resets          integer not null DEFAULT 0,\n    num_failures        integer not null DEFAULT 0,\n    last_heartbeat_at   timestamp with time zone,\n    execution_logs      json[],\n    worker_hostname     text not null DEFAULT '',\n\n    repo_id             integer not null,\n    source_hostname     text not null,\n    dest_hostname       text not null,\n    delete_source       boolean not null DEFAULT false\n);\n\n-- create the old view\nCREATE OR REPLACE VIEW gitserver_localclone_jobs_with_repo_name AS\n  SELECT glj.*, r.name AS repo_name\n  FROM gitserver_localclone_jobs glj\n  JOIN repo r ON r.id = glj.repo_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1648195639
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1649159359,
				"Name": "batch_spec_resolution_user_id",
				"UpQuery": "ALTER TABLE batch_spec_resolution_jobs\n    ADD COLUMN IF NOT EXISTS initiator_id integer,\n    ADD FOREIGN KEY (initiator_id) REFERENCES users(id) ON UPDATE CASCADE ON DELETE NO ACTION DEFERRABLE;\n\nUPDATE batch_spec_resolution_jobs SET initiator_id = (SELECT bs.user_id FROM batch_specs bs WHERE bs.id = batch_spec_id);",
				"DownQuery": "ALTER TABLE batch_spec_resolution_jobs\n    DROP COLUMN IF EXISTS initiator_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1648524019,
					1648628900
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1649269601,
				"Name": "remove unused code monitor columns",
				"UpQuery": "-- Perform migration here.\n--\n-- See /migrations/README.md. Highlights:\n--  * Make migrations idempotent (use IF EXISTS)\n--  * Make migrations backwards-compatible (old readers/writers must continue to work)\n--  * If you are using CREATE INDEX CONCURRENTLY, then make sure that only one statement\n--    is defined per file, and that each such statement is NOT wrapped in a transaction.\n--    Each such migration must also declare \"createIndexConcurrently: true\" in their\n--    associated metadata.yaml file.\n--  * If you are modifying Postgres extensions, you must also declare \"privileged: true\"\n--    in the associated metadata.yaml file.\n\nALTER TABLE cm_trigger_jobs\n    DROP COLUMN IF EXISTS results;\nALTER TABLE cm_trigger_jobs\n    DROP COLUMN IF EXISTS num_results;",
				"DownQuery": "-- Undo the changes made in the up migration\n\nALTER TABLE cm_trigger_jobs\n    ADD COLUMN IF NOT EXISTS results BOOLEAN;\nALTER TABLE cm_trigger_jobs\n    ADD COLUMN IF NOT EXISTS num_results INTEGER;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1648524019,
					1648628900
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1649441222,
				"Name": "lsif_uploads_audit_logging",
				"UpQuery": "CREATE TABLE IF NOT EXISTS lsif_uploads_audit_logs (\n    -- log entry columns\n    log_timestamp       timestamptz DEFAULT NOW(),\n    record_deleted_at   timestamptz,\n    -- associated object columns\n    upload_id           integer not null,\n    commit              text not null,\n    root                text not null,\n    repository_id       integer not null,\n    uploaded_at         timestamptz not null,\n    indexer             text not null,\n    indexer_version     text,\n    upload_size         integer,\n    associated_index_id integer,\n    committed_at        timestamptz,\n    transition_columns  hstore[]\n);\n\nCOMMENT ON COLUMN lsif_uploads_audit_logs.log_timestamp IS 'Timestamp for this log entry.';\nCOMMENT ON COLUMN lsif_uploads_audit_logs.record_deleted_at IS 'Set once the upload this entry is associated with is deleted. Once NOW() - record_deleted_at is above a certain threshold, this log entry will be deleted.';\nCOMMENT ON COLUMN lsif_uploads_audit_logs.transition_columns IS 'Array of changes that occurred to the upload for this entry, in the form of {\"column\"=\u003e\"\u003ccolumn name\u003e\", \"old\"=\u003e\"\u003cprevious value\u003e\", \"new\"=\u003e\"\u003cnew value\u003e\"}.';\n\nCREATE INDEX IF NOT EXISTS lsif_uploads_audit_logs_upload_id ON lsif_uploads_audit_logs USING btree (upload_id);\nCREATE INDEX IF NOT EXISTS lsif_uploads_audit_logs_timestamp ON lsif_uploads_audit_logs USING brin (log_timestamp);\n\n-- CREATE TYPE IF NOT EXISTS is not a thing, so we must drop it here,\n-- but also all the functions that reference the type...\nDROP FUNCTION IF EXISTS func_row_to_lsif_uploads_transition_columns;\nDROP FUNCTION IF EXISTS func_lsif_uploads_transition_columns_diff;\nDROP TYPE IF EXISTS lsif_uploads_transition_columns;\n\nCREATE TYPE lsif_uploads_transition_columns AS (\n    state           text,\n    expired         boolean,\n    num_resets      integer,\n    num_failures    integer,\n    worker_hostname text,\n    committed_at    timestamptz\n);\n\nCOMMENT ON TYPE lsif_uploads_transition_columns IS 'A type containing the columns that make-up the set of tracked transition columns. Primarily used to create a nulled record due to `OLD` being unset in INSERT queries, and creating a nulled record with a subquery is not allowed.';\n\nCREATE OR REPLACE FUNCTION func_lsif_uploads_update() RETURNS TRIGGER AS $$\n    BEGIN\n        INSERT INTO lsif_uploads_audit_logs\n        (upload_id, commit, root, repository_id, uploaded_at,\n        indexer, indexer_version, upload_size, associated_index_id,\n        committed_at, transition_columns)\n        VALUES (\n            NEW.id, NEW.commit, NEW.root, NEW.repository_id, NEW.uploaded_at,\n            NEW.indexer, NEW.indexer_version, NEW.upload_size, NEW.associated_index_id,\n            NEW.committed_at, func_lsif_uploads_transition_columns_diff(\n                func_row_to_lsif_uploads_transition_columns(OLD),\n                func_row_to_lsif_uploads_transition_columns(NEW)\n            )\n        );\n\n        RETURN NEW;\n    END;\n$$ LANGUAGE plpgsql;\n\nCREATE OR REPLACE FUNCTION func_lsif_uploads_delete() RETURNS TRIGGER AS $$\n    BEGIN\n        UPDATE lsif_uploads_audit_logs\n        SET record_deleted_at = NOW()\n        WHERE upload_id IN (\n            SELECT id FROM OLD\n        );\n\n        RETURN NULL;\n    END;\n$$ LANGUAGE plpgsql;\n\nCREATE OR REPLACE FUNCTION func_lsif_uploads_insert() RETURNS TRIGGER AS $$\n    BEGIN\n        INSERT INTO lsif_uploads_audit_logs\n        (upload_id, commit, root, repository_id, uploaded_at,\n        indexer, indexer_version, upload_size, associated_index_id,\n        committed_at, transition_columns)\n        VALUES (\n            NEW.id, NEW.commit, NEW.root, NEW.repository_id, NEW.uploaded_at,\n            NEW.indexer, NEW.indexer_version, NEW.upload_size, NEW.associated_index_id,\n            NEW.committed_at, func_lsif_uploads_transition_columns_diff(\n                (NULL, NULL, NULL, NULL, NULL, NULL),\n                func_row_to_lsif_uploads_transition_columns(NEW)\n            )\n        );\n        RETURN NULL;\n    END;\n$$ LANGUAGE plpgsql;\n\nCREATE OR REPLACE FUNCTION func_row_to_lsif_uploads_transition_columns(\n    rec record\n) RETURNS lsif_uploads_transition_columns AS $$\n    BEGIN\n        RETURN (rec.state, rec.expired, rec.num_resets, rec.num_failures, rec.worker_hostname, rec.committed_at);\n    END;\n$$ LANGUAGE plpgsql;\n\nCOMMENT ON FUNCTION func_lsif_uploads_insert IS 'Transforms a record from the lsif_uploads table into an `lsif_uploads_transition_columns` type variable.';\n\nCREATE OR REPLACE FUNCTION func_lsif_uploads_transition_columns_diff(\n    old lsif_uploads_transition_columns, new lsif_uploads_transition_columns\n) RETURNS hstore[] AS $$\n    BEGIN\n        -- array || NULL should be a noop, but that doesn't seem to be happening\n        -- hence array_remove here\n        RETURN array_remove(\n            ARRAY[]::hstore[] ||\n            CASE WHEN old.state IS DISTINCT FROM new.state THEN\n                hstore(ARRAY['column', 'state', 'old', old.state, 'new', new.state])\n                ELSE NULL\n            END ||\n            CASE WHEN old.expired IS DISTINCT FROM new.expired THEN\n                hstore(ARRAY['column', 'expired', 'old', old.expired::text, 'new', new.expired::text])\n                ELSE NULL\n            END ||\n            CASE WHEN old.num_resets IS DISTINCT FROM new.num_resets THEN\n                hstore(ARRAY['column', 'num_resets', 'old', old.num_resets::text, 'new', new.num_resets::text])\n                ELSE NULL\n            END ||\n            CASE WHEN old.num_failures IS DISTINCT FROM new.num_failures THEN\n                hstore(ARRAY['column', 'num_failures', 'old', old.num_failures::text, 'new', new.num_failures::text])\n                ELSE NULL\n            END ||\n            CASE WHEN old.worker_hostname IS DISTINCT FROM new.worker_hostname THEN\n                hstore(ARRAY['column', 'worker_hostname', 'old', old.worker_hostname, 'new', new.worker_hostname])\n                ELSE NULL\n            END ||\n            CASE WHEN old.committed_at IS DISTINCT FROM new.committed_at THEN\n                hstore(ARRAY['column', 'committed_at', 'old', old.committed_at::text, 'new', new.committed_at::text])\n                ELSE NULL\n            END,\n        NULL);\n    END;\n$$ LANGUAGE plpgsql;\n\nCOMMENT ON FUNCTION func_lsif_uploads_transition_columns_diff IS 'Diffs two `lsif_uploads_transition_columns` values into an array of hstores, where each hstore is in the format {\"column\"=\u003e\"\u003ccolumn name\u003e\", \"old\"=\u003e\"\u003cprevious value\u003e\", \"new\"=\u003e\"\u003cnew value\u003e\"}.';\n\n-- CREATE OR REPLACE only supported in Postgres 14+\nDROP TRIGGER IF EXISTS trigger_lsif_uploads_update ON lsif_uploads;\nDROP TRIGGER IF EXISTS trigger_lsif_uploads_delete ON lsif_uploads;\nDROP TRIGGER IF EXISTS trigger_lsif_uploads_insert ON lsif_uploads;\n\nCREATE TRIGGER trigger_lsif_uploads_update\nBEFORE UPDATE OF state, num_resets, num_failures, worker_hostname, expired, committed_at\nON lsif_uploads\nFOR EACH ROW\nEXECUTE FUNCTION func_lsif_uploads_update();\n\nCREATE TRIGGER trigger_lsif_uploads_delete\nAFTER DELETE\nON lsif_uploads\nREFERENCING OLD TABLE AS OLD\nFOR EACH STATEMENT\nEXECUTE FUNCTION func_lsif_uploads_delete();\n\nCREATE TRIGGER trigger_lsif_uploads_insert\nAFTER INSERT\nON lsif_uploads\nFOR EACH ROW\nEXECUTE FUNCTION func_lsif_uploads_insert();",
				"DownQuery": "DROP TRIGGER IF EXISTS trigger_lsif_uploads_update ON lsif_uploads;\nDROP TRIGGER IF EXISTS trigger_lsif_uploads_delete ON lsif_uploads;\nDROP TRIGGER IF EXISTS trigger_lsif_uploads_insert ON lsif_uploads;\n\nDROP FUNCTION IF EXISTS func_lsif_uploads_update;\nDROP FUNCTION IF EXISTS func_lsif_uploads_delete;\nDROP FUNCTION IF EXISTS func_lsif_uploads_insert;\nDROP FUNCTION IF EXISTS func_lsif_uploads_transition_columns_diff;\nDROP FUNCTION IF EXISTS func_row_to_lsif_uploads_transition_columns;\n\nDROP TABLE IF EXISTS lsif_uploads_audit_logs;\n\nDROP INDEX IF EXISTS lsif_uploads_audit_logs_upload_id;\nDROP INDEX IF EXISTS lsif_uploads_audit_logs_timestamp;\n\nDROP TYPE IF EXISTS lsif_uploads_transition_columns;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1649269601
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1649759318,
				"Name": "change_default_invite_quota",
				"UpQuery": "ALTER TABLE IF EXISTS users ALTER COLUMN invite_quota SET DEFAULT 100;",
				"DownQuery": "-- Undo the changes made in the up migration\nALTER TABLE IF EXISTS users ALTER COLUMN invite_quota SET DEFAULT 15;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1649269601
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1649432863,
				"Name": "no hash for code monitor last searched",
				"UpQuery": "-- Perform migration here.\n--\n-- See /migrations/README.md. Highlights:\n--  * Make migrations idempotent (use IF EXISTS)\n--  * Make migrations backwards-compatible (old readers/writers must continue to work)\n--  * If you are using CREATE INDEX CONCURRENTLY, then make sure that only one statement\n--    is defined per file, and that each such statement is NOT wrapped in a transaction.\n--    Each such migration must also declare \"createIndexConcurrently: true\" in their\n--    associated metadata.yaml file.\n--  * If you are modifying Postgres extensions, you must also declare \"privileged: true\"\n--    in the associated metadata.yaml file.\n\nDELETE FROM cm_last_searched;\nALTER TABLE cm_last_searched\n    DROP CONSTRAINT IF EXISTS cm_last_searched_pkey,\n    DROP COLUMN IF EXISTS args_hash,\n    ADD COLUMN IF NOT EXISTS repo_id INTEGER NOT NULL REFERENCES repo(id) ON DELETE CASCADE,\n    ADD PRIMARY KEY (monitor_id, repo_id);",
				"DownQuery": "-- Undo the changes made in the up migration\n\nALTER TABLE cm_last_searched\n    DROP CONSTRAINT IF EXISTS cm_last_searched_pkey,\n    DROP COLUMN IF EXISTS repo_id,\n    ADD COLUMN IF NOT EXISTS args_hash bigint NOT NULL,\n    ADD PRIMARY KEY (monitor_id, args_hash);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1648524019,
					1648628900
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1650456734,
				"Name": "configuration_policies_audit_logging",
				"UpQuery": "CREATE TABLE IF NOT EXISTS configuration_policies_audit_logs (\n    -- log entry columns\n    log_timestamp      timestamptz DEFAULT clock_timestamp(),\n    record_deleted_at  timestamptz,\n    -- associated object columns\n    policy_id          integer not null,\n    transition_columns hstore[]\n);\n\nCOMMENT ON COLUMN configuration_policies_audit_logs.log_timestamp IS 'Timestamp for this log entry.';\nCOMMENT ON COLUMN configuration_policies_audit_logs.record_deleted_at IS 'Set once the upload this entry is associated with is deleted. Once NOW() - record_deleted_at is above a certain threshold, this log entry will be deleted.';\nCOMMENT ON COLUMN configuration_policies_audit_logs.transition_columns IS 'Array of changes that occurred to the upload for this entry, in the form of {\"column\"=\u003e\"\u003ccolumn name\u003e\", \"old\"=\u003e\"\u003cprevious value\u003e\", \"new\"=\u003e\"\u003cnew value\u003e\"}.';\n\nCREATE INDEX IF NOT EXISTS configuration_policies_audit_logs_policy_id ON configuration_policies_audit_logs USING btree (policy_id);\nCREATE INDEX IF NOT EXISTS configuration_policies_audit_logs_timestamp ON configuration_policies_audit_logs USING brin (log_timestamp);\n\n-- CREATE TYPE IF NOT EXISTS is not a thing, so we must drop it here,\n-- but also all the functions that reference the type...\nDROP FUNCTION IF EXISTS func_row_to_configuration_policies_transition_columns;\nDROP FUNCTION IF EXISTS func_configuration_policies_transition_columns_diff;\nDROP TYPE IF EXISTS configuration_policies_transition_columns;\n\nCREATE TYPE configuration_policies_transition_columns AS (\n    name                        text,\n    type                        text,\n    pattern                     text,\n    retention_enabled           boolean,\n    retention_duration_hours    integer,\n    retain_intermediate_commits boolean,\n    indexing_enabled            boolean,\n    index_commit_max_age_hours  integer,\n    index_intermediate_commits  boolean,\n    protected                   boolean,\n    repository_patterns         text[]\n);\n\nCOMMENT ON TYPE configuration_policies_transition_columns IS 'A type containing the columns that make-up the set of tracked transition columns. Primarily used to create a nulled record due to `OLD` being unset in INSERT queries, and creating a nulled record with a subquery is not allowed.';\n\nCREATE OR REPLACE FUNCTION func_configuration_policies_update() RETURNS TRIGGER AS $$\n    DECLARE\n        diff hstore[];\n    BEGIN\n        diff = func_configuration_policies_transition_columns_diff(\n            func_row_to_configuration_policies_transition_columns(OLD),\n            func_row_to_configuration_policies_transition_columns(NEW)\n        );\n\n        IF (array_length(diff, 1) \u003e 0) THEN\n            INSERT INTO configuration_policies_audit_logs\n            (policy_id, transition_columns)\n            VALUES (\n                NEW.id,\n                diff\n            );\n        END IF;\n\n        RETURN NEW;\n    END;\n$$ LANGUAGE plpgsql;\n\nCREATE OR REPLACE FUNCTION func_configuration_policies_delete() RETURNS TRIGGER AS $$\n    BEGIN\n        UPDATE configuration_policies_audit_logs\n        SET record_deleted_at = NOW()\n        WHERE policy_id IN (\n            SELECT id FROM OLD\n        );\n\n        RETURN NULL;\n    END;\n$$ LANGUAGE plpgsql;\n\nCREATE OR REPLACE FUNCTION func_configuration_policies_insert() RETURNS TRIGGER AS $$\n    BEGIN\n        INSERT INTO configuration_policies_audit_logs\n        (policy_id, transition_columns)\n        VALUES (\n            NEW.id,\n            func_configuration_policies_transition_columns_diff(\n                (NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL),\n                func_row_to_configuration_policies_transition_columns(NEW)\n            )\n        );\n        RETURN NULL;\n    END;\n$$ LANGUAGE plpgsql;\n\n\nCREATE OR REPLACE FUNCTION func_row_to_configuration_policies_transition_columns(\n    rec record\n) RETURNS configuration_policies_transition_columns AS $$\n    BEGIN\n        RETURN (\n            rec.name, rec.type, rec.pattern,\n            rec.retention_enabled, rec.retention_duration_hours, rec.retain_intermediate_commits,\n            rec.indexing_enabled, rec.index_commit_max_age_hours, rec.index_intermediate_commits,\n            rec.protected, rec.repository_patterns);\n    END;\n$$ LANGUAGE plpgsql;\n\nCOMMENT ON FUNCTION func_configuration_policies_insert IS 'Transforms a record from the configuration_policies table into an `configuration_policies_transition_columns` type variable.';\n\nCREATE OR REPLACE FUNCTION func_configuration_policies_transition_columns_diff(\n    old configuration_policies_transition_columns, new configuration_policies_transition_columns\n) RETURNS hstore[] AS $$\n    BEGIN\n        -- array || NULL should be a noop, but that doesn't seem to be happening\n        -- hence array_remove here\n        RETURN array_remove(\n            ARRAY[]::hstore[] ||\n            CASE WHEN old.name IS DISTINCT FROM new.name THEN\n                hstore(ARRAY['column', 'name', 'old', old.name, 'new', new.name])\n                ELSE NULL\n            END ||\n            CASE WHEN old.type IS DISTINCT FROM new.type THEN\n                hstore(ARRAY['column', 'type', 'old', old.type, 'new', new.type])\n                ELSE NULL\n            END ||\n            CASE WHEN old.pattern IS DISTINCT FROM new.pattern THEN\n                hstore(ARRAY['column', 'pattern', 'old', old.pattern, 'new', new.pattern])\n                ELSE NULL\n            END ||\n            CASE WHEN old.retention_enabled IS DISTINCT FROM new.retention_enabled THEN\n                hstore(ARRAY['column', 'retention_enabled', 'old', old.retention_enabled::text, 'new', new.retention_enabled::text])\n                ELSE NULL\n            END ||\n            CASE WHEN old.retention_duration_hours IS DISTINCT FROM new.retention_duration_hours THEN\n                hstore(ARRAY['column', 'retention_duration_hours', 'old', old.retention_duration_hours::text, 'new', new.retention_duration_hours::text])\n                ELSE NULL\n            END ||\n            CASE WHEN old.indexing_enabled IS DISTINCT FROM new.indexing_enabled THEN\n                hstore(ARRAY['column', 'indexing_enabled', 'old', old.indexing_enabled::text, 'new', new.indexing_enabled::text])\n                ELSE NULL\n            END ||\n            CASE WHEN old.index_commit_max_age_hours IS DISTINCT FROM new.index_commit_max_age_hours THEN\n                hstore(ARRAY['column', 'index_commit_max_age_hours', 'old', old.index_commit_max_age_hours::text, 'new', new.index_commit_max_age_hours::text])\n                ELSE NULL\n            END ||\n            CASE WHEN old.index_intermediate_commits IS DISTINCT FROM new.index_intermediate_commits THEN\n                hstore(ARRAY['column', 'index_intermediate_commits', 'old', old.index_intermediate_commits::text, 'new', new.index_intermediate_commits::text])\n                ELSE NULL\n            END ||\n            CASE WHEN old.protected IS DISTINCT FROM new.protected THEN\n                hstore(ARRAY['column', 'protected', 'old', old.protected::text, 'new', new.protected::text])\n                ELSE NULL\n            END ||\n            CASE WHEN old.repository_patterns IS DISTINCT FROM new.repository_patterns THEN\n                hstore(ARRAY['column', 'repository_patterns', 'old', old.repository_patterns::text, 'new', new.repository_patterns::text])\n                ELSE NULL\n            END,\n        NULL);\n    END;\n$$ LANGUAGE plpgsql;\n\nCOMMENT ON FUNCTION func_configuration_policies_transition_columns_diff IS 'Diffs two `configuration_policies_transition_columns` values into an array of hstores, where each hstore is in the format {\"column\"=\u003e\"\u003ccolumn name\u003e\", \"old\"=\u003e\"\u003cprevious value\u003e\", \"new\"=\u003e\"\u003cnew value\u003e\"}.';\n\n-- CREATE OR REPLACE only supported in Postgres 14+\nDROP TRIGGER IF EXISTS trigger_configuration_policies_update ON lsif_configuration_policies;\nDROP TRIGGER IF EXISTS trigger_configuration_policies_delete ON lsif_configuration_policies;\nDROP TRIGGER IF EXISTS trigger_configuration_policies_insert ON lsif_configuration_policies;\n\nCREATE TRIGGER trigger_configuration_policies_update\nBEFORE UPDATE OF name, pattern, retention_enabled, retention_duration_hours, type, retain_intermediate_commits\nON lsif_configuration_policies\nFOR EACH ROW\nEXECUTE FUNCTION func_configuration_policies_update();\n\nCREATE TRIGGER trigger_configuration_policies_delete\nAFTER DELETE\nON lsif_configuration_policies\nREFERENCING OLD TABLE AS OLD\nFOR EACH STATEMENT\nEXECUTE FUNCTION func_configuration_policies_delete();\n\nCREATE TRIGGER trigger_configuration_policies_insert\nAFTER INSERT\nON lsif_configuration_policies\nFOR EACH ROW\nEXECUTE FUNCTION func_configuration_policies_insert();",
				"DownQuery": "DROP TRIGGER IF EXISTS trigger_configuration_policies_update ON lsif_configuration_policies;\nDROP TRIGGER IF EXISTS trigger_configuration_policies_delete ON lsif_configuration_policies;\nDROP TRIGGER IF EXISTS trigger_configuration_policies_insert ON lsif_configuration_policies;\n\nDROP FUNCTION IF EXISTS func_configuration_policies_update;\nDROP FUNCTION IF EXISTS func_configuration_policies_delete;\nDROP FUNCTION IF EXISTS func_configuration_policies_insert;\nDROP FUNCTION IF EXISTS func_configuration_policies_transition_columns_diff;\nDROP FUNCTION IF EXISTS func_row_to_configuration_policies_transition_columns;\n\nDROP TABLE IF EXISTS configuration_policies_audit_logs;\n\nDROP INDEX IF EXISTS configuration_policies_audit_logs_upload_id;\nDROP INDEX IF EXISTS configuration_policies_audit_logs_timestamp;\n\nDROP TYPE IF EXISTS configuration_policies_transition_columns;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1649432863,
					1649441222,
					1649759318
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1650637472,
				"Name": "Add codeintel_langugage_support_requests table",
				"UpQuery": "CREATE TABLE IF NOT EXISTS codeintel_langugage_support_requests (\n    id SERIAL,\n    user_id integer NOT NULL,\n    language_id text NOT NULL\n);\n\nCREATE UNIQUE INDEX IF NOT EXISTS codeintel_langugage_support_requests_user_id_language ON codeintel_langugage_support_requests(user_id, language_id);",
				"DownQuery": "DROP TABLE IF EXISTS codeintel_langugage_support_requests;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1649159359,
					1649432863,
					1649441222,
					1649759318
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1651061363,
				"Name": "lsif_uploads_audit_logging_reason",
				"UpQuery": "ALTER TABLE lsif_uploads_audit_logs\nADD COLUMN IF NOT EXISTS reason text DEFAULT '',\nDROP COLUMN IF EXISTS committed_at;\n\nCOMMENT ON COLUMN lsif_uploads_audit_logs.reason IS 'The reason/source for this entry.';\n\nCREATE OR REPLACE FUNCTION func_lsif_uploads_update() RETURNS TRIGGER AS $$\n    DECLARE\n        diff hstore[];\n    BEGIN\n        diff = func_lsif_uploads_transition_columns_diff(\n            func_row_to_lsif_uploads_transition_columns(OLD),\n            func_row_to_lsif_uploads_transition_columns(NEW)\n        );\n\n        IF (array_length(diff, 1) \u003e 0) THEN\n            INSERT INTO lsif_uploads_audit_logs\n            (reason, upload_id, commit, root, repository_id, uploaded_at,\n            indexer, indexer_version, upload_size, associated_index_id,\n            transition_columns)\n            VALUES (\n                COALESCE(current_setting('codeintel.lsif_uploads_audit.reason', true), ''),\n                NEW.id, NEW.commit, NEW.root, NEW.repository_id, NEW.uploaded_at,\n                NEW.indexer, NEW.indexer_version, NEW.upload_size, NEW.associated_index_id,\n                diff\n            );\n        END IF;\n\n        RETURN NEW;\n    END;\n$$ LANGUAGE plpgsql;\n\nCREATE OR REPLACE FUNCTION func_lsif_uploads_insert() RETURNS TRIGGER AS $$\n    BEGIN\n        INSERT INTO lsif_uploads_audit_logs\n        (upload_id, commit, root, repository_id, uploaded_at,\n        indexer, indexer_version, upload_size, associated_index_id,\n        transition_columns)\n        VALUES (\n            NEW.id, NEW.commit, NEW.root, NEW.repository_id, NEW.uploaded_at,\n            NEW.indexer, NEW.indexer_version, NEW.upload_size, NEW.associated_index_id,\n            func_lsif_uploads_transition_columns_diff(\n                (NULL, NULL, NULL, NULL, NULL, NULL),\n                func_row_to_lsif_uploads_transition_columns(NEW)\n            )\n        );\n        RETURN NULL;\n    END;\n$$ LANGUAGE plpgsql;\n\n\n-- CREATE OR REPLACE only supported in Postgres 14+\nDROP TRIGGER IF EXISTS trigger_lsif_uploads_update ON lsif_uploads;\nDROP TRIGGER IF EXISTS trigger_lsif_uploads_insert ON lsif_uploads;\n\nCREATE TRIGGER trigger_lsif_uploads_update\nBEFORE UPDATE OF state, num_resets, num_failures, worker_hostname, expired, committed_at\nON lsif_uploads\nFOR EACH ROW\nEXECUTE FUNCTION func_lsif_uploads_update();\n\nCREATE TRIGGER trigger_lsif_uploads_insert\nAFTER INSERT\nON lsif_uploads\nFOR EACH ROW\nEXECUTE FUNCTION func_lsif_uploads_insert();",
				"DownQuery": "ALTER TABLE\n    IF EXISTS lsif_uploads_audit_logs\n    DROP COLUMN IF EXISTS reason,\n    ADD COLUMN IF NOT EXISTS committed_at timestamptz;\n\n-- Revert functions to previous version\n\nCREATE OR REPLACE FUNCTION func_lsif_uploads_update() RETURNS TRIGGER AS $$\n    BEGIN\n        INSERT INTO lsif_uploads_audit_logs\n        (upload_id, commit, root, repository_id, uploaded_at,\n        indexer, indexer_version, upload_size, associated_index_id,\n        committed_at, transition_columns)\n        VALUES (\n            NEW.id, NEW.commit, NEW.root, NEW.repository_id, NEW.uploaded_at,\n            NEW.indexer, NEW.indexer_version, NEW.upload_size, NEW.associated_index_id,\n            NEW.committed_at, func_lsif_uploads_transition_columns_diff(\n                func_row_to_lsif_uploads_transition_columns(OLD),\n                func_row_to_lsif_uploads_transition_columns(NEW)\n            )\n        );\n\n        RETURN NEW;\n    END;\n$$ LANGUAGE plpgsql;\n\nCREATE OR REPLACE FUNCTION func_lsif_uploads_insert() RETURNS TRIGGER AS $$\n    BEGIN\n        INSERT INTO lsif_uploads_audit_logs\n        (upload_id, commit, root, repository_id, uploaded_at,\n        indexer, indexer_version, upload_size, associated_index_id,\n        committed_at, transition_columns)\n        VALUES (\n            NEW.id, NEW.commit, NEW.root, NEW.repository_id, NEW.uploaded_at,\n            NEW.indexer, NEW.indexer_version, NEW.upload_size, NEW.associated_index_id,\n            NEW.committed_at, func_lsif_uploads_transition_columns_diff(\n                (NULL, NULL, NULL, NULL, NULL, NULL),\n                func_row_to_lsif_uploads_transition_columns(NEW)\n            )\n        );\n        RETURN NULL;\n    END;\n$$ LANGUAGE plpgsql;\n\n-- CREATE OR REPLACE only supported in Postgres 14+\nDROP TRIGGER IF EXISTS trigger_lsif_uploads_update ON lsif_uploads;\nDROP TRIGGER IF EXISTS trigger_lsif_uploads_insert ON lsif_uploads;\n\nCREATE TRIGGER trigger_lsif_uploads_update\nBEFORE UPDATE OF state, num_resets, num_failures, worker_hostname, expired, committed_at\nON lsif_uploads\nFOR EACH ROW\nEXECUTE FUNCTION func_lsif_uploads_update();\n\nCREATE TRIGGER trigger_lsif_uploads_insert\nAFTER INSERT\nON lsif_uploads\nFOR EACH ROW\nEXECUTE FUNCTION func_lsif_uploads_insert();",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1650637472
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1651077257,
				"Name": "lsif_dirty_repo_timestamp",
				"UpQuery": "ALTER TABLE\n    lsif_dirty_repositories\nADD\n    COLUMN IF NOT EXISTS set_dirty_at timestamptz NOT NULL DEFAULT NOW();",
				"DownQuery": "ALTER TABLE\n    IF EXISTS lsif_dirty_repositories DROP COLUMN IF EXISTS set_dirty_at;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1650637472
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1651159431,
				"Name": "fix-maven-dependency-repos-name",
				"UpQuery": "UPDATE lsif_dependency_repos\nSET name = replace(regexp_replace(name, '^maven/', ''), '/', ':')\nWHERE scheme = 'semanticdb'\nAND name LIKE 'maven/%';\n\nDELETE FROM lsif_dependency_repos\nWHERE scheme = 'semanticdb'\nAND (name LIKE '%:%:%' OR name LIKE 'jdk:%' OR name LIKE 'jdk/%');",
				"DownQuery": "-- Undo the changes made in the up migration",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1651077257
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1652143849,
				"Name": "drop_constraint_from_filter_column_in_lsif_references_table",
				"UpQuery": "ALTER TABLE IF EXISTS lsif_references\n    ALTER COLUMN filter DROP NOT NULL;",
				"DownQuery": "-- Undo the changes made in the up migration\nALTER TABLE IF EXISTS lsif_references\n    ALTER COLUMN filter SET NOT NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1650456734,
					1651061363,
					1651159431
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1652175864,
				"Name": "add-unrestricted-to-repo-permissions",
				"UpQuery": "ALTER TABLE\n    repo_permissions\nADD\n    COLUMN IF NOT EXISTS unrestricted boolean NOT NULL DEFAULT false;\n\nCREATE INDEX IF NOT EXISTS repo_permissions_unrestricted_true_idx ON repo_permissions\n    USING btree (unrestricted) WHERE unrestricted;",
				"DownQuery": "ALTER TABLE\n    repo_permissions\n    DROP\n        COLUMN IF EXISTS unrestricted;\n\nDROP INDEX IF EXISTS repo_permissions_unrestricted_true_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1650456734,
					1651061363,
					1651159431
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1652228814,
				"Name": "index_bitbucket_cloud_commit",
				"UpQuery": "CREATE INDEX IF NOT EXISTS\n    changesets_bitbucket_cloud_metadata_source_commit_idx\nON\n    changesets ((metadata-\u003e'source'-\u003e'commit'-\u003e\u003e'hash'))",
				"DownQuery": "DROP INDEX IF EXISTS\n    changesets_bitbucket_cloud_metadata_source_commit_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1652175864
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1652189866,
				"Name": "Add lockfiles tables",
				"UpQuery": "CREATE TABLE IF NOT EXISTS codeintel_lockfiles (\n    id SERIAL PRIMARY KEY,\n    repository_id integer NOT NULL,\n    commit_bytea bytea NOT NULL,\n    codeintel_lockfile_reference_ids integer [] NOT NULL\n);\n\nCREATE UNIQUE INDEX IF NOT EXISTS codeintel_lockfiles_repository_id_commit_bytea ON codeintel_lockfiles USING btree (repository_id, commit_bytea);\n\nCREATE INDEX IF NOT EXISTS codeintel_lockfiles_codeintel_lockfile_reference_ids ON codeintel_lockfiles USING GIN (\n    codeintel_lockfile_reference_ids gin__int_ops\n);\n\nCOMMENT ON TABLE codeintel_lockfiles IS 'Associates a repository-commit pair with the set of repository-level dependencies parsed from lockfiles.';\n\nCOMMENT ON COLUMN codeintel_lockfiles.commit_bytea IS 'A 40-char revhash. Note that this commit may not be resolvable in the future.';\n\nCOMMENT ON COLUMN codeintel_lockfiles.codeintel_lockfile_reference_ids IS 'A key to a resolved repository name-revspec pair. Not all repository names and revspecs are resolvable.';\n\nCREATE TABLE IF NOT EXISTS codeintel_lockfile_references (\n    id SERIAL PRIMARY KEY,\n    repository_name text NOT NULL,\n    revspec text NOT NULL,\n    package_scheme text NOT NULL,\n    package_name text NOT NULL,\n    package_version text NOT NULL,\n    repository_id integer,\n    commit_bytea bytea\n);\n\nCREATE UNIQUE INDEX IF NOT EXISTS codeintel_lockfile_references_repository_name_revspec_package ON codeintel_lockfile_references USING btree (\n    repository_name,\n    revspec,\n    package_scheme,\n    package_name,\n    package_version\n);\n\nCREATE UNIQUE INDEX IF NOT EXISTS codeintel_lockfile_references_repository_id_commit_bytea ON codeintel_lockfile_references USING btree (repository_id, commit_bytea)\nWHERE\n    repository_id IS NOT NULL\n    AND commit_bytea IS NOT NULL;\n\nCOMMENT ON TABLE codeintel_lockfile_references IS 'Tracks a lockfile dependency that might be resolvable to a specific repository-commit pair.';\n\nCOMMENT ON COLUMN codeintel_lockfile_references.repository_name IS 'Encodes `reposource.PackageDependency.RepoName`. A name that is \"globally unique\" for a Sourcegraph instance. Used in `repo:...` queries.';\n\nCOMMENT ON COLUMN codeintel_lockfile_references.revspec IS 'Encodes `reposource.PackageDependency.GitTagFromVersion`. Returns the git tag associated with the given dependency version, used in `rev:` or `repo:foo@rev` queries.';\n\nCOMMENT ON COLUMN codeintel_lockfile_references.package_scheme IS 'Encodes `reposource.PackageDependency.Scheme`. The scheme of the dependency (e.g., semanticdb, npm).';\n\nCOMMENT ON COLUMN codeintel_lockfile_references.package_name IS 'Encodes `reposource.PackageDependency.PackageSyntax`. The name of the dependency as used by the package manager, excluding version information.';\n\nCOMMENT ON COLUMN codeintel_lockfile_references.package_version IS 'Encodes `reposource.PackageDependency.PackageVersion`. The version of the package.';\n\nCOMMENT ON COLUMN codeintel_lockfile_references.repository_id IS 'The identifier of the repo that resolves the associated name, if it is resolvable on this instance.';\n\nCOMMENT ON COLUMN codeintel_lockfile_references.commit_bytea IS 'The resolved 40-char revhash of the associated revspec, if it is resolvable on this instance.';",
				"DownQuery": "DROP TABLE IF EXISTS codeintel_lockfile_references;\n\nDROP TABLE IF EXISTS codeintel_lockfiles;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1650456734,
					1651061363,
					1651159431
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1652707934,
				"Name": "add last_check_at to codeintel_lockfile_references",
				"UpQuery": "DROP INDEX IF EXISTS codeintel_lockfile_references_repository_id_commit_bytea;\n\nCREATE INDEX IF NOT EXISTS codeintel_lockfile_references_repository_id_commit_bytea ON codeintel_lockfile_references USING btree (repository_id, commit_bytea)\nWHERE\n    repository_id IS NOT NULL\n    AND commit_bytea IS NOT NULL;\n\nALTER TABLE\n    codeintel_lockfile_references\nADD\n    COLUMN IF NOT EXISTS last_check_at timestamptz;\n\nCOMMENT ON COLUMN codeintel_lockfile_references.last_check_at IS 'Timestamp when background job last checked this row for repository resolution';\n\nCREATE INDEX IF NOT EXISTS codeintel_lockfile_references_last_check_at ON codeintel_lockfile_references USING btree (last_check_at);",
				"DownQuery": "ALTER TABLE\n    codeintel_lockfile_references\nDROP\n    COLUMN IF EXISTS last_check_at;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1652143849,
					1652175864,
					1652189866
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1652946496,
				"Name": "add_trigger_to_insert_gitserver_repo",
				"UpQuery": "-- batch insert repos which don't have a corresponding row in gitserver_repos table\nINSERT INTO gitserver_repos(repo_id, shard_id)\nSELECT repo.id, ''\nFROM repo\nLEFT JOIN gitserver_repos gr\nON repo.id = gr.repo_id\nWHERE gr.repo_id IS NULL\nON CONFLICT (repo_id) DO NOTHING;\n\nCREATE OR REPLACE FUNCTION func_insert_gitserver_repo() RETURNS TRIGGER AS $$\nBEGIN\nINSERT INTO gitserver_repos\n(repo_id, shard_id)\nVALUES (NEW.id, '');\nRETURN NULL;\nEND;\n$$ LANGUAGE plpgsql;\n\nDROP TRIGGER IF EXISTS trigger_gitserver_repo_insert on repo;\n\nCREATE TRIGGER trigger_gitserver_repo_insert\n    AFTER INSERT\n    ON repo\n    FOR EACH ROW\n    EXECUTE FUNCTION func_insert_gitserver_repo();",
				"DownQuery": "DROP TRIGGER IF EXISTS trigger_gitserver_repo_insert ON repo;\nDROP FUNCTION IF EXISTS func_insert_gitserver_repo;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1652228814,
					1652707934
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1652964210,
				"Name": "add last_lockfile_scan table",
				"UpQuery": "CREATE TABLE IF NOT EXISTS last_lockfile_scan (\n    repository_id integer NOT NULL PRIMARY KEY,\n    last_lockfile_scan_at timestamp with time zone NOT NULL\n);\n\nCOMMENT ON TABLE last_lockfile_scan IS 'Tracks the last time repository was checked for lockfile indexing.';\n\nCOMMENT ON COLUMN last_lockfile_scan.last_lockfile_scan_at IS 'The last time this repository was considered for lockfile indexing.';",
				"DownQuery": "DROP TABLE IF EXISTS last_lockfile_scan;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1652228814,
					1652707934
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1653334014,
				"Name": "Remove default from out_of_band_migrations created timestamp",
				"UpQuery": "ALTER TABLE\n    out_of_band_migrations\nALTER COLUMN\n    created DROP DEFAULT;",
				"DownQuery": "ALTER TABLE\n    out_of_band_migrations\nALTER COLUMN\n    created\nSET\n    DEFAULT NOW();",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1652964210
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1653472246,
				"Name": "add_nps_survey_fields",
				"UpQuery": "ALTER TABLE survey_responses\n  ADD COLUMN IF NOT EXISTS use_cases text[],\n  ADD COLUMN IF NOT EXISTS other_use_case text;",
				"DownQuery": "ALTER TABLE survey_responses\n  DROP COLUMN IF EXISTS use_cases,\n  DROP COLUMN IF EXISTS other_use_case;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1652946496,
					1653334014
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1653479179,
				"Name": "audit_log_op_and_seq",
				"UpQuery": "DO $$\nBEGIN\n    IF NOT EXISTS (SELECT 1 FROM pg_type WHERE typname = 'audit_log_operation') THEN\n        -- delete is known by record_deleted_at\n        CREATE TYPE audit_log_operation AS ENUM('create', 'modify', 'delete');\n    END IF;\nEND\n$$;\n\nCREATE SEQUENCE IF NOT EXISTS lsif_uploads_audit_logs_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nCREATE SEQUENCE IF NOT EXISTS configuration_policies_audit_logs_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\n-- table not been used yet\nTRUNCATE TABLE lsif_uploads_audit_logs;\nTRUNCATE TABLE configuration_policies_audit_logs;\n\nALTER TABLE lsif_uploads_audit_logs\nADD COLUMN IF NOT EXISTS sequence BIGINT NOT NULL DEFAULT nextval('lsif_uploads_audit_logs_seq'::regclass),\nADD COLUMN IF NOT EXISTS operation audit_log_operation NOT NULL;\n\nALTER TABLE configuration_policies_audit_logs\nADD COLUMN IF NOT EXISTS sequence BIGINT NOT NULL DEFAULT nextval('configuration_policies_audit_logs_seq'::regclass),\nADD COLUMN IF NOT EXISTS operation audit_log_operation NOT NULL;\n\nALTER SEQUENCE lsif_uploads_audit_logs_seq OWNED BY lsif_uploads_audit_logs.sequence;\nALTER SEQUENCE configuration_policies_audit_logs_seq OWNED BY configuration_policies_audit_logs.sequence;\n\n-- Start replace triggers\n\nCREATE OR REPLACE FUNCTION func_lsif_uploads_update() RETURNS TRIGGER AS $$\n    DECLARE\n        diff hstore[];\n    BEGIN\n        diff = func_lsif_uploads_transition_columns_diff(\n            func_row_to_lsif_uploads_transition_columns(OLD),\n            func_row_to_lsif_uploads_transition_columns(NEW)\n        );\n\n        IF (array_length(diff, 1) \u003e 0) THEN\n            INSERT INTO lsif_uploads_audit_logs\n            (reason, upload_id, commit, root, repository_id, uploaded_at,\n            indexer, indexer_version, upload_size, associated_index_id,\n            operation, transition_columns)\n            VALUES (\n                COALESCE(current_setting('codeintel.lsif_uploads_audit.reason', true), ''),\n                NEW.id, NEW.commit, NEW.root, NEW.repository_id, NEW.uploaded_at,\n                NEW.indexer, NEW.indexer_version, NEW.upload_size, NEW.associated_index_id,\n                'modify', diff\n            );\n        END IF;\n\n        RETURN NEW;\n    END;\n$$ LANGUAGE plpgsql;\n\nCREATE OR REPLACE FUNCTION func_lsif_uploads_insert() RETURNS TRIGGER AS $$\n    BEGIN\n        INSERT INTO lsif_uploads_audit_logs\n        (upload_id, commit, root, repository_id, uploaded_at,\n        indexer, indexer_version, upload_size, associated_index_id,\n        operation, transition_columns)\n        VALUES (\n            NEW.id, NEW.commit, NEW.root, NEW.repository_id, NEW.uploaded_at,\n            NEW.indexer, NEW.indexer_version, NEW.upload_size, NEW.associated_index_id,\n            'create', func_lsif_uploads_transition_columns_diff(\n                (NULL, NULL, NULL, NULL, NULL, NULL),\n                func_row_to_lsif_uploads_transition_columns(NEW)\n            )\n        );\n        RETURN NULL;\n    END;\n$$ LANGUAGE plpgsql;\n\nCREATE OR REPLACE FUNCTION func_configuration_policies_update() RETURNS TRIGGER AS $$\n    DECLARE\n        diff hstore[];\n    BEGIN\n        diff = func_configuration_policies_transition_columns_diff(\n            func_row_to_configuration_policies_transition_columns(OLD),\n            func_row_to_configuration_policies_transition_columns(NEW)\n        );\n\n        IF (array_length(diff, 1) \u003e 0) THEN\n            INSERT INTO configuration_policies_audit_logs\n            (policy_id, operation, transition_columns)\n            VALUES (NEW.id, 'modify', diff);\n        END IF;\n\n        RETURN NEW;\n    END;\n$$ LANGUAGE plpgsql;\n\nCREATE OR REPLACE FUNCTION func_configuration_policies_insert() RETURNS TRIGGER AS $$\n    BEGIN\n        INSERT INTO configuration_policies_audit_logs\n        (policy_id, operation, transition_columns)\n        VALUES (\n            NEW.id, 'create',\n            func_configuration_policies_transition_columns_diff(\n                (NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL),\n                func_row_to_configuration_policies_transition_columns(NEW)\n            )\n        );\n        RETURN NULL;\n    END;\n$$ LANGUAGE plpgsql;\n\n-- End replace triggers",
				"DownQuery": "ALTER TABLE lsif_uploads_audit_logs\nDROP COLUMN IF EXISTS sequence,\nDROP COLUMN IF EXISTS operation;\n\nDROP SEQUENCE IF EXISTS lsif_uploads_audit_logs_seq;\n\nALTER TABLE configuration_policies_audit_logs\nDROP COLUMN IF EXISTS sequence,\nDROP COLUMN IF EXISTS operation;\n\nDROP SEQUENCE IF EXISTS configuration_policies_audit_logs_seq;\n\nDROP TYPE IF EXISTS audit_log_operation;\n\nCREATE OR REPLACE FUNCTION func_configuration_policies_update() RETURNS TRIGGER AS $$\n    DECLARE\n        diff hstore[];\n    BEGIN\n        diff = func_configuration_policies_transition_columns_diff(\n            func_row_to_configuration_policies_transition_columns(OLD),\n            func_row_to_configuration_policies_transition_columns(NEW)\n        );\n\n        IF (array_length(diff, 1) \u003e 0) THEN\n            INSERT INTO configuration_policies_audit_logs\n            (policy_id, transition_columns)\n            VALUES (\n                NEW.id,\n                diff\n            );\n        END IF;\n\n        RETURN NEW;\n    END;\n$$ LANGUAGE plpgsql;\n\nCREATE OR REPLACE FUNCTION func_configuration_policies_insert() RETURNS TRIGGER AS $$\n    BEGIN\n        INSERT INTO configuration_policies_audit_logs\n        (policy_id, transition_columns)\n        VALUES (\n            NEW.id,\n            func_configuration_policies_transition_columns_diff(\n                (NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL),\n                func_row_to_configuration_policies_transition_columns(NEW)\n            )\n        );\n        RETURN NULL;\n    END;\n$$ LANGUAGE plpgsql;\n\nCREATE OR REPLACE FUNCTION func_lsif_uploads_update() RETURNS TRIGGER AS $$\n    DECLARE\n        diff hstore[];\n    BEGIN\n        diff = func_lsif_uploads_transition_columns_diff(\n            func_row_to_lsif_uploads_transition_columns(OLD),\n            func_row_to_lsif_uploads_transition_columns(NEW)\n        );\n\n        IF (array_length(diff, 1) \u003e 0) THEN\n            INSERT INTO lsif_uploads_audit_logs\n            (reason, upload_id, commit, root, repository_id, uploaded_at,\n            indexer, indexer_version, upload_size, associated_index_id,\n            transition_columns)\n            VALUES (\n                COALESCE(current_setting('codeintel.lsif_uploads_audit.reason', true), ''),\n                NEW.id, NEW.commit, NEW.root, NEW.repository_id, NEW.uploaded_at,\n                NEW.indexer, NEW.indexer_version, NEW.upload_size, NEW.associated_index_id,\n                diff\n            );\n        END IF;\n\n        RETURN NEW;\n    END;\n$$ LANGUAGE plpgsql;\n\nCREATE OR REPLACE FUNCTION func_lsif_uploads_insert() RETURNS TRIGGER AS $$\n    BEGIN\n        INSERT INTO lsif_uploads_audit_logs\n        (upload_id, commit, root, repository_id, uploaded_at,\n        indexer, indexer_version, upload_size, associated_index_id,\n        transition_columns)\n        VALUES (\n            NEW.id, NEW.commit, NEW.root, NEW.repository_id, NEW.uploaded_at,\n            NEW.indexer, NEW.indexer_version, NEW.upload_size, NEW.associated_index_id,\n            func_lsif_uploads_transition_columns_diff(\n                (NULL, NULL, NULL, NULL, NULL, NULL),\n                func_row_to_lsif_uploads_transition_columns(NEW)\n            )\n        );\n        RETURN NULL;\n    END;\n$$ LANGUAGE plpgsql;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1652946496,
					1653334014
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1649253538,
				"Name": "batch_spec_resolution_user_id_non_null",
				"UpQuery": "UPDATE batch_spec_resolution_jobs SET initiator_id = (SELECT bs.user_id FROM batch_specs bs WHERE bs.id = batch_spec_id);\n\nALTER TABLE batch_spec_resolution_jobs ALTER COLUMN initiator_id SET NOT NULL;",
				"DownQuery": "ALTER TABLE batch_spec_resolution_jobs ALTER COLUMN initiator_id DROP NOT NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1653479179
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1654116265,
				"Name": "add_unique_index_to_external_services",
				"UpQuery": "CREATE UNIQUE INDEX IF NOT EXISTS external_services_unique_kind_org_id ON external_services (kind, namespace_org_id) WHERE (deleted_at IS NULL AND namespace_user_id IS NULL AND namespace_org_id IS NOT NULL);\nCREATE UNIQUE INDEX IF NOT EXISTS external_services_unique_kind_user_id ON external_services (kind, namespace_user_id) WHERE (deleted_at IS NULL AND namespace_org_id IS NULL AND namespace_user_id IS NOT NULL);",
				"DownQuery": "DROP INDEX IF EXISTS external_services_unique_kind_org_id;\nDROP INDEX IF EXISTS external_services_unique_kind_user_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1653479179
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1654168174,
				"Name": "add_explicit_permissions_bitbucket_projects_jobs_table",
				"UpQuery": "CREATE TABLE IF NOT EXISTS explicit_permissions_bitbucket_projects_jobs (\n    id SERIAL PRIMARY KEY,\n    state text DEFAULT 'queued',\n    failure_message text,\n    queued_at timestamp with time zone DEFAULT NOW(),\n    started_at timestamp with time zone,\n    finished_at timestamp with time zone,\n    process_after timestamp with time zone,\n    num_resets integer not null default 0,\n    num_failures integer not null default 0,\n    last_heartbeat_at timestamp with time zone,\n    execution_logs json [],\n    worker_hostname text not null default '',\n    -- additional columns\n    project_key text not null,\n    external_service_id integer not null,\n    permissions json [],\n    unrestricted boolean not null default false,\n    CHECK (\n        (\n            permissions IS NOT NULL\n            AND unrestricted IS false\n        )\n        OR (\n            permissions IS NULL\n            AND unrestricted IS true\n        )\n    )\n);",
				"DownQuery": "DROP TABLE IF EXISTS explicit_permissions_bitbucket_projects_jobs;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1653479179
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1655226733,
				"Name": "hstore_aggregate_func",
				"UpQuery": "CREATE OR REPLACE FUNCTION merge_audit_log_transitions(internal hstore, arrayhstore hstore[]) RETURNS hstore AS $$\n    DECLARE\n        trans hstore;\n    BEGIN\n      FOREACH trans IN ARRAY arrayhstore\n      LOOP\n          internal := internal || hstore(trans-\u003e'column', trans-\u003e'new');\n      END LOOP;\n\n      RETURN internal;\n    END;\n$$ LANGUAGE plpgsql IMMUTABLE;\n\nCREATE OR REPLACE AGGREGATE snapshot_transition_columns(HSTORE[]) (\n    SFUNC = merge_audit_log_transitions,\n    STYPE = HSTORE,\n    INITCOND = ''\n);",
				"DownQuery": "DROP AGGREGATE IF EXISTS snapshot_transition_columns(HSTORE[]);\n\nDROP FUNCTION IF EXISTS merge_audit_log_transitions;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1654116265,
					1654168174
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1653524883,
				"Name": "Create view for batch spec workspace execution worker",
				"UpQuery": "ALTER TABLE batch_spec_workspace_execution_jobs ADD COLUMN IF NOT EXISTS user_id INTEGER;\n\nUPDATE batch_spec_workspace_execution_jobs exec SET user_id = (\n    SELECT spec.user_id\n    FROM batch_spec_workspaces AS workspace\n    JOIN batch_specs spec ON spec.id = workspace.batch_spec_id\n    WHERE workspace.id = exec.batch_spec_workspace_id\n);\n\nCREATE INDEX IF NOT EXISTS batch_spec_workspace_execution_jobs_user_id ON batch_spec_workspace_execution_jobs (user_id);\n\nCREATE INDEX IF NOT EXISTS batch_spec_workspace_execution_jobs_state ON batch_spec_workspace_execution_jobs (state);\n\nDROP VIEW IF EXISTS batch_spec_workspace_execution_queue;\nCREATE VIEW batch_spec_workspace_execution_queue AS\nWITH user_queues AS (\n    SELECT\n        exec.user_id,\n        MAX(exec.started_at) AS latest_dequeue\n    FROM batch_spec_workspace_execution_jobs AS exec\n    GROUP BY exec.user_id\n),\n-- We are creating this materialized CTE because PostgreSQL doesn't allow `FOR UPDATE` with window functions.\n-- Materializing it makes sure that the view query is not inlined into the FOR UPDATE select the Dequeue method\n-- performs.\nmaterialized_queue_candidates AS MATERIALIZED (\n    SELECT\n        exec.*,\n        RANK() OVER (\n            PARTITION BY queue.user_id\n            -- Make sure the jobs are still fulfilled in timely order, and that the ordering is stable.\n            ORDER BY exec.created_at ASC, exec.id ASC\n        ) AS place_in_user_queue\n    FROM batch_spec_workspace_execution_jobs exec\n    JOIN user_queues queue ON queue.user_id = exec.user_id\n    WHERE\n    \t-- Only queued records should get a rank.\n        exec.state = 'queued'\n    ORDER BY\n        -- Round-robin let users dequeue jobs.\n        place_in_user_queue,\n        -- And ensure the user who dequeued the longest ago is next.\n        queue.latest_dequeue ASC NULLS FIRST\n)\nSELECT\n    ROW_NUMBER() OVER () AS place_in_global_queue, materialized_queue_candidates.*\nFROM materialized_queue_candidates;",
				"DownQuery": "DROP VIEW IF EXISTS batch_spec_workspace_execution_queue;\n\nALTER TABLE batch_spec_workspace_execution_jobs DROP COLUMN IF EXISTS user_id;\n\nDROP INDEX IF EXISTS batch_spec_workspace_execution_jobs_user_id;\n\nDROP INDEX IF EXISTS batch_spec_workspace_execution_jobs_state;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1653334014,
					1653479179
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1654770608,
				"Name": "workspace_user_id_non_nullable",
				"UpQuery": "UPDATE batch_spec_workspace_execution_jobs exec SET user_id = (\n    SELECT spec.user_id\n    FROM batch_spec_workspaces AS workspace\n    JOIN batch_specs spec ON spec.id = workspace.batch_spec_id\n    WHERE workspace.id = exec.batch_spec_workspace_id\n);\n\nALTER TABLE batch_spec_workspace_execution_jobs ALTER COLUMN user_id SET NOT NULL;",
				"DownQuery": "ALTER TABLE batch_spec_workspace_execution_jobs ALTER COLUMN user_id DROP NOT NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1653524883,
					1654116265,
					1654168174
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1654848945,
				"Name": "add_explicit_permissions_bitbucket_projects_jobs_index",
				"UpQuery": "CREATE INDEX IF NOT EXISTS explicit_permissions_bitbucket_projects_jobs_project_key_external_service_id_state_idx ON explicit_permissions_bitbucket_projects_jobs (project_key, external_service_id, state);",
				"DownQuery": "DROP INDEX IF EXISTS explicit_permissions_bitbucket_projects_jobs_project_key_external_service_id_state_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1653524883,
					1654116265,
					1654168174
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1654872407,
				"Name": "fast_cascade_delete_batch_specs_1",
				"UpQuery": "-- Create index for foreign key reverse lookups. This is required for cascading deletes.\nCREATE INDEX CONCURRENTLY IF NOT EXISTS changeset_specs_batch_spec_id ON changeset_specs (batch_spec_id);",
				"DownQuery": "DROP INDEX IF EXISTS changeset_specs_batch_spec_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1654848945
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "changeset_specs",
					"IndexName": "changeset_specs_batch_spec_id"
				}
			},
			{
				"ID": 1654874148,
				"Name": "fast_cascade_delete_batch_specs_2",
				"UpQuery": "-- Create index for foreign key reverse lookups. This is required for cascading deletes.\nCREATE INDEX CONCURRENTLY IF NOT EXISTS batch_spec_workspaces_batch_spec_id ON batch_spec_workspaces (batch_spec_id);",
				"DownQuery": "DROP INDEX IF EXISTS batch_spec_workspaces_batch_spec_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1654872407
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "batch_spec_workspaces",
					"IndexName": "batch_spec_workspaces_batch_spec_id"
				}
			},
			{
				"ID": 1654874153,
				"Name": "fast_cascade_delete_batch_specs_3",
				"UpQuery": "-- Create index for foreign key reverse lookups. This is required for cascading deletes.\nCREATE INDEX CONCURRENTLY IF NOT EXISTS batch_spec_workspace_execution_jobs_batch_spec_workspace_id ON batch_spec_workspace_execution_jobs (batch_spec_workspace_id);",
				"DownQuery": "DROP INDEX IF EXISTS batch_spec_workspace_execution_jobs_batch_spec_workspace_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1654874148
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "batch_spec_workspace_execution_jobs",
					"IndexName": "batch_spec_workspace_execution_jobs_batch_spec_workspace_id"
				}
			},
			{
				"ID": 1655037388,
				"Name": "faster_changeset_spec_cleanup_1",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS changeset_specs_created_at ON changeset_specs (created_at);",
				"DownQuery": "DROP INDEX IF EXISTS changeset_specs_created_at;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1654874153
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "changeset_specs",
					"IndexName": "changeset_specs_created_at"
				}
			},
			{
				"ID": 1655037391,
				"Name": "faster_changeset_spec_cleanup_2",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS changesets_changeset_specs ON changesets (current_spec_id, previous_spec_id);",
				"DownQuery": "DROP INDEX IF EXISTS changesets_changeset_specs;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1655037388
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "changesets",
					"IndexName": "changesets_changeset_specs"
				}
			},
			{
				"ID": 1655067139,
				"Name": "fixup_worker_fairness_view",
				"UpQuery": "DROP VIEW IF EXISTS batch_spec_workspace_execution_jobs_with_rank;\nDROP VIEW IF EXISTS batch_spec_workspace_execution_queue;\n\nCREATE VIEW batch_spec_workspace_execution_queue AS\nWITH user_queues AS (\n    SELECT\n        exec.user_id,\n        MAX(exec.started_at) AS latest_dequeue\n    FROM batch_spec_workspace_execution_jobs AS exec\n    GROUP BY exec.user_id\n),\nqueue_candidates AS (\n    SELECT\n        exec.id,\n        RANK() OVER (\n            PARTITION BY queue.user_id\n            -- Make sure the jobs are still fulfilled in timely order, and that the ordering is stable.\n            ORDER BY exec.created_at ASC, exec.id ASC\n        ) AS place_in_user_queue\n    FROM batch_spec_workspace_execution_jobs exec\n    JOIN user_queues queue ON queue.user_id = exec.user_id\n    WHERE\n    \t-- Only queued records should get a rank.\n        exec.state = 'queued'\n    ORDER BY\n        -- Round-robin let users dequeue jobs.\n        place_in_user_queue,\n        -- And ensure the user who dequeued the longest ago is next.\n        queue.latest_dequeue ASC NULLS FIRST\n)\nSELECT\n    queue_candidates.id, ROW_NUMBER() OVER () AS place_in_global_queue, queue_candidates.place_in_user_queue\nFROM queue_candidates;\n\nCREATE VIEW batch_spec_workspace_execution_jobs_with_rank AS (\n    SELECT\n        j.*,\n        q.place_in_global_queue,\n        q.place_in_user_queue\n    FROM\n        batch_spec_workspace_execution_jobs j\n    LEFT JOIN batch_spec_workspace_execution_queue q ON j.id = q.id\n);",
				"DownQuery": "DROP VIEW IF EXISTS batch_spec_workspace_execution_jobs_with_rank;\nDROP VIEW IF EXISTS batch_spec_workspace_execution_queue;\n\nCREATE VIEW batch_spec_workspace_execution_queue AS\nWITH user_queues AS (\n    SELECT\n        exec.user_id,\n        MAX(exec.started_at) AS latest_dequeue\n    FROM batch_spec_workspace_execution_jobs AS exec\n    GROUP BY exec.user_id\n),\n-- We are creating this materialized CTE because PostgreSQL doesn't allow `FOR UPDATE` with window functions.\n-- Materializing it makes sure that the view query is not inlined into the FOR UPDATE select the Dequeue method\n-- performs.\nmaterialized_queue_candidates AS MATERIALIZED (\n    SELECT\n        exec.*,\n        RANK() OVER (\n            PARTITION BY queue.user_id\n            -- Make sure the jobs are still fulfilled in timely order, and that the ordering is stable.\n            ORDER BY exec.created_at ASC, exec.id ASC\n        ) AS place_in_user_queue\n    FROM batch_spec_workspace_execution_jobs exec\n    JOIN user_queues queue ON queue.user_id = exec.user_id\n    WHERE\n    \t-- Only queued records should get a rank.\n        exec.state = 'queued'\n    ORDER BY\n        -- Round-robin let users dequeue jobs.\n        place_in_user_queue,\n        -- And ensure the user who dequeued the longest ago is next.\n        queue.latest_dequeue ASC NULLS FIRST\n)\nSELECT\n    ROW_NUMBER() OVER () AS place_in_global_queue, materialized_queue_candidates.*\nFROM materialized_queue_candidates;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1654874153
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1655128668,
				"Name": "add indices to explicit_permissions_bitbucket_projects_jobs table",
				"UpQuery": "CREATE INDEX IF NOT EXISTS explicit_permissions_bitbucket_projects_jobs_queued_at_idx ON explicit_permissions_bitbucket_projects_jobs (queued_at);\nCREATE INDEX IF NOT EXISTS explicit_permissions_bitbucket_projects_jobs_state_idx ON explicit_permissions_bitbucket_projects_jobs (state);",
				"DownQuery": "DROP INDEX IF EXISTS explicit_permissions_bitbucket_projects_jobs_queued_at_idx;\nDROP INDEX IF EXISTS explicit_permissions_bitbucket_projects_jobs_state_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1654874153
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1655328928,
				"Name": "fix_code_insights_failed_tcp_error",
				"UpQuery": "-- In 3.40 one transient error was accidentally flagged as non-retryable and would terminally fail. This simply\n-- resets these jobs in the queue to try again after 3.41 ships.\nupdate insights_query_runner_jobs set state = 'queued', failure_message = null, num_failures = 0\nwhere state = 'failed' and failure_message like '%dial tcp%';",
				"DownQuery": "-- Nothing to do in this down migration.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1649253538,
					1655037391,
					1655067139,
					1655128668
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1655412173,
				"Name": "code_insights_queue_missing_index",
				"UpQuery": "CREATE INDEX IF NOT EXISTS process_after_insights_query_runner_jobs_idx\n    ON insights_query_runner_jobs (process_after);\n\nCREATE INDEX IF NOT EXISTS finished_at_insights_query_runner_jobs_idx\n    ON insights_query_runner_jobs (finished_at);",
				"DownQuery": "DROP INDEX IF EXISTS process_after_insights_query_runner_jobs_idx;\nDROP INDEX IF EXISTS finished_at_insights_query_runner_jobs_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1655328928
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1655481894,
				"Name": "faster_ssbc_dequeue",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS batch_spec_workspace_execution_jobs_last_dequeue ON batch_spec_workspace_execution_jobs (user_id, started_at DESC);",
				"DownQuery": "DROP INDEX IF EXISTS batch_spec_workspace_execution_jobs_last_dequeue;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1655412173
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "batch_spec_workspace_execution_jobs",
					"IndexName": "batch_spec_workspace_execution_jobs_last_dequeue"
				}
			},
			{
				"ID": 1655737737,
				"Name": "drop_unused_idx_batch_spec_workspace_execution_jobs_user_id",
				"UpQuery": "DROP INDEX IF EXISTS batch_spec_workspace_execution_jobs_user_id;",
				"DownQuery": "CREATE INDEX IF NOT EXISTS batch_spec_workspace_execution_jobs_user_id ON batch_spec_workspace_execution_jobs (user_id);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1655481894
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1655763641,
				"Name": "faster_workspace_batch_spec_lookup",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS batch_spec_workspaces_id_batch_spec_id ON batch_spec_workspaces(id, batch_spec_id);",
				"DownQuery": "DROP INDEX IF EXISTS batch_spec_workspaces_id_batch_spec_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1655481894
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "batch_spec_workspaces",
					"IndexName": "batch_spec_workspaces_id_batch_spec_id"
				}
			},
			{
				"ID": 1655843069,
				"Name": "insights_faster_job_status",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS insights_query_runner_jobs_series_id_state ON insights_query_runner_jobs (series_id, state);",
				"DownQuery": "DROP INDEX IF EXISTS insights_query_runner_jobs_series_id_state;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1655737737,
					1655763641
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "insights_query_runner_jobs",
					"IndexName": "insights_query_runner_jobs_series_id_state"
				}
			},
			{
				"ID": 1655157509,
				"Name": "no_more_ssbc_access_tokens",
				"UpQuery": "DELETE FROM access_tokens WHERE internal and note = 'batch-spec-execution';\n\nDROP VIEW IF EXISTS batch_spec_workspace_execution_jobs_with_rank;\nCREATE VIEW batch_spec_workspace_execution_jobs_with_rank AS (\n    SELECT\n        j.id,\n        j.batch_spec_workspace_id,\n        j.state,\n        j.failure_message,\n        j.started_at,\n        j.finished_at,\n        j.process_after,\n        j.num_resets,\n        j.num_failures,\n        j.execution_logs,\n        j.worker_hostname,\n        j.last_heartbeat_at,\n        j.created_at,\n        j.updated_at,\n        j.cancel,\n        j.queued_at,\n        j.user_id,\n        q.place_in_global_queue,\n        q.place_in_user_queue\n    FROM\n        batch_spec_workspace_execution_jobs j\n    LEFT JOIN batch_spec_workspace_execution_queue q ON j.id = q.id\n);\n\nALTER TABLE batch_spec_workspace_execution_jobs DROP COLUMN IF EXISTS access_token_id;",
				"DownQuery": "ALTER TABLE batch_spec_workspace_execution_jobs ADD COLUMN IF NOT EXISTS access_token_id integer REFERENCES access_tokens(id);\n\nDROP VIEW IF EXISTS batch_spec_workspace_execution_jobs_with_rank;\nCREATE VIEW batch_spec_workspace_execution_jobs_with_rank AS (\n    SELECT\n        j.*,\n        q.place_in_global_queue,\n        q.place_in_user_queue\n    FROM\n        batch_spec_workspace_execution_jobs j\n    LEFT JOIN batch_spec_workspace_execution_queue q ON j.id = q.id\n);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1649253538,
					1654874153
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1655105391,
				"Name": "lockfile_dependency_graph",
				"UpQuery": "DELETE FROM codeintel_lockfiles;\nDELETE FROM codeintel_lockfile_references;\n\nALTER TABLE codeintel_lockfiles\n  ADD COLUMN IF NOT EXISTS lockfile text;\n\n-- This is a backwards incompatible change. See dev/ci/go-backcompat/flakefiles/v3.41.0.json for details.\nDROP INDEX IF EXISTS codeintel_lockfiles_repository_id_commit_bytea;\nCREATE UNIQUE INDEX IF NOT EXISTS codeintel_lockfiles_repository_id_commit_bytea_lockfile ON codeintel_lockfiles USING btree (repository_id, commit_bytea, lockfile);\n\nCOMMENT ON COLUMN codeintel_lockfiles.lockfile IS 'Relative path of a lockfile in the given repository and the given commit.';\n\nALTER TABLE codeintel_lockfile_references\n  -- We can't make them non-nullable to stay backwards compatible\n  ADD COLUMN IF NOT EXISTS depends_on integer[] DEFAULT '{}',\n  ADD COLUMN IF NOT EXISTS resolution_lockfile text,\n  ADD COLUMN IF NOT EXISTS resolution_repository_id integer,\n  ADD COLUMN IF NOT EXISTS resolution_commit_bytea bytea;\n\nCOMMENT ON COLUMN codeintel_lockfile_references.depends_on IS 'IDs of other `codeintel_lockfile_references` this package depends on in the context of this `codeintel_lockfile_references.resolution_id`.';\nCOMMENT ON COLUMN codeintel_lockfile_references.resolution_lockfile IS 'Relative path of lockfile in which this package was referenced. Corresponds to `codeintel_lockfiles.lockfile`.';\nCOMMENT ON COLUMN codeintel_lockfile_references.resolution_repository_id IS 'ID of the repository in which lockfile was resolved. Corresponds to `codeintel_lockfiles.repository_id`.';\nCOMMENT ON COLUMN codeintel_lockfile_references.resolution_commit_bytea IS 'Commit at which lockfile was resolved. Corresponds to `codeintel_lockfiles.commit_bytea`.';\n\nCREATE INDEX IF NOT EXISTS codeintel_lockfiles_references_depends_on\nON codeintel_lockfile_references USING GIN (depends_on gin__int_ops);\n\n-- This is a backwards incompatible change. See dev/ci/go-backcompat/flakefiles/v3.41.0.json for details.\nDROP INDEX IF EXISTS codeintel_lockfile_references_repository_name_revspec_package;\nCREATE UNIQUE INDEX IF NOT EXISTS codeintel_lockfile_references_repository_name_revspec_package_resolution ON codeintel_lockfile_references USING btree (\n    repository_name,\n    revspec,\n    package_scheme,\n    package_name,\n    package_version,\n    resolution_lockfile,\n    resolution_repository_id,\n    resolution_commit_bytea\n);",
				"DownQuery": "ALTER TABLE codeintel_lockfiles\n  DROP COLUMN IF EXISTS lockfile;\n\nDROP INDEX IF EXISTS codeintel_lockfiles_repository_id_commit_bytea_lockfile;\nCREATE UNIQUE INDEX IF NOT EXISTS codeintel_lockfiles_repository_id_commit_bytea ON codeintel_lockfiles USING btree (repository_id, commit_bytea);\n\nALTER TABLE codeintel_lockfile_references\n  DROP COLUMN IF EXISTS depends_on,\n  DROP COLUMN IF EXISTS resolution_lockfile,\n  DROP COLUMN IF EXISTS resolution_repository_id,\n  DROP COLUMN IF EXISTS resolution_commit_bytea;\n\nDROP INDEX IF EXISTS codeintel_lockfile_references_repository_name_revspec_package_resolution;\nCREATE UNIQUE INDEX IF NOT EXISTS codeintel_lockfile_references_repository_name_revspec_package ON codeintel_lockfile_references USING btree (\n    repository_name,\n    revspec,\n    package_scheme,\n    package_name,\n    package_version\n);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1654848945
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1655454264,
				"Name": "add_lockfile_indexing_enabled_to_policy",
				"UpQuery": "ALTER TABLE lsif_configuration_policies\n  ADD COLUMN IF NOT EXISTS lockfile_indexing_enabled boolean NOT NULL DEFAULT false;\n\nCOMMENT ON COLUMN lsif_configuration_policies.lockfile_indexing_enabled IS 'Whether to index the lockfiles in the repositories matched by this policy';",
				"DownQuery": "ALTER TABLE lsif_configuration_policies\n  DROP COLUMN IF EXISTS lockfile_indexing_enabled;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1655105391
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1656447205,
				"Name": "create_repo_description_trgm_idx",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS repo_description_trgm_idx ON repo USING GIN (lower(description) gin_trgm_ops);",
				"DownQuery": "DROP INDEX IF EXISTS repo_description_trgm_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1655454264,
					1655843069
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "repo",
					"IndexName": "repo_description_trgm_idx"
				}
			},
			{
				"ID": 1657106983,
				"Name": "faster_failure_msg_query",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS external_service_sync_jobs_state_external_service_id ON external_service_sync_jobs (state, external_service_id) INCLUDE (finished_at);",
				"DownQuery": "DROP INDEX IF EXISTS external_service_sync_jobs_state_external_service_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1653472246,
					1655157509,
					1655226733,
					1655454264,
					1655843069
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "external_service_sync_jobs",
					"IndexName": "external_service_sync_jobs_state_external_service_id"
				}
			},
			{
				"ID": 1657107627,
				"Name": "drop_duplicate_index_sync_jobs_state",
				"UpQuery": "DROP INDEX IF EXISTS external_service_sync_jobs_state_idx;",
				"DownQuery": "CREATE INDEX IF NOT EXISTS external_service_sync_jobs_state_idx ON external_service_sync_jobs (state);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1657106983
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1657279116,
				"Name": "faster_dequeues_cm_action_jobs",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS cm_action_jobs_state_idx ON cm_action_jobs (state);",
				"DownQuery": "DROP INDEX IF EXISTS cm_action_jobs_state_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1656447205,
					1657107627
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "cm_action_jobs",
					"IndexName": "cm_action_jobs_state_idx"
				}
			},
			{
				"ID": 1657279170,
				"Name": "faster_dequeues_cm_trigger_jobs",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS cm_trigger_jobs_state_idx ON cm_trigger_jobs (state);",
				"DownQuery": "DROP INDEX IF EXISTS cm_trigger_jobs_state_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1657279116
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "cm_trigger_jobs",
					"IndexName": "cm_trigger_jobs_state_idx"
				}
			},
			{
				"ID": 1657635365,
				"Name": "add_fidelity_to_lockfiles",
				"UpQuery": "ALTER TABLE codeintel_lockfiles\n  ADD COLUMN IF NOT EXISTS fidelity text NOT NULL DEFAULT 'flat';\n\nCOMMENT ON COLUMN codeintel_lockfiles.fidelity IS 'Fidelity of the dependency graph thats persisted, whether it is a flat list, a whole graph, circular graph, ...';",
				"DownQuery": "ALTER TABLE codeintel_lockfiles DROP COLUMN IF EXISTS fidelity;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1657279170
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1658122170,
				"Name": "add_batch_change_id_to_batch_spec",
				"UpQuery": "ALTER TABLE batch_specs\n    ADD COLUMN IF NOT EXISTS batch_change_id bigint,\n    ADD FOREIGN KEY (batch_change_id) REFERENCES batch_changes(id) ON DELETE SET NULL DEFERRABLE;\n\nUPDATE batch_specs SET batch_change_id = (\n    -- In the event, the database is in a not-so-optimal state (usually in dev environment)\n    -- we want the subquery to never return more than one row.\n    -- This will never happen in production.\n    SELECT\n        bc.id\n    FROM batch_changes bc\n    WHERE bc.batch_spec_id = batch_specs.id\n    LIMIT 1\n);",
				"DownQuery": "ALTER TABLE batch_specs\n    DROP COLUMN IF EXISTS batch_change_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1657635365
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1658174103,
				"Name": "workspace_execution_user_queues",
				"UpQuery": "CREATE TABLE IF NOT EXISTS batch_spec_workspace_execution_last_dequeues (\n    user_id integer PRIMARY KEY REFERENCES users(id) ON DELETE CASCADE ON UPDATE CASCADE DEFERRABLE INITIALLY DEFERRED,\n    latest_dequeue timestamp with time zone\n);\n\nCREATE OR REPLACE FUNCTION batch_spec_workspace_execution_last_dequeues_upsert() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$ BEGIN\n    INSERT INTO\n        batch_spec_workspace_execution_last_dequeues\n    SELECT\n        user_id,\n        MAX(started_at) as latest_dequeue\n    FROM\n        newtab\n    GROUP BY\n        user_id\n    ON CONFLICT (user_id) DO UPDATE SET\n        latest_dequeue = GREATEST(batch_spec_workspace_execution_last_dequeues.latest_dequeue, EXCLUDED.latest_dequeue);\n\n    RETURN NULL;\nEND $$;\n\nDROP TRIGGER IF EXISTS batch_spec_workspace_execution_last_dequeues_insert ON batch_spec_workspace_execution_jobs;\nCREATE TRIGGER batch_spec_workspace_execution_last_dequeues_insert AFTER INSERT ON batch_spec_workspace_execution_jobs REFERENCING NEW TABLE AS newtab FOR EACH STATEMENT EXECUTE FUNCTION batch_spec_workspace_execution_last_dequeues_upsert();\n\nDROP TRIGGER IF EXISTS batch_spec_workspace_execution_last_dequeues_update ON batch_spec_workspace_execution_jobs;\nCREATE TRIGGER batch_spec_workspace_execution_last_dequeues_update AFTER UPDATE ON batch_spec_workspace_execution_jobs REFERENCING NEW TABLE AS newtab FOR EACH STATEMENT EXECUTE FUNCTION batch_spec_workspace_execution_last_dequeues_upsert();\n\nDROP VIEW IF EXISTS batch_spec_workspace_execution_jobs_with_rank;\nDROP VIEW IF EXISTS batch_spec_workspace_execution_queue;\n\nCREATE VIEW batch_spec_workspace_execution_queue AS\nWITH queue_candidates AS (\n    SELECT\n        exec.id,\n        RANK() OVER (\n            PARTITION BY queue.user_id\n            -- Make sure the jobs are still fulfilled in timely order, and that the ordering is stable.\n            ORDER BY exec.created_at ASC, exec.id ASC\n        ) AS place_in_user_queue\n    FROM batch_spec_workspace_execution_jobs exec\n    JOIN batch_spec_workspace_execution_last_dequeues queue ON queue.user_id = exec.user_id\n    WHERE\n    \t-- Only queued records should get a rank.\n        exec.state = 'queued'\n    ORDER BY\n        -- Round-robin let users dequeue jobs.\n        place_in_user_queue,\n        -- And ensure the user who dequeued the longest ago is next.\n        queue.latest_dequeue ASC NULLS FIRST\n)\nSELECT\n    queue_candidates.id, ROW_NUMBER() OVER () AS place_in_global_queue, queue_candidates.place_in_user_queue\nFROM queue_candidates;\n\nCREATE VIEW batch_spec_workspace_execution_jobs_with_rank AS (\n    SELECT\n        j.*,\n        q.place_in_global_queue,\n        q.place_in_user_queue\n    FROM\n        batch_spec_workspace_execution_jobs j\n    LEFT JOIN batch_spec_workspace_execution_queue q ON j.id = q.id\n);\n\nINSERT INTO batch_spec_workspace_execution_last_dequeues\nSELECT\n    exec.user_id as user_id,\n    MAX(exec.started_at) AS latest_dequeue\nFROM batch_spec_workspace_execution_jobs exec\nGROUP BY exec.user_id\nON CONFLICT (user_id) DO UPDATE\n    SET latest_dequeue = GREATEST(batch_spec_workspace_execution_last_dequeues.latest_dequeue, EXCLUDED.latest_dequeue);",
				"DownQuery": "DROP TRIGGER IF EXISTS batch_spec_workspace_execution_last_dequeues_insert ON batch_spec_workspace_execution_jobs;\nDROP TRIGGER IF EXISTS batch_spec_workspace_execution_last_dequeues_update ON batch_spec_workspace_execution_jobs;\nDROP FUNCTION IF EXISTS batch_spec_workspace_execution_last_dequeues_upsert();\n\nDROP VIEW IF EXISTS batch_spec_workspace_execution_jobs_with_rank;\nDROP VIEW IF EXISTS batch_spec_workspace_execution_queue;\n\nCREATE VIEW batch_spec_workspace_execution_queue AS\nWITH user_queues AS (\n    SELECT\n        exec.user_id,\n        MAX(exec.started_at) AS latest_dequeue\n    FROM batch_spec_workspace_execution_jobs AS exec\n    GROUP BY exec.user_id\n),\nqueue_candidates AS (\n    SELECT\n        exec.id,\n        RANK() OVER (\n            PARTITION BY queue.user_id\n            -- Make sure the jobs are still fulfilled in timely order, and that the ordering is stable.\n            ORDER BY exec.created_at ASC, exec.id ASC\n        ) AS place_in_user_queue\n    FROM batch_spec_workspace_execution_jobs exec\n    JOIN user_queues queue ON queue.user_id = exec.user_id\n    WHERE\n    \t-- Only queued records should get a rank.\n        exec.state = 'queued'\n    ORDER BY\n        -- Round-robin let users dequeue jobs.\n        place_in_user_queue,\n        -- And ensure the user who dequeued the longest ago is next.\n        queue.latest_dequeue ASC NULLS FIRST\n)\nSELECT\n    queue_candidates.id, ROW_NUMBER() OVER () AS place_in_global_queue, queue_candidates.place_in_user_queue\nFROM queue_candidates;\n\nCREATE VIEW batch_spec_workspace_execution_jobs_with_rank AS (\n    SELECT\n        j.*,\n        q.place_in_global_queue,\n        q.place_in_user_queue\n    FROM\n        batch_spec_workspace_execution_jobs j\n    LEFT JOIN batch_spec_workspace_execution_queue q ON j.id = q.id\n);\n\nDROP TABLE IF EXISTS batch_spec_workspace_execution_last_dequeues;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1657635365
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1658225452,
				"Name": "fast_cm_trigger_jobs_delete",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS cm_trigger_jobs_finished_at ON cm_trigger_jobs (finished_at ASC);",
				"DownQuery": "DROP INDEX IF EXISTS cm_trigger_jobs_finished_at;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1657635365
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "cm_trigger_jobs",
					"IndexName": "cm_trigger_jobs_finished_at"
				}
			},
			{
				"ID": 1657663493,
				"Name": "cancel_worker_feature",
				"UpQuery": "ALTER TABLE explicit_permissions_bitbucket_projects_jobs ADD COLUMN IF NOT EXISTS cancel BOOLEAN NOT NULL DEFAULT FALSE;\nALTER TABLE external_service_sync_jobs ADD COLUMN IF NOT EXISTS cancel BOOLEAN NOT NULL DEFAULT FALSE;\nALTER TABLE gitserver_relocator_jobs ADD COLUMN IF NOT EXISTS cancel BOOLEAN NOT NULL DEFAULT FALSE;\nALTER TABLE insights_query_runner_jobs ADD COLUMN IF NOT EXISTS cancel BOOLEAN NOT NULL DEFAULT FALSE;\nALTER TABLE lsif_dependency_indexing_jobs ADD COLUMN IF NOT EXISTS cancel BOOLEAN NOT NULL DEFAULT FALSE;\nALTER TABLE lsif_dependency_syncing_jobs ADD COLUMN IF NOT EXISTS cancel BOOLEAN NOT NULL DEFAULT FALSE;\nALTER TABLE lsif_indexes ADD COLUMN IF NOT EXISTS cancel BOOLEAN NOT NULL DEFAULT FALSE;\nALTER TABLE lsif_uploads ADD COLUMN IF NOT EXISTS cancel BOOLEAN NOT NULL DEFAULT FALSE;\nALTER TABLE batch_spec_resolution_jobs ADD COLUMN IF NOT EXISTS cancel BOOLEAN NOT NULL DEFAULT FALSE;\nALTER TABLE changeset_jobs ADD COLUMN IF NOT EXISTS cancel BOOLEAN NOT NULL DEFAULT FALSE;\nALTER TABLE changesets ADD COLUMN IF NOT EXISTS cancel BOOLEAN NOT NULL DEFAULT FALSE;\nALTER TABLE cm_action_jobs ADD COLUMN IF NOT EXISTS cancel BOOLEAN NOT NULL DEFAULT FALSE;\nALTER TABLE cm_trigger_jobs ADD COLUMN IF NOT EXISTS cancel BOOLEAN NOT NULL DEFAULT FALSE;",
				"DownQuery": "ALTER TABLE explicit_permissions_bitbucket_projects_jobs DROP COLUMN IF EXISTS cancel;\nALTER TABLE external_service_sync_jobs DROP COLUMN IF EXISTS cancel;\nALTER TABLE gitserver_relocator_jobs DROP COLUMN IF EXISTS cancel;\nALTER TABLE insights_query_runner_jobs DROP COLUMN IF EXISTS cancel;\nALTER TABLE lsif_dependency_indexing_jobs DROP COLUMN IF EXISTS cancel;\nALTER TABLE lsif_dependency_syncing_jobs DROP COLUMN IF EXISTS cancel;\nALTER TABLE lsif_indexes DROP COLUMN IF EXISTS cancel;\nALTER TABLE lsif_uploads DROP COLUMN IF EXISTS cancel;\nALTER TABLE batch_spec_resolution_jobs DROP COLUMN IF EXISTS cancel;\nALTER TABLE changeset_jobs DROP COLUMN IF EXISTS cancel;\nALTER TABLE changesets DROP COLUMN IF EXISTS cancel;\nALTER TABLE cm_action_jobs DROP COLUMN IF EXISTS cancel;\nALTER TABLE cm_trigger_jobs DROP COLUMN IF EXISTS cancel;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1657279170
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1658255432,
				"Name": "add_missing_constraints",
				"UpQuery": "DELETE FROM batch_spec_resolution_jobs WHERE batch_spec_id IS NULL OR state IS NULL;\n\nALTER TABLE batch_spec_resolution_jobs\n    ALTER COLUMN batch_spec_id SET NOT NULL,\n    ALTER COLUMN state SET NOT NULL;\n\nDELETE FROM batch_spec_workspace_execution_jobs WHERE batch_spec_workspace_id IS NULL OR state IS NULL;\n\nALTER TABLE batch_spec_workspace_execution_jobs\n    ALTER COLUMN batch_spec_workspace_id SET NOT NULL,\n    ALTER COLUMN state SET NOT NULL;\n\nDELETE FROM batch_spec_workspaces WHERE batch_spec_id IS NULL OR changeset_spec_ids IS NULL OR repo_id IS NULL;\n\nALTER TABLE batch_spec_workspaces\n    ALTER COLUMN batch_spec_id SET NOT NULL,\n    ALTER COLUMN changeset_spec_ids SET NOT NULL,\n    ALTER COLUMN repo_id SET NOT NULL;\n\nDELETE FROM changeset_jobs WHERE state IS NULL;\nALTER TABLE changeset_jobs\n    ALTER COLUMN state SET NOT NULL;",
				"DownQuery": "ALTER TABLE batch_spec_resolution_jobs\n    ALTER COLUMN batch_spec_id DROP NOT NULL,\n    ALTER COLUMN state DROP NOT NULL;\n\nALTER TABLE batch_spec_workspace_execution_jobs\n    ALTER COLUMN batch_spec_workspace_id DROP NOT NULL,\n    ALTER COLUMN state DROP NOT NULL;\n\nALTER TABLE batch_spec_workspaces\n    ALTER COLUMN batch_spec_id DROP NOT NULL,\n    ALTER COLUMN changeset_spec_ids DROP NOT NULL,\n    ALTER COLUMN repo_id DROP NOT NULL;\n\nALTER TABLE changeset_jobs\n    ALTER COLUMN state DROP NOT NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1654770608,
					1657663493,
					1658174103,
					1658225452
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1658384388,
				"Name": "normalize product_licenses.license_key fields",
				"UpQuery": "ALTER TABLE product_licenses ADD COLUMN IF NOT EXISTS license_version INT;\nALTER TABLE product_licenses ADD COLUMN IF NOT EXISTS license_tags TEXT[];\nALTER TABLE product_licenses ADD COLUMN IF NOT EXISTS license_user_count INT;\nALTER TABLE product_licenses ADD COLUMN IF NOT EXISTS license_expires_at TIMESTAMP WITH TIME ZONE;\nALTER TABLE product_subscriptions ADD COLUMN IF NOT EXISTS account_number TEXT;",
				"DownQuery": "ALTER TABLE product_licenses DROP COLUMN IF EXISTS license_version;\nALTER TABLE product_licenses DROP COLUMN IF EXISTS license_tags;\nALTER TABLE product_licenses DROP COLUMN IF EXISTS license_user_count;\nALTER TABLE product_licenses DROP COLUMN IF EXISTS license_expires_at;\nALTER TABLE product_subscriptions DROP COLUMN IF EXISTS account_number;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1658255432
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1653596521,
				"Name": "Add column detached_at to changesets table",
				"UpQuery": "ALTER TABLE changesets\n    ADD COLUMN IF NOT EXISTS detached_at timestamp with time zone;\n\nCREATE INDEX IF NOT EXISTS\n    changesets_detached_at\n    ON\n        changesets (detached_at);\n\nDROP VIEW IF EXISTS reconciler_changesets;\n\nCREATE VIEW reconciler_changesets AS\nSELECT c.id,\n       c.batch_change_ids,\n       c.repo_id,\n       c.queued_at,\n       c.created_at,\n       c.updated_at,\n       c.metadata,\n       c.external_id,\n       c.external_service_type,\n       c.external_deleted_at,\n       c.external_branch,\n       c.external_updated_at,\n       c.external_state,\n       c.external_review_state,\n       c.external_check_state,\n       c.diff_stat_added,\n       c.diff_stat_changed,\n       c.diff_stat_deleted,\n       c.sync_state,\n       c.current_spec_id,\n       c.previous_spec_id,\n       c.publication_state,\n       c.owned_by_batch_change_id,\n       c.reconciler_state,\n       c.failure_message,\n       c.started_at,\n       c.finished_at,\n       c.process_after,\n       c.num_resets,\n       c.closing,\n       c.num_failures,\n       c.log_contents,\n       c.execution_logs,\n       c.syncer_error,\n       c.external_title,\n       c.worker_hostname,\n       c.ui_publication_state,\n       c.last_heartbeat_at,\n       c.external_fork_namespace,\n       c.detached_at\nFROM changesets c\n         JOIN repo r ON r.id = c.repo_id\nWHERE r.deleted_at IS NULL AND EXISTS (\n    SELECT 1\n    FROM batch_changes\n             LEFT JOIN users namespace_user ON batch_changes.namespace_user_id = namespace_user.id\n             LEFT JOIN orgs namespace_org ON batch_changes.namespace_org_id = namespace_org.id\n    WHERE c.batch_change_ids ? batch_changes.id::text AND namespace_user.deleted_at IS NULL AND namespace_org.deleted_at IS NULL\n    );",
				"DownQuery": "DROP VIEW IF EXISTS reconciler_changesets;\n\nCREATE VIEW reconciler_changesets AS\nSELECT c.id,\n       c.batch_change_ids,\n       c.repo_id,\n       c.queued_at,\n       c.created_at,\n       c.updated_at,\n       c.metadata,\n       c.external_id,\n       c.external_service_type,\n       c.external_deleted_at,\n       c.external_branch,\n       c.external_updated_at,\n       c.external_state,\n       c.external_review_state,\n       c.external_check_state,\n       c.diff_stat_added,\n       c.diff_stat_changed,\n       c.diff_stat_deleted,\n       c.sync_state,\n       c.current_spec_id,\n       c.previous_spec_id,\n       c.publication_state,\n       c.owned_by_batch_change_id,\n       c.reconciler_state,\n       c.failure_message,\n       c.started_at,\n       c.finished_at,\n       c.process_after,\n       c.num_resets,\n       c.closing,\n       c.num_failures,\n       c.log_contents,\n       c.execution_logs,\n       c.syncer_error,\n       c.external_title,\n       c.worker_hostname,\n       c.ui_publication_state,\n       c.last_heartbeat_at,\n       c.external_fork_namespace\nFROM changesets c\n         JOIN repo r ON r.id = c.repo_id\nWHERE r.deleted_at IS NULL AND EXISTS (\n    SELECT 1\n    FROM batch_changes\n             LEFT JOIN users namespace_user ON batch_changes.namespace_user_id = namespace_user.id\n             LEFT JOIN orgs namespace_org ON batch_changes.namespace_org_id = namespace_org.id\n    WHERE c.batch_change_ids ? batch_changes.id::text AND namespace_user.deleted_at IS NULL AND namespace_org.deleted_at IS NULL\n    );\n\nDROP INDEX IF EXISTS changesets_detached_at;\n\nALTER TABLE changesets DROP COLUMN IF EXISTS detached_at;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1652946496,
					1653334014
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1658484997,
				"Name": "add webhook_build_jobs table",
				"UpQuery": "CREATE SEQUENCE IF NOT EXISTS webhook_build_jobs_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\n CREATE TABLE IF NOT EXISTS webhook_build_jobs (\n    repo_id integer,\n    repo_name text,\n    extsvc_kind text,\n    queued_at timestamp with time zone DEFAULT now(),\n    id integer DEFAULT nextval('webhook_build_jobs_id_seq'::regclass) NOT NULL,\n    state text DEFAULT 'queued'::text NOT NULL,\n    failure_message text,\n    started_at timestamp with time zone,\n    finished_at timestamp with time zone,\n    process_after timestamp with time zone,\n    num_resets integer DEFAULT 0 NOT NULL,\n    num_failures integer DEFAULT 0 NOT NULL,\n    execution_logs json[],\n    last_heartbeat_at timestamp with time zone,\n    worker_hostname text DEFAULT ''::text NOT NULL\n );\n\n CREATE INDEX IF NOT EXISTS webhook_build_jobs_queued_at_idx ON webhook_build_jobs USING btree (queued_at);",
				"DownQuery": "DROP TABLE IF EXISTS webhook_build_jobs;\nDROP INDEX IF EXISTS webhook_build_jobs_queued_at_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1653596521,
					1658384388
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1658503913,
				"Name": "batches_changeset_state_computed",
				"UpQuery": "ALTER TABLE changesets ADD COLUMN IF NOT EXISTS computed_state TEXT;\n\nDROP TRIGGER IF EXISTS changesets_update_computed_state ON changesets;\n\nUPDATE\n    changesets\nSET\n    computed_state = CASE\n        WHEN reconciler_state = 'errored' THEN 'RETRYING'\n        WHEN reconciler_state = 'failed' THEN 'FAILED'\n        WHEN reconciler_state = 'scheduled' THEN 'SCHEDULED'\n        WHEN reconciler_state != 'completed' THEN 'PROCESSING'\n        WHEN publication_state = 'UNPUBLISHED' THEN 'UNPUBLISHED'\n        ELSE external_state\n    END;\n\nALTER TABLE changesets ALTER COLUMN computed_state SET NOT NULL;\n\nCREATE OR REPLACE FUNCTION changesets_computed_state_ensure() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$ BEGIN\n\n    NEW.computed_state = CASE\n        WHEN NEW.reconciler_state = 'errored' THEN 'RETRYING'\n        WHEN NEW.reconciler_state = 'failed' THEN 'FAILED'\n        WHEN NEW.reconciler_state = 'scheduled' THEN 'SCHEDULED'\n        WHEN NEW.reconciler_state != 'completed' THEN 'PROCESSING'\n        WHEN NEW.publication_state = 'UNPUBLISHED' THEN 'UNPUBLISHED'\n        ELSE NEW.external_state\n    END AS computed_state;\n\n    RETURN NEW;\nEND $$;\n\nCREATE TRIGGER changesets_update_computed_state BEFORE INSERT OR UPDATE ON changesets FOR EACH ROW EXECUTE FUNCTION changesets_computed_state_ensure();\n\nDROP VIEW IF EXISTS branch_changeset_specs_and_changesets;\nCREATE VIEW branch_changeset_specs_and_changesets AS\n SELECT changeset_specs.id AS changeset_spec_id,\n    COALESCE(changesets.id, (0)::bigint) AS changeset_id,\n    changeset_specs.repo_id,\n    changeset_specs.batch_spec_id,\n    changesets.owned_by_batch_change_id AS owner_batch_change_id,\n    repo.name AS repo_name,\n    changeset_specs.title AS changeset_name,\n    changesets.external_state,\n    changesets.publication_state,\n    changesets.reconciler_state,\n    changesets.computed_state\n   FROM ((changeset_specs\n     LEFT JOIN changesets ON (((changesets.repo_id = changeset_specs.repo_id) AND (changesets.current_spec_id IS NOT NULL) AND (EXISTS ( SELECT 1\n           FROM changeset_specs changeset_specs_1\n          WHERE ((changeset_specs_1.id = changesets.current_spec_id) AND (changeset_specs_1.head_ref = changeset_specs.head_ref)))))))\n     JOIN repo ON ((changeset_specs.repo_id = repo.id)))\n  WHERE ((changeset_specs.external_id IS NULL) AND (repo.deleted_at IS NULL));\n\nDROP VIEW IF EXISTS tracking_changeset_specs_and_changesets;\nCREATE VIEW tracking_changeset_specs_and_changesets AS\n SELECT changeset_specs.id AS changeset_spec_id,\n    COALESCE(changesets.id, (0)::bigint) AS changeset_id,\n    changeset_specs.repo_id,\n    changeset_specs.batch_spec_id,\n    repo.name AS repo_name,\n    COALESCE((changesets.metadata -\u003e\u003e 'Title'::text), (changesets.metadata -\u003e\u003e 'title'::text)) AS changeset_name,\n    changesets.external_state,\n    changesets.publication_state,\n    changesets.reconciler_state,\n    changesets.computed_state\n   FROM ((changeset_specs\n     LEFT JOIN changesets ON (((changesets.repo_id = changeset_specs.repo_id) AND (changesets.external_id = changeset_specs.external_id))))\n     JOIN repo ON ((changeset_specs.repo_id = repo.id)))\n  WHERE ((changeset_specs.external_id IS NOT NULL) AND (repo.deleted_at IS NULL));\n\nDROP VIEW IF EXISTS reconciler_changesets;\nCREATE VIEW reconciler_changesets AS\nSELECT c.id,\n       c.batch_change_ids,\n       c.repo_id,\n       c.queued_at,\n       c.created_at,\n       c.updated_at,\n       c.metadata,\n       c.external_id,\n       c.external_service_type,\n       c.external_deleted_at,\n       c.external_branch,\n       c.external_updated_at,\n       c.external_state,\n       c.external_review_state,\n       c.external_check_state,\n       c.diff_stat_added,\n       c.diff_stat_changed,\n       c.diff_stat_deleted,\n       c.sync_state,\n       c.current_spec_id,\n       c.previous_spec_id,\n       c.publication_state,\n       c.owned_by_batch_change_id,\n       c.reconciler_state,\n       c.computed_state,\n       c.failure_message,\n       c.started_at,\n       c.finished_at,\n       c.process_after,\n       c.num_resets,\n       c.closing,\n       c.num_failures,\n       c.log_contents,\n       c.execution_logs,\n       c.syncer_error,\n       c.external_title,\n       c.worker_hostname,\n       c.ui_publication_state,\n       c.last_heartbeat_at,\n       c.external_fork_namespace,\n       c.detached_at\nFROM changesets c\n         JOIN repo r ON r.id = c.repo_id\nWHERE r.deleted_at IS NULL AND EXISTS (\n    SELECT 1\n    FROM batch_changes\n             LEFT JOIN users namespace_user ON batch_changes.namespace_user_id = namespace_user.id\n             LEFT JOIN orgs namespace_org ON batch_changes.namespace_org_id = namespace_org.id\n    WHERE c.batch_change_ids ? batch_changes.id::text AND namespace_user.deleted_at IS NULL AND namespace_org.deleted_at IS NULL\n    );",
				"DownQuery": "DROP TRIGGER IF EXISTS changesets_update_computed_state ON changesets;\nDROP FUNCTION IF EXISTS changesets_computed_state_ensure();\n\nDROP VIEW IF EXISTS branch_changeset_specs_and_changesets;\nCREATE VIEW branch_changeset_specs_and_changesets AS\n SELECT changeset_specs.id AS changeset_spec_id,\n    COALESCE(changesets.id, (0)::bigint) AS changeset_id,\n    changeset_specs.repo_id,\n    changeset_specs.batch_spec_id,\n    changesets.owned_by_batch_change_id AS owner_batch_change_id,\n    repo.name AS repo_name,\n    changeset_specs.title AS changeset_name,\n    changesets.external_state,\n    changesets.publication_state,\n    changesets.reconciler_state\n   FROM ((changeset_specs\n     LEFT JOIN changesets ON (((changesets.repo_id = changeset_specs.repo_id) AND (changesets.current_spec_id IS NOT NULL) AND (EXISTS ( SELECT 1\n           FROM changeset_specs changeset_specs_1\n          WHERE ((changeset_specs_1.id = changesets.current_spec_id) AND (changeset_specs_1.head_ref = changeset_specs.head_ref)))))))\n     JOIN repo ON ((changeset_specs.repo_id = repo.id)))\n  WHERE ((changeset_specs.external_id IS NULL) AND (repo.deleted_at IS NULL));\n\nDROP VIEW IF EXISTS tracking_changeset_specs_and_changesets;\nCREATE VIEW tracking_changeset_specs_and_changesets AS\n SELECT changeset_specs.id AS changeset_spec_id,\n    COALESCE(changesets.id, (0)::bigint) AS changeset_id,\n    changeset_specs.repo_id,\n    changeset_specs.batch_spec_id,\n    repo.name AS repo_name,\n    COALESCE((changesets.metadata -\u003e\u003e 'Title'::text), (changesets.metadata -\u003e\u003e 'title'::text)) AS changeset_name,\n    changesets.external_state,\n    changesets.publication_state,\n    changesets.reconciler_state\n   FROM ((changeset_specs\n     LEFT JOIN changesets ON (((changesets.repo_id = changeset_specs.repo_id) AND (changesets.external_id = changeset_specs.external_id))))\n     JOIN repo ON ((changeset_specs.repo_id = repo.id)))\n  WHERE ((changeset_specs.external_id IS NOT NULL) AND (repo.deleted_at IS NULL));\n\nDROP VIEW IF EXISTS reconciler_changesets;\nCREATE VIEW reconciler_changesets AS\nSELECT c.id,\n       c.batch_change_ids,\n       c.repo_id,\n       c.queued_at,\n       c.created_at,\n       c.updated_at,\n       c.metadata,\n       c.external_id,\n       c.external_service_type,\n       c.external_deleted_at,\n       c.external_branch,\n       c.external_updated_at,\n       c.external_state,\n       c.external_review_state,\n       c.external_check_state,\n       c.diff_stat_added,\n       c.diff_stat_changed,\n       c.diff_stat_deleted,\n       c.sync_state,\n       c.current_spec_id,\n       c.previous_spec_id,\n       c.publication_state,\n       c.owned_by_batch_change_id,\n       c.reconciler_state,\n       c.failure_message,\n       c.started_at,\n       c.finished_at,\n       c.process_after,\n       c.num_resets,\n       c.closing,\n       c.num_failures,\n       c.log_contents,\n       c.execution_logs,\n       c.syncer_error,\n       c.external_title,\n       c.worker_hostname,\n       c.ui_publication_state,\n       c.last_heartbeat_at,\n       c.external_fork_namespace,\n       c.detached_at\nFROM changesets c\n         JOIN repo r ON r.id = c.repo_id\nWHERE r.deleted_at IS NULL AND EXISTS (\n    SELECT 1\n    FROM batch_changes\n             LEFT JOIN users namespace_user ON batch_changes.namespace_user_id = namespace_user.id\n             LEFT JOIN orgs namespace_org ON batch_changes.namespace_org_id = namespace_org.id\n    WHERE c.batch_change_ids ? batch_changes.id::text AND namespace_user.deleted_at IS NULL AND namespace_org.deleted_at IS NULL\n    );\n\n\nALTER TABLE changesets DROP COLUMN IF EXISTS computed_state;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1653596521,
					1658384388
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1658512336,
				"Name": "batches_changeset_state_index",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS changesets_computed_state ON changesets (computed_state);",
				"DownQuery": "DROP INDEX IF EXISTS changesets_computed_state;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1658503913
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "changesets",
					"IndexName": "changesets_computed_state"
				}
			},
			{
				"ID": 1658748822,
				"Name": "add_timestamps_to_lockfiles",
				"UpQuery": "ALTER TABLE codeintel_lockfiles\n  ADD COLUMN IF NOT EXISTS created_at timestamptz NOT NULL DEFAULT NOW(),\n  ADD COLUMN IF NOT EXISTS updated_at timestamptz NOT NULL DEFAULT NOW()\n  ;\n\nCOMMENT ON COLUMN codeintel_lockfiles.created_at IS 'Time when lockfile was indexed';\nCOMMENT ON COLUMN codeintel_lockfiles.updated_at IS 'Time when lockfile index was updated';",
				"DownQuery": "ALTER TABLE codeintel_lockfiles\n  DROP COLUMN IF EXISTS created_at,\n  DROP COLUMN IF EXISTS updated_at\n  ;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1658512336
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1658837440,
				"Name": "sync_jobs_missing_index",
				"UpQuery": "DELETE FROM external_service_sync_jobs WHERE external_service_id IS NULL;\nALTER TABLE external_service_sync_jobs ALTER COLUMN external_service_id SET NOT NULL;",
				"DownQuery": "ALTER TABLE external_service_sync_jobs ALTER COLUMN external_service_id DROP NOT NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1658748822
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1658856572,
				"Name": "event_log_scrape_state",
				"UpQuery": "CREATE TABLE IF NOT EXISTS event_logs_scrape_state\n(\n    id                     SERIAL\n        CONSTRAINT event_logs_scrape_state_pk\n            PRIMARY KEY,\n    bookmark_id INT NOT NULL\n);\n\nCOMMENT ON TABLE event_logs_scrape_state IS 'Contains state for the periodic telemetry job that scrapes events if enabled.';\nCOMMENT ON COLUMN event_logs_scrape_state.bookmark_id IS 'Bookmarks the maximum most recent successful event_logs.id that was scraped';",
				"DownQuery": "DROP TABLE IF EXISTS event_logs_scrape_state;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1658748822
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1658950366,
				"Name": "event_log_scrape_allow_list",
				"UpQuery": "CREATE TABLE IF NOT EXISTS event_logs_export_allowlist\n(\n    id         SERIAL PRIMARY KEY,\n    event_name TEXT NOT NULL\n);\n\nCREATE UNIQUE INDEX IF NOT EXISTS event_logs_export_allowlist_event_name_idx ON event_logs_export_allowlist (event_name);\n\nCOMMENT ON TABLE event_logs_export_allowlist IS 'An allowlist of events that are approved for export if the scraping job is enabled';\nCOMMENT ON COLUMN event_logs_export_allowlist.event_name IS 'Name of the event that corresponds to event_logs.name';",
				"DownQuery": "DROP TABLE IF EXISTS event_logs_export_allowlist;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1658122170,
					1658484997,
					1658856572
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1659085788,
				"Name": "add_repo_stats_table",
				"UpQuery": "--------------------------------------------------------------------------------\n--                              repos table                                   --\n--------------------------------------------------------------------------------\n\n-- repo_statistics holds statistics for the repo table (hence the singular\n-- \"repo\" in the name)\nCREATE TABLE IF NOT EXISTS repo_statistics (\n  total         BIGINT NOT NULL DEFAULT 0,\n  soft_deleted  BIGINT NOT NULL DEFAULT 0,\n  not_cloned    BIGINT NOT NULL DEFAULT 0,\n  cloning       BIGINT NOT NULL DEFAULT 0,\n  cloned        BIGINT NOT NULL DEFAULT 0,\n  failed_fetch  BIGINT NOT NULL DEFAULT 0\n);\n\nCOMMENT ON COLUMN repo_statistics.total IS 'Number of repositories that are not soft-deleted and not blocked';\nCOMMENT ON COLUMN repo_statistics.soft_deleted IS 'Number of repositories that are soft-deleted and not blocked';\nCOMMENT ON COLUMN repo_statistics.not_cloned IS 'Number of repositories that are NOT soft-deleted and not blocked and not cloned by gitserver';\nCOMMENT ON COLUMN repo_statistics.cloning IS 'Number of repositories that are NOT soft-deleted and not blocked and currently being cloned by gitserver';\nCOMMENT ON COLUMN repo_statistics.cloned IS 'Number of repositories that are NOT soft-deleted and not blocked and cloned by gitserver';\nCOMMENT ON COLUMN repo_statistics.failed_fetch IS 'Number of repositories that are NOT soft-deleted and not blocked and have last_error set in gitserver_repos table';\n\n-- Insert initial values into repo_statistics table\nINSERT INTO repo_statistics (total, soft_deleted, not_cloned, cloning, cloned, failed_fetch)\nVALUES (\n  (SELECT COUNT(*) FROM repo WHERE deleted_at is NULL     AND blocked IS NULL),\n  (SELECT COUNT(*) FROM repo WHERE deleted_at is NOT NULL AND blocked IS NULL),\n  (\n    SELECT COUNT(*)\n    FROM repo\n    JOIN gitserver_repos gr ON gr.repo_id = repo.id\n    WHERE\n      repo.deleted_at is NULL\n    AND\n      repo.blocked IS NULL\n    AND\n      gr.clone_status = 'not_cloned'\n  ),\n  (\n    SELECT COUNT(*)\n    FROM repo\n    JOIN gitserver_repos gr ON gr.repo_id = repo.id\n    WHERE\n      repo.deleted_at is NULL\n    AND\n      repo.blocked IS NULL\n    AND\n      gr.clone_status = 'cloning'\n  ),\n  (\n    SELECT COUNT(*)\n    FROM repo\n    JOIN gitserver_repos gr ON gr.repo_id = repo.id\n    WHERE\n      repo.deleted_at is NULL\n    AND\n      repo.blocked IS NULL\n    AND\n      gr.clone_status = 'cloned'\n  ),\n  (\n    SELECT COUNT(*)\n    FROM repo\n    JOIN gitserver_repos gr ON gr.repo_id = repo.id\n    WHERE\n      repo.deleted_at is NULL\n    AND\n      repo.blocked IS NULL\n    AND\n      gr.last_error IS NOT NULL\n  )\n);\n\n-- UPDATE\nCREATE OR REPLACE FUNCTION recalc_repo_statistics_on_repo_update() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$ BEGIN\n      -- Insert diff of changes\n      INSERT INTO\n        repo_statistics (total, soft_deleted, not_cloned, cloning, cloned, failed_fetch)\n      VALUES (\n        (SELECT COUNT(*) FROM newtab WHERE deleted_at IS NULL     AND blocked IS NULL) - (SELECT COUNT(*) FROM oldtab WHERE deleted_at IS NULL     AND blocked IS NULL),\n        (SELECT COUNT(*) FROM newtab WHERE deleted_at IS NOT NULL AND blocked IS NULL) - (SELECT COUNT(*) FROM oldtab WHERE deleted_at IS NOT NULL AND blocked IS NULL),\n        (\n          (SELECT COUNT(*) FROM newtab JOIN gitserver_repos gr ON gr.repo_id = newtab.id WHERE newtab.deleted_at is NULL AND newtab.blocked IS NULL AND gr.clone_status = 'not_cloned')\n          -\n          (SELECT COUNT(*) FROM oldtab JOIN gitserver_repos gr ON gr.repo_id = oldtab.id WHERE oldtab.deleted_at is NULL AND oldtab.blocked IS NULL AND gr.clone_status = 'not_cloned')\n        ),\n        (\n          (SELECT COUNT(*) FROM newtab JOIN gitserver_repos gr ON gr.repo_id = newtab.id WHERE newtab.deleted_at is NULL AND newtab.blocked IS NULL AND gr.clone_status = 'cloning')\n          -\n          (SELECT COUNT(*) FROM oldtab JOIN gitserver_repos gr ON gr.repo_id = oldtab.id WHERE oldtab.deleted_at is NULL AND oldtab.blocked IS NULL AND gr.clone_status = 'cloning')\n        ),\n        (\n          (SELECT COUNT(*) FROM newtab JOIN gitserver_repos gr ON gr.repo_id = newtab.id WHERE newtab.deleted_at is NULL AND newtab.blocked IS NULL AND gr.clone_status = 'cloned')\n          -\n          (SELECT COUNT(*) FROM oldtab JOIN gitserver_repos gr ON gr.repo_id = oldtab.id WHERE oldtab.deleted_at is NULL AND oldtab.blocked IS NULL AND gr.clone_status = 'cloned')\n        ),\n        (\n          (SELECT COUNT(*) FROM newtab JOIN gitserver_repos gr ON gr.repo_id = newtab.id WHERE newtab.deleted_at is NULL AND newtab.blocked IS NULL AND gr.last_error IS NOT NULL)\n          -\n          (SELECT COUNT(*) FROM oldtab JOIN gitserver_repos gr ON gr.repo_id = oldtab.id WHERE oldtab.deleted_at is NULL AND oldtab.blocked IS NULL AND gr.last_error IS NOT NULL)\n        )\n      )\n      ;\n      RETURN NULL;\n  END\n$$;\nDROP TRIGGER IF EXISTS trig_recalc_repo_statistics_on_repo_update ON repo;\nCREATE TRIGGER trig_recalc_repo_statistics_on_repo_update\nAFTER UPDATE ON repo\nREFERENCING OLD TABLE AS oldtab NEW TABLE AS newtab\nFOR EACH STATEMENT EXECUTE FUNCTION recalc_repo_statistics_on_repo_update();\n\n-- INSERT\nCREATE OR REPLACE FUNCTION recalc_repo_statistics_on_repo_insert() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$ BEGIN\n      INSERT INTO\n        repo_statistics (total, soft_deleted, not_cloned)\n      VALUES (\n        (SELECT COUNT(*) FROM newtab WHERE deleted_at IS NULL     AND blocked IS NULL),\n        (SELECT COUNT(*) FROM newtab WHERE deleted_at IS NOT NULL AND blocked IS NULL),\n        -- New repositories are always not_cloned by default, so we can count them as not cloned here\n        (SELECT COUNT(*) FROM newtab WHERE deleted_at IS NULL     AND blocked IS NULL)\n        -- New repositories never have last_error set, so we can also ignore those here\n      );\n      RETURN NULL;\n  END\n$$;\nDROP TRIGGER IF EXISTS trig_recalc_repo_statistics_on_repo_insert ON repo;\nCREATE TRIGGER trig_recalc_repo_statistics_on_repo_insert\nAFTER INSERT ON repo\nREFERENCING NEW TABLE AS newtab\nFOR EACH STATEMENT EXECUTE FUNCTION recalc_repo_statistics_on_repo_insert();\n\n-- DELETE\nCREATE OR REPLACE FUNCTION recalc_repo_statistics_on_repo_delete() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$ BEGIN\n      INSERT INTO\n        repo_statistics (total, soft_deleted, not_cloned, cloning, cloned, failed_fetch)\n      VALUES (\n        -- Insert negative counts\n        (SELECT -COUNT(*) FROM oldtab WHERE deleted_at IS NULL     AND blocked IS NULL),\n        (SELECT -COUNT(*) FROM oldtab WHERE deleted_at IS NOT NULL AND blocked IS NULL),\n        (SELECT -COUNT(*) FROM oldtab JOIN gitserver_repos gr ON gr.repo_id = oldtab.id WHERE oldtab.deleted_at is NULL AND oldtab.blocked IS NULL AND gr.clone_status = 'not_cloned'),\n        (SELECT -COUNT(*) FROM oldtab JOIN gitserver_repos gr ON gr.repo_id = oldtab.id WHERE oldtab.deleted_at is NULL AND oldtab.blocked IS NULL AND gr.clone_status = 'cloning'),\n        (SELECT -COUNT(*) FROM oldtab JOIN gitserver_repos gr ON gr.repo_id = oldtab.id WHERE oldtab.deleted_at is NULL AND oldtab.blocked IS NULL AND gr.clone_status = 'cloned'),\n        (SELECT -COUNT(*) FROM oldtab JOIN gitserver_repos gr ON gr.repo_id = oldtab.id WHERE oldtab.deleted_at is NULL AND oldtab.blocked IS NULL AND gr.last_error IS NOT NULL)\n      );\n      RETURN NULL;\n  END\n$$;\nDROP TRIGGER IF EXISTS trig_recalc_repo_statistics_on_repo_delete ON repo;\nCREATE TRIGGER trig_recalc_repo_statistics_on_repo_delete\nAFTER DELETE ON repo\nREFERENCING OLD TABLE AS oldtab\nFOR EACH STATEMENT EXECUTE FUNCTION recalc_repo_statistics_on_repo_delete();\n\n--------------------------------------------------------------------------------\n--                       gitserver_repos table                                --\n--------------------------------------------------------------------------------\n\n-- gitserver_repos_statistics holds statistics for the gitserver_repos table\nCREATE TABLE IF NOT EXISTS gitserver_repos_statistics (\n  -- In this table we have one row per shard_id\n  shard_id text PRIMARY KEY,\n\n  total        BIGINT NOT NULL DEFAULT 0,\n  not_cloned   BIGINT NOT NULL DEFAULT 0,\n  cloning      BIGINT NOT NULL DEFAULT 0,\n  cloned       BIGINT NOT NULL DEFAULT 0,\n  failed_fetch BIGINT NOT NULL DEFAULT 0\n);\n\nCOMMENT ON COLUMN gitserver_repos_statistics.shard_id IS 'ID of this gitserver shard. If an empty string then the repositories havent been assigned a shard.';\nCOMMENT ON COLUMN gitserver_repos_statistics.total IS 'Number of repositories in gitserver_repos table on this shard';\nCOMMENT ON COLUMN gitserver_repos_statistics.not_cloned IS 'Number of repositories in gitserver_repos table on this shard that are not cloned yet';\nCOMMENT ON COLUMN gitserver_repos_statistics.cloning IS 'Number of repositories in gitserver_repos table on this shard that cloning';\nCOMMENT ON COLUMN gitserver_repos_statistics.cloned IS 'Number of repositories in gitserver_repos table on this shard that are cloned';\nCOMMENT ON COLUMN gitserver_repos_statistics.failed_fetch IS 'Number of repositories in gitserver_repos table on this shard where last_error is set';\n\n-- Insert initial values into gitserver_repos_statistics\nINSERT INTO\n  gitserver_repos_statistics (shard_id, total, not_cloned, cloning, cloned, failed_fetch)\nSELECT\n  shard_id,\n  COUNT(*) AS total,\n  COUNT(*) FILTER(WHERE clone_status = 'not_cloned') AS not_cloned,\n  COUNT(*) FILTER(WHERE clone_status = 'cloning') AS cloning,\n  COUNT(*) FILTER(WHERE clone_status = 'cloned') AS cloned,\n  COUNT(*) FILTER(WHERE last_error IS NOT NULL) AS failed_fetch\nFROM\n  gitserver_repos\nGROUP BY shard_id\nON CONFLICT(shard_id)\nDO UPDATE\nSET\n  total        = gitserver_repos_statistics.total        + excluded.total,\n  not_cloned   = gitserver_repos_statistics.not_cloned   + excluded.not_cloned,\n  cloning      = gitserver_repos_statistics.cloning      + excluded.cloning,\n  cloned       = gitserver_repos_statistics.cloned       + excluded.cloned,\n  failed_fetch = gitserver_repos_statistics.failed_fetch + excluded.failed_fetch\n;\n\n-- UPDATE\nCREATE OR REPLACE FUNCTION recalc_gitserver_repos_statistics_on_update() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$ BEGIN\n      INSERT INTO gitserver_repos_statistics AS grs (shard_id, total, not_cloned, cloning, cloned, failed_fetch)\n      SELECT\n        newtab.shard_id AS shard_id,\n        COUNT(*) AS total,\n        COUNT(*) FILTER(WHERE clone_status = 'not_cloned')  AS not_cloned,\n        COUNT(*) FILTER(WHERE clone_status = 'cloning') AS cloning,\n        COUNT(*) FILTER(WHERE clone_status = 'cloned') AS cloned,\n        COUNT(*) FILTER(WHERE last_error IS NOT NULL) AS failed_fetch\n      FROM\n        newtab\n      GROUP BY newtab.shard_id\n      ON CONFLICT(shard_id) DO\n      UPDATE\n      SET\n        total        = grs.total        + (excluded.total        - (SELECT COUNT(*)                                              FROM oldtab ot WHERE ot.shard_id = excluded.shard_id)),\n        not_cloned   = grs.not_cloned   + (excluded.not_cloned   - (SELECT COUNT(*) FILTER(WHERE ot.clone_status = 'not_cloned') FROM oldtab ot WHERE ot.shard_id = excluded.shard_id)),\n        cloning      = grs.cloning      + (excluded.cloning      - (SELECT COUNT(*) FILTER(WHERE ot.clone_status = 'cloning')    FROM oldtab ot WHERE ot.shard_id = excluded.shard_id)),\n        cloned       = grs.cloned       + (excluded.cloned       - (SELECT COUNT(*) FILTER(WHERE ot.clone_status = 'cloned')     FROM oldtab ot WHERE ot.shard_id = excluded.shard_id)),\n        failed_fetch = grs.failed_fetch + (excluded.failed_fetch - (SELECT COUNT(*) FILTER(WHERE ot.last_error IS NOT NULL)      FROM oldtab ot WHERE ot.shard_id = excluded.shard_id))\n      ;\n\n      WITH moved AS (\n        SELECT\n          oldtab.shard_id AS shard_id,\n          COUNT(*) AS total,\n          COUNT(*) FILTER(WHERE oldtab.clone_status = 'not_cloned')  AS not_cloned,\n          COUNT(*) FILTER(WHERE oldtab.clone_status = 'cloning') AS cloning,\n          COUNT(*) FILTER(WHERE oldtab.clone_status = 'cloned') AS cloned,\n          COUNT(*) FILTER(WHERE oldtab.last_error IS NOT NULL) AS failed_fetch\n        FROM\n          oldtab\n        JOIN newtab ON newtab.repo_id = oldtab.repo_id\n        WHERE\n          oldtab.shard_id != newtab.shard_id\n        GROUP BY oldtab.shard_id\n      )\n      UPDATE gitserver_repos_statistics grs\n      SET\n        total        = grs.total        - moved.total,\n        not_cloned   = grs.not_cloned   - moved.not_cloned,\n        cloning      = grs.cloning      - moved.cloning,\n        cloned       = grs.cloned       - moved.cloned,\n        failed_fetch = grs.failed_fetch - moved.failed_fetch\n      FROM moved\n      WHERE moved.shard_id = grs.shard_id;\n\n      INSERT INTO repo_statistics (not_cloned, cloning, cloned, failed_fetch)\n      VALUES (\n        (\n          (SELECT COUNT(*) FROM newtab JOIN repo r ON newtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND newtab.clone_status = 'not_cloned')\n          -\n          (SELECT COUNT(*) FROM oldtab JOIN repo r ON oldtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND oldtab.clone_status = 'not_cloned')\n        ),\n        (\n          (SELECT COUNT(*) FROM newtab JOIN repo r ON newtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND newtab.clone_status = 'cloning')\n          -\n          (SELECT COUNT(*) FROM oldtab JOIN repo r ON oldtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND oldtab.clone_status = 'cloning')\n        ),\n        (\n          (SELECT COUNT(*) FROM newtab JOIN repo r ON newtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND newtab.clone_status = 'cloned')\n          -\n          (SELECT COUNT(*) FROM oldtab JOIN repo r ON oldtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND oldtab.clone_status = 'cloned')\n        ),\n        (\n          (SELECT COUNT(*) FROM newtab JOIN repo r ON newtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND newtab.last_error IS NOT NULL)\n          -\n          (SELECT COUNT(*) FROM oldtab JOIN repo r ON oldtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND oldtab.last_error IS NOT NULL)\n        )\n      );\n\n      RETURN NULL;\n  END\n$$;\nDROP TRIGGER IF EXISTS trig_recalc_gitserver_repos_statistics_on_update ON gitserver_repos;\nCREATE TRIGGER trig_recalc_gitserver_repos_statistics_on_update\nAFTER UPDATE ON gitserver_repos\nREFERENCING OLD TABLE AS oldtab NEW TABLE AS newtab\nFOR EACH STATEMENT EXECUTE FUNCTION recalc_gitserver_repos_statistics_on_update();\n\n-- INSERT\nCREATE OR REPLACE FUNCTION recalc_gitserver_repos_statistics_on_insert() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$ BEGIN\n      INSERT INTO gitserver_repos_statistics AS grs (shard_id, total, not_cloned, cloning, cloned, failed_fetch)\n      SELECT\n        shard_id,\n        COUNT(*) AS total,\n        COUNT(*) FILTER(WHERE clone_status = 'not_cloned') AS not_cloned,\n        COUNT(*) FILTER(WHERE clone_status = 'cloning') AS cloning,\n        COUNT(*) FILTER(WHERE clone_status = 'cloned') AS cloned,\n        COUNT(*) FILTER(WHERE last_error IS NOT NULL) AS failed_fetch\n      FROM\n        newtab\n      GROUP BY shard_id\n      ON CONFLICT(shard_id)\n      DO UPDATE\n      SET\n        total        = grs.total        + excluded.total,\n        not_cloned   = grs.not_cloned   + excluded.not_cloned,\n        cloning      = grs.cloning      + excluded.cloning,\n        cloned       = grs.cloned       + excluded.cloned,\n        failed_fetch = grs.failed_fetch + excluded.failed_fetch\n      ;\n\n      RETURN NULL;\n  END\n$$;\nDROP TRIGGER IF EXISTS trig_recalc_gitserver_repos_statistics_on_insert ON gitserver_repos;\nCREATE TRIGGER trig_recalc_gitserver_repos_statistics_on_insert\nAFTER INSERT ON gitserver_repos\nREFERENCING NEW TABLE AS newtab\nFOR EACH STATEMENT EXECUTE FUNCTION recalc_gitserver_repos_statistics_on_insert();\n\n-- DELETE\nCREATE OR REPLACE FUNCTION recalc_gitserver_repos_statistics_on_delete() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$ BEGIN\n      UPDATE gitserver_repos_statistics grs\n      SET\n        total        = grs.total      - (SELECT COUNT(*)                                           FROM oldtab WHERE oldtab.shard_id = grs.shard_id),\n        not_cloned   = grs.not_cloned - (SELECT COUNT(*) FILTER(WHERE clone_status = 'not_cloned') FROM oldtab WHERE oldtab.shard_id = grs.shard_id),\n        cloning      = grs.cloning    - (SELECT COUNT(*) FILTER(WHERE clone_status = 'cloning')    FROM oldtab WHERE oldtab.shard_id = grs.shard_id),\n        cloned       = grs.cloned     - (SELECT COUNT(*) FILTER(WHERE clone_status = 'cloned')     FROM oldtab WHERE oldtab.shard_id = grs.shard_id),\n        failed_fetch = grs.cloned     - (SELECT COUNT(*) FILTER(WHERE last_error IS NOT NULL)      FROM oldtab WHERE oldtab.shard_id = grs.shard_id)\n      ;\n\n      RETURN NULL;\n  END\n$$;\nDROP TRIGGER IF EXISTS trig_recalc_gitserver_repos_statistics_on_delete ON gitserver_repos;\nCREATE TRIGGER trig_recalc_gitserver_repos_statistics_on_delete\nAFTER DELETE ON gitserver_repos REFERENCING\nOLD TABLE AS oldtab\nFOR EACH STATEMENT EXECUTE FUNCTION recalc_gitserver_repos_statistics_on_delete();",
				"DownQuery": "DROP TRIGGER IF EXISTS trig_recalc_repo_statistics_on_repo_update ON repo;\nDROP TRIGGER IF EXISTS trig_recalc_repo_statistics_on_repo_insert ON repo;\nDROP TRIGGER IF EXISTS trig_recalc_repo_statistics_on_repo_delete ON repo;\n\nDROP FUNCTION IF EXISTS recalc_repo_statistics_on_repo_update();\nDROP FUNCTION IF EXISTS recalc_repo_statistics_on_repo_insert();\nDROP FUNCTION IF EXISTS recalc_repo_statistics_on_repo_delete();\n\nDROP TRIGGER IF EXISTS trig_recalc_gitserver_repos_statistics_on_update ON gitserver_repos;\nDROP TRIGGER IF EXISTS trig_recalc_gitserver_repos_statistics_on_insert ON gitserver_repos;\nDROP TRIGGER IF EXISTS trig_recalc_gitserver_repos_statistics_on_delete ON gitserver_repos;\n\nDROP FUNCTION IF EXISTS recalc_gitserver_repos_statistics_on_update();\nDROP FUNCTION IF EXISTS recalc_gitserver_repos_statistics_on_insert();\nDROP FUNCTION IF EXISTS recalc_gitserver_repos_statistics_on_delete();\n\nDROP TABLE IF EXISTS gitserver_repos_statistics;\nDROP TABLE IF EXISTS repo_statistics;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1658950366
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1659368926,
				"Name": "cleanup_lsif_indexes_errored",
				"UpQuery": "UPDATE lsif_indexes SET state = 'failed' WHERE state = 'errored' AND num_failures \u003e 0;",
				"DownQuery": "-- Nothing to do here, to older instances both versions of this data are valid state.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1658950366
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1659380538,
				"Name": "event_log_dot_com_fields",
				"UpQuery": "ALTER TABLE IF EXISTS event_logs\n    ADD COLUMN IF NOT EXISTS first_source_url TEXT,\n    ADD COLUMN IF NOT EXISTS last_source_url  TEXT,\n    ADD COLUMN IF NOT EXISTS referrer         TEXT,\n    ADD COLUMN IF NOT EXISTS device_id        TEXT,\n    ADD COLUMN IF NOT EXISTS insert_id        TEXT;",
				"DownQuery": "ALTER TABLE IF EXISTS event_logs\n    DROP COLUMN IF EXISTS first_source_url,\n    DROP COLUMN IF EXISTS last_source_url,\n    DROP COLUMN IF EXISTS referrer,\n    DROP COLUMN IF EXISTS device_id,\n    DROP COLUMN IF EXISTS insert_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1659368926
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1659434035,
				"Name": "alter webhook_build_jobs table",
				"UpQuery": "ALTER TABLE IF EXISTS webhook_build_jobs\n    ADD COLUMN IF NOT EXISTS org text,\n    ADD COLUMN IF NOT EXISTS extsvc_id integer;",
				"DownQuery": "ALTER TABLE IF EXISTS webhook_build_jobs\n    DROP COLUMN IF EXISTS org,\n    DROP COLUMN IF EXISTS extsvc_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1659368926
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1659459805,
				"Name": "repo key value pairs",
				"UpQuery": "-- Perform migration here.\n\nCREATE TABLE IF NOT EXISTS repo_kvps (\n    repo_id INTEGER NOT NULL REFERENCES repo(id) ON DELETE CASCADE,\n    key TEXT NOT NULL,\n    value TEXT NULL,\n    PRIMARY KEY (repo_id, key) INCLUDE (value)\n);",
				"DownQuery": "-- Undo the changes made in the up migration\n\nDROP TABLE IF EXISTS repo_kvps;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1659434035
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1659721548,
				"Name": "data_usage_seed_allowlist",
				"UpQuery": "INSERT INTO event_logs_export_allowlist (event_name)\nVALUES ('codeintel.searchDocumentHighlight'),\n       ('SearchNotebookBlocksUpdated'),\n       ('search.latencies.symbol'),\n       ('hover'),\n       ('codeintel.lsifDocumentHighlight'),\n       ('search.latencies.literal'),\n       ('codeintel.lsifHover'),\n       ('codeintel.lsifDefinitions'),\n       ('SearchResultsFetched'),\n       ('search.latencies.regexp'),\n       ('codeintel.searchDefinitions'),\n       ('codeintel.searchHover'),\n       ('ViewHome'),\n       ('ViewSearchResults'),\n       ('search.latencies.repo'),\n       ('HomepageInvitationsViewEmpty'),\n       ('RecentSearchesPanelLoaded'),\n       ('SavedSearchesPanelLoaded'),\n       ('SearchResultClicked'),\n       ('INSIGHT_TOTAL_ORGS_WITH_DASHBOARD'),\n       ('INSIGHT_TOTAL_COUNT_CRITICAL'),\n       ('INSIGHT_TIME_INTERVALS'),\n       ('INSIGHT_ORG_VISIBLE_INSIGHTS'),\n       ('INSIGHT_TOTAL_COUNTS'),\n       ('INSIGHT_DASHBOARD_TOTAL_COUNT'),\n       ('INSIGHTS_PER_DASHBORD_STATS'),\n       ('RepositoriesPanelLoaded'),\n       ('RecentFilesPanelLoaded'),\n       ('SearchResultsCacheRetrieved'),\n       ('BrowserExtensionConnectedToServer'),\n       ('ViewTree'),\n       ('FileTreeClick'),\n       ('codeintel.searchDefinitions.xrepo'),\n       ('search.latencies.file'),\n       ('ViewNoResultsPage'),\n       ('ViewRepository'),\n       ('search.latencies.structural'),\n       ('InsightHover'),\n       ('ExternalAuthSignupFailed'),\n       ('CodeIntelRefs'),\n       ('search.latencies.diff'),\n       ('SurveyReminderViewed'),\n       ('ExtensionActivation'),\n       ('InstallBrowserExtensionCTAShown'),\n       ('ViewSiteAdminOverview'),\n       ('ViewSettingsUser'),\n       ('SearchContextDropdownToggled'),\n       ('definitionHoverOverlay.click'),\n       ('InstallIDEExtensionCTAShown'),\n       ('search.latencies.commit'),\n       ('ViewRepositoryCommit'),\n       ('ViewOnboardingTour'),\n       ('ViewCodeIntelIndexes'),\n       ('ViewInsights'),\n       ('codeintel.lsifReferences'),\n       ('NotebookVisibilitySettingsDropdownToggled'),\n       ('referenceHoverOverlay.click'),\n       ('ViewSearchNotebooksListMyNotebooks'),\n       ('ViewBatchChangesListPage'),\n       ('SearchContextsDropdownViewed'),\n       ('ViewExecutorsList'),\n       ('findReferences'),\n       ('ReferencePanelResultsClicked'),\n       ('SearchNotebooksListPageViewed'),\n       ('SearchNotebookPageViewed'),\n       ('ViewCodeIntelUploads'),\n       ('ViewCodeIntelConfiguration'),\n       ('ExternalAuthSignupSucceeded'),\n       ('ViewSiteAdminConfiguration'),\n       ('goToDefinition.preloaded'),\n       ('ViewSiteAdminExternalServices'),\n       ('CodeCopied'),\n       ('SearchNotebookRunBlock'),\n       ('ViewSiteAdminRepos'),\n       ('git.blame.toggle'),\n       ('codeintel.searchReferences'),\n       ('SearchContextSelected'),\n       ('ViewSiteAdminUsageStatistics'),\n       ('ViewUserProfile'),\n       ('SettingsFileSaved'),\n       ('CodeMonitoringGettingStartedPageViewed'),\n       ('SignInAttempted'),\n       ('SearchNotebookAddBlock'),\n       ('ViewUserSettingsTokens'),\n       ('ViewCodeIntelIndex'),\n       ('GoToCodeHostClicked'),\n       ('RecentSearchesPanelSearchClicked'),\n       ('RepositoriesPanelRepoFilterClicked'),\n       ('codeintel.lsifDefinitions.xrepo'),\n       ('ViewSiteAdminAllUsers'),\n       ('SignInSucceeded'),\n       ('CodeMonitoringPageViewed'),\n       ('ViewCodeIntelRepositoryIndexConfiguration'),\n       ('ViewCodeIntelConfigurationPolicy'),\n       ('NotebooksGettingStartedTabViewed'),\n       ('ViewAddExternalService'),\n       ('InsightUICustomization'),\n       ('ViewRepositoryError'),\n       ('ViewCodeInsightsCreationPage'),\n       ('SearchNotebookShareModalOpened'),\n       ('ViewSiteAdminExternalService'),\n       ('ViewExtensionsOverview'),\n       ('ManageCodeMonitorPageViewed'),\n       ('ViewInsightsGetStartedPage'),\n       ('StandaloneInsightPageViewed'),\n       ('ViewBatchChangeDetailsPage'),\n       ('ViewRevisionsPopover'),\n       ('ViewUserSettingsEmails'),\n       ('codeintel.searchReferences.xrepo'),\n       ('SymbolTreeViewClicked'),\n       ('ViewApiConsole'),\n       ('UTMCodeHostIntegration'),\n       ('ViewSettingsSite'),\n       ('ViewRepoSettingsIndex'),\n       ('codeintel.lsifImplementations'),\n       ('IDESearchSubmitted'),\n       ('ViewUserSettingsProductResearch'),\n       ('ViewUserSettingsPassword'),\n       ('ViewSettingsOrg'),\n       ('ViewSearchNotebooksListExploreNotebooks'),\n       ('ViewRepoSettings'),\n       ('SearchDidYouMeanDisplayed'),\n       ('SiteConfigurationSaved'),\n       ('ShowHistoryPanel'),\n       ('ViewSavedSearchListPage'),\n       ('ViewCodeInsightsSearchBasedCreationPage'),\n       ('findImplementations'),\n       ('ViewRepoSettingsMirror'),\n       ('AdminAnalyticsCodeIntelViewed'),\n       ('AdminAnalyticsSearchViewed'),\n       ('InsightAddMoreClick'),\n       ('ViewSignIn'),\n       ('ViewOrgSettingsProfile'),\n       ('InsightDataPointClick'),\n       ('SignInFailed'),\n       ('ViewSearchNotebooksListStarredNotebooks'),\n       ('ViewSiteAdminOrgs'),\n       ('ViewRepoSettingsPermissions'),\n       ('BrowserExtensionPopupOpened'),\n       ('CreateCodeMonitorPageViewed'),\n       ('FuzzyFinderViewed'),\n       ('ViewNewAccessToken'),\n       ('AccessTokenCreated'),\n       ('RepositoriesPopover'),\n       ('ViewRepositoriesPopover'),\n       ('SearchNotebookDeleteBlock'),\n       ('RootBreadcrumbClicked'),\n       ('ViewUserEventLogPage'),\n       ('CodeInsightsCreateSearchBasedInsightClick'),\n       ('ViewRepositoryCompareOverview'),\n       ('InsightAddition'),\n       ('AdminAnalyticsCodeIntelAggUniquesClicked'),\n       ('StandaloneInsightPageEditClick'),\n       ('SearchNotebookTitleUpdated'),\n       ('SearchNotebooksNotebooksTabClick'),\n       ('CopyFilePath'),\n       ('ViewOrgMembers'),\n       ('InsightEdit'),\n       ('RepositoryComparisonFetched'),\n       ('SearchNotebookCreated'),\n       ('AdminAnalyticsNotebooksViewed'),\n       ('NoResultsPanel'),\n       ('ViewSiteAdminProductSubscription'),\n       ('AdminAnalyticsUsersViewed'),\n       ('ReferencePanelClickedReferences'),\n       ('CreateCodeMonitorFormSubmitted'),\n       ('ViewBatchChangeApplyPage'),\n       ('CloseOnboardingTourClicked'),\n       ('IDEInstalled'),\n       ('FileTreeViewClicked'),\n       ('AdminAnalyticsBatchChangesViewed'),\n       ('ViewRepositoryBranchesOverview'),\n       ('WAUsChartSelected'),\n       ('ViewCodeIntelUpload'),\n       ('codeintel.lsifReferences.xrepo'),\n       ('mixPreciseAndSearchBasedReferences.toggle'),\n       ('ViewSiteAdminSurveyResponses'),\n       ('ViewRepositoryCommits'),\n       ('ViewNewOrg'),\n       ('SearchResultsFetchFailed'),\n       ('SiteConfigurationActionExecuted'),\n       ('CodeInsightsSearchBasedCreationPageSubmitClick'),\n       ('ReferencePanelClickedImplementations'),\n       ('SearchNotebookMoveBlock'),\n       ('UserNotificationsLinkClicked'),\n       ('AdminAnalyticsCodeIntelAggTotalsClicked'),\n       ('ReferencePanelClickedDefinition'),\n       ('ViewCodeInsightsCaptureGroupCreationPage'),\n       ('SearchNotebooksGettingStartedTabClick'),\n       ('ViewUserSettingsPermissions'),\n       ('CodeInsightsCreateCaptureGroupInsightClick'),\n       ('BrowserExtensionPopupRejected'),\n       ('AdminAnalyticsSearchAggUniquesClicked'),\n       ('CommitSHACopiedToClipboard'),\n       ('ExtensionToggled'),\n       ('vscode.open.file'),\n       ('SearchNotebookRunAllBlocks'),\n       ('CodeInsightsDashboardCreationPageSubmitClick'),\n       ('BatchSpecCreated'),\n       ('AddExternalServiceSucceeded'),\n       ('ManageCodeMonitorFormSubmitted'),\n       ('BatchChangeCreatedOrUpdated'),\n       ('SearchNotepadEnabled'),\n       ('ReferencePanelClickedHistory'),\n       ('SearchSnippetClicked'),\n       ('ViewSiteAdminUpdates'),\n       ('CodeInsightsCaptureGroupCreationPageSubmitClick'),\n       ('SearchSkippedResultsAgainClicked'),\n       ('ViewRepositoryReleasesTags'),\n       ('OrgMemberAdded'),\n       ('RepositoryComparisonSubmitted'),\n       ('AdminAnalyticsSearchDateRangeLAST_WEEKSelected'),\n       ('ViewCodeInsightsCodeStatsCreationPage'),\n       ('DAUsChartSelected'),\n       ('goToDefinition'),\n       ('MAUsChartSelected'),\n       ('SettingsFileDiscard'),\n       ('ViewRepositoryStatsContributors'),\n       ('InstallBrowserExtensionCTAClicked'),\n       ('NewUserEmailAddressAdded'),\n       ('HomepageFooterCTASelected'),\n       ('ViewedOnboardingTourFilterRepoStep'),\n       ('SurveyButtonClicked'),\n       ('ViewNewSavedSearchPage'),\n       ('allResultsCollapsed'),\n       ('SearchHelpDropdownQueryDocsLinkClicked'),\n       ('CodeMonitoringLogsPageViewed'),\n       ('AdminAnalyticsSearchAggTotalsClicked'),\n       ('ViewBatchChangeDetailsPageAfterCreate'),\n       ('OnboardingTourRepositoryOptionClicked'),\n       ('CodeInsightsCreateCodeStatsInsightClick'),\n       ('referenceCodeHost.click'),\n       ('InsightsGetStartedTabClick'),\n       ('NewOrgCreated'),\n       ('BatchChangeClosed'),\n       ('CreateNewOrgClicked'),\n       ('AddExternalServiceFailed'),\n       ('CommitBodyToggled'),\n       ('ViewSurvey'),\n       ('HideHistoryPanel'),\n       ('IDEUninstalled'),\n       ('ViewSiteAdminPings'),\n       ('InsightRemoval'),\n       ('ViewRepositoryBranchesAll'),\n       ('SavedSearchCreated'),\n       ('UserEmailAddressSetAsPrimary'),\n       ('WrappedCode'),\n       ('batch_change_list_page:create_batch_change_details:clicked'),\n       ('ViewRegistryExtensionManifest'),\n       ('SearchReferenceClosed'),\n       ('AdminAnalyticsUsersAggTotalsClicked'),\n       ('SearchNotebookCopyNotebookButtonClick'),\n       ('codecov.decorations.toggleCoverage'),\n       ('AdminAnalyticsUsersAggUniquesClicked'),\n       ('AlertNeedsRepoConfigCTAClicked'),\n       ('BatchChangeDeleted'),\n       ('ManageCodeMonitorDeleteSubmitted'),\n       ('AdminAnalyticsNotebooksAggTotalsClicked'),\n       ('CodeInsightsCodeStatsCreationPageSubmitClick'),\n       ('SearchNotebookImportMarkdownNotebookButtonClick'),\n       ('NoResultsVideoPlayed'),\n       ('AdminAnalyticsNotebooksAggUniquesClicked'),\n       ('NoResultsMore'),\n       ('SearchNotebookDeleteButtonClicked'),\n       ('SurveySubmitted'),\n       ('UpdateUserClicked'),\n       ('SavedSearchesPanelCreateButtonClicked'),\n       ('UserEmailAddressMarkedVerified'),\n       ('SearchNotebookImportedFromMarkdown'),\n       ('AddOrgMemberFailed'),\n       ('SearchResultsAutoPureOther'),\n       ('allResultsExpanded'),\n       ('SettingsFileDiscardCanceled'),\n       ('SearchResultsAutoPureAnd'),\n       ('SignUpSucceeded'),\n       ('SearchNotebookDeleteModalOpened'),\n       ('AdminAnalyticsNotebooksDateRangeLAST_MONTHSelected'),\n       ('AdminAnalyticsNotebooksDateRangeLAST_WEEKSelected'),\n       ('ViewSiteAdminRegistryExtensions'),\n       ('InsightsGetStartedBigTemplateClick'),\n       ('ViewSiteAdminCreateUser'),\n       ('SearchResultContextsCTAShown'),\n       ('AdminAnalyticsNotebooksDateRangeLAST_THREE_MONTHSSelected'),\n       ('SearchDidYouMeanClicked'),\n       ('SearchNotebookExportNotebook'),\n       ('InsightGetStartedTemplateClick'),\n       ('UserProfileUpdated'),\n       ('AdminAnalyticsSearchMinutesInputEdited'),\n       ('UserEmailAddressMarkedUnverified'),\n       ('searchExport.export'),\n       ('CodeMonitoringExampleMonitorClicked'),\n       ('BrowserExtensionPopupClosed'),\n       ('ViewSearchNotebooksListOrgNotebooks')\nON CONFLICT DO NOTHING;",
				"DownQuery": "DELETE\nFROM event_logs_export_allowlist\nWHERE event_name IN ('codeintel.searchDocumentHighlight',\n                     'SearchNotebookBlocksUpdated',\n                     'search.latencies.symbol',\n                     'hover',\n                     'codeintel.lsifDocumentHighlight',\n                     'search.latencies.literal',\n                     'codeintel.lsifHover',\n                     'codeintel.lsifDefinitions',\n                     'SearchResultsFetched',\n                     'search.latencies.regexp',\n                     'codeintel.searchDefinitions',\n                     'codeintel.searchHover',\n                     'ViewHome',\n                     'ViewSearchResults',\n                     'search.latencies.repo',\n                     'HomepageInvitationsViewEmpty',\n                     'RecentSearchesPanelLoaded',\n                     'SavedSearchesPanelLoaded',\n                     'SearchResultClicked',\n                     'INSIGHT_TOTAL_ORGS_WITH_DASHBOARD',\n                     'INSIGHT_TOTAL_COUNT_CRITICAL',\n                     'INSIGHT_TIME_INTERVALS',\n                     'INSIGHT_ORG_VISIBLE_INSIGHTS',\n                     'INSIGHT_TOTAL_COUNTS',\n                     'INSIGHT_DASHBOARD_TOTAL_COUNT',\n                     'INSIGHTS_PER_DASHBORD_STATS',\n                     'RepositoriesPanelLoaded',\n                     'RecentFilesPanelLoaded',\n                     'SearchResultsCacheRetrieved',\n                     'BrowserExtensionConnectedToServer',\n                     'ViewTree',\n                     'FileTreeClick',\n                     'codeintel.searchDefinitions.xrepo',\n                     'search.latencies.file',\n                     'ViewNoResultsPage',\n                     'ViewRepository',\n                     'search.latencies.structural',\n                     'InsightHover',\n                     'ExternalAuthSignupFailed',\n                     'CodeIntelRefs',\n                     'search.latencies.diff',\n                     'SurveyReminderViewed',\n                     'ExtensionActivation',\n                     'InstallBrowserExtensionCTAShown',\n                     'ViewSiteAdminOverview',\n                     'ViewSettingsUser',\n                     'SearchContextDropdownToggled',\n                     'definitionHoverOverlay.click',\n                     'InstallIDEExtensionCTAShown',\n                     'search.latencies.commit',\n                     'ViewRepositoryCommit',\n                     'ViewOnboardingTour',\n                     'ViewCodeIntelIndexes',\n                     'ViewInsights',\n                     'codeintel.lsifReferences',\n                     'NotebookVisibilitySettingsDropdownToggled',\n                     'referenceHoverOverlay.click',\n                     'ViewSearchNotebooksListMyNotebooks',\n                     'ViewBatchChangesListPage',\n                     'SearchContextsDropdownViewed',\n                     'ViewExecutorsList',\n                     'findReferences',\n                     'ReferencePanelResultsClicked',\n                     'SearchNotebooksListPageViewed',\n                     'SearchNotebookPageViewed',\n                     'ViewCodeIntelUploads',\n                     'ViewCodeIntelConfiguration',\n                     'ExternalAuthSignupSucceeded',\n                     'ViewSiteAdminConfiguration',\n                     'goToDefinition.preloaded',\n                     'ViewSiteAdminExternalServices',\n                     'CodeCopied',\n                     'SearchNotebookRunBlock',\n                     'ViewSiteAdminRepos',\n                     'git.blame.toggle',\n                     'codeintel.searchReferences',\n                     'SearchContextSelected',\n                     'ViewSiteAdminUsageStatistics',\n                     'ViewUserProfile',\n                     'SettingsFileSaved',\n                     'CodeMonitoringGettingStartedPageViewed',\n                     'SignInAttempted',\n                     'SearchNotebookAddBlock',\n                     'ViewUserSettingsTokens',\n                     'ViewCodeIntelIndex',\n                     'GoToCodeHostClicked',\n                     'RecentSearchesPanelSearchClicked',\n                     'RepositoriesPanelRepoFilterClicked',\n                     'codeintel.lsifDefinitions.xrepo',\n                     'ViewSiteAdminAllUsers',\n                     'SignInSucceeded',\n                     'CodeMonitoringPageViewed',\n                     'ViewCodeIntelRepositoryIndexConfiguration',\n                     'ViewCodeIntelConfigurationPolicy',\n                     'NotebooksGettingStartedTabViewed',\n                     'ViewAddExternalService',\n                     'InsightUICustomization',\n                     'ViewRepositoryError',\n                     'ViewCodeInsightsCreationPage',\n                     'SearchNotebookShareModalOpened',\n                     'ViewSiteAdminExternalService',\n                     'ViewExtensionsOverview',\n                     'ManageCodeMonitorPageViewed',\n                     'ViewInsightsGetStartedPage',\n                     'StandaloneInsightPageViewed',\n                     'ViewBatchChangeDetailsPage',\n                     'ViewRevisionsPopover',\n                     'ViewUserSettingsEmails',\n                     'codeintel.searchReferences.xrepo',\n                     'SymbolTreeViewClicked',\n                     'ViewApiConsole',\n                     'UTMCodeHostIntegration',\n                     'ViewSettingsSite',\n                     'ViewRepoSettingsIndex',\n                     'codeintel.lsifImplementations',\n                     'IDESearchSubmitted',\n                     'ViewUserSettingsProductResearch',\n                     'ViewUserSettingsPassword',\n                     'ViewSettingsOrg',\n                     'ViewSearchNotebooksListExploreNotebooks',\n                     'ViewRepoSettings',\n                     'SearchDidYouMeanDisplayed',\n                     'SiteConfigurationSaved',\n                     'ShowHistoryPanel',\n                     'ViewSavedSearchListPage',\n                     'ViewCodeInsightsSearchBasedCreationPage',\n                     'findImplementations',\n                     'ViewRepoSettingsMirror',\n                     'AdminAnalyticsCodeIntelViewed',\n                     'AdminAnalyticsSearchViewed',\n                     'InsightAddMoreClick',\n                     'ViewSignIn',\n                     'ViewOrgSettingsProfile',\n                     'InsightDataPointClick',\n                     'SignInFailed',\n                     'ViewSearchNotebooksListStarredNotebooks',\n                     'ViewSiteAdminOrgs',\n                     'ViewRepoSettingsPermissions',\n                     'BrowserExtensionPopupOpened',\n                     'CreateCodeMonitorPageViewed',\n                     'FuzzyFinderViewed',\n                     'ViewNewAccessToken',\n                     'AccessTokenCreated',\n                     'RepositoriesPopover',\n                     'ViewRepositoriesPopover',\n                     'SearchNotebookDeleteBlock',\n                     'RootBreadcrumbClicked',\n                     'ViewUserEventLogPage',\n                     'CodeInsightsCreateSearchBasedInsightClick',\n                     'ViewRepositoryCompareOverview',\n                     'InsightAddition',\n                     'AdminAnalyticsCodeIntelAggUniquesClicked',\n                     'StandaloneInsightPageEditClick',\n                     'SearchNotebookTitleUpdated',\n                     'SearchNotebooksNotebooksTabClick',\n                     'CopyFilePath',\n                     'ViewOrgMembers',\n                     'InsightEdit',\n                     'RepositoryComparisonFetched',\n                     'SearchNotebookCreated',\n                     'AdminAnalyticsNotebooksViewed',\n                     'NoResultsPanel',\n                     'ViewSiteAdminProductSubscription',\n                     'AdminAnalyticsUsersViewed',\n                     'ReferencePanelClickedReferences',\n                     'CreateCodeMonitorFormSubmitted',\n                     'ViewBatchChangeApplyPage',\n                     'CloseOnboardingTourClicked',\n                     'IDEInstalled',\n                     'FileTreeViewClicked',\n                     'AdminAnalyticsBatchChangesViewed',\n                     'ViewRepositoryBranchesOverview',\n                     'WAUsChartSelected',\n                     'ViewCodeIntelUpload',\n                     'codeintel.lsifReferences.xrepo',\n                     'mixPreciseAndSearchBasedReferences.toggle',\n                     'ViewSiteAdminSurveyResponses',\n                     'ViewRepositoryCommits',\n                     'ViewNewOrg',\n                     'SearchResultsFetchFailed',\n                     'SiteConfigurationActionExecuted',\n                     'CodeInsightsSearchBasedCreationPageSubmitClick',\n                     'ReferencePanelClickedImplementations',\n                     'SearchNotebookMoveBlock',\n                     'UserNotificationsLinkClicked',\n                     'AdminAnalyticsCodeIntelAggTotalsClicked',\n                     'ReferencePanelClickedDefinition',\n                     'ViewCodeInsightsCaptureGroupCreationPage',\n                     'SearchNotebooksGettingStartedTabClick',\n                     'ViewUserSettingsPermissions',\n                     'CodeInsightsCreateCaptureGroupInsightClick',\n                     'BrowserExtensionPopupRejected',\n                     'AdminAnalyticsSearchAggUniquesClicked',\n                     'CommitSHACopiedToClipboard',\n                     'ExtensionToggled',\n                     'vscode.open.file',\n                     'SearchNotebookRunAllBlocks',\n                     'CodeInsightsDashboardCreationPageSubmitClick',\n                     'BatchSpecCreated',\n                     'AddExternalServiceSucceeded',\n                     'ManageCodeMonitorFormSubmitted',\n                     'BatchChangeCreatedOrUpdated',\n                     'SearchNotepadEnabled',\n                     'ReferencePanelClickedHistory',\n                     'SearchSnippetClicked',\n                     'ViewSiteAdminUpdates',\n                     'CodeInsightsCaptureGroupCreationPageSubmitClick',\n                     'SearchSkippedResultsAgainClicked',\n                     'ViewRepositoryReleasesTags',\n                     'OrgMemberAdded',\n                     'RepositoryComparisonSubmitted',\n                     'AdminAnalyticsSearchDateRangeLAST_WEEKSelected',\n                     'ViewCodeInsightsCodeStatsCreationPage',\n                     'DAUsChartSelected',\n                     'goToDefinition',\n                     'MAUsChartSelected',\n                     'SettingsFileDiscard',\n                     'ViewRepositoryStatsContributors',\n                     'InstallBrowserExtensionCTAClicked',\n                     'NewUserEmailAddressAdded',\n                     'HomepageFooterCTASelected',\n                     'ViewedOnboardingTourFilterRepoStep',\n                     'SurveyButtonClicked',\n                     'ViewNewSavedSearchPage',\n                     'allResultsCollapsed',\n                     'SearchHelpDropdownQueryDocsLinkClicked',\n                     'CodeMonitoringLogsPageViewed',\n                     'AdminAnalyticsSearchAggTotalsClicked',\n                     'ViewBatchChangeDetailsPageAfterCreate',\n                     'OnboardingTourRepositoryOptionClicked',\n                     'CodeInsightsCreateCodeStatsInsightClick',\n                     'referenceCodeHost.click',\n                     'InsightsGetStartedTabClick',\n                     'NewOrgCreated',\n                     'BatchChangeClosed',\n                     'CreateNewOrgClicked',\n                     'AddExternalServiceFailed',\n                     'CommitBodyToggled',\n                     'ViewSurvey',\n                     'HideHistoryPanel',\n                     'IDEUninstalled',\n                     'ViewSiteAdminPings',\n                     'InsightRemoval',\n                     'ViewRepositoryBranchesAll',\n                     'SavedSearchCreated',\n                     'UserEmailAddressSetAsPrimary',\n                     'WrappedCode',\n                     'batch_change_list_page:create_batch_change_details:clicked',\n                     'ViewRegistryExtensionManifest',\n                     'SearchReferenceClosed',\n                     'AdminAnalyticsUsersAggTotalsClicked',\n                     'SearchNotebookCopyNotebookButtonClick',\n                     'codecov.decorations.toggleCoverage',\n                     'AdminAnalyticsUsersAggUniquesClicked',\n                     'AlertNeedsRepoConfigCTAClicked',\n                     'BatchChangeDeleted',\n                     'ManageCodeMonitorDeleteSubmitted',\n                     'AdminAnalyticsNotebooksAggTotalsClicked',\n                     'CodeInsightsCodeStatsCreationPageSubmitClick',\n                     'SearchNotebookImportMarkdownNotebookButtonClick',\n                     'NoResultsVideoPlayed',\n                     'AdminAnalyticsNotebooksAggUniquesClicked',\n                     'NoResultsMore',\n                     'SearchNotebookDeleteButtonClicked',\n                     'SurveySubmitted',\n                     'UpdateUserClicked',\n                     'SavedSearchesPanelCreateButtonClicked',\n                     'UserEmailAddressMarkedVerified',\n                     'SearchNotebookImportedFromMarkdown',\n                     'AddOrgMemberFailed',\n                     'SearchResultsAutoPureOther',\n                     'allResultsExpanded',\n                     'SettingsFileDiscardCanceled',\n                     'SearchResultsAutoPureAnd',\n                     'SignUpSucceeded',\n                     'SearchNotebookDeleteModalOpened',\n                     'AdminAnalyticsNotebooksDateRangeLAST_MONTHSelected',\n                     'AdminAnalyticsNotebooksDateRangeLAST_WEEKSelected',\n                     'ViewSiteAdminRegistryExtensions',\n                     'InsightsGetStartedBigTemplateClick',\n                     'ViewSiteAdminCreateUser',\n                     'SearchResultContextsCTAShown',\n                     'AdminAnalyticsNotebooksDateRangeLAST_THREE_MONTHSSelected',\n                     'SearchDidYouMeanClicked',\n                     'SearchNotebookExportNotebook',\n                     'InsightGetStartedTemplateClick',\n                     'UserProfileUpdated',\n                     'AdminAnalyticsSearchMinutesInputEdited',\n                     'UserEmailAddressMarkedUnverified',\n                     'searchExport.export',\n                     'CodeMonitoringExampleMonitorClicked',\n                     'BrowserExtensionPopupClosed',\n                     'ViewSearchNotebooksListOrgNotebooks');",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1658837440,
					1659380538,
					1659434035
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1660132915,
				"Name": "lsif_uploads_uncompressed_size",
				"UpQuery": "ALTER TABLE lsif_uploads\nADD COLUMN IF NOT EXISTS uncompressed_size bigint;\n\nDROP VIEW IF EXISTS lsif_uploads_with_repository_name;\n\nCREATE VIEW lsif_uploads_with_repository_name AS\nSELECT u.id,\n    u.commit,\n    u.root,\n    u.queued_at,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.indexer_version,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.expired,\n    u.last_retention_scan_at,\n    r.name AS repository_name,\n    u.uncompressed_size\nFROM lsif_uploads u\nJOIN repo r ON r.id = u.repository_id\nWHERE r.deleted_at IS NULL;",
				"DownQuery": "DROP VIEW IF EXISTS lsif_uploads_with_repository_name;\n\nCREATE VIEW lsif_uploads_with_repository_name AS\nSELECT u.id,\n    u.commit,\n    u.root,\n    u.queued_at,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.indexer_version,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.expired,\n    u.last_retention_scan_at,\n    r.name AS repository_name\nFROM lsif_uploads u\nJOIN repo r ON r.id = u.repository_id\nWHERE r.deleted_at IS NULL;\n\nALTER TABLE lsif_uploads\nDROP COLUMN IF EXISTS uncompressed_size;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1659721548
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1660312877,
				"Name": "add aggregated user statistics table",
				"UpQuery": "-- Perform migration here.\n\nCREATE TABLE IF NOT EXISTS aggregated_user_statistics (\n    user_id BIGINT NOT NULL PRIMARY KEY,\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW() NOT NULL,\n    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW() NOT NULL,\n    user_last_active_at TIMESTAMP WITH TIME ZONE DEFAULT NULL,\n    user_events_count BIGINT DEFAULT NULL,\n    CONSTRAINT aggregated_user_statistics_user_id_fkey FOREIGN KEY (user_id) REFERENCES users (id) ON DELETE CASCADE\n);",
				"DownQuery": "-- Undo the changes made in the up migration\n\nDROP TABLE IF EXISTS aggregated_user_statistics;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1659459805,
					1660132915
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1658874734,
				"Name": "normalized_changeset_specs",
				"UpQuery": "ALTER TABLE changeset_specs\n    ADD COLUMN IF NOT EXISTS diff bytea,\n    ADD COLUMN IF NOT EXISTS base_rev TEXT,\n    ADD COLUMN IF NOT EXISTS base_ref TEXT,\n    ADD COLUMN IF NOT EXISTS body TEXT,\n    ADD COLUMN IF NOT EXISTS published TEXT,\n    ADD COLUMN IF NOT EXISTS commit_message TEXT,\n    ADD COLUMN IF NOT EXISTS commit_author_name TEXT,\n    ADD COLUMN IF NOT EXISTS commit_author_email TEXT,\n    ADD COLUMN IF NOT EXISTS type TEXT;\n\nUPDATE\n    changeset_specs\nSET\n    diff = convert_to(spec-\u003e'commits'-\u003e0-\u003e\u003e'diff', 'UTF8'),\n    base_rev = spec-\u003e\u003e'baseRev',\n    base_ref = spec-\u003e\u003e'baseRef',\n    body = spec-\u003e\u003e'body',\n    published = spec-\u003e\u003e'published',\n    commit_message = spec-\u003e'commits'-\u003e0-\u003e\u003e'message',\n    commit_author_name = spec-\u003e'commits'-\u003e0-\u003e\u003e'authorName',\n    commit_author_email = spec-\u003e'commits'-\u003e0-\u003e\u003e'authorEmail',\n    type = CASE WHEN spec-\u003e\u003e'externalID' IS NOT NULL THEN 'existing' ELSE 'branch' END;",
				"DownQuery": "ALTER TABLE changeset_specs\n    DROP COLUMN IF EXISTS diff,\n    DROP COLUMN IF EXISTS base_rev,\n    DROP COLUMN IF EXISTS base_ref,\n    DROP COLUMN IF EXISTS body,\n    DROP COLUMN IF EXISTS published,\n    DROP COLUMN IF EXISTS commit_message,\n    DROP COLUMN IF EXISTS commit_author_name,\n    DROP COLUMN IF EXISTS commit_author_email,\n    DROP COLUMN IF EXISTS type;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1658748822
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1660710812,
				"Name": "update_reconciler_changeset_view",
				"UpQuery": "DROP VIEW IF EXISTS reconciler_changesets;\n\nCREATE VIEW reconciler_changesets AS\n SELECT c.id,\n    c.batch_change_ids,\n    c.repo_id,\n    c.queued_at,\n    c.created_at,\n    c.updated_at,\n    c.metadata,\n    c.external_id,\n    c.external_service_type,\n    c.external_deleted_at,\n    c.external_branch,\n    c.external_updated_at,\n    c.external_state,\n    c.external_review_state,\n    c.external_check_state,\n    c.diff_stat_added,\n    c.diff_stat_deleted,\n    c.sync_state,\n    c.current_spec_id,\n    c.previous_spec_id,\n    c.publication_state,\n    c.owned_by_batch_change_id,\n    c.reconciler_state,\n    c.computed_state,\n    c.failure_message,\n    c.started_at,\n    c.finished_at,\n    c.process_after,\n    c.num_resets,\n    c.closing,\n    c.num_failures,\n    c.log_contents,\n    c.execution_logs,\n    c.syncer_error,\n    c.external_title,\n    c.worker_hostname,\n    c.ui_publication_state,\n    c.last_heartbeat_at,\n    c.external_fork_namespace,\n    c.detached_at\n   FROM (changesets c\n     JOIN repo r ON ((r.id = c.repo_id)))\n  WHERE ((r.deleted_at IS NULL) AND (EXISTS ( SELECT 1\n           FROM ((batch_changes\n             LEFT JOIN users namespace_user ON ((batch_changes.namespace_user_id = namespace_user.id)))\n             LEFT JOIN orgs namespace_org ON ((batch_changes.namespace_org_id = namespace_org.id)))\n          WHERE ((c.batch_change_ids ? (batch_changes.id)::text) AND (namespace_user.deleted_at IS NULL) AND (namespace_org.deleted_at IS NULL)))));",
				"DownQuery": "DROP VIEW IF EXISTS reconciler_changesets;\n\nCREATE VIEW reconciler_changesets AS\n SELECT c.id,\n    c.batch_change_ids,\n    c.repo_id,\n    c.queued_at,\n    c.created_at,\n    c.updated_at,\n    c.metadata,\n    c.external_id,\n    c.external_service_type,\n    c.external_deleted_at,\n    c.external_branch,\n    c.external_updated_at,\n    c.external_state,\n    c.external_review_state,\n    c.external_check_state,\n    c.diff_stat_added,\n    c.diff_stat_changed,\n    c.diff_stat_deleted,\n    c.sync_state,\n    c.current_spec_id,\n    c.previous_spec_id,\n    c.publication_state,\n    c.owned_by_batch_change_id,\n    c.reconciler_state,\n    c.computed_state,\n    c.failure_message,\n    c.started_at,\n    c.finished_at,\n    c.process_after,\n    c.num_resets,\n    c.closing,\n    c.num_failures,\n    c.log_contents,\n    c.execution_logs,\n    c.syncer_error,\n    c.external_title,\n    c.worker_hostname,\n    c.ui_publication_state,\n    c.last_heartbeat_at,\n    c.external_fork_namespace,\n    c.detached_at\n   FROM (changesets c\n     JOIN repo r ON ((r.id = c.repo_id)))\n  WHERE ((r.deleted_at IS NULL) AND (EXISTS ( SELECT 1\n           FROM ((batch_changes\n             LEFT JOIN users namespace_user ON ((batch_changes.namespace_user_id = namespace_user.id)))\n             LEFT JOIN orgs namespace_org ON ((batch_changes.namespace_org_id = namespace_org.id)))\n          WHERE ((c.batch_change_ids ? (batch_changes.id)::text) AND (namespace_user.deleted_at IS NULL) AND (namespace_org.deleted_at IS NULL)))));",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1658874734,
					1660312877
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1660710916,
				"Name": "remove_diff_stat_changed_changeset_specs",
				"UpQuery": "-- We update the `diff_stat_added` and `diff_stat_deleted` to reflect the way git calculate diffs.\n-- When calculating diffs, we only care about the added \u0026 deleted lines\ndo $$\nbegin\n    /* if column `diff_stat_changed` exists on `changeset_specs` table */\n    IF EXISTS(\n        SELECT 1\n            FROM information_schema.columns\n        WHERE table_schema = 'public'\n            AND table_name = 'changeset_specs'\n            AND column_name = 'diff_stat_changed'\n    ) THEN\n        /* update the `diff_stat_added` and `diff_stat_deleted` */\n        UPDATE changeset_specs\n        SET\n            diff_stat_added = diff_stat_added + diff_stat_changed,\n            diff_stat_deleted = diff_stat_deleted + diff_stat_changed\n        WHERE\n            diff_stat_changed != 0;\n    END IF;\nend$$;\n\nALTER TABLE IF EXISTS changeset_specs DROP COLUMN IF EXISTS diff_stat_changed;",
				"DownQuery": "ALTER TABLE IF EXISTS changeset_specs ADD COLUMN IF NOT EXISTS diff_stat_changed integer;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1660710812
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1660711451,
				"Name": "remove_diff_stat_changed_changesets",
				"UpQuery": "-- We update the `diff_stat_added` and `diff_stat_deleted` to reflect the way git calculate diffs.\n-- When calculating diffs, we only care about the added \u0026 deleted lines\ndo $$\nbegin\n    /* if column `diff_stat_changed` exists on `changesets` table */\n    IF EXISTS(\n        SELECT 1\n            FROM information_schema.columns\n        WHERE table_schema = 'public'\n            AND table_name = 'changesets'\n            AND column_name = 'diff_stat_changed'\n    ) THEN\n        /* update the `diff_stat_added` and `diff_stat_deleted` */\n        UPDATE changesets\n        SET\n            diff_stat_added = diff_stat_added + diff_stat_changed,\n            diff_stat_deleted = diff_stat_deleted + diff_stat_changed\n        WHERE\n            diff_stat_changed != 0;\n    END IF;\nend$$;\n\nALTER TABLE IF EXISTS changesets DROP COLUMN IF EXISTS diff_stat_changed;",
				"DownQuery": "ALTER TABLE IF EXISTS changesets ADD COLUMN IF NOT EXISTS diff_stat_changed integer;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1660710916
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1660742069,
				"Name": "non_null_changeset_spec_type",
				"UpQuery": "-- Ensure no unmigrated records exist.\nUPDATE\n    changeset_specs\nSET\n    diff = convert_to(spec-\u003e'commits'-\u003e0-\u003e\u003e'diff', 'UTF8'),\n    base_rev = spec-\u003e\u003e'baseRev',\n    base_ref = spec-\u003e\u003e'baseRef',\n    body = spec-\u003e\u003e'body',\n    published = spec-\u003e\u003e'published',\n    commit_message = spec-\u003e'commits'-\u003e0-\u003e\u003e'message',\n    commit_author_name = spec-\u003e'commits'-\u003e0-\u003e\u003e'authorName',\n    commit_author_email = spec-\u003e'commits'-\u003e0-\u003e\u003e'authorEmail',\n    type = CASE WHEN spec-\u003e\u003e'externalID' IS NOT NULL THEN 'existing' ELSE 'branch' END;\n\nALTER TABLE changeset_specs ALTER COLUMN type SET NOT NULL;\nALTER TABLE changeset_specs ALTER COLUMN spec DROP NOT NULL;\nUPDATE changeset_specs SET spec = NULL;",
				"DownQuery": "ALTER TABLE changeset_specs ALTER COLUMN type DROP NOT NULL;\nALTER TABLE changeset_specs ADD COLUMN IF NOT EXISTS spec jsonb;\n\nUPDATE\n    changeset_specs\nSET\n    spec = jsonb_build_object(\n        'baseRev', base_rev,\n        'baseRef', base_ref,\n        'externalID', external_id,\n        'headRef', head_ref,\n        'title', title,\n        'body', body,\n        'published', published,\n        'commits', json_build_array(\n            jsonb_build_object(\n                'diff', encode(diff, 'escape'),\n                'message', commit_message,\n                'authorName', commit_author_name,\n                'authorEmail', commit_author_email\n            )\n        )\n    );\n\nALTER TABLE changeset_specs ALTER COLUMN spec SET NOT NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1658874734,
					1660312877
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1661441160,
				"Name": "batch spec remote mounts",
				"UpQuery": "CREATE TABLE IF NOT EXISTS batch_spec_workspace_files\n(\n    id            serial PRIMARY KEY,\n    rand_id       text                                   NOT NULL,\n    batch_spec_id bigint                                 NOT NULL,\n    filename      text                                   NOT NULL,\n    path          text                                   NOT NULL,\n    size          bigint                                 NOT NULL,\n    content       bytea                                  NOT NULL,\n    modified_at   timestamp with time zone               NOT NULL,\n    created_at    timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at    timestamp with time zone DEFAULT now() NOT NULL\n);\n\nALTER TABLE batch_spec_workspace_files\n    DROP CONSTRAINT IF EXISTS batch_spec_workspace_files_batch_spec_id_fkey;\n\nALTER TABLE ONLY batch_spec_workspace_files\n    ADD CONSTRAINT batch_spec_workspace_files_batch_spec_id_fkey FOREIGN KEY (batch_spec_id) REFERENCES batch_specs (id) ON DELETE CASCADE;\n\nCREATE INDEX IF NOT EXISTS batch_spec_workspace_files_rand_id ON batch_spec_workspace_files USING btree (rand_id);\n\nCREATE UNIQUE INDEX IF NOT EXISTS batch_spec_workspace_files_batch_spec_id_filename_path ON batch_spec_workspace_files (batch_spec_id, filename, path);",
				"DownQuery": "DROP TABLE IF EXISTS batch_spec_workspace_files;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1659085788,
					1660742069
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1661502186,
				"Name": "fix_repo_stats_initial_state",
				"UpQuery": "-- In the previous migration (1659085788_add_repo_stats_table) the triggers\n-- adding data to the stats table and the initial state of the stats table were\n-- setup in the wrong order:\n--\n--   1. Create repo_statistics/gitserver_repos_statistics tables\n--   2. Insert initial state into tables\n--   3. Setup database triggers that insert/update these tables\n--\n-- That's wrong. Instead we should've :\n--\n--   1. Create repo_statistics/gitserver_repos_statistics tables\n--   2. Setup database triggers that insert/update these tables\n--   3. Update tables to have correct initial state\n--\n--\n-- What this migration does is correct the initial wrong states by\n\n-- 1. Lock repo and gitserver_repos tables, so that no inserts/updates/deletes happen while we compute new total state.\n--    EXCLUSIVE is the mode that says \"no one else can write, only read\".\n\nLOCK repo IN EXCLUSIVE MODE;            -- first lock repo, since we have triggers that write `repo` and cause updates on `gitserver_repos` but not the other way around\nLOCK gitserver_repos IN EXCLUSIVE MODE; -- then lock `gitserver_repos`\n\n--- 2. Delete old state in `repo_statistics` (we can't update the state, since this is an append-only table).\nDELETE FROM repo_statistics;\n\n--- 3. Insert new total counts in `repo_statistics`\nINSERT INTO repo_statistics (total, soft_deleted, not_cloned, cloning, cloned, failed_fetch)\nSELECT\n  COUNT(*) AS total,\n  (SELECT COUNT(*) FROM repo WHERE deleted_at is NOT NULL AND blocked IS NULL) AS soft_deleted,\n  COUNT(*) FILTER(WHERE gitserver_repos.clone_status = 'not_cloned') AS not_cloned,\n  COUNT(*) FILTER(WHERE gitserver_repos.clone_status = 'cloning') AS cloning,\n  COUNT(*) FILTER(WHERE gitserver_repos.clone_status = 'cloned') AS cloned,\n  COUNT(*) FILTER(WHERE gitserver_repos.last_error IS NOT NULL) AS failed_fetch\nFROM repo\nJOIN gitserver_repos ON gitserver_repos.repo_id = repo.id\nWHERE\n  repo.deleted_at is NULL AND repo.blocked IS NULL;\n\n--- 4. Insert/update `gitserver_repos_statistics` by updating/insert the recalculated counts per shard.\nINSERT INTO\n  gitserver_repos_statistics (shard_id, total, not_cloned, cloning, cloned, failed_fetch)\nSELECT\n  shard_id,\n  COUNT(*) AS total,\n  COUNT(*) FILTER(WHERE clone_status = 'not_cloned') AS not_cloned,\n  COUNT(*) FILTER(WHERE clone_status = 'cloning') AS cloning,\n  COUNT(*) FILTER(WHERE clone_status = 'cloned') AS cloned,\n  COUNT(*) FILTER(WHERE last_error IS NOT NULL) AS failed_fetch\nFROM\n  gitserver_repos\nGROUP BY shard_id\nON CONFLICT(shard_id)\nDO UPDATE\nSET\n  total        = excluded.total,\n  not_cloned   = excluded.not_cloned,\n  cloning      = excluded.cloning,\n  cloned       = excluded.cloned,\n  failed_fetch = excluded.failed_fetch\n;",
				"DownQuery": "-- No schema changes made in up migrations, only data migrations that can't be\n-- undone.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1659085788,
					1660742069
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1661507724,
				"Name": "update_repo_stats_trigger_to_avoid_all_zeros",
				"UpQuery": "-- repo UPDATE trigger\nCREATE OR REPLACE FUNCTION recalc_repo_statistics_on_repo_update() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$ BEGIN\n      -- Insert diff of changes\n      WITH diff(total, soft_deleted, not_cloned, cloning, cloned, failed_fetch) AS (\n        VALUES (\n          (SELECT COUNT(*) FROM newtab WHERE deleted_at IS NULL     AND blocked IS NULL) - (SELECT COUNT(*) FROM oldtab WHERE deleted_at IS NULL     AND blocked IS NULL),\n          (SELECT COUNT(*) FROM newtab WHERE deleted_at IS NOT NULL AND blocked IS NULL) - (SELECT COUNT(*) FROM oldtab WHERE deleted_at IS NOT NULL AND blocked IS NULL),\n          (\n            (SELECT COUNT(*) FROM newtab JOIN gitserver_repos gr ON gr.repo_id = newtab.id WHERE newtab.deleted_at is NULL AND newtab.blocked IS NULL AND gr.clone_status = 'not_cloned')\n            -\n            (SELECT COUNT(*) FROM oldtab JOIN gitserver_repos gr ON gr.repo_id = oldtab.id WHERE oldtab.deleted_at is NULL AND oldtab.blocked IS NULL AND gr.clone_status = 'not_cloned')\n          ),\n          (\n            (SELECT COUNT(*) FROM newtab JOIN gitserver_repos gr ON gr.repo_id = newtab.id WHERE newtab.deleted_at is NULL AND newtab.blocked IS NULL AND gr.clone_status = 'cloning')\n            -\n            (SELECT COUNT(*) FROM oldtab JOIN gitserver_repos gr ON gr.repo_id = oldtab.id WHERE oldtab.deleted_at is NULL AND oldtab.blocked IS NULL AND gr.clone_status = 'cloning')\n          ),\n          (\n            (SELECT COUNT(*) FROM newtab JOIN gitserver_repos gr ON gr.repo_id = newtab.id WHERE newtab.deleted_at is NULL AND newtab.blocked IS NULL AND gr.clone_status = 'cloned')\n            -\n            (SELECT COUNT(*) FROM oldtab JOIN gitserver_repos gr ON gr.repo_id = oldtab.id WHERE oldtab.deleted_at is NULL AND oldtab.blocked IS NULL AND gr.clone_status = 'cloned')\n          ),\n          (\n            (SELECT COUNT(*) FROM newtab JOIN gitserver_repos gr ON gr.repo_id = newtab.id WHERE newtab.deleted_at is NULL AND newtab.blocked IS NULL AND gr.last_error IS NOT NULL)\n            -\n            (SELECT COUNT(*) FROM oldtab JOIN gitserver_repos gr ON gr.repo_id = oldtab.id WHERE oldtab.deleted_at is NULL AND oldtab.blocked IS NULL AND gr.last_error IS NOT NULL)\n          )\n        )\n      )\n      INSERT INTO\n        repo_statistics (total, soft_deleted, not_cloned, cloning, cloned, failed_fetch)\n      SELECT total, soft_deleted, not_cloned, cloning, cloned, failed_fetch\n      FROM diff\n      WHERE\n           total != 0\n        OR soft_deleted != 0\n        OR not_cloned != 0\n        OR cloning != 0\n        OR cloned != 0\n        OR failed_fetch != 0\n      ;\n      RETURN NULL;\n  END\n$$;\n\nCREATE OR REPLACE FUNCTION recalc_gitserver_repos_statistics_on_update() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$ BEGIN\n      --------------------\n      -- THIS IS UNCHANGED\n      --------------------\n      INSERT INTO gitserver_repos_statistics AS grs (shard_id, total, not_cloned, cloning, cloned, failed_fetch)\n      SELECT\n        newtab.shard_id AS shard_id,\n        COUNT(*) AS total,\n        COUNT(*) FILTER(WHERE clone_status = 'not_cloned')  AS not_cloned,\n        COUNT(*) FILTER(WHERE clone_status = 'cloning') AS cloning,\n        COUNT(*) FILTER(WHERE clone_status = 'cloned') AS cloned,\n        COUNT(*) FILTER(WHERE last_error IS NOT NULL) AS failed_fetch\n      FROM\n        newtab\n      GROUP BY newtab.shard_id\n      ON CONFLICT(shard_id) DO\n      UPDATE\n      SET\n        total        = grs.total        + (excluded.total        - (SELECT COUNT(*)                                              FROM oldtab ot WHERE ot.shard_id = excluded.shard_id)),\n        not_cloned   = grs.not_cloned   + (excluded.not_cloned   - (SELECT COUNT(*) FILTER(WHERE ot.clone_status = 'not_cloned') FROM oldtab ot WHERE ot.shard_id = excluded.shard_id)),\n        cloning      = grs.cloning      + (excluded.cloning      - (SELECT COUNT(*) FILTER(WHERE ot.clone_status = 'cloning')    FROM oldtab ot WHERE ot.shard_id = excluded.shard_id)),\n        cloned       = grs.cloned       + (excluded.cloned       - (SELECT COUNT(*) FILTER(WHERE ot.clone_status = 'cloned')     FROM oldtab ot WHERE ot.shard_id = excluded.shard_id)),\n        failed_fetch = grs.failed_fetch + (excluded.failed_fetch - (SELECT COUNT(*) FILTER(WHERE ot.last_error IS NOT NULL)      FROM oldtab ot WHERE ot.shard_id = excluded.shard_id))\n      ;\n\n      --------------------\n      -- THIS IS UNCHANGED\n      --------------------\n      WITH moved AS (\n        SELECT\n          oldtab.shard_id AS shard_id,\n          COUNT(*) AS total,\n          COUNT(*) FILTER(WHERE oldtab.clone_status = 'not_cloned')  AS not_cloned,\n          COUNT(*) FILTER(WHERE oldtab.clone_status = 'cloning') AS cloning,\n          COUNT(*) FILTER(WHERE oldtab.clone_status = 'cloned') AS cloned,\n          COUNT(*) FILTER(WHERE oldtab.last_error IS NOT NULL) AS failed_fetch\n        FROM\n          oldtab\n        JOIN newtab ON newtab.repo_id = oldtab.repo_id\n        WHERE\n          oldtab.shard_id != newtab.shard_id\n        GROUP BY oldtab.shard_id\n      )\n      UPDATE gitserver_repos_statistics grs\n      SET\n        total        = grs.total        - moved.total,\n        not_cloned   = grs.not_cloned   - moved.not_cloned,\n        cloning      = grs.cloning      - moved.cloning,\n        cloned       = grs.cloned       - moved.cloned,\n        failed_fetch = grs.failed_fetch - moved.failed_fetch\n      FROM moved\n      WHERE moved.shard_id = grs.shard_id;\n\n      -------------------------------------------------\n      -- IMPORTANT: THIS IS CHANGED\n      -------------------------------------------------\n      WITH diff(not_cloned, cloning, cloned, failed_fetch) AS (\n        VALUES (\n          (\n            (SELECT COUNT(*) FROM newtab JOIN repo r ON newtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND newtab.clone_status = 'not_cloned')\n            -\n            (SELECT COUNT(*) FROM oldtab JOIN repo r ON oldtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND oldtab.clone_status = 'not_cloned')\n          ),\n          (\n            (SELECT COUNT(*) FROM newtab JOIN repo r ON newtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND newtab.clone_status = 'cloning')\n            -\n            (SELECT COUNT(*) FROM oldtab JOIN repo r ON oldtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND oldtab.clone_status = 'cloning')\n          ),\n          (\n            (SELECT COUNT(*) FROM newtab JOIN repo r ON newtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND newtab.clone_status = 'cloned')\n            -\n            (SELECT COUNT(*) FROM oldtab JOIN repo r ON oldtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND oldtab.clone_status = 'cloned')\n          ),\n          (\n            (SELECT COUNT(*) FROM newtab JOIN repo r ON newtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND newtab.last_error IS NOT NULL)\n            -\n            (SELECT COUNT(*) FROM oldtab JOIN repo r ON oldtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND oldtab.last_error IS NOT NULL)\n          )\n        )\n      )\n      INSERT INTO repo_statistics (not_cloned, cloning, cloned, failed_fetch)\n      SELECT not_cloned, cloning, cloned, failed_fetch\n      FROM diff\n      WHERE\n           not_cloned != 0\n        OR cloning != 0\n        OR cloned != 0\n        OR failed_fetch != 0\n      ;\n\n      RETURN NULL;\n  END\n$$;",
				"DownQuery": "-- Recreate old version of function\nCREATE OR REPLACE FUNCTION recalc_repo_statistics_on_repo_update() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$ BEGIN\n      -- Insert diff of changes\n      INSERT INTO\n        repo_statistics (total, soft_deleted, not_cloned, cloning, cloned, failed_fetch)\n      VALUES (\n        (SELECT COUNT(*) FROM newtab WHERE deleted_at IS NULL     AND blocked IS NULL) - (SELECT COUNT(*) FROM oldtab WHERE deleted_at IS NULL     AND blocked IS NULL),\n        (SELECT COUNT(*) FROM newtab WHERE deleted_at IS NOT NULL AND blocked IS NULL) - (SELECT COUNT(*) FROM oldtab WHERE deleted_at IS NOT NULL AND blocked IS NULL),\n        (\n          (SELECT COUNT(*) FROM newtab JOIN gitserver_repos gr ON gr.repo_id = newtab.id WHERE newtab.deleted_at is NULL AND newtab.blocked IS NULL AND gr.clone_status = 'not_cloned')\n          -\n          (SELECT COUNT(*) FROM oldtab JOIN gitserver_repos gr ON gr.repo_id = oldtab.id WHERE oldtab.deleted_at is NULL AND oldtab.blocked IS NULL AND gr.clone_status = 'not_cloned')\n        ),\n        (\n          (SELECT COUNT(*) FROM newtab JOIN gitserver_repos gr ON gr.repo_id = newtab.id WHERE newtab.deleted_at is NULL AND newtab.blocked IS NULL AND gr.clone_status = 'cloning')\n          -\n          (SELECT COUNT(*) FROM oldtab JOIN gitserver_repos gr ON gr.repo_id = oldtab.id WHERE oldtab.deleted_at is NULL AND oldtab.blocked IS NULL AND gr.clone_status = 'cloning')\n        ),\n        (\n          (SELECT COUNT(*) FROM newtab JOIN gitserver_repos gr ON gr.repo_id = newtab.id WHERE newtab.deleted_at is NULL AND newtab.blocked IS NULL AND gr.clone_status = 'cloned')\n          -\n          (SELECT COUNT(*) FROM oldtab JOIN gitserver_repos gr ON gr.repo_id = oldtab.id WHERE oldtab.deleted_at is NULL AND oldtab.blocked IS NULL AND gr.clone_status = 'cloned')\n        ),\n        (\n          (SELECT COUNT(*) FROM newtab JOIN gitserver_repos gr ON gr.repo_id = newtab.id WHERE newtab.deleted_at is NULL AND newtab.blocked IS NULL AND gr.last_error IS NOT NULL)\n          -\n          (SELECT COUNT(*) FROM oldtab JOIN gitserver_repos gr ON gr.repo_id = oldtab.id WHERE oldtab.deleted_at is NULL AND oldtab.blocked IS NULL AND gr.last_error IS NOT NULL)\n        )\n      )\n      ;\n      RETURN NULL;\n  END\n$$;\n\n-- Recreate old version of function\nCREATE OR REPLACE FUNCTION recalc_gitserver_repos_statistics_on_update() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$ BEGIN\n      INSERT INTO gitserver_repos_statistics AS grs (shard_id, total, not_cloned, cloning, cloned, failed_fetch)\n      SELECT\n        newtab.shard_id AS shard_id,\n        COUNT(*) AS total,\n        COUNT(*) FILTER(WHERE clone_status = 'not_cloned')  AS not_cloned,\n        COUNT(*) FILTER(WHERE clone_status = 'cloning') AS cloning,\n        COUNT(*) FILTER(WHERE clone_status = 'cloned') AS cloned,\n        COUNT(*) FILTER(WHERE last_error IS NOT NULL) AS failed_fetch\n      FROM\n        newtab\n      GROUP BY newtab.shard_id\n      ON CONFLICT(shard_id) DO\n      UPDATE\n      SET\n        total        = grs.total        + (excluded.total        - (SELECT COUNT(*)                                              FROM oldtab ot WHERE ot.shard_id = excluded.shard_id)),\n        not_cloned   = grs.not_cloned   + (excluded.not_cloned   - (SELECT COUNT(*) FILTER(WHERE ot.clone_status = 'not_cloned') FROM oldtab ot WHERE ot.shard_id = excluded.shard_id)),\n        cloning      = grs.cloning      + (excluded.cloning      - (SELECT COUNT(*) FILTER(WHERE ot.clone_status = 'cloning')    FROM oldtab ot WHERE ot.shard_id = excluded.shard_id)),\n        cloned       = grs.cloned       + (excluded.cloned       - (SELECT COUNT(*) FILTER(WHERE ot.clone_status = 'cloned')     FROM oldtab ot WHERE ot.shard_id = excluded.shard_id)),\n        failed_fetch = grs.failed_fetch + (excluded.failed_fetch - (SELECT COUNT(*) FILTER(WHERE ot.last_error IS NOT NULL)      FROM oldtab ot WHERE ot.shard_id = excluded.shard_id))\n      ;\n\n      WITH moved AS (\n        SELECT\n          oldtab.shard_id AS shard_id,\n          COUNT(*) AS total,\n          COUNT(*) FILTER(WHERE oldtab.clone_status = 'not_cloned')  AS not_cloned,\n          COUNT(*) FILTER(WHERE oldtab.clone_status = 'cloning') AS cloning,\n          COUNT(*) FILTER(WHERE oldtab.clone_status = 'cloned') AS cloned,\n          COUNT(*) FILTER(WHERE oldtab.last_error IS NOT NULL) AS failed_fetch\n        FROM\n          oldtab\n        JOIN newtab ON newtab.repo_id = oldtab.repo_id\n        WHERE\n          oldtab.shard_id != newtab.shard_id\n        GROUP BY oldtab.shard_id\n      )\n      UPDATE gitserver_repos_statistics grs\n      SET\n        total        = grs.total        - moved.total,\n        not_cloned   = grs.not_cloned   - moved.not_cloned,\n        cloning      = grs.cloning      - moved.cloning,\n        cloned       = grs.cloned       - moved.cloned,\n        failed_fetch = grs.failed_fetch - moved.failed_fetch\n      FROM moved\n      WHERE moved.shard_id = grs.shard_id;\n\n      INSERT INTO repo_statistics (not_cloned, cloning, cloned, failed_fetch)\n      VALUES (\n        (\n          (SELECT COUNT(*) FROM newtab JOIN repo r ON newtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND newtab.clone_status = 'not_cloned')\n          -\n          (SELECT COUNT(*) FROM oldtab JOIN repo r ON oldtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND oldtab.clone_status = 'not_cloned')\n        ),\n        (\n          (SELECT COUNT(*) FROM newtab JOIN repo r ON newtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND newtab.clone_status = 'cloning')\n          -\n          (SELECT COUNT(*) FROM oldtab JOIN repo r ON oldtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND oldtab.clone_status = 'cloning')\n        ),\n        (\n          (SELECT COUNT(*) FROM newtab JOIN repo r ON newtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND newtab.clone_status = 'cloned')\n          -\n          (SELECT COUNT(*) FROM oldtab JOIN repo r ON oldtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND oldtab.clone_status = 'cloned')\n        ),\n        (\n          (SELECT COUNT(*) FROM newtab JOIN repo r ON newtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND newtab.last_error IS NOT NULL)\n          -\n          (SELECT COUNT(*) FROM oldtab JOIN repo r ON oldtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND oldtab.last_error IS NOT NULL)\n        )\n      );\n\n      RETURN NULL;\n  END\n$$;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1659085788,
					1660742069
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1662467128,
				"Name": "Add on-demand autoindexing queue",
				"UpQuery": "CREATE TABLE IF NOT EXISTS codeintel_autoindex_queue (\n    id SERIAL PRIMARY KEY,\n    repository_id int NOT NULL,\n    rev text NOT NULL,\n    queued_at timestamptz NOT NULL DEFAULT NOW(),\n    processed_at timestamptz\n);\n\nCREATE UNIQUE INDEX IF NOT EXISTS codeintel_autoindex_queue_repository_id_commit ON codeintel_autoindex_queue(repository_id, rev);",
				"DownQuery": "DROP TABLE IF EXISTS codeintel_autoindex_queue;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1661502186,
					1661507724
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1663569995,
				"Name": "update_username_valid_chars_contraint",
				"UpQuery": "-- Allow underscores in usernames.\n\nALTER TABLE users\n  DROP CONSTRAINT users_username_valid_chars,\n    ADD CONSTRAINT users_username_valid_chars CHECK (username ~ '^\\w(?:\\w|[-.](?=\\w))*-?$'::citext);",
				"DownQuery": "-- Undo allow underscores in usernames.\n\nALTER TABLE users\n  DROP CONSTRAINT users_username_valid_chars,\n    ADD CONSTRAINT users_username_valid_chars CHECK (username ~ '^[a-zA-Z0-9](?:[a-zA-Z0-9]|[-.](?=[a-zA-Z0-9]))*-?$'::citext);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1662467128
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1664300936,
				"Name": "Move lsif_upload reference count to different table",
				"UpQuery": "CREATE TABLE IF NOT EXISTS lsif_uploads_reference_counts (\n    upload_id INTEGER UNIQUE NOT NULL,\n    reference_count INTEGER NOT NULL\n);\n\nCOMMENT ON TABLE lsif_uploads_reference_counts IS 'A less hot-path reference count for upload records.';\n\nCOMMENT ON COLUMN lsif_uploads_reference_counts.upload_id IS 'The identifier of the referenced upload.';\n\nCOMMENT ON COLUMN lsif_uploads_reference_counts.reference_count IS 'The number of references to the associated upload from other records (via lsif_references).';\n\nALTER TABLE\n    lsif_uploads_reference_counts DROP CONSTRAINT IF EXISTS lsif_data_docs_search_private_repo_name_id_fk;\n\nALTER TABLE\n    lsif_uploads_reference_counts\nADD\n    CONSTRAINT lsif_data_docs_search_private_repo_name_id_fk FOREIGN KEY (upload_id) REFERENCES lsif_uploads(id) ON DELETE CASCADE;",
				"DownQuery": "-- Force recalculation of reference counts\nUPDATE\n    lsif_uploads\nSET\n    reference_count = NULL;\n\n-- Remove new table\nDROP TABLE IF EXISTS lsif_uploads_reference_counts;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1660711451,
					1661441160,
					1663569995
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1663665519,
				"Name": "perforce_merge_includes_excludes_columns",
				"UpQuery": "ALTER TABLE ONLY sub_repo_permissions\n    ADD COLUMN IF NOT EXISTS paths text[];\n\nCOMMENT ON COLUMN sub_repo_permissions.paths IS 'Paths that begin with a minus sign (-) are exclusion paths.';\n\nUPDATE sub_repo_permissions\n    SET paths = (ARRAY(SELECT CONCAT('/', path_include) FROM unnest(path_includes) as path_include) || ARRAY(SELECT CONCAT('-/', path_exclude) FROM unnest(path_excludes) as path_exclude));",
				"DownQuery": "ALTER TABLE sub_repo_permissions\n    DROP COLUMN IF EXISTS paths;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1660711451,
					1662467128
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1663871069,
				"Name": "changeset specs null published",
				"UpQuery": "UPDATE changeset_specs\nSET published = NULL\nWHERE published = 'null';\n\nUPDATE changeset_specs\nSET published = '\"draft\"'\nWHERE published = 'draft';\n\nALTER TABLE changeset_specs\n    DROP CONSTRAINT IF EXISTS changeset_specs_published_valid_values,\n    ADD CONSTRAINT changeset_specs_published_valid_values CHECK (published = 'true' OR published = 'false' OR\n                                                                 published = '\"draft\"' OR published IS NULL);",
				"DownQuery": "ALTER TABLE changeset_specs\n    DROP CONSTRAINT IF EXISTS changeset_specs_published_valid_values;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1660711451,
					1662467128
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1664897165,
				"Name": "executor_secrets",
				"UpQuery": "CREATE TABLE IF NOT EXISTS executor_secrets (\n    id SERIAL PRIMARY KEY,\n    key text NOT NULL,\n    value bytea NOT NULL,\n    scope text NOT NULL,\n    encryption_key_id text,\n    namespace_user_id integer REFERENCES users(id) ON DELETE CASCADE,\n    namespace_org_id integer REFERENCES orgs(id) ON DELETE CASCADE,\n    created_at timestamp with time zone NOT NULL DEFAULT NOW(),\n    updated_at timestamp with time zone NOT NULL DEFAULT NOW(),\n    creator_id integer REFERENCES users(id) ON DELETE SET NULL\n);\n\nCOMMENT ON COLUMN executor_secrets.creator_id IS 'NULL, if the user has been deleted.';\n\n-- Enforce uniqueness of the key in a given namespace.\nCREATE UNIQUE INDEX IF NOT EXISTS executor_secrets_unique_key_namespace_user ON executor_secrets (key, namespace_user_id, scope) WHERE namespace_user_id IS NOT NULL;\nCREATE UNIQUE INDEX IF NOT EXISTS executor_secrets_unique_key_namespace_org ON executor_secrets (key, namespace_org_id, scope) WHERE namespace_org_id IS NOT NULL;\n-- Enforce uniqueness of the key in the global namespace. NULL is a fun type :)\nCREATE UNIQUE INDEX IF NOT EXISTS executor_secrets_unique_key_global ON executor_secrets(key, scope) WHERE namespace_user_id IS NULL AND namespace_org_id IS NULL;\n\nCREATE TABLE IF NOT EXISTS executor_secret_access_logs (\n    id SERIAL PRIMARY KEY,\n    executor_secret_id integer NOT NULL REFERENCES executor_secrets(id) ON DELETE CASCADE,\n    user_id integer NOT NULL REFERENCES users(id) ON DELETE CASCADE,\n    created_at timestamp with time zone NOT NULL DEFAULT NOW()\n);",
				"DownQuery": "DROP TABLE IF EXISTS executor_secret_access_logs;\nDROP TABLE IF EXISTS executor_secrets;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1663665519,
					1663871069,
					1664300936
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1664988036,
				"Name": "create_webhooks_table",
				"UpQuery": "CREATE TABLE IF NOT EXISTS webhooks(\n    id UUID NOT NULL,\n    code_host_kind TEXT NOT NULL,\n    code_host_urn TEXT NOT NULL,\n    secret TEXT,\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW() NOT NULL,\n    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW() NOT NULL,\n    encryption_key_id TEXT NOT NULL DEFAULT ''\n);\n\nCOMMENT ON TABLE webhooks IS 'Webhooks registered in Sourcegraph instance.';\nCOMMENT ON COLUMN webhooks.code_host_kind IS 'Kind of an external service for which webhooks are registered.';\nCOMMENT ON COLUMN webhooks.code_host_urn IS 'URN of a code host. This column maps to external_service_id column of repo table.';\nCOMMENT ON COLUMN webhooks.secret IS 'Secret used to decrypt webhook payload (if supported by the code host).';",
				"DownQuery": "DROP TABLE IF EXISTS webhooks;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1663665519,
					1663871069,
					1664300936
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1665056530,
				"Name": "auto-generate-webhook-id",
				"UpQuery": "ALTER TABLE webhooks\n   DROP CONSTRAINT IF EXISTS webhooks_pkey,\n   ADD CONSTRAINT webhooks_pkey PRIMARY KEY (id),\n   ALTER COLUMN id SET DEFAULT gen_random_uuid();",
				"DownQuery": "ALTER TABLE IF EXISTS webhooks\n    ALTER COLUMN id DROP DEFAULT,\n    DROP CONSTRAINT IF EXISTS webhooks_pkey;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1664988036
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1665138849,
				"Name": "add-rand-id-to-webhooks",
				"UpQuery": "-- We are changing the schema and we don't expect any rows yet so we can just drop\n-- the old table\nDROP TABLE IF EXISTS webhooks;\n\nCREATE TABLE webhooks (\n      id SERIAL PRIMARY KEY,\n      rand_id uuid DEFAULT gen_random_uuid() NOT NULL,\n      code_host_kind text NOT NULL,\n      code_host_urn text NOT NULL,\n      secret text,\n      created_at timestamp with time zone DEFAULT now() NOT NULL,\n      updated_at timestamp with time zone DEFAULT now() NOT NULL,\n      encryption_key_id text\n);\n\nCOMMENT ON TABLE webhooks IS 'Webhooks registered in Sourcegraph instance.';\n\nCOMMENT ON COLUMN webhooks.code_host_kind IS 'Kind of an external service for which webhooks are registered.';\n\nCOMMENT ON COLUMN webhooks.code_host_urn IS 'URN of a code host. This column maps to external_service_id column of repo table.';\n\nCOMMENT ON COLUMN webhooks.secret IS 'Secret used to decrypt webhook payload (if supported by the code host).';\n\nCOMMENT ON COLUMN webhooks.rand_id IS 'rand_id will be the user facing ID';",
				"DownQuery": "-- We can just drop the new table and create the old one again\n\nDROP TABLE IF EXISTS webhooks;\n\nCREATE TABLE webhooks (\n      id uuid DEFAULT gen_random_uuid() NOT NULL,\n      code_host_kind text NOT NULL,\n      code_host_urn text NOT NULL,\n      secret text,\n      created_at timestamp with time zone DEFAULT now() NOT NULL,\n      updated_at timestamp with time zone DEFAULT now() NOT NULL,\n      encryption_key_id text DEFAULT ''::text NOT NULL\n);\n\nCOMMENT ON TABLE webhooks IS 'Webhooks registered in Sourcegraph instance.';\n\nCOMMENT ON COLUMN webhooks.code_host_kind IS 'Kind of an external service for which webhooks are registered.';\n\nCOMMENT ON COLUMN webhooks.code_host_urn IS 'URN of a code host. This column maps to external_service_id column of repo table.';\n\nCOMMENT ON COLUMN webhooks.secret IS 'Secret used to decrypt webhook payload (if supported by the code host).';\n\nALTER TABLE webhooks\n    ADD CONSTRAINT webhooks_pkey PRIMARY KEY (id);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1665056530
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1665399117,
				"Name": "rename a column and add an index to webhooks table",
				"UpQuery": "ALTER TABLE webhooks\n    DROP COLUMN IF EXISTS rand_id,\n    ADD COLUMN IF NOT EXISTS uuid UUID UNIQUE NOT NULL DEFAULT gen_random_uuid();",
				"DownQuery": "ALTER TABLE webhooks\n    DROP COLUMN IF EXISTS uuid,\n    ADD COLUMN IF NOT EXISTS rand_id UUID DEFAULT gen_random_uuid() NOT NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1665138849
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1662636054,
				"Name": "autoindexing_persisted_inference_script",
				"UpQuery": "CREATE TABLE IF NOT EXISTS codeintel_inference_scripts (\n    insert_timestamp timestamptz NOT NULL default NOW(),\n    script text NOT NULL\n);\n\nCOMMENT ON table codeintel_inference_scripts IS 'Contains auto-index job inference Lua scripts as an alternative to setting via environment variables.';",
				"DownQuery": "-- Undo the changes made in the up migration\nDROP TABLE IF EXISTS codeintel_inference_scripts;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1661502186,
					1661507724
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1665420690,
				"Name": "persisted repo document ranks",
				"UpQuery": "CREATE TABLE IF NOT EXISTS codeintel_path_ranks (\n    repository_id integer NOT NULL UNIQUE,\n    payload text NOT NULL\n);",
				"DownQuery": "DROP TABLE IF EXISTS codeintel_path_ranks;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1662636054,
					1665399117
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1665477911,
				"Name": "add_zoekt_repos_table",
				"UpQuery": "CREATE TABLE IF NOT EXISTS zoekt_repos (\n    repo_id integer NOT NULL PRIMARY KEY REFERENCES repo(id) ON DELETE CASCADE,\n    branches jsonb DEFAULT '[]'::jsonb NOT NULL,\n\n    index_status text DEFAULT 'not_indexed'::text NOT NULL,\n\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL\n);\n\nCREATE INDEX IF NOT EXISTS zoekt_repos_index_status ON zoekt_repos USING btree (index_status);\n\nCREATE OR REPLACE FUNCTION func_insert_zoekt_repo() RETURNS TRIGGER AS $$\nBEGIN\n  INSERT INTO zoekt_repos (repo_id) VALUES (NEW.id);\n\n  RETURN NULL;\nEND;\n$$ LANGUAGE plpgsql;\n\nDROP TRIGGER IF EXISTS trig_create_zoekt_repo_on_repo_insert on repo;\n\nCREATE TRIGGER trig_create_zoekt_repo_on_repo_insert\nAFTER INSERT\nON repo\nFOR EACH ROW\nEXECUTE FUNCTION func_insert_zoekt_repo();",
				"DownQuery": "DROP TRIGGER IF EXISTS trig_create_zoekt_repo_on_repo_insert ON repo;\nDROP FUNCTION IF EXISTS func_insert_zoekt_repo();\n\nDROP TABLE IF EXISTS zoekt_repos;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1662636054,
					1665399117
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1665488828,
				"Name": "add columns to webhooks table",
				"UpQuery": "ALTER TABLE webhooks\n    DROP COLUMN IF EXISTS created_by_user_id,\n    DROP COLUMN IF EXISTS updated_by_user_id,\n    ADD COLUMN created_by_user_id INTEGER REFERENCES users(id) ON DELETE SET NULL,\n    ADD COLUMN updated_by_user_id INTEGER DEFAULT NULL REFERENCES users(id) ON DELETE SET NULL;\n\nCOMMENT ON COLUMN webhooks.created_by_user_id IS 'ID of a user, who created the webhook. If NULL, then the user does not exist (never existed or was deleted).';\nCOMMENT ON COLUMN webhooks.updated_by_user_id IS 'ID of a user, who updated the webhook. If NULL, then the user does not exist (never existed or was deleted).';",
				"DownQuery": "ALTER TABLE webhooks\n    DROP COLUMN IF EXISTS created_by_user_id,\n    DROP COLUMN IF EXISTS updated_by_user_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1662636054,
					1665399117
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1665524865,
				"Name": "add column repo_status to gitserver_repos table",
				"UpQuery": "ALTER TABLE gitserver_repos\n      -- repo_status indicates the \"live\" status of a cloned repo and\n      -- is to be used in addition to clone_status. For example, it\n      -- may indicate if a repo is currently being \"fetched\" or if it\n      -- is currently being garbage collcted by one of the cleanup\n      -- jobs.\n      ADD COLUMN IF NOT EXISTS repo_status text;",
				"DownQuery": "-- Undo the changes made in the up migration\n\nALTER TABLE gitserver_repos\n      DROP COLUMN IF EXISTS repo_status;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1662636054,
					1665399117
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1665646849,
				"Name": "add-counters-to-external-service-sync-job",
				"UpQuery": "ALTER TABLE IF EXISTS external_service_sync_jobs\nADD COLUMN IF NOT EXISTS repos_synced integer DEFAULT 0 NOT NULL,\nADD COLUMN IF NOT EXISTS repo_sync_errors integer DEFAULT 0 NOT NULL,\nADD COLUMN IF NOT EXISTS repos_added integer DEFAULT 0 NOT NULL,\nADD COLUMN IF NOT EXISTS repos_deleted integer DEFAULT 0 NOT NULL,\nADD COLUMN IF NOT EXISTS repos_modified integer DEFAULT 0 NOT NULL,\nADD COLUMN IF NOT EXISTS repos_unmodified integer DEFAULT 0 NOT NULL;\n\nCOMMENT ON COLUMN external_service_sync_jobs.repos_synced IS 'The number of repos synced during this sync job.';\nCOMMENT ON COLUMN external_service_sync_jobs.repo_sync_errors IS 'The number of times an error occurred syncing a repo during this sync job.';\nCOMMENT ON COLUMN external_service_sync_jobs.repos_added IS 'The number of new repos discovered during this sync job.';\nCOMMENT ON COLUMN external_service_sync_jobs.repos_deleted IS 'The number of repos deleted as a result of this sync job.';\nCOMMENT ON COLUMN external_service_sync_jobs.repos_modified IS 'The number of existing repos whose metadata has changed during this sync job.';\nCOMMENT ON COLUMN external_service_sync_jobs.repos_unmodified IS 'The number of existing repos whose metadata did not change during this sync job.';",
				"DownQuery": "ALTER TABLE IF EXISTS external_service_sync_jobs\nDROP COLUMN IF EXISTS repos_synced,\nDROP COLUMN IF EXISTS repo_sync_errors,\nDROP COLUMN IF EXISTS repos_added,\nDROP COLUMN IF EXISTS repos_deleted,\nDROP COLUMN IF EXISTS repos_modified,\nDROP COLUMN IF EXISTS repos_unmodified;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1665524865
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1665588249,
				"Name": "Rename bad fk constraint",
				"UpQuery": "-- Migration 1664300936 had a really weird copy and paste error we can fix here.\nALTER TABLE\n    lsif_uploads_reference_counts DROP CONSTRAINT IF EXISTS lsif_uploads_reference_counts_upload_id_fk;\n\nALTER TABLE\n    lsif_uploads_reference_counts DROP CONSTRAINT IF EXISTS lsif_data_docs_search_private_repo_name_id_fk;\n\nALTER TABLE\n    lsif_uploads_reference_counts\nADD\n    CONSTRAINT lsif_uploads_reference_counts_upload_id_fk FOREIGN KEY (upload_id) REFERENCES lsif_uploads(id) ON DELETE CASCADE;",
				"DownQuery": "-- Put the weird name back\nALTER TABLE\n    lsif_uploads_reference_counts DROP CONSTRAINT IF EXISTS lsif_uploads_reference_counts_upload_id_fk;\n\nALTER TABLE\n    lsif_uploads_reference_counts DROP CONSTRAINT IF EXISTS lsif_data_docs_search_private_repo_name_id_fk;\n\nALTER TABLE\n    lsif_uploads_reference_counts\nADD\n    CONSTRAINT lsif_data_docs_search_private_repo_name_id_fk FOREIGN KEY (upload_id) REFERENCES lsif_uploads(id) ON DELETE CASCADE;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1662636054,
					1665399117
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1665770699,
				"Name": "Add codeintel_commit_dates",
				"UpQuery": "CREATE TABLE IF NOT EXISTS codeintel_commit_dates(\n    repository_id integer NOT NULL,\n    commit_bytea bytea NOT NULL,\n    committed_at timestamp with time zone,\n    PRIMARY KEY(repository_id, commit_bytea)\n);\n\nCOMMENT ON TABLE codeintel_commit_dates IS 'Maps commits within a repository to the commit date as reported by gitserver.';\n\nCOMMENT ON COLUMN codeintel_commit_dates.repository_id IS 'Identifies a row in the `repo` table.';\n\nCOMMENT ON COLUMN codeintel_commit_dates.commit_bytea IS 'Identifies the 40-character commit hash.';\n\nCOMMENT ON COLUMN codeintel_commit_dates.committed_at IS 'The commit date (may be -infinity if unresolvable).';\n\nINSERT INTO\n    codeintel_commit_dates (repository_id, commit_bytea, committed_at)\nSELECT\n    u.repository_id,\n    decode(u.commit, 'hex'),\n    MIN(u.committed_at)\nFROM\n    lsif_uploads u\nWHERE\n    u.committed_at IS NOT NULL\nGROUP BY\n    u.repository_id,\n    u.commit\nON CONFLICT DO NOTHING;",
				"DownQuery": "DROP TABLE IF EXISTS codeintel_commit_dates;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1665420690,
					1665488828,
					1665524865,
					1665588249
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1666034720,
				"Name": "Add lsif_upload references (gc) scan timestamp",
				"UpQuery": "ALTER TABLE\n    lsif_uploads\nADD\n    COLUMN IF NOT EXISTS last_referenced_scan_at timestamp with time zone;\n\nCOMMENT ON COLUMN lsif_uploads.last_referenced_scan_at IS 'The last time this upload was known to be referenced by another (possibly expired) index.';",
				"DownQuery": "ALTER TABLE\n    lsif_uploads DROP COLUMN IF EXISTS last_referenced_scan_at;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1665420690,
					1665488828,
					1665524865,
					1665588249
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1666131819,
				"Name": "Add lsif_upload traversal scan timestamp",
				"UpQuery": "ALTER TABLE\n    lsif_uploads\nADD\n    COLUMN IF NOT EXISTS last_traversal_scan_at timestamp with time zone;\n\nCOMMENT ON COLUMN lsif_uploads.last_traversal_scan_at IS 'The last time this upload was known to be reachable by a non-expired index.';",
				"DownQuery": "ALTER TABLE\n    lsif_uploads DROP COLUMN IF EXISTS last_traversal_scan_at;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1665646849,
					1665770699,
					1666034720
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1666145729,
				"Name": "Add lsif_indexes.should__reindex",
				"UpQuery": "ALTER TABLE lsif_indexes ADD COLUMN IF NOT EXISTS should_reindex boolean NOT NULL DEFAULT false;\n\nDROP VIEW IF EXISTS lsif_indexes_with_repository_name;\n\nCREATE VIEW lsif_indexes_with_repository_name AS\n SELECT u.id,\n    u.commit,\n    u.queued_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.process_after,\n    u.num_resets,\n    u.num_failures,\n    u.docker_steps,\n    u.root,\n    u.indexer,\n    u.indexer_args,\n    u.outfile,\n    u.log_contents,\n    u.execution_logs,\n    u.local_steps,\n    u.should_reindex,\n    r.name AS repository_name\n   FROM (lsif_indexes u\n     JOIN repo r ON ((r.id = u.repository_id)))\n  WHERE (r.deleted_at IS NULL);",
				"DownQuery": "DROP VIEW IF EXISTS lsif_indexes_with_repository_name;\n\nCREATE VIEW lsif_indexes_with_repository_name AS\n SELECT u.id,\n    u.commit,\n    u.queued_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.process_after,\n    u.num_resets,\n    u.num_failures,\n    u.docker_steps,\n    u.root,\n    u.indexer,\n    u.indexer_args,\n    u.outfile,\n    u.log_contents,\n    u.execution_logs,\n    u.local_steps,\n    r.name AS repository_name\n   FROM (lsif_indexes u\n     JOIN repo r ON ((r.id = u.repository_id)))\n  WHERE (r.deleted_at IS NULL);\n\nALTER TABLE lsif_indexes DROP COLUMN IF EXISTS should_reindex;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1665420690,
					1665488828,
					1665524865,
					1665588249
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1666344635,
				"Name": "fill_zoekt_repos_table",
				"UpQuery": "INSERT INTO zoekt_repos (repo_id)\nSELECT id\nFROM repo\nLEFT JOIN zoekt_repos zr ON repo.id = zr.repo_id\nWHERE zr.repo_id IS NULL\nON CONFLICT (repo_id) DO NOTHING;",
				"DownQuery": "-- No undo",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1665477911,
					1666131819,
					1666145729
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1666398757,
				"Name": "ensure_cancel_column",
				"UpQuery": "ALTER TABLE webhook_build_jobs ADD COLUMN IF NOT EXISTS cancel BOOLEAN NOT NULL DEFAULT FALSE;",
				"DownQuery": "ALTER TABLE webhook_build_jobs DROP COLUMN IF EXISTS cancel;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1666131819,
					1666145729
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1666524436,
				"Name": "Add missing state index on lsif_dependency_indexing_jobs table",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS lsif_dependency_indexing_jobs_state ON lsif_dependency_indexing_jobs (state);",
				"DownQuery": "DROP INDEX IF EXISTS lsif_dependency_indexing_jobs_state;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1666131819,
					1666145729
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "lsif_dependency_indexing_jobs",
					"IndexName": "lsif_dependency_indexing_jobs_state"
				}
			},
			{
				"ID": 1666598814,
				"Name": "Add missing state index on lsif_dependency_syncing_jobs table",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS lsif_dependency_syncing_jobs_state ON lsif_dependency_syncing_jobs (state);",
				"DownQuery": "DROP INDEX IF EXISTS lsif_dependency_syncing_jobs_state;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1666524436
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "lsif_dependency_syncing_jobs",
					"IndexName": "lsif_dependency_syncing_jobs_state"
				}
			},
			{
				"ID": 1666598828,
				"Name": "Add missing state index on batch_spec_resolution_jobs table",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS batch_spec_resolution_jobs_state ON batch_spec_resolution_jobs (state);",
				"DownQuery": "DROP INDEX IF EXISTS batch_spec_resolution_jobs_state;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1666598814
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "batch_spec_resolution_jobs",
					"IndexName": "batch_spec_resolution_jobs_state"
				}
			},
			{
				"ID": 1666598983,
				"Name": "Add missing state index on gitserver_relocator_jobs table",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS gitserver_relocator_jobs_state ON gitserver_relocator_jobs (state);",
				"DownQuery": "DROP INDEX IF EXISTS gitserver_relocator_jobs_state;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1666598828
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "gitserver_relocator_jobs",
					"IndexName": "gitserver_relocator_jobs_state"
				}
			},
			{
				"ID": 1666598987,
				"Name": "Add missing state index on webhook_build_jobs table",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS webhook_build_jobs_state ON webhook_build_jobs (state);",
				"DownQuery": "DROP INDEX IF EXISTS webhook_build_jobs_state;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1666598983
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "webhook_build_jobs",
					"IndexName": "webhook_build_jobs_state"
				}
			},
			{
				"ID": 1666598990,
				"Name": "add columns to webhooks table",
				"UpQuery": "ALTER TABLE webhook_logs\n    ADD COLUMN IF NOT EXISTS webhook_id INTEGER REFERENCES webhooks(id) ON DELETE CASCADE;",
				"DownQuery": "ALTER TABLE webhook_logs\n     DROP COLUMN IF EXISTS webhook_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1666598987
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1666717223,
				"Name": "Add codeintel_ranking_exports table",
				"UpQuery": "CREATE TABLE IF NOT EXISTS codeintel_ranking_exports (\n    upload_id integer NOT NULL,\n    graph_key text NOT NULL,\n    locked_at timestamp with time zone NOT NULL DEFAULT NOW(),\n    PRIMARY KEY (upload_id, graph_key),\n    FOREIGN KEY (upload_id) REFERENCES lsif_uploads(id) ON DELETE CASCADE\n);",
				"DownQuery": "DROP TABLE IF EXISTS codeintel_ranking_exports;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1666598987
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1666886757,
				"Name": "add_event_logs_user_id_timestamp_index",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS event_logs_user_id_timestamp ON event_logs(user_id, timestamp);",
				"DownQuery": "DROP INDEX IF EXISTS event_logs_user_id_timestamp;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1664897165,
					1666598990,
					1666717223
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "event_logs",
					"IndexName": "event_logs_user_id_timestamp"
				}
			},
			{
				"ID": 1666904087,
				"Name": "Add codeintel_path_rank_inputs table",
				"UpQuery": "CREATE\nOR REPLACE AGGREGATE sg_jsonb_concat_agg(jsonb) (\n    SFUNC = 'jsonb_concat',\n    STYPE = jsonb,\n    INITCOND = '{}'\n);\n\nALTER TABLE\n    codeintel_path_ranks\nALTER COLUMN\n    payload TYPE jsonb USING payload :: jsonb;\n\nCREATE TABLE IF NOT EXISTS codeintel_path_rank_inputs(\n    id BIGSERIAL PRIMARY KEY,\n    graph_key text NOT NULL,\n    input_filename text NOT NULL,\n    repository_name text NOT NULL,\n    payload jsonb NOT NULL,\n    processed boolean NOT NULL DEFAULT false,\n    UNIQUE (graph_key, input_filename, repository_name)\n);\n\nCREATE INDEX IF NOT EXISTS codeintel_path_rank_graph_key_id_repository_name_processed ON codeintel_path_rank_inputs(graph_key, id, repository_name)\nWHERE\n    NOT processed;\n\nCOMMENT ON TABLE codeintel_path_rank_inputs IS 'Sharded inputs from Spark jobs that will subsequently be written into `codeintel_path_ranks`.';",
				"DownQuery": "DROP TABLE IF EXISTS codeintel_path_rank_inputs;\n\nALTER TABLE\n    codeintel_path_ranks\nALTER COLUMN\n    payload TYPE text USING payload :: text;\n\nDROP AGGREGATE IF EXISTS sg_jsonb_concat_agg(jsonb);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1664897165,
					1666344635,
					1666598990,
					1666717223
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1666939263,
				"Name": "add_index_on_event_logs_user_id_name",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS event_logs_user_id_name ON event_logs (user_id, name);",
				"DownQuery": "DROP INDEX IF EXISTS event_logs_user_id_name;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1664897165,
					1666344635,
					1666598990,
					1666717223
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "event_logs",
					"IndexName": "event_logs_user_id_name"
				}
			},
			{
				"ID": 1667220502,
				"Name": "Add precision to codeintel_path_ranks",
				"UpQuery": "DELETE FROM\n    codeintel_path_ranks;\n\nALTER TABLE\n    codeintel_path_ranks\nADD\n    COLUMN IF NOT EXISTS precision float NOT NULL;",
				"DownQuery": "ALTER TABLE\n    codeintel_path_ranks DROP COLUMN IF EXISTS precision;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1666886757,
					1666904087,
					1666939263
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1667220626,
				"Name": "Rename codeintel_path_ranks key",
				"UpQuery": "-- Rename default constraint name to something we can control\nALTER TABLE codeintel_path_ranks DROP CONSTRAINT IF EXISTS codeintel_path_ranks_repository_id_key;\nCREATE UNIQUE INDEX IF NOT EXISTS codeintel_path_ranks_repository_id ON codeintel_path_ranks (repository_id);",
				"DownQuery": "-- Note: same as up.sql\nALTER TABLE codeintel_path_ranks DROP CONSTRAINT IF EXISTS codeintel_path_ranks_repository_id_key;\nCREATE UNIQUE INDEX IF NOT EXISTS codeintel_path_ranks_repository_id ON codeintel_path_ranks (repository_id);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1667220502
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1667220628,
				"Name": "Update codeintel_path_ranks unique constraint to include precision",
				"UpQuery": "DROP INDEX IF EXISTS codeintel_path_ranks_repository_id;\n\nCREATE UNIQUE INDEX IF NOT EXISTS codeintel_path_ranks_repository_id_precision ON codeintel_path_ranks (repository_id, precision);",
				"DownQuery": "DROP INDEX IF EXISTS codeintel_path_ranks_repository_id_precision;\n\nCREATE UNIQUE INDEX IF NOT EXISTS codeintel_path_ranks_repository_id ON codeintel_path_ranks (repository_id);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1667220626
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1667220768,
				"Name": "Add precision to codeintel_path_rank_inputs",
				"UpQuery": "ALTER TABLE\n    codeintel_path_rank_inputs\nADD\n    COLUMN IF NOT EXISTS precision float NOT NULL;",
				"DownQuery": "ALTER TABLE\n    codeintel_path_rank_inputs DROP COLUMN IF EXISTS precision;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1667220628
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1667222952,
				"Name": "Add codeintel ranking timestamps",
				"UpQuery": "ALTER TABLE\n    codeintel_path_ranks\nADD\n    COLUMN IF NOT EXISTS updated_at timestamp with time zone NOT NULL DEFAULT NOW();\n\nCREATE INDEX IF NOT EXISTS codeintel_path_ranks_updated_at ON codeintel_path_ranks(updated_at) INCLUDE (repository_id);\n\nCREATE OR REPLACE FUNCTION update_codeintel_path_ranks_updated_at_column() RETURNS TRIGGER AS\n$$ BEGIN\n    NEW.updated_at = NOW();\n    RETURN NEW;\nEND;\n$$ language 'plpgsql';\n\nDROP TRIGGER IF EXISTS update_codeintel_path_ranks_updated_at ON codeintel_path_ranks;\nCREATE TRIGGER update_codeintel_path_ranks_updated_at BEFORE UPDATE ON codeintel_path_ranks FOR EACH ROW EXECUTE PROCEDURE update_codeintel_path_ranks_updated_at_column();",
				"DownQuery": "DROP TRIGGER IF EXISTS update_codeintel_path_ranks_updated_at ON codeintel_path_ranks;\nDROP FUNCTION IF EXISTS update_codeintel_path_ranks_updated_at_column;\nDROP INDEX IF EXISTS codeintel_path_ranks_updated_at;\nALTER TABLE codeintel_path_ranks DROP COLUMN IF EXISTS updated_at;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1666886757,
					1666904087,
					1666939263
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1667259203,
				"Name": "Add graph_key to codeintel_path_ranks",
				"UpQuery": "ALTER TABLE\n    codeintel_path_ranks\nADD\n    COLUMN IF NOT EXISTS graph_key text;",
				"DownQuery": "ALTER TABLE\n    codeintel_path_ranks DROP COLUMN IF EXISTS graph_key;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1667220768,
					1667222952
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1667313173,
				"Name": "Add index to lsif_uploads_visible_at_tip",
				"UpQuery": "CREATE INDEX IF NOT EXISTS lsif_uploads_visible_at_tip_is_default_branch ON lsif_uploads_visible_at_tip(upload_id)\nWHERE\n    is_default_branch;",
				"DownQuery": "DROP INDEX IF EXISTS lsif_uploads_visible_at_tip_is_default_branch;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1667259203
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1667395984,
				"Name": "Remove filter from lsif_references",
				"UpQuery": "ALTER TABLE\n    lsif_references DROP COLUMN IF EXISTS filter;",
				"DownQuery": "ALTER TABLE\n    lsif_references\nADD\n    COLUMN IF NOT EXISTS filter bytea;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1667313173
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1667433265,
				"Name": "Add last_reconcile to lsif_uploads table",
				"UpQuery": "ALTER TABLE\n    lsif_uploads\nADD\n    COLUMN IF NOT EXISTS last_reconcile_at timestamp with time zone;\n\nCREATE INDEX IF NOT EXISTS lsif_uploads_last_reconcile_at ON lsif_uploads(last_reconcile_at, id)\nWHERE\n    state = 'completed';",
				"DownQuery": "DROP INDEX IF EXISTS lsif_uploads_last_reconcile_at;\n\nALTER TABLE\n    lsif_uploads DROP COLUMN IF EXISTS last_reconcile_at;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1667395984
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1667497565,
				"Name": "Fix cascade behavior for codeintel_ranking_exports",
				"UpQuery": "-- Change primary key\nALTER TABLE codeintel_ranking_exports DROP CONSTRAINT IF EXISTS codeintel_ranking_exports_pkey;\nALTER TABLE codeintel_ranking_exports ADD COLUMN IF NOT EXISTS id SERIAL NOT NULL;\nALTER TABLE codeintel_ranking_exports ADD PRIMARY KEY (id);\n\n-- Make column + foreign key nullable\nALTER TABLE codeintel_ranking_exports DROP CONSTRAINT IF EXISTS codeintel_ranking_exports_upload_id_fkey;\nALTER TABLE codeintel_ranking_exports ALTER COLUMN upload_id DROP NOT NULL;\nALTER TABLE codeintel_ranking_exports ADD CONSTRAINT codeintel_ranking_exports_upload_id_fkey FOREIGN KEY (upload_id) REFERENCES lsif_uploads(id) ON DELETE SET NULL;\n\n-- Emulate old primary key index\nCREATE UNIQUE INDEX IF NOT EXISTS codeintel_ranking_exports_upload_id_graph_key ON codeintel_ranking_exports(upload_id, graph_key);\n\n-- Add prefix to control authoritative GCS paths as we might set upload_id to NULL now\nALTER TABLE codeintel_ranking_exports ADD COLUMN IF NOT EXISTS object_prefix TEXT;",
				"DownQuery": "-- Drop dependent constraints\nALTER TABLE codeintel_ranking_exports DROP CONSTRAINT IF EXISTS codeintel_ranking_exports_pkey;\n\n-- Make column + foreign key non-nullable\nALTER TABLE codeintel_ranking_exports DROP CONSTRAINT IF EXISTS codeintel_ranking_exports_upload_id_fkey;\nDELETE FROM codeintel_ranking_exports WHERE upload_id IS NULL;\nALTER TABLE codeintel_ranking_exports ALTER COLUMN upload_id SET NOT NULL;\nALTER TABLE codeintel_ranking_exports ADD CONSTRAINT codeintel_ranking_exports_upload_id_fkey FOREIGN KEY (upload_id) REFERENCES lsif_uploads(id) ON DELETE CASCADE;\n\n-- Restore the old primary key\nALTER TABLE codeintel_ranking_exports DROP COLUMN IF EXISTS id;\nALTER TABLE codeintel_ranking_exports ADD PRIMARY KEY (upload_id, graph_key);\n\n-- Drop now duplicate index\nDROP INDEX IF EXISTS codeintel_ranking_exports_upload_id_graph_key;\n\n-- Drop new column\nALTER TABLE codeintel_ranking_exports DROP COLUMN IF EXISTS object_prefix;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1667395984
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1667500111,
				"Name": "Fix codeintel_path_ranks trigger condition",
				"UpQuery": "DROP TRIGGER IF EXISTS update_codeintel_path_ranks_updated_at ON codeintel_path_ranks;\nCREATE TRIGGER update_codeintel_path_ranks_updated_at BEFORE UPDATE ON codeintel_path_ranks FOR EACH ROW WHEN (NEW IS DISTINCT FROM OLD) EXECUTE PROCEDURE update_codeintel_path_ranks_updated_at_column();",
				"DownQuery": "DROP TRIGGER IF EXISTS update_codeintel_path_ranks_updated_at ON codeintel_path_ranks;\nCREATE TRIGGER update_codeintel_path_ranks_updated_at BEFORE UPDATE ON codeintel_path_ranks FOR EACH ROW EXECUTE PROCEDURE update_codeintel_path_ranks_updated_at_column();",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1667395984
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1667825028,
				"Name": "Add SSBC execution V2 flag",
				"UpQuery": "ALTER TABLE batch_spec_workspace_execution_jobs ADD COLUMN IF NOT EXISTS version integer NOT NULL DEFAULT 1;\n\nDROP VIEW batch_spec_workspace_execution_jobs_with_rank;\nCREATE VIEW batch_spec_workspace_execution_jobs_with_rank AS (\n    SELECT\n        j.*,\n        q.place_in_global_queue,\n        q.place_in_user_queue\n    FROM\n        batch_spec_workspace_execution_jobs j\n    LEFT JOIN batch_spec_workspace_execution_queue q ON j.id = q.id\n);",
				"DownQuery": "DROP VIEW batch_spec_workspace_execution_jobs_with_rank;\nCREATE VIEW batch_spec_workspace_execution_jobs_with_rank AS (\n    SELECT\n        j.id,\n        j.batch_spec_workspace_id,\n        j.state,\n        j.failure_message,\n        j.started_at,\n        j.finished_at,\n        j.process_after,\n        j.num_resets,\n        j.num_failures,\n        j.execution_logs,\n        j.worker_hostname,\n        j.last_heartbeat_at,\n        j.created_at,\n        j.updated_at,\n        j.cancel,\n        j.queued_at,\n        j.user_id,\n        q.place_in_global_queue,\n        q.place_in_user_queue\n    FROM\n        batch_spec_workspace_execution_jobs j\n    LEFT JOIN batch_spec_workspace_execution_queue q ON j.id = q.id\n);\n\nALTER TABLE batch_spec_workspace_execution_jobs DROP COLUMN IF EXISTS version;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1667433265,
					1667497565,
					1667500111
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1667848448,
				"Name": "Flip index field order",
				"UpQuery": "-- Effectively replaces codeintel_path_rank_graph_key_id_repository_name_processed\nCREATE INDEX IF NOT EXISTS codeintel_path_rank_inputs_graph_key_repository_name_id_processed ON codeintel_path_rank_inputs(graph_key, repository_name, id)\nWHERE\n    NOT processed;",
				"DownQuery": "DROP INDEX IF EXISTS codeintel_path_rank_inputs_graph_key_repository_name_id_processed;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1667433265,
					1667497565,
					1667500111
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1667863757,
				"Name": "Drop old index",
				"UpQuery": "DROP INDEX IF EXISTS codeintel_path_rank_graph_key_id_repository_name_processed;",
				"DownQuery": "CREATE INDEX IF NOT EXISTS codeintel_path_rank_graph_key_id_repository_name_processed ON codeintel_path_rank_inputs(graph_key, id, repository_name)\nWHERE\n    NOT processed;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1667848448
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1667917030,
				"Name": "Fix codeintel_ranking_exports index order",
				"UpQuery": "CREATE UNIQUE INDEX IF NOT EXISTS codeintel_ranking_exports_graph_key_upload_id ON codeintel_ranking_exports(graph_key, upload_id);\n\nDROP INDEX IF EXISTS codeintel_ranking_exports_upload_id_graph_key;",
				"DownQuery": "CREATE UNIQUE INDEX IF NOT EXISTS codeintel_ranking_exports_upload_id_graph_key ON codeintel_ranking_exports(upload_id, graph_key);\n\nDROP INDEX IF EXISTS codeintel_ranking_exports_graph_key_upload_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1667863757
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1667950421,
				"Name": "Speed up ListSourcegraphDotComIndexableRepos",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS repo_dotcom_indexable_repos_idx ON repo (stars DESC NULLS LAST) INCLUDE (id, name)\nWHERE\n    deleted_at IS NULL AND blocked IS NULL AND (\n        (repo.stars \u003e= 5 AND NOT COALESCE(fork, false) AND NOT archived)\n        OR\n        (lower(repo.name) ~ '^(src\\.fedoraproject\\.org|maven|npm|jdk)')\n    );",
				"DownQuery": "DROP INDEX IF EXISTS repo_dotcom_indexable_repos_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1667917030
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "repo",
					"IndexName": "repo_dotcom_indexable_repos_idx"
				}
			},
			{
				"ID": 1667952974,
				"Name": "Speed up ListSourcegraphDotComIndexableRepos (part 2)",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS gitserver_repos_not_explicitly_cloned_idx ON gitserver_repos (repo_id) WHERE clone_status \u003c\u003e 'cloned';",
				"DownQuery": "DROP INDEX IF EXISTS gitserver_repos_not_explicitly_cloned_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1667950421
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "gitserver_repos",
					"IndexName": "gitserver_repos_not_explicitly_cloned_idx"
				}
			},
			{
				"ID": 1668174127,
				"Name": "Add gitserver_repos_last_changed_idx",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS gitserver_repos_last_changed_idx ON gitserver_repos(last_changed, repo_id);",
				"DownQuery": "DROP INDEX IF EXISTS gitserver_repos_last_changed_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1667825028,
					1667952974
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "gitserver_repos",
					"IndexName": "gitserver_repos_last_changed_idx"
				}
			},
			{
				"ID": 1668184279,
				"Name": "remove git_status column from gitserver_repos table",
				"UpQuery": "-- Perform migration here.\n--\n-- See /migrations/README.md. Highlights:\n--  * Make migrations idempotent (use IF EXISTS)\n--  * Make migrations backwards-compatible (old readers/writers must continue to work)\n--  * If you are using CREATE INDEX CONCURRENTLY, then make sure that only one statement\n--    is defined per file, and that each such statement is NOT wrapped in a transaction.\n--    Each such migration must also declare \"createIndexConcurrently: true\" in their\n--    associated metadata.yaml file.\n--  * If you are modifying Postgres extensions, you must also declare \"privileged: true\"\n--    in the associated metadata.yaml file.\n\nALTER TABLE gitserver_repos DROP COLUMN IF EXISTS repo_status;",
				"DownQuery": "-- Undo the changes made in the up migration\nALTER TABLE gitserver_repos\nADD COLUMN IF NOT EXISTS repo_status text;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1668174127
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1668179496,
				"Name": "Add event_logs_name_timestamp",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS event_logs_name_timestamp ON event_logs(name, timestamp desc);",
				"DownQuery": "DROP INDEX IF EXISTS event_logs_name_timestamp;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1667825028,
					1667952974
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "event_logs",
					"IndexName": "event_logs_name_timestamp"
				}
			},
			{
				"ID": 1668179619,
				"Name": "Drop redundant index",
				"UpQuery": "DROP INDEX IF EXISTS event_logs_name;",
				"DownQuery": "CREATE INDEX IF NOT EXISTS event_logs_name ON event_logs(name);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1668179496
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1668603582,
				"Name": "add gitserver.repo_size_bytes index",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS gitserver_repo_size_bytes\n    ON gitserver_repos USING btree (repo_size_bytes);",
				"DownQuery": "DROP INDEX IF EXISTS gitserver_repo_size_bytes;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1668179619,
					1668184279
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "gitserver_repos",
					"IndexName": "gitserver_repo_size_bytes"
				}
			},
			{
				"ID": 1668707631,
				"Name": "add_unique_constraint_batch_specs_rand_id",
				"UpQuery": "CREATE UNIQUE INDEX\n    IF NOT EXISTS batch_specs_unique_rand_id ON batch_specs (rand_id);",
				"DownQuery": "DROP INDEX IF EXISTS batch_specs_unique_rand_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1668603582
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1668767882,
				"Name": "add_unique_constraint_changeset_specs_rand_id",
				"UpQuery": "CREATE UNIQUE INDEX\n    IF NOT EXISTS changeset_specs_unique_rand_id ON changeset_specs (rand_id);",
				"DownQuery": "DROP INDEX IF EXISTS changeset_specs_unique_rand_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1668707631
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1668808118,
				"Name": "temp_codeinsights_trace_with_query",
				"UpQuery": "ALTER TABLE IF EXISTS insights_query_runner_jobs\n    ADD COLUMN IF NOT EXISTS trace_id TEXT;",
				"DownQuery": "ALTER TABLE IF EXISTS insights_query_runner_jobs\n    DROP COLUMN IF EXISTS trace_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1668603582
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1669184869,
				"Name": "add name to webhooks table",
				"UpQuery": "ALTER TABLE webhooks\n    ADD COLUMN IF NOT EXISTS name TEXT;\n\nCOMMENT ON COLUMN webhooks.name IS 'Descriptive name of a webhook.';\n\nUPDATE webhooks SET name = code_host_urn WHERE name IS NULL;\n\nALTER TABLE webhooks\n    ALTER COLUMN name SET NOT NULL;",
				"DownQuery": "ALTER TABLE webhooks\n    DROP COLUMN IF EXISTS name;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1666398757,
					1668808118
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1669297489,
				"Name": "add_permission_sync_jobs",
				"UpQuery": "CREATE TABLE IF NOT EXISTS permission_sync_jobs (\n  id                SERIAL PRIMARY KEY,\n  state             text DEFAULT 'queued',\n  failure_message   text,\n  queued_at         timestamp with time zone DEFAULT NOW(),\n  started_at        timestamp with time zone,\n  finished_at       timestamp with time zone,\n  process_after     timestamp with time zone,\n  num_resets        integer not null default 0,\n  num_failures      integer not null default 0,\n  last_heartbeat_at timestamp with time zone,\n  execution_logs    json[],\n  worker_hostname   text not null default '',\n  cancel            boolean not null default false,\n\n  repository_id integer,\n  user_id       integer,\n\n  high_priority     boolean not null default false,\n  invalidate_caches boolean not null default false\n);\n\nCREATE INDEX IF NOT EXISTS permission_sync_jobs_state ON permission_sync_jobs (state);\nCREATE INDEX IF NOT EXISTS permission_sync_jobs_process_after ON permission_sync_jobs (process_after);\nCREATE INDEX IF NOT EXISTS permission_sync_jobs_repository_id ON permission_sync_jobs (repository_id);\nCREATE INDEX IF NOT EXISTS permission_sync_jobs_user_id ON permission_sync_jobs (user_id);",
				"DownQuery": "DROP TABLE IF EXISTS permission_sync_jobs;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1669184869
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1669576792,
				"Name": "Make batch spec of batch change nullable",
				"UpQuery": "ALTER TABLE batch_changes ALTER COLUMN batch_spec_id DROP NOT NULL;\n\nCREATE TEMPORARY TABLE minimal_batch_specs (id bigint);\n\nINSERT INTO minimal_batch_specs\nSELECT batch_spec_id FROM batch_changes WHERE batch_spec_id IS NOT NULL AND last_applied_at IS NULL;\n\nUPDATE batch_changes SET batch_spec_id = NULL WHERE batch_spec_id IN (SELECT id FROM minimal_batch_specs);\n\n-- Delete existing empty batch specs.\nDELETE FROM batch_specs WHERE id IN (SELECT id FROM minimal_batch_specs);-- Delete existing empty batch specs.\n\nDROP TABLE minimal_batch_specs;",
				"DownQuery": "WITH reconstructed_batch_specs AS (\n    INSERT INTO batch_specs\n        (batch_change_id, user_id, namespace_user_id, namespace_org_id, rand_id, raw_spec, spec, created_from_raw)\n    SELECT\n        id, creator_id, namespace_user_id, namespace_org_id, md5(CONCAT(id, name)::bytea), CONCAT('name: ', name), json_build_object('name', name), TRUE\n    FROM\n        batch_changes\n    WHERE\n        batch_spec_id IS NULL\n    RETURNING\n\t    batch_change_id, id\n)\nUPDATE\n    batch_changes\nSET batch_spec_id = (SELECT id FROM reconstructed_batch_specs WHERE batch_change_id = batch_changes.id)\nWHERE id IN (SELECT batch_change_id FROM reconstructed_batch_specs);\n\nALTER TABLE batch_changes ALTER COLUMN batch_spec_id SET NOT NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1669184869
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1669645608,
				"Name": "Make batch change name pattern",
				"UpQuery": "ALTER TABLE batch_changes DROP CONSTRAINT IF EXISTS batch_change_name_is_valid;\nALTER TABLE batch_changes ADD CONSTRAINT batch_change_name_is_valid CHECK (name ~ '^[\\w.-]+$');",
				"DownQuery": "ALTER TABLE batch_changes DROP CONSTRAINT IF EXISTS batch_change_name_is_valid;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1669576792
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1669836151,
				"Name": "Add manager to lsif_package/references",
				"UpQuery": "ALTER TABLE lsif_packages ADD COLUMN IF NOT EXISTS manager TEXT NOT NULL DEFAULT '';\nALTER TABLE lsif_references ADD COLUMN IF NOT EXISTS manager TEXT NOT NULL DEFAULT '';\n\nCOMMENT ON COLUMN lsif_packages.manager IS 'The package manager name.';\nCOMMENT ON COLUMN lsif_references.manager IS 'The package manager name.';",
				"DownQuery": "ALTER TABLE lsif_packages DROP COLUMN IF EXISTS manager;\nALTER TABLE lsif_references DROP COLUMN IF EXISTS manager;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1668767882,
					1669184869
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1670256530,
				"Name": "Add content type to lsif uploads",
				"UpQuery": "DROP VIEW IF EXISTS lsif_uploads_with_repository_name;\nALTER TABLE lsif_uploads ADD COLUMN IF NOT EXISTS content_type TEXT NOT NULL DEFAULT 'application/x-ndjson+lsif';\nALTER TABLE lsif_uploads_audit_logs ADD COLUMN IF NOT EXISTS content_type TEXT NOT NULL DEFAULT 'application/x-ndjson+lsif';\n\nCOMMENT ON COLUMN lsif_uploads.content_type IS 'The content type of the upload record. For now, the default value is `application/x-ndjson+lsif` to backfill existing records. This will change as we remove LSIF support.';\n\nCREATE VIEW lsif_uploads_with_repository_name AS\nSELECT u.id,\n    u.commit,\n    u.root,\n    u.queued_at,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.indexer_version,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.content_type,\n    u.expired,\n    u.last_retention_scan_at,\n    r.name AS repository_name,\n    u.uncompressed_size\nFROM lsif_uploads u\nJOIN repo r ON r.id = u.repository_id\nWHERE r.deleted_at IS NULL;\n\nCREATE OR REPLACE FUNCTION func_lsif_uploads_update() RETURNS TRIGGER AS $$\n    DECLARE\n        diff hstore[];\n    BEGIN\n        diff = func_lsif_uploads_transition_columns_diff(\n            func_row_to_lsif_uploads_transition_columns(OLD),\n            func_row_to_lsif_uploads_transition_columns(NEW)\n        );\n\n        IF (array_length(diff, 1) \u003e 0) THEN\n            INSERT INTO lsif_uploads_audit_logs\n            (reason, upload_id, commit, root, repository_id, uploaded_at,\n            indexer, indexer_version, upload_size, associated_index_id,\n            content_type,\n            operation, transition_columns)\n            VALUES (\n                COALESCE(current_setting('codeintel.lsif_uploads_audit.reason', true), ''),\n                NEW.id, NEW.commit, NEW.root, NEW.repository_id, NEW.uploaded_at,\n                NEW.indexer, NEW.indexer_version, NEW.upload_size, NEW.associated_index_id,\n                NEW.content_type,\n                'modify', diff\n            );\n        END IF;\n\n        RETURN NEW;\n    END;\n$$ LANGUAGE plpgsql;\n\nCREATE OR REPLACE FUNCTION func_lsif_uploads_insert() RETURNS TRIGGER AS $$\n    BEGIN\n        INSERT INTO lsif_uploads_audit_logs\n        (upload_id, commit, root, repository_id, uploaded_at,\n        indexer, indexer_version, upload_size, associated_index_id,\n        content_type,\n        operation, transition_columns)\n        VALUES (\n            NEW.id, NEW.commit, NEW.root, NEW.repository_id, NEW.uploaded_at,\n            NEW.indexer, NEW.indexer_version, NEW.upload_size, NEW.associated_index_id,\n            NEW.content_type,\n            'create', func_lsif_uploads_transition_columns_diff(\n                (NULL, NULL, NULL, NULL, NULL, NULL),\n                func_row_to_lsif_uploads_transition_columns(NEW)\n            )\n        );\n        RETURN NULL;\n    END;\n$$ LANGUAGE plpgsql;",
				"DownQuery": "CREATE OR REPLACE FUNCTION func_lsif_uploads_update() RETURNS TRIGGER AS $$\n    DECLARE\n        diff hstore[];\n    BEGIN\n        diff = func_lsif_uploads_transition_columns_diff(\n            func_row_to_lsif_uploads_transition_columns(OLD),\n            func_row_to_lsif_uploads_transition_columns(NEW)\n        );\n\n        IF (array_length(diff, 1) \u003e 0) THEN\n            INSERT INTO lsif_uploads_audit_logs\n            (reason, upload_id, commit, root, repository_id, uploaded_at,\n            indexer, indexer_version, upload_size, associated_index_id,\n            operation, transition_columns)\n            VALUES (\n                COALESCE(current_setting('codeintel.lsif_uploads_audit.reason', true), ''),\n                NEW.id, NEW.commit, NEW.root, NEW.repository_id, NEW.uploaded_at,\n                NEW.indexer, NEW.indexer_version, NEW.upload_size, NEW.associated_index_id,\n                'modify', diff\n            );\n        END IF;\n\n        RETURN NEW;\n    END;\n$$ LANGUAGE plpgsql;\n\nCREATE OR REPLACE FUNCTION func_lsif_uploads_insert() RETURNS TRIGGER AS $$\n    BEGIN\n        INSERT INTO lsif_uploads_audit_logs\n        (upload_id, commit, root, repository_id, uploaded_at,\n        indexer, indexer_version, upload_size, associated_index_id,\n        operation, transition_columns)\n        VALUES (\n            NEW.id, NEW.commit, NEW.root, NEW.repository_id, NEW.uploaded_at,\n            NEW.indexer, NEW.indexer_version, NEW.upload_size, NEW.associated_index_id,\n            'create', func_lsif_uploads_transition_columns_diff(\n                (NULL, NULL, NULL, NULL, NULL, NULL),\n                func_row_to_lsif_uploads_transition_columns(NEW)\n            )\n        );\n        RETURN NULL;\n    END;\n$$ LANGUAGE plpgsql;\n\nDROP VIEW IF EXISTS lsif_uploads_with_repository_name;\nALTER TABLE lsif_uploads DROP COLUMN IF EXISTS content_type;\nALTER TABLE lsif_uploads_audit_logs DROP COLUMN IF EXISTS content_type;\n\nCREATE VIEW lsif_uploads_with_repository_name AS \nSELECT u.id,\n    u.commit,\n    u.root,\n    u.queued_at,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.indexer_version,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.expired,\n    u.last_retention_scan_at,\n    r.name AS repository_name,\n    u.uncompressed_size\nFROM lsif_uploads u\nJOIN repo r ON r.id = u.repository_id\nWHERE r.deleted_at IS NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1669836151
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1668813365,
				"Name": "create_search_contexts_stars_defaults",
				"UpQuery": "CREATE TABLE IF NOT EXISTS search_context_stars (\n    search_context_id bigint REFERENCES search_contexts(id) ON DELETE CASCADE DEFERRABLE,\n    user_id integer REFERENCES users(id) ON DELETE CASCADE DEFERRABLE,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    PRIMARY KEY (search_context_id, user_id)\n);\n\nCOMMENT ON TABLE search_context_stars IS 'When a user stars a search context, a row is inserted into this table. If the user unstars the search context, the row is deleted. The global context is not in the database, and therefore cannot be starred.';\n\nCREATE TABLE IF NOT EXISTS search_context_default (\n    user_id integer PRIMARY KEY REFERENCES users(id) ON DELETE CASCADE DEFERRABLE,\n    search_context_id bigint NOT NULL REFERENCES search_contexts(id) ON DELETE CASCADE DEFERRABLE\n);\n\nCOMMENT ON TABLE search_context_default IS 'When a user sets a search context as default, a row is inserted into this table. A user can only have one default search context. If the user has not set their default search context, it will fall back to `global`.';",
				"DownQuery": "DROP TABLE IF EXISTS search_context_stars;\n\nDROP TABLE IF EXISTS search_context_default;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1668603582
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1670350006,
				"Name": "add_should_reindex_to_lsif_uploads",
				"UpQuery": "ALTER TABLE lsif_uploads ADD COLUMN IF NOT EXISTS should_reindex boolean NOT NULL DEFAULT false;",
				"DownQuery": "ALTER TABLE lsif_uploads DROP COLUMN IF EXISTS should_reindex;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1668813365,
					1670256530
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1670539388,
				"Name": "create_roles_table",
				"UpQuery": "CREATE TABLE IF NOT EXISTS roles (\n    id SERIAL PRIMARY KEY,\n    name TEXT NOT NULL,\n\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW() NOT NULL,\n    deleted_at TIMESTAMP WITH TIME ZONE,\n\n    CONSTRAINT name_not_blank CHECK ((name \u003c\u003e ''::text)),\n    CONSTRAINT roles_name UNIQUE (name)\n);\n\nCOMMENT ON COLUMN roles.name IS 'The uniquely identifying name of the role.';",
				"DownQuery": "DROP TABLE IF EXISTS roles;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1668813365,
					1670256530
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1670539913,
				"Name": "create_permissions_table",
				"UpQuery": "CREATE TABLE IF NOT EXISTS permissions (\n    id SERIAL PRIMARY KEY,\n    namespace text NOT NULL,\n    action TEXT NOT NULL,\n\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n\n    CONSTRAINT namespace_not_blank CHECK (namespace \u003c\u003e ''::text),\n    CONSTRAINT action_not_blank CHECK (action \u003c\u003e ''::text)\n);\n\n-- Enforce uniqueness of actions in a given namespace\nCREATE UNIQUE INDEX IF NOT EXISTS permissions_unique_namespace_action ON permissions (namespace, action);",
				"DownQuery": "DROP TABLE IF EXISTS permissions;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1670539388
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1670542168,
				"Name": "create_user_roles_table",
				"UpQuery": "CREATE TABLE IF NOT EXISTS user_roles (\n    user_id integer REFERENCES users(id) ON DELETE CASCADE DEFERRABLE,\n    role_id integer REFERENCES roles(id) ON DELETE CASCADE DEFERRABLE,\n\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n\n    PRIMARY KEY (user_id, role_id)\n);",
				"DownQuery": "DROP TABLE IF EXISTS user_roles;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1670539913
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1670543231,
				"Name": "create_role_permissions_table",
				"UpQuery": "CREATE TABLE IF NOT EXISTS role_permissions (\n    role_id integer REFERENCES roles(id) ON DELETE CASCADE DEFERRABLE,\n    permission_id integer REFERENCES permissions(id) ON DELETE CASCADE DEFERRABLE,\n\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n\n    PRIMARY KEY (permission_id, role_id)\n);",
				"DownQuery": "DROP TABLE IF EXISTS role_permissions;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1670542168
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1670870072,
				"Name": "add_read_only_column_roles",
				"UpQuery": "ALTER TABLE roles\n    ADD COLUMN IF NOT EXISTS readonly BOOLEAN DEFAULT FALSE;\n\nCOMMENT ON COLUMN roles.readonly IS 'This is used to indicate whether a role is read-only or can be modified.';\n\nUPDATE roles SET readonly = FALSE;\n\nALTER TABLE roles\n    ALTER COLUMN readonly SET NOT NULL;",
				"DownQuery": "ALTER TABLE roles\n    DROP COLUMN IF EXISTS readonly;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1670350006,
					1670543231
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1670934184,
				"Name": "add_gitserver_corruption_columns",
				"UpQuery": "ALTER TABLE gitserver_repos\n    ADD COLUMN IF NOT EXISTS corrupted_at TIMESTAMP WITH TIME ZONE,\n    ADD COLUMN IF NOT EXISTS corruption_logs JSONB NOT NULL DEFAULT '[]';\n\nCOMMENT ON COLUMN gitserver_repos.corrupted_at IS 'Timestamp of when repo corruption was detected';\nCOMMENT ON COLUMN gitserver_repos.corruption_logs IS 'Log output of repo corruptions that have been detected - encoded as json';",
				"DownQuery": "ALTER TABLE gitserver_repos\n    DROP COLUMN IF EXISTS corrupted_at,\n    DROP COLUMN IF EXISTS corrupted_logs;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1670350006,
					1670543231
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1670600028,
				"Name": "executor_secrets_accesslogs_codeintel_user",
				"UpQuery": "ALTER TABLE executor_secret_access_logs\nADD COLUMN IF NOT EXISTS machine_user text NOT NULL DEFAULT '';\n\nALTER TABLE executor_secret_access_logs\nDROP CONSTRAINT IF EXISTS user_id_or_machine_user;\n\nALTER TABLE executor_secret_access_logs\nADD CONSTRAINT user_id_or_machine_user\nCHECK (\n    (user_id IS NULL AND machine_user \u003c\u003e '') OR\n    (user_id IS NOT NULL AND machine_user = '')\n);\n\nALTER TABLE executor_secret_access_logs\nALTER COLUMN user_id\nDROP NOT NULL;\n\nDO $$\nBEGIN\n    IF EXISTS (\n        SELECT 1 FROM information_schema.tables\n        WHERE\n            table_name = 'executor_secret_access_logs_machineuser_bak_1670600028' AND\n            table_schema = current_schema()\n    ) THEN\n        DECLARE\n            err_details text;\n        BEGIN\n            INSERT INTO executor_secret_access_logs\n            SELECT * FROM executor_secret_access_logs_machineuser_bak_1670600028;\n        EXCEPTION WHEN unique_violation THEN\n            GET STACKED DIAGNOSTICS err_details = PG_EXCEPTION_DETAIL;\n            RAISE unique_violation\n                USING MESSAGE = SQLERRM,\n                DETAIL = err_details,\n                HINT = 'This up-migration attempts to re-insert executor secret access logs '\n                'from a backup table that would have lost information due to the associated '\n                'down-migration changing the table schema. In doing so, a unique violation exception '\n                'occurred and will have to be resolved manually. The backed up access logs are stored '\n                'in the executor_secret_access_logs_machineuser_bak_1670600028 table.';\n        END;\n    END IF;\nEND\n$$;\n\nDROP TABLE IF EXISTS executor_secret_access_logs_machineuser_bak_1670600028;\n\nALTER TABLE lsif_indexes\nADD COLUMN IF NOT EXISTS requested_envvars text[];\n\nDROP VIEW IF EXISTS lsif_indexes_with_repository_name;\n\nCREATE VIEW lsif_indexes_with_repository_name AS\n    SELECT u.id,\n        u.commit,\n        u.queued_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.process_after,\n        u.num_resets,\n        u.num_failures,\n        u.docker_steps,\n        u.root,\n        u.indexer,\n        u.indexer_args,\n        u.outfile,\n        u.log_contents,\n        u.execution_logs,\n        u.local_steps,\n        u.should_reindex,\n        u.requested_envvars,\n        r.name AS repository_name\n    FROM (lsif_indexes u\n        JOIN repo r ON ((r.id = u.repository_id)))\n    WHERE (r.deleted_at IS NULL);",
				"DownQuery": "DO $$\nBEGIN\n    IF NOT EXISTS (\n        SELECT 1 FROM information_schema.tables\n        WHERE\n            table_name = 'executor_secret_access_logs_machineuser_bak_1670600028' AND\n            table_schema = current_schema()\n    ) THEN\n        -- create and copy\n        CREATE TABLE executor_secret_access_logs_machineuser_bak_1670600028 AS\n        SELECT * FROM executor_secret_access_logs\n        -- these two should match the same rows, but just in case\n        WHERE machine_user \u003c\u003e '' OR user_id IS NULL;\n    ELSEIF EXISTS (\n        -- must check for double-down idempotency test\n        SELECT 1 FROM information_schema.columns\n        WHERE\n            table_name = 'executor_secret_access_logs' AND\n            table_schema = current_schema() AND\n            column_name = 'machine_user'\n    ) THEN\n        -- copy over any rows that may have been added since (unlikely edge-case)\n        INSERT INTO executor_secret_access_logs_machineuser_bak_1670600028\n        SELECT * FROM executor_secret_access_logs AS esal\n        LEFT JOIN executor_secret_access_logs_machineuser_bak_1670600028 AS bak\n        ON esal.id = bak.id\n        WHERE bak.id IS NULL AND esal.machine_user \u003c\u003e '' OR esal.user_id IS NULL;\n    END IF;\nEND\n$$;\n\nALTER TABLE executor_secret_access_logs\nDROP CONSTRAINT IF EXISTS user_id_or_machine_user;\n\nALTER TABLE executor_secret_access_logs\nDROP COLUMN IF EXISTS machine_user;\n\nDELETE FROM executor_secret_access_logs WHERE user_id IS NULL;\n\nALTER TABLE executor_secret_access_logs\nALTER COLUMN user_id\nSET NOT NULL;\n\nDROP VIEW IF EXISTS lsif_indexes_with_repository_name;\n\nCREATE VIEW lsif_indexes_with_repository_name AS\n    SELECT u.id,\n        u.commit,\n        u.queued_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.process_after,\n        u.num_resets,\n        u.num_failures,\n        u.docker_steps,\n        u.root,\n        u.indexer,\n        u.indexer_args,\n        u.outfile,\n        u.log_contents,\n        u.execution_logs,\n        u.local_steps,\n        u.should_reindex,\n        r.name AS repository_name\n    FROM (lsif_indexes u\n        JOIN repo r ON ((r.id = u.repository_id)))\n    WHERE (r.deleted_at IS NULL);\n\nALTER TABLE lsif_indexes\nDROP COLUMN IF EXISTS requested_envvars;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1668813365,
					1670256530
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1671159453,
				"Name": "outbound webhooks",
				"UpQuery": "-- Create the basic outbound webhook registry table.\nCREATE TABLE IF NOT EXISTS outbound_webhooks (\n    id BIGSERIAL NOT NULL PRIMARY KEY,\n    created_by INTEGER NULL REFERENCES users (id) ON DELETE SET NULL,\n    created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n    updated_by INTEGER NULL REFERENCES users (id) ON DELETE SET NULL,\n    updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n    encryption_key_id TEXT NULL,\n    url BYTEA NOT NULL,\n    secret BYTEA NOT NULL\n);\n\n-- Each webhook can have one or many event types associated with it, so we'll\n-- use a separate table to track that.\nCREATE TABLE IF NOT EXISTS outbound_webhook_event_types (\n    id BIGSERIAL NOT NULL PRIMARY KEY,\n    outbound_webhook_id BIGINT NOT NULL REFERENCES outbound_webhooks (id) ON DELETE CASCADE ON UPDATE CASCADE,\n    event_type TEXT NOT NULL,\n    scope TEXT NULL\n);\n\nCREATE INDEX IF NOT EXISTS outbound_webhook_event_types_event_type_idx\nON outbound_webhook_event_types (event_type, scope);\n\nDROP VIEW IF EXISTS outbound_webhooks_with_event_types;\n\n-- Most of the time we interact with webhooks from code, we want to also hydrate\n-- the event types. This view does exactly that.\nCREATE VIEW outbound_webhooks_with_event_types AS\nSELECT\n    id,\n    created_by,\n    created_at,\n    updated_by,\n    updated_at,\n    encryption_key_id,\n    url,\n    secret,\n    array_to_json(\n        array(\n            SELECT\n                json_build_object(\n                    'id', id,\n                    'outbound_webhook_id', outbound_webhook_id,\n                    'event_type', event_type,\n                    'scope', scope\n                )\n            FROM\n                outbound_webhook_event_types\n            WHERE\n                outbound_webhook_id = outbound_webhooks.id\n        )\n     ) AS event_types\nFROM\n    outbound_webhooks;\n\n-- Create a table to track outbound webhook worker jobs.\nCREATE TABLE IF NOT EXISTS outbound_webhook_jobs (\n    id BIGSERIAL NOT NULL PRIMARY KEY,\n\n    -- Requirements to send a payload.\n    event_type TEXT NOT NULL,\n    scope TEXT NULL,\n    encryption_key_id TEXT NULL,\n    payload BYTEA NOT NULL,\n\n    -- Generic worker fields.\n    state TEXT NOT NULL DEFAULT 'queued',\n    failure_message TEXT,\n    queued_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n    started_at TIMESTAMP WITH TIME ZONE,\n    finished_at TIMESTAMP WITH TIME ZONE,\n    process_after TIMESTAMP WITH TIME ZONE,\n    num_resets INTEGER NOT NULL DEFAULT 0,\n    num_failures INTEGER NOT NULL DEFAULT 0,\n    last_heartbeat_at TIMESTAMP WITH TIME ZONE NULL,\n    execution_logs JSON[],\n    worker_hostname TEXT NOT NULL DEFAULT '',\n    cancel BOOLEAN NOT NULL DEFAULT FALSE\n);\n\nCREATE INDEX IF NOT EXISTS outbound_webhook_jobs_state_idx\nON outbound_webhook_jobs (state);\n\nCREATE INDEX IF NOT EXISTS outbound_webhook_payload_process_after_idx\nON outbound_webhook_jobs (process_after);\n\n-- Create a table to store outbound webhook logs.\nCREATE TABLE IF NOT EXISTS outbound_webhook_logs (\n    id BIGSERIAL NOT NULL PRIMARY KEY,\n    job_id BIGINT NOT NULL REFERENCES outbound_webhook_jobs (id) ON DELETE CASCADE ON UPDATE CASCADE,\n    outbound_webhook_id BIGINT NOT NULL REFERENCES outbound_webhooks (id) ON DELETE CASCADE ON UPDATE CASCADE,\n    sent_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n    status_code INTEGER NOT NULL,\n    encryption_key_id TEXT NULL,\n    request BYTEA NOT NULL,\n    response BYTEA NOT NULL,\n    error BYTEA NOT NULL\n);\n\nCREATE INDEX IF NOT EXISTS outbound_webhook_logs_outbound_webhook_id_idx\nON outbound_webhook_logs (outbound_webhook_id);\n\nCREATE INDEX IF NOT EXISTS outbound_webhooks_logs_status_code_idx\nON outbound_webhook_logs (status_code);",
				"DownQuery": "DROP TABLE IF EXISTS outbound_webhook_logs;\nDROP TABLE IF EXISTS outbound_webhook_jobs;\n\nDROP VIEW IF EXISTS outbound_webhooks_with_event_types;\n\nDROP TABLE IF EXISTS outbound_webhook_event_types;\nDROP TABLE IF EXISTS outbound_webhooks;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1669645608,
					1670600028,
					1670870072
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1671463799,
				"Name": "Teams",
				"UpQuery": "CREATE TABLE IF NOT EXISTS teams (\n    id SERIAL PRIMARY KEY,\n    name citext NOT NULL CONSTRAINT teams_name_max_length CHECK (char_length(name::text) \u003c= 255) CONSTRAINT teams_name_valid_chars CHECK (name ~ '^[a-zA-Z0-9](?:[a-zA-Z0-9]|[-.](?=[a-zA-Z0-9]))*-?$'::citext),\n    display_name text CONSTRAINT teams_display_name_max_length CHECK (char_length(display_name) \u003c= 255),\n    readonly boolean NOT NULL DEFAULT false,\n    parent_team_id integer REFERENCES teams(id) ON DELETE CASCADE,\n    creator_id integer NOT NULL REFERENCES users(id) ON DELETE SET NULL,\n    created_at timestamp with time zone NOT NULL DEFAULT now(),\n    updated_at timestamp with time zone NOT NULL DEFAULT now()\n);\n\nCREATE UNIQUE INDEX IF NOT EXISTS teams_name ON teams(name);\n\nCREATE TABLE IF NOT EXISTS team_members (\n    team_id integer NOT NULL REFERENCES teams(id) ON DELETE CASCADE,\n    user_id integer NOT NULL REFERENCES users(id) ON DELETE CASCADE,\n    created_at timestamp with time zone NOT NULL DEFAULT now(),\n    updated_at timestamp with time zone NOT NULL DEFAULT now(),\n    CONSTRAINT team_members_team_id_user_id_key UNIQUE (team_id, user_id),\n    PRIMARY KEY(team_id, user_id)\n);\n\nALTER TABLE names ADD COLUMN IF NOT EXISTS team_id integer REFERENCES teams(id) ON UPDATE CASCADE ON DELETE CASCADE;\nALTER TABLE names DROP CONSTRAINT IF EXISTS names_check;\nALTER TABLE names ADD CONSTRAINT names_check CHECK (user_id IS NOT NULL OR org_id IS NOT NULL OR team_id IS NOT NULL);",
				"DownQuery": "ALTER TABLE names DROP CONSTRAINT IF EXISTS names_check;\n\nALTER TABLE names DROP COLUMN IF EXISTS team_id;\n\nALTER TABLE names ADD CONSTRAINT names_check CHECK (user_id IS NOT NULL OR org_id IS NOT NULL);\n\nDROP TABLE IF EXISTS team_members;\n\nDROP TABLE IF EXISTS teams;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1669645608,
					1670600028,
					1670870072
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1671543381,
				"Name": "add_default_roles",
				"UpQuery": "-- system roles that come with every sourcegraph instance\nINSERT INTO\n    roles (id, name, created_at, deleted_at, readonly)\nVALUES\n    (1, 'USER', '2023-01-04 16:29:41.195966+00', NULL, TRUE),\n    (2, 'SITE_ADMINISTRATOR', '2023-01-04 16:29:41.195966+00', NULL, TRUE)\nON CONFLICT (id) DO NOTHING;\n\nSELECT pg_catalog.setval('roles_id_seq', 3, true);",
				"DownQuery": "DELETE FROM roles WHERE id IN (1, 2);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1669645608,
					1670600028,
					1670870072
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1672884222,
				"Name": "create_namespace_permissions_table",
				"UpQuery": "CREATE TABLE IF NOT EXISTS namespace_permissions (\n    id SERIAL PRIMARY KEY,\n    namespace text NOT NULL,\n    resource_id integer NOT NULL,\n    action text NOT NULL,\n\n    user_id integer REFERENCES users(id) ON DELETE CASCADE DEFERRABLE,\n\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n\n    CONSTRAINT namespace_not_blank CHECK (namespace \u003c\u003e ''::text),\n    CONSTRAINT action_not_blank CHECK (action \u003c\u003e ''::text),\n\n    CONSTRAINT unique_resource_permission UNIQUE (namespace, resource_id, action, user_id)\n);",
				"DownQuery": "DROP TABLE IF EXISTS namespace_permissions;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1669645608,
					1670600028,
					1670870072
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1673019611,
				"Name": "lsif_uploads_audit_logs_bigint_upload_size",
				"UpQuery": "ALTER TABLE lsif_uploads_audit_logs\nALTER COLUMN upload_size\nTYPE bigint;",
				"DownQuery": "ALTER TABLE lsif_uploads_audit_logs\nALTER COLUMN upload_size\nTYPE integer;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1672884222
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1672897105,
				"Name": "add column author_user_id to critical_and_site_config",
				"UpQuery": "ALTER TABLE critical_and_site_config\n      ADD COLUMN IF NOT EXISTS author_user_id integer;\nCOMMENT ON COLUMN critical_and_site_config.author_user_id IS 'A null value indicates that this config was most likely added by code on the start-up path, for example from the SITE_CONFIG_FILE unless the config itself was added before this column existed in which case it could also have been a user.';",
				"DownQuery": "ALTER TABLE critical_and_site_config\n      DROP COLUMN IF EXISTS author_user_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1669645608,
					1670600028,
					1670870072
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1673351808,
				"Name": "add_repo_corruption_stat",
				"UpQuery": "ALTER TABLE gitserver_repos_statistics\n  ADD COLUMN IF NOT EXISTS corrupted bigint NOT NULL DEFAULT 0;\nCOMMENT ON COLUMN gitserver_repos_statistics.corrupted IS 'Number of repositories that are NOT soft-deleted and not blocked and have corrupted_at set in gitserver_repos table';\n\nALTER TABLE repo_statistics\n  ADD COLUMN IF NOT EXISTS corrupted bigint NOT NULL DEFAULT 0;\nCOMMENT ON COLUMN repo_statistics.corrupted IS 'Number of repositories that are NOT soft-deleted and not blocked and have corrupted_at set in gitserver_repos table';\n\n--- repo UPDATE trigger\nCREATE OR REPLACE FUNCTION recalc_repo_statistics_on_repo_update() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$ BEGIN\n      -- Insert diff of changes\n      WITH diff(total, soft_deleted, not_cloned, cloning, cloned, failed_fetch, corrupted) AS (\n        VALUES (\n          (SELECT COUNT(*) FROM newtab WHERE deleted_at IS NULL     AND blocked IS NULL) - (SELECT COUNT(*) FROM oldtab WHERE deleted_at IS NULL     AND blocked IS NULL),\n          (SELECT COUNT(*) FROM newtab WHERE deleted_at IS NOT NULL AND blocked IS NULL) - (SELECT COUNT(*) FROM oldtab WHERE deleted_at IS NOT NULL AND blocked IS NULL),\n          (\n            (SELECT COUNT(*) FROM newtab JOIN gitserver_repos gr ON gr.repo_id = newtab.id WHERE newtab.deleted_at is NULL AND newtab.blocked IS NULL AND gr.clone_status = 'not_cloned')\n            -\n            (SELECT COUNT(*) FROM oldtab JOIN gitserver_repos gr ON gr.repo_id = oldtab.id WHERE oldtab.deleted_at is NULL AND oldtab.blocked IS NULL AND gr.clone_status = 'not_cloned')\n          ),\n          (\n            (SELECT COUNT(*) FROM newtab JOIN gitserver_repos gr ON gr.repo_id = newtab.id WHERE newtab.deleted_at is NULL AND newtab.blocked IS NULL AND gr.clone_status = 'cloning')\n            -\n            (SELECT COUNT(*) FROM oldtab JOIN gitserver_repos gr ON gr.repo_id = oldtab.id WHERE oldtab.deleted_at is NULL AND oldtab.blocked IS NULL AND gr.clone_status = 'cloning')\n          ),\n          (\n            (SELECT COUNT(*) FROM newtab JOIN gitserver_repos gr ON gr.repo_id = newtab.id WHERE newtab.deleted_at is NULL AND newtab.blocked IS NULL AND gr.clone_status = 'cloned')\n            -\n            (SELECT COUNT(*) FROM oldtab JOIN gitserver_repos gr ON gr.repo_id = oldtab.id WHERE oldtab.deleted_at is NULL AND oldtab.blocked IS NULL AND gr.clone_status = 'cloned')\n          ),\n          (\n            (SELECT COUNT(*) FROM newtab JOIN gitserver_repos gr ON gr.repo_id = newtab.id WHERE newtab.deleted_at is NULL AND newtab.blocked IS NULL AND gr.last_error IS NOT NULL)\n            -\n            (SELECT COUNT(*) FROM oldtab JOIN gitserver_repos gr ON gr.repo_id = oldtab.id WHERE oldtab.deleted_at is NULL AND oldtab.blocked IS NULL AND gr.last_error IS NOT NULL)\n          ),\n          (\n            (SELECT COUNT(*) FROM newtab JOIN gitserver_repos gr ON gr.repo_id = newtab.id WHERE newtab.deleted_at is NULL AND newtab.blocked IS NULL AND gr.corrupted_at IS NOT NULL)\n            -\n            (SELECT COUNT(*) FROM oldtab JOIN gitserver_repos gr ON gr.repo_id = oldtab.id WHERE oldtab.deleted_at is NULL AND oldtab.blocked IS NULL AND gr.corrupted_at IS NOT NULL)\n          )\n        )\n      )\n      INSERT INTO\n        repo_statistics (total, soft_deleted, not_cloned, cloning, cloned, failed_fetch, corrupted)\n      SELECT total, soft_deleted, not_cloned, cloning, cloned, failed_fetch, corrupted\n      FROM diff\n      WHERE\n           total != 0\n        OR soft_deleted != 0\n        OR not_cloned != 0\n        OR cloning != 0\n        OR cloned != 0\n        OR failed_fetch != 0\n        OR corrupted != 0\n      ;\n      RETURN NULL;\n  END\n$$;\n\nCREATE OR REPLACE FUNCTION recalc_gitserver_repos_statistics_on_update() RETURNS trigger\n    LANGUAGE plpgsql\n    -------------------------------------------------\n    -- IMPORTANT: THIS IS CHANGED TO INCLUDE `corrupted`\n    -------------------------------------------------\n    AS $$ BEGIN\n      INSERT INTO gitserver_repos_statistics AS grs (shard_id, total, not_cloned, cloning, cloned, failed_fetch, corrupted)\n      SELECT\n        newtab.shard_id AS shard_id,\n        COUNT(*) AS total,\n        COUNT(*) FILTER(WHERE clone_status = 'not_cloned')  AS not_cloned,\n        COUNT(*) FILTER(WHERE clone_status = 'cloning') AS cloning,\n        COUNT(*) FILTER(WHERE clone_status = 'cloned') AS cloned,\n        COUNT(*) FILTER(WHERE last_error IS NOT NULL) AS failed_fetch,\n        COUNT(*) FILTER(WHERE corrupted_at IS NOT NULL) AS corrupted\n      FROM\n        newtab\n      GROUP BY newtab.shard_id\n      ON CONFLICT(shard_id) DO\n      UPDATE\n      SET\n        total        = grs.total        + (excluded.total        - (SELECT COUNT(*)                                              FROM oldtab ot WHERE ot.shard_id = excluded.shard_id)),\n        not_cloned   = grs.not_cloned   + (excluded.not_cloned   - (SELECT COUNT(*) FILTER(WHERE ot.clone_status = 'not_cloned') FROM oldtab ot WHERE ot.shard_id = excluded.shard_id)),\n        cloning      = grs.cloning      + (excluded.cloning      - (SELECT COUNT(*) FILTER(WHERE ot.clone_status = 'cloning')    FROM oldtab ot WHERE ot.shard_id = excluded.shard_id)),\n        cloned       = grs.cloned       + (excluded.cloned       - (SELECT COUNT(*) FILTER(WHERE ot.clone_status = 'cloned')     FROM oldtab ot WHERE ot.shard_id = excluded.shard_id)),\n        failed_fetch = grs.failed_fetch + (excluded.failed_fetch - (SELECT COUNT(*) FILTER(WHERE ot.last_error IS NOT NULL)      FROM oldtab ot WHERE ot.shard_id = excluded.shard_id)),\n        corrupted    = grs.corrupted    + (excluded.corrupted    - (SELECT COUNT(*) FILTER(WHERE ot.corrupted_at IS NOT NULL)    FROM oldtab ot WHERE ot.shard_id = excluded.shard_id))\n      ;\n\n      -------------------------------------------------\n      -- IMPORTANT: THIS IS CHANGED TO INCLUDE `corrupted`\n      -------------------------------------------------\n      WITH moved AS (\n        SELECT\n          oldtab.shard_id AS shard_id,\n          COUNT(*) AS total,\n          COUNT(*) FILTER(WHERE oldtab.clone_status = 'not_cloned')  AS not_cloned,\n          COUNT(*) FILTER(WHERE oldtab.clone_status = 'cloning') AS cloning,\n          COUNT(*) FILTER(WHERE oldtab.clone_status = 'cloned') AS cloned,\n          COUNT(*) FILTER(WHERE oldtab.last_error IS NOT NULL) AS failed_fetch,\n          COUNT(*) FILTER(WHERE oldtab.corrupted_at IS NOT NULL) AS corrupted\n        FROM\n          oldtab\n        JOIN newtab ON newtab.repo_id = oldtab.repo_id\n        WHERE\n          oldtab.shard_id != newtab.shard_id\n        GROUP BY oldtab.shard_id\n      )\n      UPDATE gitserver_repos_statistics grs\n      SET\n        total        = grs.total        - moved.total,\n        not_cloned   = grs.not_cloned   - moved.not_cloned,\n        cloning      = grs.cloning      - moved.cloning,\n        cloned       = grs.cloned       - moved.cloned,\n        failed_fetch = grs.failed_fetch - moved.failed_fetch,\n        corrupted    = grs.corrupted    - moved.corrupted\n      FROM moved\n      WHERE moved.shard_id = grs.shard_id;\n\n      -------------------------------------------------\n      -- IMPORTANT: THIS IS CHANGED TO INCLUDE `corrupted`\n      -------------------------------------------------\n      WITH diff(not_cloned, cloning, cloned, failed_fetch, corrupted) AS (\n        VALUES (\n          (\n            (SELECT COUNT(*) FROM newtab JOIN repo r ON newtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND newtab.clone_status = 'not_cloned')\n            -\n            (SELECT COUNT(*) FROM oldtab JOIN repo r ON oldtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND oldtab.clone_status = 'not_cloned')\n          ),\n          (\n            (SELECT COUNT(*) FROM newtab JOIN repo r ON newtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND newtab.clone_status = 'cloning')\n            -\n            (SELECT COUNT(*) FROM oldtab JOIN repo r ON oldtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND oldtab.clone_status = 'cloning')\n          ),\n          (\n            (SELECT COUNT(*) FROM newtab JOIN repo r ON newtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND newtab.clone_status = 'cloned')\n            -\n            (SELECT COUNT(*) FROM oldtab JOIN repo r ON oldtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND oldtab.clone_status = 'cloned')\n          ),\n          (\n            (SELECT COUNT(*) FROM newtab JOIN repo r ON newtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND newtab.last_error IS NOT NULL)\n            -\n            (SELECT COUNT(*) FROM oldtab JOIN repo r ON oldtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND oldtab.last_error IS NOT NULL)\n          ),\n          (\n            (SELECT COUNT(*) FROM newtab JOIN repo r ON newtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND newtab.corrupted_at IS NOT NULL)\n            -\n            (SELECT COUNT(*) FROM oldtab JOIN repo r ON oldtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND oldtab.corrupted_at IS NOT NULL)\n          )\n\n        )\n      )\n      INSERT INTO repo_statistics (not_cloned, cloning, cloned, failed_fetch, corrupted)\n      SELECT not_cloned, cloning, cloned, failed_fetch, corrupted\n      FROM diff\n      WHERE\n           not_cloned != 0\n        OR cloning != 0\n        OR cloned != 0\n        OR failed_fetch != 0\n        OR corrupted != 0\n      ;\n\n      RETURN NULL;\n  END\n$$;",
				"DownQuery": "ALTER TABLE gitserver_repos_statistics\n  DROP COLUMN IF EXISTS corrupted;\n\nALTER TABLE repo_statistics\n  DROP COLUMN IF EXISTS corrupted;\n\n--- Restore previous version of trigger\n--- repo UPDATE trigger\nCREATE OR REPLACE FUNCTION recalc_repo_statistics_on_repo_update() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$ BEGIN\n      -- Insert diff of changes\n      WITH diff(total, soft_deleted, not_cloned, cloning, cloned, failed_fetch) AS (\n        VALUES (\n          (SELECT COUNT(*) FROM newtab WHERE deleted_at IS NULL     AND blocked IS NULL) - (SELECT COUNT(*) FROM oldtab WHERE deleted_at IS NULL     AND blocked IS NULL),\n          (SELECT COUNT(*) FROM newtab WHERE deleted_at IS NOT NULL AND blocked IS NULL) - (SELECT COUNT(*) FROM oldtab WHERE deleted_at IS NOT NULL AND blocked IS NULL),\n          (\n            (SELECT COUNT(*) FROM newtab JOIN gitserver_repos gr ON gr.repo_id = newtab.id WHERE newtab.deleted_at is NULL AND newtab.blocked IS NULL AND gr.clone_status = 'not_cloned')\n            -\n            (SELECT COUNT(*) FROM oldtab JOIN gitserver_repos gr ON gr.repo_id = oldtab.id WHERE oldtab.deleted_at is NULL AND oldtab.blocked IS NULL AND gr.clone_status = 'not_cloned')\n          ),\n          (\n            (SELECT COUNT(*) FROM newtab JOIN gitserver_repos gr ON gr.repo_id = newtab.id WHERE newtab.deleted_at is NULL AND newtab.blocked IS NULL AND gr.clone_status = 'cloning')\n            -\n            (SELECT COUNT(*) FROM oldtab JOIN gitserver_repos gr ON gr.repo_id = oldtab.id WHERE oldtab.deleted_at is NULL AND oldtab.blocked IS NULL AND gr.clone_status = 'cloning')\n          ),\n          (\n            (SELECT COUNT(*) FROM newtab JOIN gitserver_repos gr ON gr.repo_id = newtab.id WHERE newtab.deleted_at is NULL AND newtab.blocked IS NULL AND gr.clone_status = 'cloned')\n            -\n            (SELECT COUNT(*) FROM oldtab JOIN gitserver_repos gr ON gr.repo_id = oldtab.id WHERE oldtab.deleted_at is NULL AND oldtab.blocked IS NULL AND gr.clone_status = 'cloned')\n          ),\n          (\n            (SELECT COUNT(*) FROM newtab JOIN gitserver_repos gr ON gr.repo_id = newtab.id WHERE newtab.deleted_at is NULL AND newtab.blocked IS NULL AND gr.last_error IS NOT NULL)\n            -\n            (SELECT COUNT(*) FROM oldtab JOIN gitserver_repos gr ON gr.repo_id = oldtab.id WHERE oldtab.deleted_at is NULL AND oldtab.blocked IS NULL AND gr.last_error IS NOT NULL)\n          )\n        )\n      )\n      INSERT INTO\n        repo_statistics (total, soft_deleted, not_cloned, cloning, cloned, failed_fetch)\n      SELECT total, soft_deleted, not_cloned, cloning, cloned, failed_fetch\n      FROM diff\n      WHERE\n           total != 0\n        OR soft_deleted != 0\n        OR not_cloned != 0\n        OR cloning != 0\n        OR cloned != 0\n        OR failed_fetch != 0\n      ;\n      RETURN NULL;\n  END\n$$;\n\nCREATE OR REPLACE FUNCTION recalc_gitserver_repos_statistics_on_update() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$ BEGIN\n      INSERT INTO gitserver_repos_statistics AS grs (shard_id, total, not_cloned, cloning, cloned, failed_fetch)\n      SELECT\n        newtab.shard_id AS shard_id,\n        COUNT(*) AS total,\n        COUNT(*) FILTER(WHERE clone_status = 'not_cloned')  AS not_cloned,\n        COUNT(*) FILTER(WHERE clone_status = 'cloning') AS cloning,\n        COUNT(*) FILTER(WHERE clone_status = 'cloned') AS cloned,\n        COUNT(*) FILTER(WHERE last_error IS NOT NULL) AS failed_fetch\n      FROM\n        newtab\n      GROUP BY newtab.shard_id\n      ON CONFLICT(shard_id) DO\n      UPDATE\n      SET\n        total        = grs.total        + (excluded.total        - (SELECT COUNT(*)                                              FROM oldtab ot WHERE ot.shard_id = excluded.shard_id)),\n        not_cloned   = grs.not_cloned   + (excluded.not_cloned   - (SELECT COUNT(*) FILTER(WHERE ot.clone_status = 'not_cloned') FROM oldtab ot WHERE ot.shard_id = excluded.shard_id)),\n        cloning      = grs.cloning      + (excluded.cloning      - (SELECT COUNT(*) FILTER(WHERE ot.clone_status = 'cloning')    FROM oldtab ot WHERE ot.shard_id = excluded.shard_id)),\n        cloned       = grs.cloned       + (excluded.cloned       - (SELECT COUNT(*) FILTER(WHERE ot.clone_status = 'cloned')     FROM oldtab ot WHERE ot.shard_id = excluded.shard_id)),\n        failed_fetch = grs.failed_fetch + (excluded.failed_fetch - (SELECT COUNT(*) FILTER(WHERE ot.last_error IS NOT NULL)      FROM oldtab ot WHERE ot.shard_id = excluded.shard_id))\n      ;\n\n      WITH moved AS (\n        SELECT\n          oldtab.shard_id AS shard_id,\n          COUNT(*) AS total,\n          COUNT(*) FILTER(WHERE oldtab.clone_status = 'not_cloned')  AS not_cloned,\n          COUNT(*) FILTER(WHERE oldtab.clone_status = 'cloning') AS cloning,\n          COUNT(*) FILTER(WHERE oldtab.clone_status = 'cloned') AS cloned,\n          COUNT(*) FILTER(WHERE oldtab.last_error IS NOT NULL) AS failed_fetch\n        FROM\n          oldtab\n        JOIN newtab ON newtab.repo_id = oldtab.repo_id\n        WHERE\n          oldtab.shard_id != newtab.shard_id\n        GROUP BY oldtab.shard_id\n      )\n      UPDATE gitserver_repos_statistics grs\n      SET\n        total        = grs.total        - moved.total,\n        not_cloned   = grs.not_cloned   - moved.not_cloned,\n        cloning      = grs.cloning      - moved.cloning,\n        cloned       = grs.cloned       - moved.cloned,\n        failed_fetch = grs.failed_fetch - moved.failed_fetch\n      FROM moved\n      WHERE moved.shard_id = grs.shard_id;\n\n      WITH diff(not_cloned, cloning, cloned, failed_fetch) AS (\n        VALUES (\n          (\n            (SELECT COUNT(*) FROM newtab JOIN repo r ON newtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND newtab.clone_status = 'not_cloned')\n            -\n            (SELECT COUNT(*) FROM oldtab JOIN repo r ON oldtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND oldtab.clone_status = 'not_cloned')\n          ),\n          (\n            (SELECT COUNT(*) FROM newtab JOIN repo r ON newtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND newtab.clone_status = 'cloning')\n            -\n            (SELECT COUNT(*) FROM oldtab JOIN repo r ON oldtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND oldtab.clone_status = 'cloning')\n          ),\n          (\n            (SELECT COUNT(*) FROM newtab JOIN repo r ON newtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND newtab.clone_status = 'cloned')\n            -\n            (SELECT COUNT(*) FROM oldtab JOIN repo r ON oldtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND oldtab.clone_status = 'cloned')\n          ),\n          (\n            (SELECT COUNT(*) FROM newtab JOIN repo r ON newtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND newtab.last_error IS NOT NULL)\n            -\n            (SELECT COUNT(*) FROM oldtab JOIN repo r ON oldtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND oldtab.last_error IS NOT NULL)\n          )\n        )\n      )\n      INSERT INTO repo_statistics (not_cloned, cloning, cloned, failed_fetch)\n      SELECT not_cloned, cloning, cloned, failed_fetch\n      FROM diff\n      WHERE\n           not_cloned != 0\n        OR cloning != 0\n        OR cloned != 0\n        OR failed_fetch != 0\n      ;\n\n      RETURN NULL;\n  END\n$$;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1670934184,
					1672897105,
					1673019611
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1673405886,
				"Name": "make batch spec of batch change not nullable again",
				"UpQuery": "-- This reverts a previous migration, so this is literally just 1669576792_make_batch_spec_of_batch_change_nullable/down.sql\nWITH reconstructed_batch_specs AS (\n    INSERT INTO batch_specs\n        (batch_change_id, user_id, namespace_user_id, namespace_org_id, rand_id, raw_spec, spec, created_from_raw)\n    SELECT\n        id, creator_id, namespace_user_id, namespace_org_id, md5(CONCAT(id, name)::bytea), CONCAT('name: ', name), json_build_object('name', name), TRUE\n    FROM\n        batch_changes\n    WHERE\n        batch_spec_id IS NULL\n    RETURNING\n\t    batch_change_id, id\n)\nUPDATE\n    batch_changes\nSET batch_spec_id = (SELECT id FROM reconstructed_batch_specs WHERE batch_change_id = batch_changes.id)\nWHERE id IN (SELECT batch_change_id FROM reconstructed_batch_specs);\n\nALTER TABLE batch_changes ALTER COLUMN batch_spec_id SET NOT NULL;",
				"DownQuery": "-- This is literally just 1669576792_make_batch_spec_of_batch_change_nullable/up.sql\nALTER TABLE batch_changes ALTER COLUMN batch_spec_id DROP NOT NULL;\n\nCREATE TEMPORARY TABLE minimal_batch_specs (id bigint);\n\nINSERT INTO minimal_batch_specs\nSELECT batch_spec_id FROM batch_changes WHERE batch_spec_id IS NOT NULL AND last_applied_at IS NULL;\n\nUPDATE batch_changes SET batch_spec_id = NULL WHERE batch_spec_id IN (SELECT id FROM minimal_batch_specs);\n\n-- Delete existing empty batch specs.\nDELETE FROM batch_specs WHERE id IN (SELECT id FROM minimal_batch_specs);-- Delete existing empty batch specs.\n\nDROP TABLE minimal_batch_specs;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1670934184,
					1672897105,
					1673019611
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1673871310,
				"Name": "add columns to permission_sync_jobs table",
				"UpQuery": "ALTER TABLE permission_sync_jobs\n    ADD COLUMN IF NOT EXISTS reason TEXT,\n    ADD COLUMN IF NOT EXISTS triggered_by_user_id INTEGER,\n    ADD FOREIGN KEY (triggered_by_user_id) REFERENCES users(id) ON DELETE SET NULL DEFERRABLE;\n\nCOMMENT ON COLUMN permission_sync_jobs.reason IS 'Specifies why permissions sync job was triggered.';\nCOMMENT ON COLUMN permission_sync_jobs.triggered_by_user_id IS 'Specifies an ID of a user who triggered a sync.';",
				"DownQuery": "ALTER TABLE permission_sync_jobs\n    DROP COLUMN IF EXISTS reason,\n    DROP COLUMN IF EXISTS triggered_by_user_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1669297489,
					1673405886
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1673897709,
				"Name": "add_cascade_batch_spec_resolution_jobs",
				"UpQuery": "ALTER TABLE \n    batch_spec_resolution_jobs\nDROP \n    CONSTRAINT IF EXISTS batch_spec_resolution_jobs_initiator_id_fkey;\n\nALTER TABLE \n    batch_spec_resolution_jobs\nADD \n    CONSTRAINT batch_spec_resolution_jobs_initiator_id_fkey \n        FOREIGN KEY (initiator_id) \n        REFERENCES users(id) \n        ON DELETE CASCADE\n        ON UPDATE CASCADE \n        DEFERRABLE;",
				"DownQuery": "ALTER TABLE \n    batch_spec_resolution_jobs\nDROP \n    CONSTRAINT IF EXISTS batch_spec_resolution_jobs_initiator_id_fkey;\n\nALTER TABLE \n    batch_spec_resolution_jobs\nADD \n    CONSTRAINT batch_spec_resolution_jobs_initiator_id_fkey \n        FOREIGN KEY (initiator_id) \n        REFERENCES users(id) \n        ON UPDATE CASCADE DEFERRABLE;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1673351808,
					1673871310
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1674035302,
				"Name": "remove webhook_build_jobs table",
				"UpQuery": "DROP INDEX IF EXISTS webhook_build_jobs_queued_at_idx;\nDROP INDEX IF EXISTS webhook_build_jobs_state;\nDROP TABLE IF EXISTS webhook_build_jobs;\nDROP SEQUENCE IF EXISTS webhook_build_jobs_id_seq;",
				"DownQuery": "CREATE SEQUENCE IF NOT EXISTS webhook_build_jobs_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nCREATE TABLE IF NOT EXISTS webhook_build_jobs (\n    repo_id integer,\n    repo_name text,\n    extsvc_kind text,\n    queued_at timestamp with time zone DEFAULT now(),\n    id integer DEFAULT nextval('webhook_build_jobs_id_seq'::regclass) NOT NULL,\n    state text DEFAULT 'queued'::text NOT NULL,\n    failure_message text,\n    started_at timestamp with time zone,\n    finished_at timestamp with time zone,\n    process_after timestamp with time zone,\n    num_resets integer DEFAULT 0 NOT NULL,\n    num_failures integer DEFAULT 0 NOT NULL,\n    execution_logs json[],\n    last_heartbeat_at timestamp with time zone,\n    worker_hostname text DEFAULT ''::text NOT NULL,\n    org text,\n    extsvc_id integer,\n    cancel boolean DEFAULT false NOT NULL\n);\n\nCREATE INDEX IF NOT EXISTS webhook_build_jobs_queued_at_idx ON webhook_build_jobs USING btree (queued_at);\nCREATE INDEX IF NOT EXISTS webhook_build_jobs_state ON webhook_build_jobs USING btree (state);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1671159453,
					1673897709
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1674041632,
				"Name": "add constraints to permission_sync_jobs table",
				"UpQuery": "-- We are changing the schema and we don't expect any rows yet so we can just drop\n-- the old table.\nDROP TABLE IF EXISTS permission_sync_jobs;\n\nCREATE TABLE permission_sync_jobs\n(\n    id                   SERIAL PRIMARY KEY,\n    state                TEXT                     DEFAULT 'queued',\n    reason               TEXT    NOT NULL,\n    failure_message      TEXT,\n    queued_at            TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n    started_at           TIMESTAMP WITH TIME ZONE,\n    finished_at          TIMESTAMP WITH TIME ZONE,\n    process_after        TIMESTAMP WITH TIME ZONE,\n    num_resets           INTEGER NOT NULL         DEFAULT 0,\n    num_failures         INTEGER NOT NULL         DEFAULT 0,\n    last_heartbeat_at    TIMESTAMP WITH TIME ZONE,\n    execution_logs       JSON[],\n    worker_hostname      TEXT    NOT NULL         DEFAULT '',\n    cancel               BOOLEAN NOT NULL         DEFAULT FALSE,\n\n    repository_id        INTEGER,\n    user_id              INTEGER,\n    triggered_by_user_id INTEGER REFERENCES users (id) ON DELETE SET NULL DEFERRABLE,\n\n    high_priority        BOOLEAN NOT NULL         DEFAULT FALSE,\n    invalidate_caches    BOOLEAN NOT NULL         DEFAULT FALSE,\n    CONSTRAINT permission_sync_jobs_for_repo_or_user CHECK (((user_id IS NULL) \u003c\u003e (repository_id IS NULL)))\n);\n\nCREATE INDEX IF NOT EXISTS permission_sync_jobs_state ON permission_sync_jobs (state);\nCREATE INDEX IF NOT EXISTS permission_sync_jobs_process_after ON permission_sync_jobs (process_after);\nCREATE INDEX IF NOT EXISTS permission_sync_jobs_repository_id ON permission_sync_jobs (repository_id);\nCREATE INDEX IF NOT EXISTS permission_sync_jobs_user_id ON permission_sync_jobs (user_id);\n\n-- this index is used as a last resort if deduplication logic fails to work.\n-- we should not enqueue more that one high priority immediate sync job (process_after IS NULL) for given repo/user.\nCREATE UNIQUE INDEX IF NOT EXISTS permission_sync_jobs_unique ON permission_sync_jobs\n    USING btree (high_priority, user_id, repository_id, cancel, process_after)\n    WHERE (state = 'queued');\n\nCOMMENT ON COLUMN permission_sync_jobs.reason IS 'Specifies why permissions sync job was triggered.';\nCOMMENT ON COLUMN permission_sync_jobs.triggered_by_user_id IS 'Specifies an ID of a user who triggered a sync.';",
				"DownQuery": "-- We are changing the schema and we don't expect any rows yet so we can just drop\n-- the old table.\nDROP TABLE IF EXISTS permission_sync_jobs;\n\nCREATE TABLE IF NOT EXISTS permission_sync_jobs\n(\n    id                SERIAL PRIMARY KEY,\n    state             text                     DEFAULT 'queued',\n    failure_message   text,\n    queued_at         timestamp with time zone DEFAULT NOW(),\n    started_at        timestamp with time zone,\n    finished_at       timestamp with time zone,\n    process_after     timestamp with time zone,\n    num_resets        integer not null         default 0,\n    num_failures      integer not null         default 0,\n    last_heartbeat_at timestamp with time zone,\n    execution_logs    json[],\n    worker_hostname   text    not null         default '',\n    cancel            boolean not null         default false,\n\n    repository_id     integer,\n    user_id           integer,\n\n    high_priority     boolean not null         default false,\n    invalidate_caches boolean not null         default false\n);\n\nCREATE INDEX IF NOT EXISTS permission_sync_jobs_state ON permission_sync_jobs (state);\nCREATE INDEX IF NOT EXISTS permission_sync_jobs_process_after ON permission_sync_jobs (process_after);\nCREATE INDEX IF NOT EXISTS permission_sync_jobs_repository_id ON permission_sync_jobs (repository_id);\nCREATE INDEX IF NOT EXISTS permission_sync_jobs_user_id ON permission_sync_jobs (user_id);\n\nALTER TABLE permission_sync_jobs\n    ADD COLUMN IF NOT EXISTS reason               TEXT,\n    ADD COLUMN IF NOT EXISTS triggered_by_user_id INTEGER,\n    ADD FOREIGN KEY (triggered_by_user_id) REFERENCES users (id) ON DELETE SET NULL DEFERRABLE;\n\nCOMMENT ON COLUMN permission_sync_jobs.reason IS 'Specifies why permissions sync job was triggered.';\nCOMMENT ON COLUMN permission_sync_jobs.triggered_by_user_id IS 'Specifies an ID of a user who triggered a sync.';",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1671159453,
					1673897709
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1674047296,
				"Name": "rename_roles_readonly_column_to_system",
				"UpQuery": "-- ALTER TABLE IF EXISTS\n--     roles\n-- RENAME COLUMN readonly TO system;\n\n-- The above query isn't idempotent because `RENAME COLUMN` doesn't have an `IF EXISTS`\n-- clause that checks for the existence of the column in question.\n\nDO $$\nBEGIN\n    ALTER TABLE IF EXISTS\n        roles\n    RENAME COLUMN readonly TO system;\nEXCEPTION\n    WHEN undefined_column THEN RAISE NOTICE 'column readonly does not exist in table roles';\nEND $$;",
				"DownQuery": "-- ALTER TABLE IF EXISTS\n--     roles\n-- RENAME COLUMN system TO readonly;\n\n-- The above query isn't idempotent because `RENAME COLUMN` doesn't have an `IF EXISTS`\n-- clause that checks for the existence of the column in question.\n\nDO $$\nBEGIN\n    ALTER TABLE IF EXISTS\n        roles\n    RENAME COLUMN system TO readonly;\nEXCEPTION\n    WHEN undefined_column THEN RAISE NOTICE 'column system does not exist in table roles';\nEND $$;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1671543381,
					1673897709
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1674455760,
				"Name": "add cancellation_reason to permission_sync_jobs table",
				"UpQuery": "ALTER TABLE permission_sync_jobs ADD COLUMN IF NOT EXISTS cancellation_reason TEXT;\n\nCOMMENT ON COLUMN permission_sync_jobs.cancellation_reason IS 'Specifies why permissions sync job was cancelled.';",
				"DownQuery": "ALTER TABLE permission_sync_jobs\n    DROP COLUMN IF EXISTS reason,\n    DROP COLUMN IF EXISTS triggered_by_user_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1674041632,
					1674047296
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1674480050,
				"Name": "add column redacted_contents to critical_and_site_config",
				"UpQuery": "ALTER TABLE critical_and_site_config\n      ADD COLUMN IF NOT EXISTS redacted_contents text;\nCOMMENT ON COLUMN critical_and_site_config.redacted_contents IS 'This column stores the contents but redacts all secrets. The redacted form is a sha256 hash of the secret appended to the REDACTED string. This is used to generate diffs between two subsequent changes in a way that allows us to detect changes to any secrets while also ensuring that we do not leak it in the diff. A null value indicates that this config was added before this column was added or redacting the secrets during write failed so we skipped writing to this column instead of a hard failure.';",
				"DownQuery": "ALTER TABLE critical_and_site_config\n      DROP COLUMN IF EXISTS redacted_contents;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1674035302,
					1674455760
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1674669326,
				"Name": "package_repos_separate_versions_table",
				"UpQuery": "-- This will be a two-step migration:\n-- 1. Create the new table and make versions column in old table nullable\n-- This is so that during a migration, an instance on vX-1 can still read \u0026 write without incorrect data.\n-- Then when the instance is on vX, it will read \u0026 write to the new+old tables but not the version\n-- column from the old table.\n-- 2. Drop version column in old table and flatten remaining duplicates\n-- The instance on vX is not using this column, and the read queries should be designed to\n-- handle both flattened and non-flattened\n\nCREATE TABLE IF NOT EXISTS package_repo_versions (\n    id BIGSERIAL PRIMARY KEY,\n    package_id BIGINT NOT NULL,\n    version TEXT NOT NULL,\n\n    CONSTRAINT package_id_fk FOREIGN KEY (package_id) REFERENCES lsif_dependency_repos (id) ON DELETE CASCADE\n);\n\nCREATE INDEX IF NOT EXISTS package_repo_versions_fk_idx ON package_repo_versions (package_id);\nCREATE UNIQUE INDEX IF NOT EXISTS package_repo_versions_unique_version_per_package ON package_repo_versions (package_id, version);\n\nCREATE INDEX IF NOT EXISTS lsif_dependency_repos_name_idx ON lsif_dependency_repos (name);\n\n-- if any rows were inserted into lsif_dependency_repos an instance on a version older than this\n-- schema after the migration happened but before the instance was ugpraded, then we need this trigger\n-- to copy over anything added _after_ the migration but before the _instance upgrade_\nCREATE OR REPLACE FUNCTION func_lsif_dependency_repos_backfill() RETURNS TRIGGER AS $$\n    BEGIN\n        INSERT INTO package_repo_versions (package_id, version)\n        VALUES (NEW.id, NEW.version);\n\n        RETURN NULL;\n    END;\n$$ LANGUAGE plpgsql;\n\nDROP TRIGGER IF EXISTS lsif_dependency_repos_backfill ON lsif_dependency_repos;\nCREATE TRIGGER lsif_dependency_repos_backfill AFTER INSERT ON lsif_dependency_repos\nFOR EACH ROW\nWHEN (NEW.version \u003c\u003e '👁️temporary_sentinel_value👁️')\nEXECUTE FUNCTION func_lsif_dependency_repos_backfill();\n\n-- for every existing triplet, we use the lowest ID for a given (scheme,name) tuple\n-- and insert the (version) using that ID into package_repo_versions\nINSERT INTO package_repo_versions (package_id, version)\nSELECT (\n    SELECT MIN(id)\n    FROM lsif_dependency_repos\n    WHERE\n        scheme = lr.scheme AND\n        name = lr.name\n) AS package_id, version\nFROM lsif_dependency_repos lr;",
				"DownQuery": "DO $$\nBEGIN\n    IF EXISTS (\n        SELECT 1 FROM information_schema.tables\n        WHERE\n            table_name = 'package_repo_versions' AND\n            table_schema = current_schema()\n    ) THEN\n        WITH matched_triplets AS (\n            SELECT lr.scheme, lr.name, rpv.version\n            FROM package_repo_versions rpv\n            JOIN lsif_dependency_repos lr\n            ON rpv.package_id = lr.id\n        )\n        INSERT INTO lsif_dependency_repos (scheme, name, version)\n        SELECT * FROM matched_triplets\n        ON CONFLICT DO NOTHING;\n    END IF;\nEND\n$$;\n\nDELETE FROM lsif_dependency_repos\nWHERE version = '👁️temporary_sentinel_value👁️';\n\nDROP INDEX IF EXISTS package_repo_versions_fk_idx;\nDROP INDEX IF EXISTS package_repo_versions_unique_version_per_package;\n\nDROP INDEX IF EXISTS lsif_dependency_repos_name_idx;\n\nDROP TABLE IF EXISTS package_repo_versions;\n\nDROP TRIGGER IF EXISTS lsif_dependency_repos_backfill ON lsif_dependency_repos;\nDROP FUNCTION IF EXISTS func_lsif_dependency_repos_backfill;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1674480050
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1674642349,
				"Name": "add_priority_to_permission_sync_jobs",
				"UpQuery": "ALTER TABLE permission_sync_jobs ADD COLUMN IF NOT EXISTS priority INTEGER NOT NULL DEFAULT 0;\nCOMMENT ON COLUMN permission_sync_jobs.priority IS 'Specifies numeric priority for the permissions sync job.';\n\nALTER TABLE permission_sync_jobs DROP COLUMN IF EXISTS high_priority;\n\n-- this index is used as a last resort if deduplication logic fails to work.\n-- we should not enqueue more that one high priority immediate sync job (process_after IS NULL) for given repo/user.\nCREATE UNIQUE INDEX IF NOT EXISTS permission_sync_jobs_unique ON permission_sync_jobs\n    USING btree (priority, user_id, repository_id, cancel, process_after)\n    WHERE (state = 'queued');",
				"DownQuery": "ALTER TABLE permission_sync_jobs ADD COLUMN IF NOT EXISTS high_priority BOOLEAN NOT NULL DEFAULT FALSE;\nCOMMENT ON COLUMN permission_sync_jobs.high_priority IS 'Specifies if the permissions sync job is high priority.';\n\nALTER TABLE permission_sync_jobs DROP COLUMN IF EXISTS priority;\n\n-- this index is used as a last resort if deduplication logic fails to work.\n-- we should not enqueue more that one high priority immediate sync job (process_after IS NULL) for given repo/user.\nCREATE UNIQUE INDEX IF NOT EXISTS permission_sync_jobs_unique ON permission_sync_jobs\n    USING btree (high_priority, user_id, repository_id, cancel, process_after)\n    WHERE (state = 'queued');",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1674035302,
					1674455760
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1674669794,
				"Name": "add_foreign_keys_to_permission_sync_jobs",
				"UpQuery": "-- We are changing the schema and we don't expect any rows yet so we can just drop\n-- the old table.\nDROP TABLE IF EXISTS permission_sync_jobs;\n\nCREATE TABLE permission_sync_jobs\n(\n    id                   SERIAL PRIMARY KEY,\n    state                TEXT                     DEFAULT 'queued',\n    reason               TEXT    NOT NULL,\n    failure_message      TEXT,\n    queued_at            TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n    started_at           TIMESTAMP WITH TIME ZONE,\n    finished_at          TIMESTAMP WITH TIME ZONE,\n    process_after        TIMESTAMP WITH TIME ZONE,\n    num_resets           INTEGER NOT NULL         DEFAULT 0,\n    num_failures         INTEGER NOT NULL         DEFAULT 0,\n    last_heartbeat_at    TIMESTAMP WITH TIME ZONE,\n    execution_logs       JSON[],\n    worker_hostname      TEXT    NOT NULL         DEFAULT '',\n    cancel               BOOLEAN NOT NULL         DEFAULT FALSE,\n\n    repository_id        INTEGER REFERENCES repo (id) ON DELETE CASCADE,\n    user_id              INTEGER REFERENCES users (id) ON DELETE CASCADE,\n    triggered_by_user_id INTEGER REFERENCES users (id) ON DELETE SET NULL DEFERRABLE,\n\n    priority             INTEGER NOT NULL         DEFAULT 0,\n    invalidate_caches    BOOLEAN NOT NULL         DEFAULT FALSE,\n    cancellation_reason  TEXT,\n    CONSTRAINT permission_sync_jobs_for_repo_or_user CHECK (((user_id IS NULL) \u003c\u003e (repository_id IS NULL)))\n);\n\nCREATE INDEX IF NOT EXISTS permission_sync_jobs_state ON permission_sync_jobs (state);\nCREATE INDEX IF NOT EXISTS permission_sync_jobs_process_after ON permission_sync_jobs (process_after);\nCREATE INDEX IF NOT EXISTS permission_sync_jobs_repository_id ON permission_sync_jobs (repository_id);\nCREATE INDEX IF NOT EXISTS permission_sync_jobs_user_id ON permission_sync_jobs (user_id);\n\n-- this index is used as a last resort if deduplication logic fails to work.\n-- we should not enqueue more that one high priority immediate sync job (process_after IS NULL) for given repo/user.\nCREATE UNIQUE INDEX IF NOT EXISTS permission_sync_jobs_unique ON permission_sync_jobs\n    USING btree (priority, user_id, repository_id, cancel, process_after)\n    WHERE (state = 'queued');\n\nCOMMENT ON COLUMN permission_sync_jobs.reason IS 'Specifies why permissions sync job was triggered.';\nCOMMENT ON COLUMN permission_sync_jobs.triggered_by_user_id IS 'Specifies an ID of a user who triggered a sync.';\nCOMMENT ON COLUMN permission_sync_jobs.cancellation_reason IS 'Specifies why permissions sync job was cancelled.';\nCOMMENT ON COLUMN permission_sync_jobs.priority IS 'Specifies numeric priority for the permissions sync job.';",
				"DownQuery": "-- We are changing the schema and we don't expect any rows yet so we can just drop\n-- the old table.\nDROP TABLE IF EXISTS permission_sync_jobs;\n\nCREATE TABLE permission_sync_jobs\n(\n    id                   SERIAL PRIMARY KEY,\n    state                TEXT                     DEFAULT 'queued',\n    reason               TEXT    NOT NULL,\n    failure_message      TEXT,\n    queued_at            TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n    started_at           TIMESTAMP WITH TIME ZONE,\n    finished_at          TIMESTAMP WITH TIME ZONE,\n    process_after        TIMESTAMP WITH TIME ZONE,\n    num_resets           INTEGER NOT NULL         DEFAULT 0,\n    num_failures         INTEGER NOT NULL         DEFAULT 0,\n    last_heartbeat_at    TIMESTAMP WITH TIME ZONE,\n    execution_logs       JSON[],\n    worker_hostname      TEXT    NOT NULL         DEFAULT '',\n    cancel               BOOLEAN NOT NULL         DEFAULT FALSE,\n\n    repository_id        INTEGER,\n    user_id              INTEGER,\n    triggered_by_user_id INTEGER REFERENCES users (id) ON DELETE SET NULL DEFERRABLE,\n\n    priority             INTEGER NOT NULL         DEFAULT 0,\n    invalidate_caches    BOOLEAN NOT NULL         DEFAULT FALSE,\n    cancellation_reason  TEXT,\n    CONSTRAINT permission_sync_jobs_for_repo_or_user CHECK (((user_id IS NULL) \u003c\u003e (repository_id IS NULL)))\n);\n\nCREATE INDEX IF NOT EXISTS permission_sync_jobs_state ON permission_sync_jobs (state);\nCREATE INDEX IF NOT EXISTS permission_sync_jobs_process_after ON permission_sync_jobs (process_after);\nCREATE INDEX IF NOT EXISTS permission_sync_jobs_repository_id ON permission_sync_jobs (repository_id);\nCREATE INDEX IF NOT EXISTS permission_sync_jobs_user_id ON permission_sync_jobs (user_id);\n\n-- this index is used as a last resort if deduplication logic fails to work.\n-- we should not enqueue more that one high priority immediate sync job (process_after IS NULL) for given repo/user.\nCREATE UNIQUE INDEX IF NOT EXISTS permission_sync_jobs_unique ON permission_sync_jobs\n    USING btree (priority, user_id, repository_id, cancel, process_after)\n    WHERE (state = 'queued');\n\nCOMMENT ON COLUMN permission_sync_jobs.reason IS 'Specifies why permissions sync job was triggered.';\nCOMMENT ON COLUMN permission_sync_jobs.triggered_by_user_id IS 'Specifies an ID of a user who triggered a sync.';\nCOMMENT ON COLUMN permission_sync_jobs.cancellation_reason IS 'Specifies why permissions sync job was cancelled.';\nCOMMENT ON COLUMN permission_sync_jobs.priority IS 'Specifies numeric priority for the permissions sync job.';",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1674480050,
					1674642349
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1674814035,
				"Name": "add_user_repo_permissions_table_for_unified_permissions",
				"UpQuery": "CREATE TABLE IF NOT EXISTS user_repo_permissions(\n    id SERIAL PRIMARY KEY,\n    user_id INT NULL REFERENCES users(id) ON DELETE CASCADE,\n    repo_id INT NOT NULL REFERENCES repo(id) ON DELETE CASCADE,\n    user_external_account_id INT NULL REFERENCES user_external_accounts(id) ON DELETE CASCADE,\n    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),\n    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),\n    source TEXT NOT NULL DEFAULT 'sync'\n);\n\nCREATE INDEX IF NOT EXISTS user_repo_permissions_user_id_idx ON user_repo_permissions(user_id);\nCREATE INDEX IF NOT EXISTS user_repo_permissions_repo_id_idx ON user_repo_permissions(repo_id);\nCREATE INDEX IF NOT EXISTS user_repo_permissions_user_external_account_id_idx ON user_repo_permissions(user_external_account_id);\nCREATE INDEX IF NOT EXISTS user_repo_permissions_updated_at_idx ON user_repo_permissions(updated_at);\nCREATE INDEX IF NOT EXISTS user_repo_permissions_source_idx ON user_repo_permissions(source);\nCREATE UNIQUE INDEX IF NOT EXISTS user_repo_permissions_perms_unique_idx ON user_repo_permissions(user_id, user_external_account_id, repo_id);",
				"DownQuery": "DROP TABLE IF EXISTS user_repo_permissions;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1674669794
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1674952295,
				"Name": "make_user_id_namespace_permissions_non_nullable",
				"UpQuery": "ALTER TABLE namespace_permissions ALTER COLUMN user_id SET NOT NULL;",
				"DownQuery": "ALTER TABLE namespace_permissions ALTER COLUMN user_id DROP NOT NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1674669794
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1675155867,
				"Name": "add no_perms column to permission_sync_jobs table",
				"UpQuery": "-- We are changing the schema and we don't expect any rows yet so we can just drop\n-- the old table.\nDROP TABLE IF EXISTS permission_sync_jobs;\n\nCREATE TABLE permission_sync_jobs\n(\n    id                   SERIAL PRIMARY KEY,\n    state                TEXT                     DEFAULT 'queued',\n    reason               TEXT    NOT NULL,\n    failure_message      TEXT,\n    queued_at            TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n    started_at           TIMESTAMP WITH TIME ZONE,\n    finished_at          TIMESTAMP WITH TIME ZONE,\n    process_after        TIMESTAMP WITH TIME ZONE,\n    num_resets           INTEGER NOT NULL         DEFAULT 0,\n    num_failures         INTEGER NOT NULL         DEFAULT 0,\n    last_heartbeat_at    TIMESTAMP WITH TIME ZONE,\n    execution_logs       JSON[],\n    worker_hostname      TEXT    NOT NULL         DEFAULT '',\n    cancel               BOOLEAN NOT NULL         DEFAULT FALSE,\n\n    repository_id        INTEGER REFERENCES repo (id) ON DELETE CASCADE,\n    user_id              INTEGER REFERENCES users (id) ON DELETE CASCADE,\n    triggered_by_user_id INTEGER REFERENCES users (id) ON DELETE SET NULL DEFERRABLE,\n\n    priority             INTEGER NOT NULL         DEFAULT 0,\n    invalidate_caches    BOOLEAN NOT NULL         DEFAULT FALSE,\n    cancellation_reason  TEXT,\n    no_perms             BOOLEAN NOT NULL         DEFAULT FALSE\n    CONSTRAINT permission_sync_jobs_for_repo_or_user CHECK (((user_id IS NULL) \u003c\u003e (repository_id IS NULL)))\n);\n\nCREATE INDEX IF NOT EXISTS permission_sync_jobs_state ON permission_sync_jobs (state);\nCREATE INDEX IF NOT EXISTS permission_sync_jobs_process_after ON permission_sync_jobs (process_after);\nCREATE INDEX IF NOT EXISTS permission_sync_jobs_repository_id ON permission_sync_jobs (repository_id);\nCREATE INDEX IF NOT EXISTS permission_sync_jobs_user_id ON permission_sync_jobs (user_id);\n\n-- this index is used as a last resort if deduplication logic fails to work.\n-- we should not enqueue more that one high priority immediate sync job (process_after IS NULL) for given repo/user.\nCREATE UNIQUE INDEX IF NOT EXISTS permission_sync_jobs_unique ON permission_sync_jobs\n    USING btree (priority, user_id, repository_id, cancel, process_after)\n    WHERE (state = 'queued');\n\nCOMMENT ON COLUMN permission_sync_jobs.reason IS 'Specifies why permissions sync job was triggered.';\nCOMMENT ON COLUMN permission_sync_jobs.triggered_by_user_id IS 'Specifies an ID of a user who triggered a sync.';\nCOMMENT ON COLUMN permission_sync_jobs.cancellation_reason IS 'Specifies why permissions sync job was cancelled.';\nCOMMENT ON COLUMN permission_sync_jobs.priority IS 'Specifies numeric priority for the permissions sync job.';",
				"DownQuery": "-- We are changing the schema and we don't expect any rows yet so we can just drop\n-- the old table.\n-- We are changing the schema and we don't expect any rows yet so we can just drop\n-- the old table.\nDROP TABLE IF EXISTS permission_sync_jobs;\n\nCREATE TABLE permission_sync_jobs\n(\n    id                   SERIAL PRIMARY KEY,\n    state                TEXT                     DEFAULT 'queued',\n    reason               TEXT    NOT NULL,\n    failure_message      TEXT,\n    queued_at            TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n    started_at           TIMESTAMP WITH TIME ZONE,\n    finished_at          TIMESTAMP WITH TIME ZONE,\n    process_after        TIMESTAMP WITH TIME ZONE,\n    num_resets           INTEGER NOT NULL         DEFAULT 0,\n    num_failures         INTEGER NOT NULL         DEFAULT 0,\n    last_heartbeat_at    TIMESTAMP WITH TIME ZONE,\n    execution_logs       JSON[],\n    worker_hostname      TEXT    NOT NULL         DEFAULT '',\n    cancel               BOOLEAN NOT NULL         DEFAULT FALSE,\n\n    repository_id        INTEGER REFERENCES repo (id) ON DELETE CASCADE,\n    user_id              INTEGER REFERENCES users (id) ON DELETE CASCADE,\n    triggered_by_user_id INTEGER REFERENCES users (id) ON DELETE SET NULL DEFERRABLE,\n\n    priority             INTEGER NOT NULL         DEFAULT 0,\n    invalidate_caches    BOOLEAN NOT NULL         DEFAULT FALSE,\n    cancellation_reason  TEXT,\n    CONSTRAINT permission_sync_jobs_for_repo_or_user CHECK (((user_id IS NULL) \u003c\u003e (repository_id IS NULL)))\n);\n\nCREATE INDEX IF NOT EXISTS permission_sync_jobs_state ON permission_sync_jobs (state);\nCREATE INDEX IF NOT EXISTS permission_sync_jobs_process_after ON permission_sync_jobs (process_after);\nCREATE INDEX IF NOT EXISTS permission_sync_jobs_repository_id ON permission_sync_jobs (repository_id);\nCREATE INDEX IF NOT EXISTS permission_sync_jobs_user_id ON permission_sync_jobs (user_id);\n\n-- this index is used as a last resort if deduplication logic fails to work.\n-- we should not enqueue more that one high priority immediate sync job (process_after IS NULL) for given repo/user.\nCREATE UNIQUE INDEX IF NOT EXISTS permission_sync_jobs_unique ON permission_sync_jobs\n    USING btree (priority, user_id, repository_id, cancel, process_after)\n    WHERE (state = 'queued');\n\nCOMMENT ON COLUMN permission_sync_jobs.reason IS 'Specifies why permissions sync job was triggered.';\nCOMMENT ON COLUMN permission_sync_jobs.triggered_by_user_id IS 'Specifies an ID of a user who triggered a sync.';\nCOMMENT ON COLUMN permission_sync_jobs.cancellation_reason IS 'Specifies why permissions sync job was cancelled.';\nCOMMENT ON COLUMN permission_sync_jobs.priority IS 'Specifies numeric priority for the permissions sync job.';",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1671463799,
					1674952295
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1675257827,
				"Name": "redis_key_value",
				"UpQuery": "-- Perform migration here.\n\nCREATE TABLE IF NOT EXISTS redis_key_value (\n    namespace TEXT NOT NULL,\n    key TEXT NOT NULL,\n    value BYTEA NOT NULL,\n    PRIMARY KEY (namespace, key) INCLUDE (value)\n);",
				"DownQuery": "-- Undo the changes made in the up migration\n\nDROP TABLE IF EXISTS redis_key_value;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1675155867
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1675194688,
				"Name": "Fix should_reindex in views",
				"UpQuery": "DROP VIEW IF EXISTS lsif_uploads_with_repository_name;\nCREATE VIEW lsif_uploads_with_repository_name AS \nSELECT\n    u.id,\n    u.commit,\n    u.root,\n    u.queued_at,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.indexer_version,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.content_type,\n    u.should_reindex,\n    u.expired,\n    u.last_retention_scan_at,\n    r.name AS repository_name,\n    u.uncompressed_size\nFROM lsif_uploads u\nJOIN repo r ON r.id = u.repository_id\nWHERE r.deleted_at IS NULL;",
				"DownQuery": "DROP VIEW IF EXISTS lsif_uploads_with_repository_name;\nCREATE VIEW lsif_uploads_with_repository_name AS \nSELECT\n    u.id,\n    u.commit,\n    u.root,\n    u.queued_at,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.indexer_version,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.content_type,\n    u.expired,\n    u.last_retention_scan_at,\n    r.name AS repository_name,\n    u.uncompressed_size\nFROM lsif_uploads u\nJOIN repo r ON r.id = u.repository_id\nWHERE r.deleted_at IS NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1671463799,
					1674669794
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1675277218,
				"Name": "Add lsif_uploads_uploaded_at_id",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS lsif_uploads_uploaded_at_id ON lsif_uploads(uploaded_at desc, id) WHERE state != 'deleted';",
				"DownQuery": "DROP INDEX IF EXISTS lsif_uploads_uploaded_at_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1675155867,
					1675194688
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "lsif_uploads",
					"IndexName": "lsif_uploads_uploaded_at_id"
				}
			},
			{
				"ID": 1675277500,
				"Name": "Drop lsif_uploads_uploaded_at",
				"UpQuery": "DROP INDEX IF EXISTS lsif_uploads_uploaded_at;",
				"DownQuery": "CREATE INDEX IF NOt EXISTS lsif_uploads_uploaded_at ON lsif_uploads(uploaded_at);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1675277218
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1675277968,
				"Name": "Drop lsif_indexes_queued_at",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS lsif_indexes_queued_at_id ON lsif_indexes(queued_at DESC, id);",
				"DownQuery": "DROP INDEX IF EXISTS lsif_indexes_queued_at_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1675277500
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "lsif_indexes",
					"IndexName": "lsif_indexes_queued_at_id"
				}
			},
			{
				"ID": 1675296942,
				"Name": "add column to changesets for external fork name",
				"UpQuery": "-- Note that we have to regenerate the reconciler_changesets view, as the SELECT\n-- statement in the view definition isn't refreshed when the fields change within the\n-- changesets table.\nDROP VIEW IF EXISTS\n    reconciler_changesets;\n\nALTER TABLE\n  changesets\nADD COLUMN IF NOT EXISTS\n  external_fork_name CITEXT NULL;\n\nCREATE VIEW reconciler_changesets AS\nSELECT c.id,\n    c.batch_change_ids,\n    c.repo_id,\n    c.queued_at,\n    c.created_at,\n    c.updated_at,\n    c.metadata,\n    c.external_id,\n    c.external_service_type,\n    c.external_deleted_at,\n    c.external_branch,\n    c.external_updated_at,\n    c.external_state,\n    c.external_review_state,\n    c.external_check_state,\n    c.diff_stat_added,\n    c.diff_stat_deleted,\n    c.sync_state,\n    c.current_spec_id,\n    c.previous_spec_id,\n    c.publication_state,\n    c.owned_by_batch_change_id,\n    c.reconciler_state,\n    c.computed_state,\n    c.failure_message,\n    c.started_at,\n    c.finished_at,\n    c.process_after,\n    c.num_resets,\n    c.closing,\n    c.num_failures,\n    c.log_contents,\n    c.execution_logs,\n    c.syncer_error,\n    c.external_title,\n    c.worker_hostname,\n    c.ui_publication_state,\n    c.last_heartbeat_at,\n    c.external_fork_name,\n    c.external_fork_namespace,\n    c.detached_at\nFROM changesets c\nJOIN repo r ON r.id = c.repo_id\nWHERE r.deleted_at IS NULL AND EXISTS (\n    SELECT 1\n    FROM batch_changes\n        LEFT JOIN users namespace_user ON batch_changes.namespace_user_id = namespace_user.id\n        LEFT JOIN orgs namespace_org ON batch_changes.namespace_org_id = namespace_org.id\n    WHERE c.batch_change_ids ? batch_changes.id::text AND namespace_user.deleted_at IS NULL AND namespace_org.deleted_at IS NULL\n    );",
				"DownQuery": "-- Note that we have to regenerate the reconciler_changesets view, as the SELECT\n-- statement in the view definition isn't refreshed when the fields change within the\n-- changesets table.\nDROP VIEW IF EXISTS\n    reconciler_changesets;\n\nALTER TABLE\n  changesets\nDROP COLUMN IF EXISTS\n  external_fork_name;\n\nCREATE VIEW reconciler_changesets AS\nSELECT c.id,\n    c.batch_change_ids,\n    c.repo_id,\n    c.queued_at,\n    c.created_at,\n    c.updated_at,\n    c.metadata,\n    c.external_id,\n    c.external_service_type,\n    c.external_deleted_at,\n    c.external_branch,\n    c.external_updated_at,\n    c.external_state,\n    c.external_review_state,\n    c.external_check_state,\n    c.diff_stat_added,\n    c.diff_stat_deleted,\n    c.sync_state,\n    c.current_spec_id,\n    c.previous_spec_id,\n    c.publication_state,\n    c.owned_by_batch_change_id,\n    c.reconciler_state,\n    c.computed_state,\n    c.failure_message,\n    c.started_at,\n    c.finished_at,\n    c.process_after,\n    c.num_resets,\n    c.closing,\n    c.num_failures,\n    c.log_contents,\n    c.execution_logs,\n    c.syncer_error,\n    c.external_title,\n    c.worker_hostname,\n    c.ui_publication_state,\n    c.last_heartbeat_at,\n    c.external_fork_namespace,\n    c.detached_at\nFROM changesets c\nJOIN repo r ON r.id = c.repo_id\nWHERE r.deleted_at IS NULL AND EXISTS (\n    SELECT 1\n    FROM batch_changes\n        LEFT JOIN users namespace_user ON batch_changes.namespace_user_id = namespace_user.id\n        LEFT JOIN orgs namespace_org ON batch_changes.namespace_org_id = namespace_org.id\n    WHERE c.batch_change_ids ? batch_changes.id::text AND namespace_user.deleted_at IS NULL AND namespace_org.deleted_at IS NULL\n    );",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1675277968
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1675367314,
				"Name": "add_results_to_permission_sync_jobs",
				"UpQuery": "ALTER TABLE permission_sync_jobs ADD COLUMN IF NOT EXISTS permissions_added integer NOT NULL DEFAULT 0;\nALTER TABLE permission_sync_jobs ADD COLUMN IF NOT EXISTS permissions_removed integer NOT NULL DEFAULT 0;\nALTER TABLE permission_sync_jobs ADD COLUMN IF NOT EXISTS permissions_found integer NOT NULL DEFAULT 0;",
				"DownQuery": "ALTER TABLE permission_sync_jobs DROP COLUMN IF EXISTS permissions_added;\nALTER TABLE permission_sync_jobs DROP COLUMN IF EXISTS permissions_removed;\nALTER TABLE permission_sync_jobs DROP COLUMN IF EXISTS permissions_found;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1675277968
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1675647612,
				"Name": "remove_roles_deleted_at",
				"UpQuery": "ALTER TABLE roles DROP COLUMN IF EXISTS deleted_at;",
				"DownQuery": "ALTER TABLE roles\nADD COLUMN IF NOT EXISTS deleted_at TIMESTAMP WITH TIME ZONE;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1674669326,
					1674814035,
					1675257827,
					1675367314
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1675962678,
				"Name": "remove_action_namespace_perms",
				"UpQuery": "ALTER TABLE namespace_permissions DROP COLUMN IF EXISTS action;\n\nALTER TABLE namespace_permissions DROP CONSTRAINT IF EXISTS unique_resource_permission;\n\nCREATE UNIQUE INDEX IF NOT EXISTS unique_resource_permission ON namespace_permissions (namespace, resource_id, user_id);",
				"DownQuery": "ALTER TABLE namespace_permissions\n    ADD COLUMN IF NOT EXISTS action text NOT NULL;\n\nALTER TABLE namespace_permissions DROP CONSTRAINT IF EXISTS unique_resource_permission;\n\nCREATE UNIQUE INDEX IF NOT EXISTS unique_resource_permission ON namespace_permissions (namespace, resource_id, action, user_id);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1675647612
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1676996650,
				"Name": "package_repos_separate_versions_table_patch1",
				"UpQuery": "ALTER TABLE lsif_dependency_repos\nALTER COLUMN version SET DEFAULT '👁️temporary_sentinel_value👁️';",
				"DownQuery": "ALTER TABLE lsif_dependency_repos\nALTER COLUMN version DROP DEFAULT;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1675962678
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1675864432,
				"Name": "add code_host_states to permission_sync_jobs table",
				"UpQuery": "ALTER TABLE permission_sync_jobs ADD COLUMN IF NOT EXISTS code_host_states JSON[];",
				"DownQuery": "ALTER TABLE permission_sync_jobs DROP COLUMN IF EXISTS code_host_states;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1674669326,
					1674814035,
					1675257827,
					1675367314
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			}
		],
		"BoundsByRev": {
			"v3.20.0": {
				"RootID": -1528395684,
				"LeafIDs": [
					1528395718
				],
				"PreCreation": false
			},
			"v3.21.0": {
				"RootID": -1528395684,
				"LeafIDs": [
					1528395733
				],
				"PreCreation": false
			},
			"v3.22.0": {
				"RootID": -1528395684,
				"LeafIDs": [
					1528395747
				],
				"PreCreation": false
			},
			"v3.23.0": {
				"RootID": -1528395684,
				"LeafIDs": [
					1528395768
				],
				"PreCreation": false
			},
			"v3.24.0": {
				"RootID": -1528395684,
				"LeafIDs": [
					1528395773
				],
				"PreCreation": false
			},
			"v3.25.0": {
				"RootID": -1528395733,
				"LeafIDs": [
					1528395787
				],
				"PreCreation": false
			},
			"v3.26.0": {
				"RootID": -1528395733,
				"LeafIDs": [
					1528395800
				],
				"PreCreation": false
			},
			"v3.27.0": {
				"RootID": -1528395733,
				"LeafIDs": [
					1528395816
				],
				"PreCreation": false
			},
			"v3.28.0": {
				"RootID": -1528395733,
				"LeafIDs": [
					1528395822
				],
				"PreCreation": false
			},
			"v3.29.0": {
				"RootID": -1528395787,
				"LeafIDs": [
					1528395834
				],
				"PreCreation": false
			},
			"v3.30.0": {
				"RootID": -1528395787,
				"LeafIDs": [
					1528395853
				],
				"PreCreation": false
			},
			"v3.31.0": {
				"RootID": -1528395787,
				"LeafIDs": [
					1528395871
				],
				"PreCreation": false
			},
			"v3.32.0": {
				"RootID": -1528395787,
				"LeafIDs": [
					1528395891
				],
				"PreCreation": false
			},
			"v3.33.0": {
				"RootID": -1528395834,
				"LeafIDs": [
					1528395918
				],
				"PreCreation": false
			},
			"v3.34.0": {
				"RootID": -1528395834,
				"LeafIDs": [
					1528395944
				],
				"PreCreation": false
			},
			"v3.35.0": {
				"RootID": -1528395834,
				"LeafIDs": [
					1528395964
				],
				"PreCreation": false
			},
			"v3.36.0": {
				"RootID": -1528395834,
				"LeafIDs": [
					1528395968
				],
				"PreCreation": false
			},
			"v3.37.0": {
				"RootID": -1528395834,
				"LeafIDs": [
					1645106226
				],
				"PreCreation": false
			},
			"v3.38.0": {
				"RootID": 1528395943,
				"LeafIDs": [
					1646652951,
					1647282553
				],
				"PreCreation": false
			},
			"v3.39.0": {
				"RootID": 1528395943,
				"LeafIDs": [
					1649441222,
					1649759318,
					1649432863
				],
				"PreCreation": false
			},
			"v3.40.0": {
				"RootID": 1528395943,
				"LeafIDs": [
					1652228814,
					1652707934
				],
				"PreCreation": false
			},
			"v3.41.0": {
				"RootID": 1644868458,
				"LeafIDs": [
					1655481894
				],
				"PreCreation": false
			},
			"v3.42.0": {
				"RootID": 1646027072,
				"LeafIDs": [
					1654770608,
					1658174103,
					1658225452,
					1657663493
				],
				"PreCreation": false
			},
			"v3.43.0": {
				"RootID": 1646027072,
				"LeafIDs": [
					1660312877,
					1658874734
				],
				"PreCreation": false
			},
			"v4.0.0": {
				"RootID": 1646027072,
				"LeafIDs": [
					1660711451,
					1662467128
				],
				"PreCreation": false
			},
			"v4.1.0": {
				"RootID": 1648051770,
				"LeafIDs": [
					1665646849,
					1665770699
				],
				"PreCreation": false
			},
			"v4.2.0": {
				"RootID": 1648051770,
				"LeafIDs": [
					1668603582
				],
				"PreCreation": false
			},
			"v4.3.0": {
				"RootID": 1648051770,
				"LeafIDs": [
					1670350006,
					1670543231
				],
				"PreCreation": false
			},
			"v4.4.0": {
				"RootID": 1648051770,
				"LeafIDs": [
					1673897709
				],
				"PreCreation": false
			},
			"v4.5.0": {
				"RootID": 1648051770,
				"LeafIDs": [
					1675296942,
					1676996650,
					1675864432
				],
				"PreCreation": false
			}
		}
	}
}
