load("@io_bazel_rules_go//go:def.bzl", "go_library")
load("//dev:go_defs.bzl", "go_test")

go_library(
    name = "tokenizer",
    srcs = ["tokenizer.go"],
    importpath = "github.com/sourcegraph/sourcegraph/internal/completions/tokenizer",
    visibility = [
        "//cmd/cody-gateway:__subpackages__",
        "//internal/completions/client/anthropic:__pkg__",
        "//internal/completions/client/azureopenai:__pkg__",
        "//internal/completions/client/openai:__pkg__",
        "//internal/completions/tokenusage:__pkg__",
    ],
    deps = [
        "//internal/completions/types",
        "//lib/errors",
        "@com_github_pkoukk_tiktoken_go//:tiktoken-go",
        "@com_github_pkoukk_tiktoken_go_loader//:tiktoken-go-loader",
    ],
)

go_test(
    name = "tokenizer_test",
    srcs = ["tokenizer_test.go"],
    deps = [
        ":tokenizer",
        "@com_github_hexops_autogold_v2//:autogold",
        "@com_github_stretchr_testify//require",
    ],
)
