[role="xpack"]
[testenv="basic"]
[[inference-processor]]
=== {infer-cap} processor
++++
<titleabbrev>{infer-cap}</titleabbrev>
++++


Uses a pre-trained {dfanalytics} model to infer against the data that is being
ingested in the pipeline.


[[inference-options]]
.{infer-cap} Options
[options="header"]
|======
| Name               | Required  | Default                        | Description
| `model_id`         | yes       | -                              | (String) The ID or alias for the trained model.
| `target_field`     | no        | `ml.inference.<processor_tag>` | (String) Field added to incoming documents to contain results objects.
| `field_map`        | no        | If defined the model's default field map | (Object) Maps the document field names to the known field names of the model. This mapping takes precedence over any default mappings provided in the model configuration.
| `inference_config` | no        | The default settings defined in the model  | (Object) Contains the inference type and its options. There are two types: <<inference-processor-regression-opt,`regression`>> and <<inference-processor-classification-opt,`classification`>>.
include::common-options.asciidoc[]
|======


[source,js]
--------------------------------------------------
{
  "inference": {
    "model_id": "flight_delay_regression-1571767128603",
    "target_field": "FlightDelayMin_prediction_infer",
    "field_map": {
      "your_field": "my_field"
    },
    "inference_config": { "regression": {} }
  }
}
--------------------------------------------------
// NOTCONSOLE


[discrete]
[[inference-processor-regression-opt]]
==== {regression-cap} configuration options

Regression configuration for inference.

`results_field`::
(Optional, string)
include::{es-repo-dir}/ml/ml-shared.asciidoc[tag=inference-config-results-field-processor]

`num_top_feature_importance_values`::
(Optional, integer)
include::{es-repo-dir}/ml/ml-shared.asciidoc[tag=inference-config-regression-num-top-feature-importance-values]


[discrete]
[[inference-processor-classification-opt]]
==== {classification-cap} configuration options

Classification configuration for inference.

`num_top_classes`::
(Optional, integer)
include::{es-repo-dir}/ml/ml-shared.asciidoc[tag=inference-config-classification-num-top-classes]

`num_top_feature_importance_values`::
(Optional, integer)
include::{es-repo-dir}/ml/ml-shared.asciidoc[tag=inference-config-classification-num-top-feature-importance-values]

`results_field`::
(Optional, string)
include::{es-repo-dir}/ml/ml-shared.asciidoc[tag=inference-config-results-field-processor]

`top_classes_results_field`::
(Optional, string)
include::{es-repo-dir}/ml/ml-shared.asciidoc[tag=inference-config-classification-top-classes-results-field]

`prediction_field_type`::
(Optional, string)
include::{es-repo-dir}/ml/ml-shared.asciidoc[tag=inference-config-classification-prediction-field-type]

[discrete]
[[inference-processor-config-example]]
==== `inference_config` examples

[source,js]
--------------------------------------------------
"inference":{
  "model_id":"my_model_id"
  "inference_config": {
    "regression": {
      "results_field": "my_regression"
    }
  }
}
--------------------------------------------------
// NOTCONSOLE

This configuration specifies a `regression` inference and the results are
written to the `my_regression` field contained in the `target_field` results
object.


[source,js]
--------------------------------------------------
"inference":{
  "model_id":"my_model_id"
  "inference_config": {
    "classification": {
      "num_top_classes": 2,
      "results_field": "prediction",
      "top_classes_results_field": "probabilities"
    }
  }
}
--------------------------------------------------
// NOTCONSOLE

This configuration specifies a `classification` inference. The number of
categories for which the predicted probabilities are reported is 2
(`num_top_classes`). The result is written to the `prediction` field and the top
classes to the `probabilities` field. Both fields are contained in the
`target_field` results object.

Refer to the 
{ml-docs}/ml-lang-ident.html#ml-lang-ident-example[language identification] 
trained model documentation for a full example.


[discrete]
[[inference-processor-feature-importance]]
==== {feat-imp-cap} object mapping

To get the full benefit of aggregating and searching for
{ml-docs}/ml-feature-importance.html[{feat-imp}], update your index mapping of 
the {feat-imp} result field as you can see below:

[source,js]
--------------------------------------------------
"ml.inference.feature_importance": {
  "type": "nested",
  "dynamic": true,
  "properties": {
    "feature_name": {
      "type": "keyword"
    },
    "importance": {
      "type": "double"
    }
  }
}
--------------------------------------------------
// NOTCONSOLE

The mapping field name for {feat-imp} (in the example above, it is 
`ml.inference.feature_importance`) is compounded as follows:

`<ml.inference.target_field>`.`<inference.tag>`.`feature_importance`

* `<ml.inference.target_field>`: defaults to `ml.inference`.
* `<inference.tag>`: if is not provided in the processor definition, then it is 
not part of the field path.

For example, if you provide a tag `foo` in the definition as you can see below:

[source,js]
--------------------------------------------------
{
  "tag": "foo",
  ...
}
--------------------------------------------------
// NOTCONSOLE


Then, the {feat-imp} value is written to the 
`ml.inference.foo.feature_importance` field.

You can also specify the target field as follows:

[source,js]
--------------------------------------------------
{
  "tag": "foo",
  "target_field": "my_field"
}
--------------------------------------------------
// NOTCONSOLE

In this case, {feat-imp} is exposed in the
`my_field.foo.feature_importance` field.
